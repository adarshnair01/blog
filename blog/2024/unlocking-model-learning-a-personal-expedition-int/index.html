<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Unlocking Model Learning: A Personal Expedition into Gradient Descent | Adarsh Nair </title> <meta name="author" content="Adarsh Nair"> <meta name="description" content="A deep dive into machine learning, AI, and data science. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <meta http-equiv="Content-Security-Policy" content="default-src 'self'; script-src 'self' 'unsafe-inline' https:; style-src 'self' 'unsafe-inline' https:; img-src 'self' data: https:; font-src 'self' data: https:; media-src 'self' https:; frame-src 'self' https:; connect-src 'self' https:;"> <link rel="stylesheet" href="/blog/assets/css/bootstrap.min.css?v=a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/blog/assets/css/academicons.min.css?v=f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/blog/assets/css/scholar-icons.css?v=62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-github.css?v=591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/blog/assets/css/main.css?v=d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://adarshnair.online/blog/blog/blog/2024/unlocking-model-learning-a-personal-expedition-int/"> <script src="/blog/assets/js/theme.js?v=5fea5159b787642c1bbc1f334d60f883"></script> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-native.css?v=5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/blog/cv/"> Adarsh Nair </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/blog/"> </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/index.html">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/cv/">CV </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/repositories/">repositories </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="fa-solid fa-magnifying-glass"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-half-sun-moon" id="light-toggle-system"></i> <i class="fa-solid fa-moon" id="light-toggle-dark"></i> <i class="fa-solid fa-sun" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Unlocking Model Learning: A Personal Expedition into Gradient Descent</h1> <p class="post-meta"> Created on October 02, 2024 by Adarsh Nair </p> <p class="post-tags"> <a href="/blog/blog/2024"> <i class="fa-solid fa-calendar fa-sm"></i> 2024 </a>   ·   <a href="/blog/blog/tag/machine-learning"> <i class="fa-solid fa-hashtag fa-sm"></i> Machine Learning</a>   <a href="/blog/blog/tag/gradient-descent"> <i class="fa-solid fa-hashtag fa-sm"></i> Gradient Descent</a>   <a href="/blog/blog/tag/optimization"> <i class="fa-solid fa-hashtag fa-sm"></i> Optimization</a>   <a href="/blog/blog/tag/algorithms"> <i class="fa-solid fa-hashtag fa-sm"></i> Algorithms</a>   <a href="/blog/blog/tag/data-science"> <i class="fa-solid fa-hashtag fa-sm"></i> Data Science</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p>Hello fellow explorers of the data universe!</p> <p>Today, I want to share a concept that, for me, was a massive “aha!” moment in understanding how machine learning models actually <em>learn</em>. It’s an algorithm that underpins so much of what we do in this field, from linear regression to the deepest neural networks. I’m talking about <strong>Gradient Descent</strong>.</p> <p>If you’re anything like I was, you might have heard the term thrown around, perhaps seen some intimidating mathematical symbols, and thought, “That sounds important, but also, terrifyingly complex.” Well, I’m here to tell you it’s not. Or, rather, the <em>core idea</em> is elegantly simple, and once you grasp that, the rest falls into place. Think of this as our personal journal entry on this crucial concept.</p> <h3 id="the-big-problem-finding-the-best-fit">The Big Problem: Finding the “Best” Fit</h3> <p>Imagine you’re building a simple model. Let’s say you’re trying to predict house prices based on their size. You collect some data, plot it, and it looks something like this:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>      ^ Price
      |   .
      | .   .
      |.      .
      | .       .
      +----------------&gt; Size
</code></pre></div></div> <p>You want to draw a line that best fits these data points. This line represents your model, and its job is to make predictions. But what does “best fit” even mean? And how do we find that magical line?</p> <p>This is where the idea of <strong>optimization</strong> comes in. In machine learning, “learning” often boils down to finding the best set of parameters (like the slope and y-intercept of our line) that make our model as accurate as possible.</p> <h3 id="introducing-the-cost-function-how-wrong-are-we">Introducing the “Cost Function”: How Wrong Are We?</h3> <p>Before we can find the “best” line, we need a way to measure how <em>bad</em> any given line is. This measure of “badness” or “error” is what we call a <strong>cost function</strong> (sometimes also called a <strong>loss function</strong>).</p> <p>For our house price example, a common cost function is the <strong>Mean Squared Error (MSE)</strong>. If our model predicts a price $ \hat{y} $ for a house that actually sold for $ y $, the error for that house is $ (y - \hat{y}) $. We square this error to ensure positive values and to penalize larger errors more heavily, and then we average it over all our houses.</p> <p>Mathematically, if we have $m$ training examples, and our prediction $ \hat{y}_i $ is a function of our model parameters $ \theta $ (e.g., $ \hat{y}_i = \theta_0 + \theta_1 x_i $ for a line), the MSE cost function $ J(\theta) $ would look like this:</p> <p>$ J(\theta) = \frac{1}{2m} \sum_{i=1}^{m} (y_i - \hat{y}_i)^2 $</p> <p>(I’ve included the $ \frac{1}{2} $ term for convenience; it makes the derivative cleaner later on, but doesn’t change where the minimum is.)</p> <p>Now, imagine we have just <em>one</em> parameter, say the slope of our line. As we change the slope, the value of $ J(\theta) $ (our cost) changes. If we plot $ J(\theta) $ against that parameter, we often get a beautiful, bowl-shaped curve for simple models:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>           ^ J(theta)
           |    *
           |   * *
           |  *   *
           | *     *
           +------------&gt; theta
                  min
</code></pre></div></div> <p>Our goal is to find the value of $ \theta $ that minimizes $ J(\theta) $. We want to find the very bottom of that bowl!</p> <h3 id="the-core-idea-feeling-your-way-downhill">The Core Idea: Feeling Your Way Downhill</h3> <p>So, how do we find the bottom of the bowl? If we could see the whole landscape, we’d just walk straight to the lowest point. But in machine learning, especially with many parameters, our “landscape” can be incredibly complex – a high-dimensional space we can’t visualize directly.</p> <p>This is where my favorite analogy comes in:</p> <p><strong>Imagine you’re blindfolded on a vast, misty mountain range. You want to find the lowest point in a valley. You can’t see far ahead, but you <em>can</em> feel the slope directly beneath your feet.</strong></p> <p>What would you do? You’d take a step in the direction that feels most steeply downhill, right? Then you’d feel the slope again and take another step. You’d repeat this process, incrementally moving downwards, until you feel like you can’t go any lower.</p> <p><strong>This, my friends, is Gradient Descent in a nutshell!</strong></p> <h3 id="the-gradient-our-compass-to-downhill">The “Gradient”: Our Compass to Downhill</h3> <p>That “feeling the slope directly beneath your feet” is mathematically represented by the <strong>gradient</strong>.</p> <p>In calculus, the derivative tells us the slope of a function at a single point. For a function with multiple parameters (our $ \theta $ values), the gradient is a vector that contains the partial derivatives with respect to each parameter.</p> <p>$ \nabla J(\theta) = \left( \frac{\partial J}{\partial \theta_0}, \frac{\partial J}{\partial \theta_1}, \dots, \frac{\partial J}{\partial \theta_n} \right) $</p> <p>Crucially, the gradient points in the direction of the <em>steepest ascent</em>. But we want to go <em>downhill</em> to minimize our cost function. So, we’ll move in the <em>opposite</em> direction of the gradient.</p> <p>Let’s take our MSE example for a single parameter $ \theta_1 $ (assuming $ \theta_0 $ is fixed for simplicity):</p> <p>$ J(\theta_1) = \frac{1}{2m} \sum_{i=1}^{m} (y_i - (\theta_0 + \theta_1 x_i))^2 $</p> <p>The partial derivative with respect to $ \theta_1 $ would be:</p> <p>$ \frac{\partial J}{\partial \theta_1} = \frac{1}{m} \sum_{i=1}^{m} (y_i - (\theta_0 + \theta_1 x_i)) (-x_i) $ $ \frac{\partial J}{\partial \theta_1} = \frac{1}{m} \sum_{i=1}^{m} (\hat{y}_i - y_i) x_i $</p> <p>(And similarly for $ \theta_0 $, but let’s not get lost in too much specific calculus for now, just understand the concept.)</p> <p>This $ \frac{\partial J}{\partial \theta_1} $ value tells us the slope of the cost function with respect to $ \theta_1 $ at our current point.</p> <h3 id="the-descent-taking-the-steps">The “Descent”: Taking the Steps</h3> <p>Now we have our compass (the gradient). How do we take a step?</p> <p>We update our parameters iteratively. For each parameter $ \theta_j $:</p> <p>$ \theta_j^{\text{new}} = \theta_j^{\text{old}} - \alpha \frac{\partial J}{\partial \theta_j} $</p> <p>Let’s break down this powerful little equation:</p> <ul> <li>$ \theta_j^{\text{new}} $: This is the updated value for our parameter $j$.</li> <li>$ \theta_j^{\text{old}} $: This is the current value of our parameter $j$.</li> <li>$ \alpha $ (alpha): This is called the <strong>learning rate</strong>. It’s a hyperparameter that we choose, and it dictates the size of our steps.</li> <li>$ \frac{\partial J}{\partial \theta_j} $: This is the partial derivative of the cost function with respect to parameter $j$ at our current $ \theta $ values. It tells us the slope.</li> </ul> <p>The minus sign is crucial! Remember, the gradient points uphill, and we want to go <em>downhill</em>, so we subtract it.</p> <h3 id="the-learning-rate-alpha-our-step-size">The Learning Rate ($\alpha$): Our Step Size</h3> <p>The learning rate $ \alpha $ is one of the most critical hyperparameters in Gradient Descent. Think back to our mountain analogy:</p> <ul> <li> <strong>If $ \alpha $ is too small:</strong> You’ll take tiny, hesitant steps. It will take a very long time to reach the bottom, potentially even an infinite amount of time for practical purposes.</li> <li> <strong>If $ \alpha $ is too large:</strong> You might take huge, reckless leaps. You could overshoot the minimum, bounce around erratically, or even diverge entirely and shoot off further up the mountain!</li> </ul> <p>Finding the right $ \alpha $ is often a balancing act and requires some experimentation. This is why it’s a <em>hyperparameter</em> – something we set <em>before</em> training, rather than something the model learns itself.</p> <h3 id="the-gradient-descent-algorithm-a-simplified-view">The Gradient Descent Algorithm (A Simplified View)</h3> <ol> <li> <strong>Initialize Parameters:</strong> Start with some random values for your model parameters $ (\theta_0, \theta_1, \dots, \theta_n) $. These are your starting coordinates on the mountain.</li> <li> <strong>Choose a Learning Rate:</strong> Pick a value for $ \alpha $.</li> <li> <strong>Iterate (Loop):</strong> Repeat the following steps until convergence (or for a fixed number of iterations): a. <strong>Calculate Gradients:</strong> For <em>every</em> parameter $ \theta_j $, calculate $ \frac{\partial J}{\partial \theta_j} $ using your <em>current</em> parameter values and your entire dataset. b. <strong>Update Parameters:</strong> Simultaneously update <em>all</em> parameters using the rule: $ \theta_j^{\text{new}} = \theta_j^{\text{old}} - \alpha \frac{\partial J}{\partial \theta_j} $. c. <strong>Check for Convergence:</strong> Monitor the cost function $ J(\theta) $. If it stops decreasing significantly, or the changes in $ \theta $ become very small, you’ve likely reached a minimum.</li> </ol> <h3 id="three-flavors-of-gradient-descent">Three Flavors of Gradient Descent</h3> <p>The basic idea remains the same, but how we calculate the gradient over our data gives rise to different “flavors” of Gradient Descent:</p> <ol> <li> <strong>Batch Gradient Descent (BGD):</strong> <ul> <li> <strong>How it works:</strong> It calculates the gradient using <em>all</em> training examples in your dataset at each step.</li> <li> <strong>Pros:</strong> Produces very stable and smooth convergence directly to the minimum (for convex functions).</li> <li> <strong>Cons:</strong> Can be extremely slow and computationally expensive if your dataset is very large, as you have to process <em>all</em> data for <em>every single update</em>. Imagine feeling the slope across an entire continent before taking each step!</li> </ul> </li> <li> <strong>Stochastic Gradient Descent (SGD):</strong> <ul> <li> <strong>How it works:</strong> Instead of using all examples, it calculates the gradient using just <em>one</em> randomly chosen training example at each step.</li> <li> <strong>Pros:</strong> Much faster updates. Because it’s “noisy” (the gradient from one example isn’t perfectly representative of the whole dataset), it can sometimes help escape shallow local minima in complex, non-convex landscapes.</li> <li> <strong>Cons:</strong> The path to convergence is much noisier and more erratic. It tends to oscillate around the minimum rather than settling precisely into it. Imagine feeling the slope only with one foot at a time!</li> </ul> </li> <li> <strong>Mini-Batch Gradient Descent:</strong> <ul> <li> <strong>How it works:</strong> This is the most common and practical approach. It calculates the gradient using a small, randomly selected subset (a “mini-batch”) of training examples at each step.</li> <li> <strong>Pros:</strong> Combines the best of both worlds. It gets faster updates than BGD but with less noise than SGD, leading to more stable convergence than pure SGD. It’s also computationally efficient due to vectorized operations on mini-batches.</li> <li> <strong>Cons:</strong> Requires tuning an additional hyperparameter: the batch size.</li> </ul> </li> </ol> <h3 id="challenges-and-considerations">Challenges and Considerations</h3> <p>While powerful, Gradient Descent isn’t without its quirks:</p> <ul> <li> <strong>Local Minima &amp; Saddle Points:</strong> For complex cost functions (especially in deep learning), the landscape isn’t always a perfect bowl. It can have multiple “valleys” (local minima) or flat regions that look like minima but are actually “saddle points.” Gradient Descent might get stuck in a local minimum, unable to find the absolute lowest point (global minimum). SGD’s noise can sometimes help it jump out of these.</li> <li> <strong>Feature Scaling:</strong> If your input features have very different scales (e.g., house size in square feet and number of bathrooms), your cost function contours might be very elongated ellipses rather than nice circles. This makes Gradient Descent oscillate wildly and take longer to converge. Scaling your features (e.g., normalization or standardization) makes the contours more circular, allowing GD to take more direct paths.</li> <li> <strong>Vanishing/Exploding Gradients:</strong> More relevant in deep neural networks, this refers to gradients becoming extremely small or extremely large, making learning either too slow or unstable. This has led to the development of more advanced optimizers.</li> </ul> <h3 id="beyond-the-basics-adaptive-learning-rates">Beyond the Basics: Adaptive Learning Rates</h3> <p>The learning rate $ \alpha $ is static in basic Gradient Descent. This means you use the same step size throughout training. However, the ideal step size might change as you get closer to the minimum. This is where more advanced <strong>optimizers</strong> like AdaGrad, RMSprop, and the ever-popular <strong>Adam</strong> come into play. These algorithms adapt the learning rate for each parameter individually and dynamically throughout training, often leading to faster and more robust convergence. But the fundamental principle of descending the gradient remains at their core!</p> <h3 id="my-journey-continues">My Journey Continues…</h3> <p>Gradient Descent, once a mysterious incantation, now feels like a fundamental building block. It’s the engine that powers so much of what we do in machine learning. Understanding it not only demystifies “learning” but also empowers you to debug models, choose better hyperparameters, and appreciate the elegant dance between data and algorithms.</p> <p>So, the next time you train a model, take a moment to appreciate the humble Gradient Descent, diligently feeling its way down the cost function, step by calculated step, to find that optimal set of parameters. It’s a silent hero, constantly learning, constantly improving, and constantly pushing the boundaries of what our models can achieve.</p> <p>Keep exploring, keep questioning, and happy descending!</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/cracking-the-ai-black-box-why-explainable-ai-xai-i/">Cracking the AI Black Box: Why Explainable AI (XAI) is Our Superpower</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/the-secret-life-of-states-how-markov-chains-predic/">The Secret Life of States: How Markov Chains Predict Our Next Move (Without Remembering the Past!)</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/gradient-descent-unpacking-the-engine-of-machine-l/">Gradient Descent: Unpacking the Engine of Machine Learning</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Adarsh Nair. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/blog/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/masonry.js?v=a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/zoom.js?v=85ddb88934d28b74e78031fd54cf8308"></script> <script src="/blog/assets/js/no_defer.js?v=2781658a0a2b13ed609542042a859126"></script> <script defer src="/blog/assets/js/common.js?v=c15de51d4bb57887caa2c21988d97279"></script> <script defer src="/blog/assets/js/copy_code.js?v=c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/blog/assets/js/jupyter_new_tab.js?v=d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/blog/assets/js/mathjax-setup.js?v=a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/progress-bar.js?v=2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/blog/assets/js/vanilla-back-to-top.min.js?v=f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/blog/assets/js/search/ninja-keys.min.js?v=a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/blog/assets/js/search-setup.js?v=6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/blog/assets/js/search-data.js"></script> <script src="/blog/assets/js/shortcut-key.js?v=ccc841c459bfc0e64c1c2b5acd10df02"></script> </body> </html>