<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> The Algorithm That Learns: My Journey into Gradient Descent | Adarsh Nair </title> <meta name="author" content="Adarsh Nair"> <meta name="description" content="A deep dive into machine learning, AI, and data science. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <meta http-equiv="Content-Security-Policy" content="default-src 'self'; script-src 'self' 'unsafe-inline' https:; style-src 'self' 'unsafe-inline' https:; img-src 'self' data: https:; font-src 'self' data: https:; media-src 'self' https:; frame-src 'self' https:; connect-src 'self' https:;"> <link rel="stylesheet" href="/blog/assets/css/bootstrap.min.css?v=a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/blog/assets/css/academicons.min.css?v=f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/blog/assets/css/scholar-icons.css?v=62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-github.css?v=591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/blog/assets/css/main.css?v=d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://adarshnair.online/blog/blog/2024/the-algorithm-that-learns-my-journey-into-gradient/"> <script src="/blog/assets/js/theme.js?v=5fea5159b787642c1bbc1f334d60f883"></script> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-native.css?v=5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/blog/cv/"> Adarsh Nair </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/blog/"> </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/cv/">CV </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/repositories/">repositories </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="fa-solid fa-magnifying-glass"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-half-sun-moon" id="light-toggle-system"></i> <i class="fa-solid fa-moon" id="light-toggle-dark"></i> <i class="fa-solid fa-sun" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">The Algorithm That Learns: My Journey into Gradient Descent</h1> <p class="post-meta"> Created on March 23, 2024 by Adarsh Nair </p> <p class="post-tags"> <a href="/blog/blog/2024"> <i class="fa-solid fa-calendar fa-sm"></i> 2024 </a>   ·   <a href="/blog/blog/tag/machine-learning"> <i class="fa-solid fa-hashtag fa-sm"></i> Machine Learning</a>   <a href="/blog/blog/tag/optimization"> <i class="fa-solid fa-hashtag fa-sm"></i> Optimization</a>   <a href="/blog/blog/tag/gradient-descent"> <i class="fa-solid fa-hashtag fa-sm"></i> Gradient Descent</a>   <a href="/blog/blog/tag/deep-learning"> <i class="fa-solid fa-hashtag fa-sm"></i> Deep Learning</a>   <a href="/blog/blog/tag/algorithms"> <i class="fa-solid fa-hashtag fa-sm"></i> Algorithms</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p>Hello fellow data adventurers! Today, I want to share a foundational concept that truly blew my mind when I first encountered it. It’s the engine behind so much of what we call “machine learning” and “artificial intelligence,” and it’s something called Gradient Descent.</p> <p>Imagine you’re blindfolded and standing somewhere in a vast, hilly landscape. Your goal? To find the absolute lowest point in this valley. You can’t see, so you have to rely on feeling the slope beneath your feet. If you feel the ground sloping down to your left, you take a step in that direction. If it slopes down to your right, you go right. You keep taking small steps, always moving in the direction of the steepest descent, until you feel flat ground all around you. That flat spot? That’s your minimum.</p> <p>In a nutshell, that’s Gradient Descent. But instead of a physical valley, we’re navigating a mathematical “cost landscape,” and instead of our feet, we’re using calculus to ‘feel’ the slope.</p> <h3 id="the-quest-for-best-understanding-the-cost-function">The Quest for “Best”: Understanding the Cost Function</h3> <p>Before we can descend, we need to know what we’re trying to minimize. In machine learning, our models make predictions. We want these predictions to be as accurate as possible. The “cost” or “loss” function is our mathematical way of measuring how wrong our model is. A high cost means our model is performing poorly; a low cost means it’s doing great. Our goal is to find the parameters for our model that result in the absolute lowest cost.</p> <p>Let’s take a super simple example: <strong>Linear Regression</strong>. We’re trying to fit a straight line to a bunch of data points. A line is defined by its slope and y-intercept. Let’s call these parameters $\theta_1$ (slope) and $\theta_0$ (y-intercept). Our hypothesis, the predicted value $\hat{y}$ for a given $x$, would be:</p> <p>$h_\theta(x) = \theta_0 + \theta_1 x$</p> <p>Now, how do we measure how “good” this line is? A common choice is the <strong>Mean Squared Error (MSE)</strong>. We take the difference between our predicted value ($h_\theta(x^{(i)})$) and the actual value ($y^{(i)}$) for each data point, square it (to remove negative values and penalize larger errors more), sum them up, and then average across all $m$ data points. For convenience, we often multiply by $\frac{1}{2}$ to simplify derivatives later.</p> <p>The cost function $J(\theta_0, \theta_1)$ looks like this:</p> <p>$J(\theta_0, \theta_1) = \frac{1}{2m} \sum_{i=1}^{m} (h_\theta(x^{(i)}) - y^{(i)})^2$</p> <p>This $J(\theta_0, \theta_1)$ is our “valley.” It’s a function where the inputs are our model’s parameters ($\theta_0$ and $\theta_1$), and the output is the error. We want to find the specific values of $\theta_0$ and $\theta_1$ that give us the smallest possible $J$.</p> <h3 id="the-gradient-our-compass-for-the-descent">The Gradient: Our Compass for the Descent</h3> <p>So, we have our valley ($J(\theta)$). How do we know which way is down? This is where the “gradient” comes in. In calculus, the gradient of a function tells you the direction of the steepest <em>ascent</em> (uphill). Since we want to go <em>downhill</em>, we’ll simply move in the <em>opposite</em> direction of the gradient.</p> <p>The gradient is a vector of partial derivatives. For our linear regression example with parameters $\theta_0$ and $\theta_1$, the gradient would involve calculating $\frac{\partial J}{\partial \theta_0}$ and $\frac{\partial J}{\partial \theta_1}$.</p> <p>Let’s break down what those partial derivatives tell us:</p> <ul> <li>$\frac{\partial J}{\partial \theta_0}$: How much does the cost function $J$ change if we slightly tweak $\theta_0$?</li> <li>$\frac{\partial J}{\partial \theta_1}$: How much does the cost function $J$ change if we slightly tweak $\theta_1$?</li> </ul> <p>Each of these partial derivatives tells us the slope with respect to one parameter, assuming all other parameters are held constant. Together, they form the “gradient vector” that points directly uphill.</p> <h3 id="taking-a-step-the-update-rule">Taking a Step: The Update Rule</h3> <p>With our compass (the gradient) guiding us, we can now take a step. But how big should that step be? This is where the <strong>learning rate</strong>, often denoted by $\alpha$ (alpha), plays a crucial role.</p> <p>The learning rate is a hyperparameter that we choose <em>before</em> starting the training.</p> <ul> <li> <strong>If $\alpha$ is too small:</strong> We’ll take tiny, hesitant steps. It might take an incredibly long time to reach the bottom of the valley, or we might even get stuck in small bumps along the way.</li> <li> <strong>If $\alpha$ is too large:</strong> We’ll take huge, clumsy strides. We might overshoot the minimum, bounce around erratically, or even diverge completely and climb <em>out</em> of the valley!</li> </ul> <p>It’s a delicate balance, and choosing an appropriate learning rate is often more art than science, requiring experimentation.</p> <p>Now, let’s put it all together into the update rule for each parameter $\theta_j$:</p> <p>$\theta_j := \theta_j - \alpha \frac{\partial}{\partial \theta_j} J(\theta)$</p> <p>This equation simply means: “Update each parameter $\theta_j$ by subtracting the learning rate times its corresponding partial derivative of the cost function.” We repeat this process iteratively until convergence (when our parameters stop changing significantly, indicating we’ve reached the bottom).</p> <p>For our linear regression example using MSE, the partial derivatives turn out to be:</p> <p>$\frac{\partial}{\partial \theta_0} J(\theta) = \frac{1}{m} \sum_{i=1}^{m} (h_\theta(x^{(i)}) - y^{(i)})$</p> <p>$\frac{\partial}{\partial \theta_1} J(\theta) = \frac{1}{m} \sum_{i=1}^{m} (h_\theta(x^{(i)}) - y^{(i)}) x^{(i)}$</p> <p>So, in each iteration, we’d update $\theta_0$ and $\theta_1$ simultaneously using these formulas. This process makes our line progressively better at fitting the data until it reaches its optimal position.</p> <h3 id="varieties-of-descent-batch-stochastic-and-mini-batch">Varieties of Descent: Batch, Stochastic, and Mini-Batch</h3> <p>The core idea of taking steps down the gradient remains, but how we calculate that gradient can vary significantly. This leads to different flavors of Gradient Descent, each with its own pros and cons.</p> <h4 id="1-batch-gradient-descent-bgd">1. Batch Gradient Descent (BGD)</h4> <p>This is the “traditional” Gradient Descent we’ve discussed so far. In each iteration, we calculate the gradient using <em>all</em> the training examples in our dataset.</p> <ul> <li> <strong>Pros:</strong> Each step is an accurate descent towards the minimum. For convex cost functions (like our simple MSE for linear regression), it’s guaranteed to find the global minimum. The path to convergence is usually smooth.</li> <li> <strong>Cons:</strong> If your dataset is huge (millions or billions of examples), calculating the sum over <em>all</em> data points in every single iteration can be incredibly slow and computationally expensive. It might take forever to make just one parameter update.</li> </ul> <p>Imagine our blindfolded person pausing after every single step to survey the entire valley from every angle, calculating the exact steepest path before taking the next small step. Very thorough, but very slow if the valley is enormous.</p> <h4 id="2-stochastic-gradient-descent-sgd">2. Stochastic Gradient Descent (SGD)</h4> <p>“Stochastic” means random. In SGD, instead of using <em>all</em> training examples, we pick <em>one</em> random training example at a time to calculate the gradient and update the parameters.</p> <ul> <li> <strong>Pros:</strong> Incredibly fast for large datasets because each update is based on just one example. This means we make many updates per “epoch” (one pass through the entire dataset). Its noisy updates can sometimes help it escape shallow local minima in complex, non-convex cost landscapes (common in deep learning).</li> <li> <strong>Cons:</strong> The gradient calculated from a single example can be very noisy and inaccurate. This leads to a much more erratic path towards the minimum, often oscillating wildly around it rather than smoothly converging. It might never truly settle at the exact minimum.</li> </ul> <p>Our blindfolded friend now just feels the ground directly under one foot and takes a step based on that tiny, local observation. Fast, but potentially a bit chaotic!</p> <h4 id="3-mini-batch-gradient-descent-mbgd">3. Mini-Batch Gradient Descent (MBGD)</h4> <p>This is often the sweet spot and the most commonly used variant in practice. It strikes a balance between BGD and SGD. In each iteration, we use a small “batch” of $n$ (e.g., 32, 64, 128, 256) randomly selected training examples to calculate the gradient.</p> <ul> <li> <strong>Pros:</strong> It’s faster than BGD because it doesn’t process the entire dataset for each update. It’s more stable than SGD because the gradient calculated from a batch of examples is a better approximation of the true gradient than a single example. It benefits from vectorized operations, making it computationally efficient.</li> <li> <strong>Cons:</strong> Requires tuning the batch size, which can affect performance and convergence.</li> </ul> <p>This is like our blindfolded explorer feeling a small patch of ground (a “mini-batch”) around them to get a better sense of the slope before taking a step. It’s a good compromise between thoroughness and speed.</p> <h3 id="beyond-the-basics-challenges-and-advanced-optimizers">Beyond the Basics: Challenges and Advanced Optimizers</h3> <p>While Gradient Descent is incredibly powerful, it’s not without its challenges:</p> <ul> <li> <strong>Local Minima:</strong> In very complex cost landscapes (think deep neural networks), there can be many “dips” or local minima. BGD can get stuck in one of these, while SGD/MBGD’s noisy updates sometimes help them “jump out” and find a better minimum.</li> <li> <strong>Feature Scaling:</strong> If your input features have very different scales (e.g., one feature ranges from 0-1 and another from 0-10,000), your cost function can become elongated and distorted, like an oval valley. Gradient Descent will then oscillate severely, taking a very long time to converge. <strong>Feature scaling</strong> (normalizing or standardizing your data) makes the cost function more spherical, allowing GD to converge much faster.</li> <li> <strong>Learning Rate Selection:</strong> As we discussed, choosing the right $\alpha$ is critical. Modern approaches often use <strong>learning rate schedules</strong>, which dynamically decrease the learning rate over time, or more sophisticated <strong>adaptive learning rate optimizers</strong>.</li> </ul> <p>Speaking of adaptive optimizers, algorithms like <strong>Momentum</strong>, <strong>RMSprop</strong>, and <strong>Adam</strong> build upon the fundamental idea of Gradient Descent. They introduce concepts like “momentum” (remembering previous updates to accelerate descent in consistent directions) or adaptively adjust the learning rate for each parameter based on its historical gradients. These optimizers are the workhorses of deep learning, but at their core, they are still performing Gradient Descent – just in a smarter, more efficient way.</p> <h3 id="my-takeaway">My Takeaway</h3> <p>My journey into understanding Gradient Descent felt like unlocking a secret chamber in the grand castle of machine learning. It’s a testament to the power of iterative improvement and simple mathematical principles. From fitting a humble line to powering the complex neural networks that recognize faces, translate languages, and drive autonomous vehicles, Gradient Descent is quietly working its magic, teaching machines how to learn, one careful step at a time.</p> <p>It’s a concept that truly bridges the gap between abstract mathematics and tangible intelligent systems. If you’re starting your own data science or MLE journey, truly grasping Gradient Descent isn’t just an academic exercise; it’s a foundational skill that will illuminate countless other advanced topics. So go forth, explore those cost landscapes, and happy descending!</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/cracking-the-ai-black-box-why-explainable-ai-xai-i/">Cracking the AI Black Box: Why Explainable AI (XAI) is Our Superpower</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/the-secret-life-of-states-how-markov-chains-predic/">The Secret Life of States: How Markov Chains Predict Our Next Move (Without Remembering the Past!)</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/gradient-descent-unpacking-the-engine-of-machine-l/">Gradient Descent: Unpacking the Engine of Machine Learning</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Adarsh Nair. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/blog/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/masonry.js?v=a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/zoom.js?v=85ddb88934d28b74e78031fd54cf8308"></script> <script src="/blog/assets/js/no_defer.js?v=2781658a0a2b13ed609542042a859126"></script> <script defer src="/blog/assets/js/common.js?v=c15de51d4bb57887caa2c21988d97279"></script> <script defer src="/blog/assets/js/copy_code.js?v=c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/blog/assets/js/jupyter_new_tab.js?v=d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/blog/assets/js/mathjax-setup.js?v=a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/progress-bar.js?v=2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/blog/assets/js/vanilla-back-to-top.min.js?v=f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/blog/assets/js/search/ninja-keys.min.js?v=a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/blog/assets/js/search-setup.js?v=6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/blog/assets/js/search-data.js"></script> <script src="/blog/assets/js/shortcut-key.js?v=ccc841c459bfc0e64c1c2b5acd10df02"></script> </body> </html>