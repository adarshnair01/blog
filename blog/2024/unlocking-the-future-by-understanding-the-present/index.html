<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Unlocking the Future by Understanding the Present: A Journey into Markov Chains | Adarsh Nair </title> <meta name="author" content="Adarsh Nair"> <meta name="description" content="A deep dive into machine learning, AI, and data science. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <meta http-equiv="Content-Security-Policy" content="default-src 'self'; script-src 'self' 'unsafe-inline' https:; style-src 'self' 'unsafe-inline' https:; img-src 'self' data: https:; font-src 'self' data: https:; media-src 'self' https:; frame-src 'self' https:; connect-src 'self' https:;"> <link rel="stylesheet" href="/blog/assets/css/bootstrap.min.css?v=a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/blog/assets/css/academicons.min.css?v=f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/blog/assets/css/scholar-icons.css?v=62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-github.css?v=591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/blog/assets/css/main.css?v=d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://adarshnair.online/blog/blog/blog/2024/unlocking-the-future-by-understanding-the-present/"> <script src="/blog/assets/js/theme.js?v=5fea5159b787642c1bbc1f334d60f883"></script> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-native.css?v=5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="https://adarshnair.online" rel="external nofollow noopener" target="_blank"> Adarsh Nair </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/blog/"> </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/index.html">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/cv/">CV </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/repositories/">repositories </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="fa-solid fa-magnifying-glass"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-half-sun-moon" id="light-toggle-system"></i> <i class="fa-solid fa-moon" id="light-toggle-dark"></i> <i class="fa-solid fa-sun" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Unlocking the Future by Understanding the Present: A Journey into Markov Chains</h1> <p class="post-meta"> Created on December 04, 2024 by Adarsh Nair </p> <p class="post-tags"> <a href="/blog/blog/2024"> <i class="fa-solid fa-calendar fa-sm"></i> 2024 </a>   ·   <a href="/blog/blog/tag/markov-chains"> <i class="fa-solid fa-hashtag fa-sm"></i> Markov Chains</a>   <a href="/blog/blog/tag/probability"> <i class="fa-solid fa-hashtag fa-sm"></i> Probability</a>   <a href="/blog/blog/tag/stochastic-processes"> <i class="fa-solid fa-hashtag fa-sm"></i> Stochastic Processes</a>   <a href="/blog/blog/tag/data-science"> <i class="fa-solid fa-hashtag fa-sm"></i> Data Science</a>   <a href="/blog/blog/tag/machine-learning"> <i class="fa-solid fa-hashtag fa-sm"></i> Machine Learning</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p>Hey everyone!</p> <p>As a data science enthusiast, there are certain foundational concepts that, once you grasp them, suddenly make a lot of complex systems seem brilliantly simple. For me, one of those “aha!” moments came with understanding <strong>Markov Chains</strong>. It’s a concept so elegant, so intuitive, yet so immensely powerful that it feels like discovering a secret language the universe uses to describe change.</p> <p>It started with a simple thought experiment: What will the weather be like tomorrow? If it’s sunny today, is it more likely to be sunny tomorrow, or cloudy? What if it’s been raining for three days straight – does that history make rain more probable for day four? This seemingly trivial question opens the door to a fundamental idea in probability and statistics: the Markov Chain.</p> <h3 id="what-is-a-markov-chain-the-memoryless-marvel">What is a Markov Chain? The “Memoryless” Marvel</h3> <p>Imagine you’re trying to predict the weather. You know it’s sunny today. Does knowing it was sunny yesterday, and cloudy the day before, help you predict tomorrow’s weather <em>more</em> accurately than just knowing it’s sunny <em>today</em>?</p> <p>For a Markov Chain, the answer is a resounding “no!”</p> <p>At its core, a <strong>Markov Chain</strong> is a sequence of events where the probability of the <em>next</em> event depends <em>only</em> on the <em>current</em> event, not on the entire sequence of events that preceded it. This is famously known as the <strong>Markov Property</strong>, or sometimes, the “memoryless” property.</p> <p>Think of it like this: You’re playing a board game. Your next move depends on where you are <em>right now</em> (your current square) and the dice roll. It doesn’t matter how many turns it took you to get to that square, or which path you took. Your past moves are irrelevant to your next move, only your current position matters.</p> <p>Mathematically, we can express the Markov Property as:</p> <table> <tbody> <tr> <td>$P(X_{n+1} = x</td> <td>X_n = x_n, X_{n-1} = x_{n-1}, …, X_0 = x_0) = P(X_{n+1} = x</td> <td>X_n = x_n)$</td> </tr> </tbody> </table> <p>Where:</p> <ul> <li>$X_n$ represents the state of the system at time step $n$.</li> <li>$x$ and $x_i$ represent specific possible states.</li> <li>$P(…)$ is the probability of an event.</li> </ul> <p>This equation simply says: the probability of transitioning to state $x$ at the next time step ($n+1$), given all past states up to the current state ($n$), is the same as the probability of transitioning to state $x$ given <em>only</em> the current state ($X_n$). Pretty neat, right?</p> <h3 id="building-our-first-markov-chain-the-weather-model">Building Our First Markov Chain: The Weather Model</h3> <p>Let’s stick with our weather example to make this concrete. Suppose the weather in a particular region can only be in one of three states: <strong>S</strong>unny, <strong>C</strong>loudy, or <strong>R</strong>ainy.</p> <p>To define our Markov Chain, we need two things:</p> <ol> <li> <strong>States:</strong> The possible conditions the system can be in. In our case: {Sunny, Cloudy, Rainy}.</li> <li> <strong>Transition Probabilities:</strong> The probabilities of moving from one state to another. These are the heart of a Markov Chain.</li> </ol> <p>Let’s make up some probabilities (these would usually be derived from historical data):</p> <ul> <li>If it’s <strong>Sunny</strong> today: <ul> <li>70% chance it’s Sunny tomorrow ($P(S \to S) = 0.7$)</li> <li>20% chance it’s Cloudy tomorrow ($P(S \to C) = 0.2$)</li> <li>10% chance it’s Rainy tomorrow ($P(S \to R) = 0.1$)</li> </ul> </li> <li>If it’s <strong>Cloudy</strong> today: <ul> <li>30% chance it’s Sunny tomorrow ($P(C \to S) = 0.3$)</li> <li>40% chance it’s Cloudy tomorrow ($P(C \to C) = 0.4$)</li> <li>30% chance it’s Rainy tomorrow ($P(C \to R) = 0.3$)</li> </ul> </li> <li>If it’s <strong>Rainy</strong> today: <ul> <li>20% chance it’s Sunny tomorrow ($P(R \to S) = 0.2$)</li> <li>30% chance it’s Cloudy tomorrow ($P(R \to C) = 0.3$)</li> <li>50% chance it’s Rainy tomorrow ($P(R \to R) = 0.5$)</li> </ul> </li> </ul> <p>Notice that for each starting state, the probabilities of transitioning to <em>all</em> possible next states sum up to 1 (e.g., $0.7 + 0.2 + 0.1 = 1$). This makes sense, as the weather <em>has</em> to be one of those options tomorrow.</p> <h3 id="the-transition-matrix-our-crystal-ball">The Transition Matrix: Our Crystal Ball</h3> <p>These probabilities can be neatly organized into a <strong>Transition Matrix</strong>, often denoted by $P$. Each row represents the <em>current</em> state, and each column represents the <em>next</em> state.</p> \[P = \begin{pmatrix} P(S \to S) &amp; P(S \to C) &amp; P(S \to R) \\ P(C \to S) &amp; P(C \to C) &amp; P(C \to R) \\ P(R \to S) &amp; P(R \to C) &amp; P(R \to R) \end{pmatrix}\] <p>Plugging in our values:</p> \[P = \begin{pmatrix} 0.7 &amp; 0.2 &amp; 0.1 \\ 0.3 &amp; 0.4 &amp; 0.3 \\ 0.2 &amp; 0.3 &amp; 0.5 \end{pmatrix}\] <p>This matrix is incredibly powerful! If we know the weather today, say it’s Sunny, we can represent our current state as a row vector $\pi_0 = \begin{pmatrix} 1 &amp; 0 &amp; 0 \end{pmatrix}$ (100% Sunny, 0% Cloudy, 0% Rainy).</p> <p>To find the probability distribution for tomorrow’s weather ($\pi_1$), we simply multiply our current state vector by the transition matrix:</p> <p>$\pi_1 = \pi_0 P = \begin{pmatrix} 1 &amp; 0 &amp; 0 \end{pmatrix} \begin{pmatrix} 0.7 &amp; 0.2 &amp; 0.1 \ 0.3 &amp; 0.4 &amp; 0.3 \ 0.2 &amp; 0.3 &amp; 0.5 \end{pmatrix} = \begin{pmatrix} 0.7 &amp; 0.2 &amp; 0.1 \end{pmatrix}$</p> <p>This makes sense! If it’s Sunny today, there’s a 70% chance of Sunny, 20% of Cloudy, and 10% of Rainy tomorrow.</p> <p>What about the day after tomorrow? We can find $\pi_2$ by multiplying $\pi_1$ by $P$:</p> <p>$\pi_2 = \pi_1 P = (\pi_0 P) P = \pi_0 P^2$</p> <p>And for $n$ days into the future, it’s just $\pi_n = \pi_0 P^n$. The transition matrix allows us to peer into the future, albeit probabilistically!</p> <h3 id="visualizing-the-flow-state-diagrams">Visualizing the Flow: State Diagrams</h3> <p>Sometimes, it’s easier to see things visually. We can represent a Markov Chain using a <strong>state diagram</strong>:</p> <ul> <li>Each state is a node (a circle).</li> <li>Arrows (directed edges) connect states, indicating possible transitions.</li> <li>Each arrow is labeled with its transition probability.</li> </ul> <pre><code class="language-mermaid">graph TD
    S[Sunny] --&gt;|0.7| S
    S --&gt;|0.2| C[Cloudy]
    S --&gt;|0.1| R[Rainy]
    C --&gt;|0.3| S
    C --&gt;|0.4| C
    C --&gt;|0.3| R
    R --&gt;|0.2| S
    R --&gt;|0.3| C
    R --&gt;|0.5| R
</code></pre> <p>(Note: Markdown does not natively support Mermaid diagrams, but this illustrates how one would represent it, perhaps using an image in a real blog post.)</p> <p>This diagram helps us visualize the “flow” of probability between states.</p> <h3 id="the-long-run-stationary-distribution-steady-state">The Long Run: Stationary Distribution (Steady State)</h3> <p>One of the most fascinating properties of many Markov Chains is what happens in the <em>long run</em>. If we keep multiplying our probability distribution by the transition matrix ($P^n$ for large $n$), what do you think happens?</p> <p>For many Markov Chains (specifically, those that are “irreducible” and “aperiodic” – terms for ensuring every state is reachable from every other state and there are no deterministic cycles), the system eventually reaches a <strong>stationary distribution</strong>, also known as a <strong>steady state</strong>.</p> <p>This means that after a very long time, the probability of being in any particular state stabilizes, <em>regardless of the initial state</em>. The system forgets its starting point entirely!</p> <p>Mathematically, the stationary distribution $\pi_{steady}$ is a probability vector that satisfies:</p> <p>$\pi_{steady} = \pi_{steady} P$</p> <p>This means that if the system is already in its steady state distribution, applying another transition step doesn’t change the distribution. The “flow” of probability into a state exactly balances the “flow” out of it.</p> <p>For our weather example, if you ran the simulation for weeks or months, you’d find a stable probability distribution for Sunny, Cloudy, and Rainy days. For instance, it might converge to something like: 40% Sunny, 30% Cloudy, 30% Rainy. This would tell us the long-term proportion of each type of day, completely independent of whether it was sunny or rainy <em>today</em>. This is incredibly useful for understanding the inherent characteristics of the system!</p> <h3 id="where-do-markov-chains-shine-real-world-applications">Where Do Markov Chains Shine? Real-World Applications!</h3> <p>The simplicity of Markov Chains belies their immense applicability. Here are just a few places where they pop up in the real world:</p> <ol> <li> <strong>Google PageRank:</strong> This is perhaps the most famous application! Google used a Markov Chain to rank web pages. Each web page is a state, and a hyperlink from one page to another is a transition. The probability of transitioning from page A to page B is related to the number of links on page A pointing to page B. The steady-state distribution of this massive Markov Chain gives each page a “rank” or “importance score.” Pages with a higher steady-state probability are more likely to be visited by a “random surfer” and thus deemed more important.</li> <li> <strong>Natural Language Processing (NLP):</strong> <ul> <li> <strong>Text Generation:</strong> Simple Markov models can generate text by predicting the next word based on the current word or a sequence of words. “I like to eat” followed by “apples” or “pizza”. This is how early predictive text worked!</li> <li> <strong>Speech Recognition:</strong> Markov models (specifically Hidden Markov Models, or HMMs, which are an extension) are fundamental to translating spoken words into text.</li> <li> <strong>Spam Filtering:</strong> Analyzing patterns of words.</li> </ul> </li> <li> <strong>Weather Forecasting:</strong> As we explored, predicting tomorrow’s weather based on today’s. More complex models are used now, but the underlying concept is often inspired by Markovian ideas.</li> <li> <strong>Genetics:</strong> Modeling DNA sequences, where the next nucleotide might depend on the current one.</li> <li> <strong>Finance:</strong> Modeling stock price movements (though financial markets are complex and often not strictly Markovian).</li> <li> <strong>Reinforcement Learning:</strong> Markov Decision Processes (MDPs), which are an extension of Markov Chains, are the backbone of many AI agents that learn to make decisions in dynamic environments (think game AI or robotics).</li> </ol> <h3 id="limitations">Limitations</h3> <p>While powerful, it’s important to remember the “memoryless” property. Not all real-world phenomena strictly adhere to it. For instance, the stock market’s behavior tomorrow might not <em>just</em> depend on today’s closing price, but also on the trend of the past week, or global economic news. In such cases, more complex models that incorporate more history (like Hidden Markov Models or Recurrent Neural Networks) might be necessary.</p> <h3 id="my-takeaway--your-turn">My Takeaway &amp; Your Turn!</h3> <p>Learning about Markov Chains was a pivotal moment in my data science journey. It showed me how complex, seemingly unpredictable systems can be modeled with a simple probabilistic framework. It’s a testament to the power of breaking down problems into their core components and understanding the probabilities that govern their transitions.</p> <p>If you’re just starting out in data science or curious about how things work under the hood, I highly encourage you to dive deeper into Markov Chains. Try to:</p> <ul> <li> <strong>Implement a simple weather model</strong> in Python.</li> <li> <strong>Explore how PageRank works</strong> in more detail.</li> <li> <strong>Think about systems around you</strong> and whether they might be modeled as a Markov Chain.</li> </ul> <p>The world is full of these elegant, memoryless processes just waiting to be understood!</p> <p>Happy exploring!</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/cracking-the-ai-black-box-why-explainable-ai-xai-i/">Cracking the AI Black Box: Why Explainable AI (XAI) is Our Superpower</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/the-secret-life-of-states-how-markov-chains-predic/">The Secret Life of States: How Markov Chains Predict Our Next Move (Without Remembering the Past!)</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/gradient-descent-unpacking-the-engine-of-machine-l/">Gradient Descent: Unpacking the Engine of Machine Learning</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Adarsh Nair. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/blog/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/masonry.js?v=a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/zoom.js?v=85ddb88934d28b74e78031fd54cf8308"></script> <script src="/blog/assets/js/no_defer.js?v=2781658a0a2b13ed609542042a859126"></script> <script defer src="/blog/assets/js/common.js?v=c15de51d4bb57887caa2c21988d97279"></script> <script defer src="/blog/assets/js/copy_code.js?v=c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/blog/assets/js/jupyter_new_tab.js?v=d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/blog/assets/js/mathjax-setup.js?v=a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/progress-bar.js?v=2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/blog/assets/js/vanilla-back-to-top.min.js?v=f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/blog/assets/js/search/ninja-keys.min.js?v=a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/blog/assets/js/search-setup.js?v=6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/blog/assets/js/search-data.js"></script> <script src="/blog/assets/js/shortcut-key.js?v=ccc841c459bfc0e64c1c2b5acd10df02"></script> </body> </html>