<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> My Deep Dive into Gradient Descent: The Secret Sauce of Machine Learning | Adarsh Nair </title> <meta name="author" content="Adarsh Nair"> <meta name="description" content="A deep dive into machine learning, AI, and data science. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <meta http-equiv="Content-Security-Policy" content="default-src 'self'; script-src 'self' 'unsafe-inline' https:; style-src 'self' 'unsafe-inline' https:; img-src 'self' data: https:; font-src 'self' data: https:; media-src 'self' https:; frame-src 'self' https:; connect-src 'self' https:;"> <link rel="stylesheet" href="/blog/assets/css/bootstrap.min.css?v=a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/blog/assets/css/academicons.min.css?v=f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/blog/assets/css/scholar-icons.css?v=62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-github.css?v=591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/blog/assets/css/main.css?v=d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://adarshnair.online/blog/blog/blog/2024/my-deep-dive-into-gradient-descent-the-secret-sauc/"> <script src="/blog/assets/js/theme.js?v=5fea5159b787642c1bbc1f334d60f883"></script> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-native.css?v=5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="https://adarshnair.online" rel="external nofollow noopener" target="_blank"> Adarsh Nair </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/blog/"> </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/index.html">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/cv/">CV </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/repositories/">repositories </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="fa-solid fa-magnifying-glass"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-half-sun-moon" id="light-toggle-system"></i> <i class="fa-solid fa-moon" id="light-toggle-dark"></i> <i class="fa-solid fa-sun" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">My Deep Dive into Gradient Descent: The Secret Sauce of Machine Learning</h1> <p class="post-meta"> Created on March 30, 2024 by Adarsh Nair </p> <p class="post-tags"> <a href="/blog/blog/2024"> <i class="fa-solid fa-calendar fa-sm"></i> 2024 </a>   ·   <a href="/blog/blog/tag/machine-learning"> <i class="fa-solid fa-hashtag fa-sm"></i> Machine Learning</a>   <a href="/blog/blog/tag/gradient-descent"> <i class="fa-solid fa-hashtag fa-sm"></i> Gradient Descent</a>   <a href="/blog/blog/tag/optimization"> <i class="fa-solid fa-hashtag fa-sm"></i> Optimization</a>   <a href="/blog/blog/tag/deep-learning"> <i class="fa-solid fa-hashtag fa-sm"></i> Deep Learning</a>   <a href="/blog/blog/tag/algorithms"> <i class="fa-solid fa-hashtag fa-sm"></i> Algorithms</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p>As a budding data scientist, there are those moments when a concept clicks, when the abstract math suddenly morphs into an intuitive, elegant solution. For me, one of those pivotal “aha!” moments came with understanding Gradient Descent. It’s not just an algorithm; it’s the very heartbeat of how many machine learning models, from simple linear regression to complex neural networks, find their way to optimal performance.</p> <p>So, buckle up! In this post, I want to share my personal journey into unraveling Gradient Descent, explaining it in a way that I wish someone had explained it to me – accessible, engaging, and deeply insightful.</p> <h3 id="the-mountain-climbers-dilemma-what-are-we-trying-to-achieve">The Mountain Climber’s Dilemma: What are We Trying to Achieve?</h3> <p>Imagine you’re blindfolded, standing on a vast, uneven landscape. Your goal? To find the lowest point in the valley, a point where you can finally rest. You can’t see the whole landscape, only feel the slope immediately beneath your feet. How would you move?</p> <p>This, my friends, is precisely the problem our machine learning models face. In the world of algorithms, this “landscape” is represented by a <strong>cost function</strong> (also known as a loss function or objective function). This function measures how “wrong” our model’s predictions are compared to the actual data. Our goal is to minimize this cost function – to find the set of model parameters (like the slope and intercept in a line, or the weights and biases in a neural network) that results in the smallest possible error.</p> <p>Let’s say we’re building a simple linear regression model. Our model predicts an output $\hat{y}$ based on an input $x$ using the equation: \(\hat{y} = w x + b\) Here, $w$ is the weight (slope) and $b$ is the bias (y-intercept). These are our “parameters” – the settings we need to tune.</p> <p>A common cost function for linear regression is the Mean Squared Error (MSE): \(J(w, b) = \frac{1}{2m} \sum\_{i=1}^{m} (\hat{y}^{(i)} - y^{(i)})^2\) Where:</p> <ul> <li>$m$ is the number of training examples.</li> <li>$\hat{y}^{(i)}$ is our model’s prediction for the $i$-th example.</li> <li>$y^{(i)}$ is the actual value for the $i$-th example.</li> <li>The $\frac{1}{2}$ is just a convention that makes the math a bit cleaner later on when we take derivatives.</li> </ul> <p>Our mission, should we choose to accept it, is to find the values of $w$ and $b$ that make $J(w, b)$ as small as possible.</p> <h3 id="the-intuition-taking-steps-downhill">The Intuition: Taking Steps Downhill</h3> <p>Back to our blindfolded mountain climber. To find the lowest point, what’s the most sensible thing to do? Take a step in the direction that feels most steeply downhill! If you keep taking small steps in the steepest downhill direction, eventually you’ll reach the bottom of the valley.</p> <p>This intuitive idea is the core of Gradient Descent.</p> <ol> <li> <p><strong>Start Somewhere:</strong> We begin by picking some initial, random values for our model parameters ($w$ and $b$). It’s like dropping our blindfolded climber anywhere on the landscape.</p> </li> <li> <p><strong>Feel the Slope (The Gradient):</strong> At our current position (current values of $w$ and $b$), we need to figure out which way is “downhill.” Mathematically, the direction of the steepest ascent is given by the <strong>gradient</strong> of the cost function. Conversely, the direction of the steepest <em>descent</em> is the negative of the gradient.</p> <p>The gradient is a vector of partial derivatives. For our linear regression example with parameters $w$ and $b$, the gradient of the cost function $J(w, b)$ with respect to $w$ and $b$ would be: \(\nabla J(w, b) = \begin{pmatrix} \frac{\partial J}{\partial w} \\ \frac{\partial J}{\partial b} \end{pmatrix}\)</p> <p>Let’s calculate these partial derivatives for our MSE cost function: \(\frac{\partial J}{\partial w} = \frac{1}{m} \sum*{i=1}^{m} (\hat{y}^{(i)} - y^{(i)}) x^{(i)}\) \(\frac{\partial J}{\partial b} = \frac{1}{m} \sum*{i=1}^{m} (\hat{y}^{(i)} - y^{(i)})\) (You can derive these using the chain rule! It’s a fun exercise if you’re into calculus.)</p> </li> <li> <p><strong>Take a Step (The Update Rule):</strong> Once we know the direction of steepest descent, we take a step in that direction. How big of a step? That’s controlled by a crucial hyperparameter called the <strong>learning rate</strong>, denoted by $\alpha$ (alpha).</p> <p>The update rule for each parameter ($\theta$ representing either $w$ or $b$) is: \(\theta*{new} = \theta*{old} - \alpha \frac{\partial J}{\partial \theta*{old}}\) So, for our $w$ and $b$: \(w*{new} = w*{old} - \alpha \frac{\partial J}{\partial w*{old}}\) \(b*{new} = b*{old} - \alpha \frac{\partial J}{\partial b\_{old}}\)</p> <p>We repeat steps 2 and 3 iteratively. Each iteration, our parameters $w$ and $b$ get updated, moving us closer and closer to the minimum of the cost function, until ideally, we converge to a point where the cost function is minimized.</p> </li> </ol> <h3 id="visualizing-the-descent">Visualizing the Descent</h3> <p>Imagine a 2D plot where the x-axis represents $w$, the y-axis represents $b$, and the z-axis (height) represents the value of $J(w, b)$. This creates a bowl-shaped surface (for convex functions like MSE in linear regression).</p> <p>Our Gradient Descent algorithm starts at some random point on this surface. It calculates the slope (gradient) at that point, takes a step downhill, and repeats. Visually, it’s like a ball rolling down the sides of a bowl until it settles at the very bottom.</p> <h3 id="the-learning-rate-alpha-a-crucial-hyperparameter">The Learning Rate ($\alpha$): A Crucial Hyperparameter</h3> <p>The learning rate is perhaps the most critical hyperparameter in Gradient Descent. It dictates the size of the steps we take down the cost function’s surface.</p> <ul> <li> <strong>If $\alpha$ is too small:</strong> We’ll take tiny baby steps. The algorithm will eventually reach the minimum, but it will take a very long time, making training inefficient.</li> <li> <strong>If $\alpha$ is too large:</strong> We might overshoot the minimum repeatedly, bouncing back and forth across the valley, or even diverge completely and climb <em>up</em> the other side of the landscape, never finding the minimum. The cost function might even increase!</li> </ul> <p>Finding the right learning rate often involves trial and error, a process called hyperparameter tuning.</p> <h3 id="types-of-gradient-descent-a-family-affair">Types of Gradient Descent: A Family Affair</h3> <p>The core idea of Gradient Descent remains the same, but how we calculate the gradient across our data can vary, leading to different flavors:</p> <ol> <li> <strong>Batch Gradient Descent (BGD):</strong> <ul> <li> <strong>How it works:</strong> In each iteration, it calculates the gradient of the cost function using <em>all</em> the training examples.</li> <li> <strong>Pros:</strong> Guaranteed to converge to the global minimum for convex functions, and to a local minimum for non-convex functions (like those in deep learning). The updates are very stable.</li> <li> <strong>Cons:</strong> Can be very slow and computationally expensive for large datasets because it has to process all data points before making a single update. Memory intensive.</li> </ul> </li> <li> <strong>Stochastic Gradient Descent (SGD):</strong> <ul> <li> <strong>How it works:</strong> Instead of using all examples, it calculates the gradient and updates the parameters using <em>only one training example</em> at a time.</li> <li> <strong>Pros:</strong> Much faster than BGD, especially for large datasets, as it makes an update after every single example. It can escape shallow local minima due to the noisy updates.</li> <li> <strong>Cons:</strong> The updates are noisy and less stable. The cost function might not smoothly decrease but rather fluctuate quite a bit, making it harder to determine convergence. It might “oscillate” around the minimum rather than settling precisely.</li> </ul> </li> <li> <strong>Mini-Batch Gradient Descent:</strong> <ul> <li> <strong>How it works:</strong> This is the Goldilocks solution, and by far the most commonly used variant. It calculates the gradient and updates parameters using a small “mini-batch” of training examples (typically 32, 64, 128, or 256 examples) in each iteration.</li> <li> <strong>Pros:</strong> Balances the advantages of BGD and SGD. It’s much faster than BGD and more stable than SGD. Leveraging matrix operations, mini-batches allow for significant computational efficiency on GPUs.</li> <li> <strong>Cons:</strong> Requires careful selection of the mini-batch size.</li> </ul> </li> </ol> <h3 id="beyond-the-basics-the-optimizers">Beyond the Basics: The Optimizers</h3> <p>While Gradient Descent is the foundational algorithm, modern deep learning libraries often use more sophisticated optimizers built upon its principles. These optimizers, like Adam, RMSprop, Adagrad, and Momentum, essentially supercharge Gradient Descent by adaptively adjusting the learning rate for each parameter, incorporating moving averages of gradients, or adding a “momentum” term to help navigate tricky landscapes and accelerate convergence. They address issues like vanishing/exploding gradients and slow convergence.</p> <h3 id="my-takeaways-and-why-it-matters">My Takeaways and Why It Matters</h3> <p>Understanding Gradient Descent isn’t just about memorizing formulas; it’s about grasping the core mechanism by which machines learn from data. It’s the engine beneath the hood of countless AI applications we use every day.</p> <p>For me, realizing that complex models simply “feel” their way to better performance, much like a blindfolded person navigating a landscape, demystified a huge part of machine learning. It empowered me to not just use off-the-shelf algorithms but to truly understand <em>why</em> they work and how to troubleshoot them when they don’t.</p> <p>So, the next time you see a machine learning model performing its magic, remember the elegant simplicity and power of Gradient Descent – the silent mountain climber, always striving to reach the bottom of the valley, one calculated step at a time.</p> <p>Keep exploring, keep learning, and keep descending into the depths of knowledge!</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/cracking-the-ai-black-box-why-explainable-ai-xai-i/">Cracking the AI Black Box: Why Explainable AI (XAI) is Our Superpower</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/the-secret-life-of-states-how-markov-chains-predic/">The Secret Life of States: How Markov Chains Predict Our Next Move (Without Remembering the Past!)</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/gradient-descent-unpacking-the-engine-of-machine-l/">Gradient Descent: Unpacking the Engine of Machine Learning</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Adarsh Nair. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/blog/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/masonry.js?v=a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/zoom.js?v=85ddb88934d28b74e78031fd54cf8308"></script> <script src="/blog/assets/js/no_defer.js?v=2781658a0a2b13ed609542042a859126"></script> <script defer src="/blog/assets/js/common.js?v=c15de51d4bb57887caa2c21988d97279"></script> <script defer src="/blog/assets/js/copy_code.js?v=c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/blog/assets/js/jupyter_new_tab.js?v=d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/blog/assets/js/mathjax-setup.js?v=a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/progress-bar.js?v=2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/blog/assets/js/vanilla-back-to-top.min.js?v=f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/blog/assets/js/search/ninja-keys.min.js?v=a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/blog/assets/js/search-setup.js?v=6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/blog/assets/js/search-data.js"></script> <script src="/blog/assets/js/shortcut-key.js?v=ccc841c459bfc0e64c1c2b5acd10df02"></script> </body> </html>