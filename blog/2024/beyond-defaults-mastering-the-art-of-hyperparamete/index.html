<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Beyond Defaults: Mastering the Art of Hyperparameter Tuning | Adarsh Nair </title> <meta name="author" content="Adarsh Nair"> <meta name="description" content="A deep dive into machine learning, AI, and data science. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <meta http-equiv="Content-Security-Policy" content="default-src 'self'; script-src 'self' 'unsafe-inline' https:; style-src 'self' 'unsafe-inline' https:; img-src 'self' data: https:; font-src 'self' data: https:; media-src 'self' https:; frame-src 'self' https:; connect-src 'self' https:;"> <link rel="stylesheet" href="/blog/assets/css/bootstrap.min.css?v=a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/blog/assets/css/academicons.min.css?v=f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/blog/assets/css/scholar-icons.css?v=62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-github.css?v=591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/blog/assets/css/main.css?v=d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://adarshnair.online/blog/blog/blog/2024/beyond-defaults-mastering-the-art-of-hyperparamete/"> <script src="/blog/assets/js/theme.js?v=5fea5159b787642c1bbc1f334d60f883"></script> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-native.css?v=5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/blog/cv/"> Adarsh Nair </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/blog/"> </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/index.html">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/cv/">CV </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/repositories/">repositories </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="fa-solid fa-magnifying-glass"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-half-sun-moon" id="light-toggle-system"></i> <i class="fa-solid fa-moon" id="light-toggle-dark"></i> <i class="fa-solid fa-sun" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Beyond Defaults: Mastering the Art of Hyperparameter Tuning</h1> <p class="post-meta"> Created on February 16, 2024 by Adarsh Nair </p> <p class="post-tags"> <a href="/blog/blog/2024"> <i class="fa-solid fa-calendar fa-sm"></i> 2024 </a> </p> </header> <article class="post-content"> <div id="markdown-content"> <h1 id="beyond-defaults-mastering-the-art-of-hyperparameter-tuning">Beyond Defaults: Mastering the Art of Hyperparameter Tuning</h1> <p>Hey everyone! Welcome back to my journal. Today, I want to talk about something crucial in machine learning that often separates good models from great ones: Hyperparameter Tuning. Think of building a machine learning model like baking a cake. You have your ingredients (your data) and your recipe (your algorithm). But what about the oven temperature, the mixing time, or how long you let it cool? These aren’t ingredients, but they <em>drastically</em> affect the final outcome. In ML, these are our hyperparameters.</p> <h2 id="what-exactly-are-hyperparameters">What Exactly Are Hyperparameters?</h2> <p>In machine learning, we deal with two types of ‘parameters’. Model parameters are values the model <em>learns</em> during training, like the weights in a neural network. Hyperparameters, however, are configurations we set <em>before</em> training. They dictate <em>how</em> the model learns. Examples include the learning rate for an optimizer ($\alpha$), the number of neighbors ($k$) in a K-Nearest Neighbors (KNN) algorithm, or the maximum depth of a decision tree. They are essentially the ‘settings’ of your learning process.</p> <h2 id="why-does-tuning-matter-so-much">Why Does Tuning Matter So Much?</h2> <p>Setting hyperparameters randomly is like guessing the oven temperature – you might get lucky, but more often you’ll end up with a burnt or undercooked cake. Poorly chosen hyperparameters can lead to:</p> <ul> <li> <strong>Underfitting:</strong> Your model is too simple and can’t learn patterns from the data (like a cake that didn’t rise).</li> <li> <strong>Overfitting:</strong> Your model learns the training data <em>too</em> well, but fails on new, unseen data (the cake looks perfect, but tastes bad).</li> <li> <strong>Slow Training:</strong> Inefficient learning rates can make training agonizingly long.</li> </ul> <p>Proper tuning ensures your model generalizes well to new data, making it robust and useful in the real world.</p> <h2 id="the-journey-to-optimal-settings-tuning-methods">The Journey to Optimal Settings: Tuning Methods</h2> <p>So, how do we find these ‘perfect’ settings?</p> <ol> <li> <p><strong>Manual Tuning:</strong> The simplest but least efficient method. You try values, see results, and repeat. Good for quick initial exploration, but largely impractical for complex models or large search spaces.</p> </li> <li> <p><strong>Grid Search:</strong> Imagine you have two hyperparameters: <code class="language-plaintext highlighter-rouge">learning_rate</code> and <code class="language-plaintext highlighter-rouge">batch_size</code>. <code class="language-plaintext highlighter-rouge">learning_rate</code> options: $[0.001, 0.01, 0.1]$ <code class="language-plaintext highlighter-rouge">batch_size</code> options: $[16, 32, 64]$ Grid Search tries <em>every single combination</em>: $(0.001, 16)$, $(0.001, 32)$, …, $(0.1, 64)$. It’s exhaustive and guarantees finding the best combination within your defined search space. However, as the number of hyperparameters and their possible values grow, the computational cost explodes. If you have $N$ hyperparameters, each with $M$ possible values, you’d perform $M^N$ trials. That’s a lot of cake baking!</p> </li> <li> <p><strong>Random Search:</strong> Instead of trying every point on the ‘grid’, Random Search randomly samples points from the specified search space. Surprisingly, it often finds a ‘good enough’ or even optimal hyperparameter combination much faster than Grid Search, especially when only a few hyperparameters truly impact performance. It’s like randomly picking oven temperatures and times, but covering a wider range faster.</p> </li> <li> <p><strong>Bayesian Optimization:</strong> This is where things get really smart. Bayesian Optimization uses probability to build a ‘surrogate model’ that estimates the performance of different hyperparameter combinations based on past evaluations. It intelligently chooses the <em>next</em> set of hyperparameters to try, balancing exploration (trying new, unknown areas) and exploitation (refining promising areas). Think of it as an experienced chef who learns from every batch of cake and wisely adjusts the recipe for the next one, rather than randomly trying or exhaustively checking every option. It’s generally much more computationally efficient for complex problems.</p> </li> </ol> <h2 id="key-takeaways-for-your-tuning-adventures">Key Takeaways for Your Tuning Adventures</h2> <ul> <li> <strong>Validation is King:</strong> Always evaluate your models on a separate validation set, never just the training set. This gives an unbiased estimate of performance on new data.</li> <li> <strong>Start Broad, Then Refine:</strong> Begin with a wide search range, then narrow it down around promising values.</li> <li> <strong>Patience:</strong> Tuning can be time-consuming, but the reward is a much more robust and accurate model.</li> </ul> <h2 id="conclusion">Conclusion</h2> <p>Hyperparameter tuning isn’t just a technical step; it’s an art that transforms a basic model into a high-performing one. It’s about understanding your model’s sensitivity and guiding its learning process to achieve optimal results. So, next time you’re building a model, remember to tweak those knobs – your future self (and your users) will thank you for the perfectly baked result!</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/cracking-the-ai-black-box-why-explainable-ai-xai-i/">Cracking the AI Black Box: Why Explainable AI (XAI) is Our Superpower</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/the-secret-life-of-states-how-markov-chains-predic/">The Secret Life of States: How Markov Chains Predict Our Next Move (Without Remembering the Past!)</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/gradient-descent-unpacking-the-engine-of-machine-l/">Gradient Descent: Unpacking the Engine of Machine Learning</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Adarsh Nair. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/blog/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/masonry.js?v=a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/zoom.js?v=85ddb88934d28b74e78031fd54cf8308"></script> <script src="/blog/assets/js/no_defer.js?v=2781658a0a2b13ed609542042a859126"></script> <script defer src="/blog/assets/js/common.js?v=c15de51d4bb57887caa2c21988d97279"></script> <script defer src="/blog/assets/js/copy_code.js?v=c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/blog/assets/js/jupyter_new_tab.js?v=d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/blog/assets/js/mathjax-setup.js?v=a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/progress-bar.js?v=2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/blog/assets/js/vanilla-back-to-top.min.js?v=f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/blog/assets/js/search/ninja-keys.min.js?v=a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/blog/assets/js/search-setup.js?v=6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/blog/assets/js/search-data.js"></script> <script src="/blog/assets/js/shortcut-key.js?v=ccc841c459bfc0e64c1c2b5acd10df02"></script> </body> </html>