<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Taming the Overfit Beast: My Journey with Regularization in Machine Learning | Adarsh Nair </title> <meta name="author" content="Adarsh Nair"> <meta name="description" content="A deep dive into machine learning, AI, and data science. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <meta http-equiv="Content-Security-Policy" content="default-src 'self'; script-src 'self' 'unsafe-inline' https:; style-src 'self' 'unsafe-inline' https:; img-src 'self' data: https:; font-src 'self' data: https:; media-src 'self' https:; frame-src 'self' https:; connect-src 'self' https:;"> <link rel="stylesheet" href="/blog/assets/css/bootstrap.min.css?v=a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/blog/assets/css/academicons.min.css?v=f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/blog/assets/css/scholar-icons.css?v=62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-github.css?v=591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/blog/assets/css/main.css?v=d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://adarshnair.online/blog/blog/blog/2024/taming-the-overfit-beast-my-journey-with-regulariz/"> <script src="/blog/assets/js/theme.js?v=5fea5159b787642c1bbc1f334d60f883"></script> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-native.css?v=5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="https://adarshnair.online" rel="external nofollow noopener" target="_blank"> Adarsh Nair </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/blog/"> </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/index.html">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/about/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/cv/">CV </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="https://adarshnair.online/books/" rel="external nofollow noopener" target="_blank">books </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="fa-solid fa-magnifying-glass"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-half-sun-moon" id="light-toggle-system"></i> <i class="fa-solid fa-moon" id="light-toggle-dark"></i> <i class="fa-solid fa-sun" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Taming the Overfit Beast: My Journey with Regularization in Machine Learning</h1> <p class="post-meta"> Created on December 22, 2024 by Adarsh Nair </p> <p class="post-tags"> <a href="/blog/blog/2024"> <i class="fa-solid fa-calendar fa-sm"></i> 2024 </a>   ·   <a href="/blog/blog/tag/machine-learning"> <i class="fa-solid fa-hashtag fa-sm"></i> Machine Learning</a>   <a href="/blog/blog/tag/regularization"> <i class="fa-solid fa-hashtag fa-sm"></i> Regularization</a>   <a href="/blog/blog/tag/overfitting"> <i class="fa-solid fa-hashtag fa-sm"></i> Overfitting</a>   <a href="/blog/blog/tag/data-science"> <i class="fa-solid fa-hashtag fa-sm"></i> Data Science</a>   <a href="/blog/blog/tag/model-training"> <i class="fa-solid fa-hashtag fa-sm"></i> Model Training</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p>Oh, the thrill of building your first machine learning model! You gather data, meticulously clean it, choose an algorithm, train it, and then… <em>boom!</em> On your training set, the model performs like a superstar, predicting with astounding accuracy. You feel like a wizard. Then, you unleash it on new, unseen data, and suddenly, it’s less wizard, more bewildered. The accuracy tanks. The predictions are wild. What happened?</p> <p>Welcome, my friends, to the frustrating, yet utterly common, world of <strong>overfitting</strong>. It’s a rite of passage for every aspiring data scientist and machine learning engineer. I remember my own early encounters with it, staring at evaluation metrics, wondering if I’d accidentally summoned a data-eating demon instead of a predictive model.</p> <p>This is where <strong>regularization</strong> enters the stage – not as a fancy algorithm, but as a fundamental <em>principle</em> that helps our models learn smarter, not just harder. Think of it as the wise mentor who tells your enthusiastic model, “Slow down, don’t try to memorize everything; understand the general patterns.”</p> <h3 id="the-overfitting-dilemma-when-models-get-too-smart-for-their-own-good">The Overfitting Dilemma: When Models Get Too Smart for Their Own Good</h3> <p>Imagine you’re studying for a history exam. You could spend hours memorizing every single date, name, and obscure fact from the textbook. You might ace a quiz that uses exact phrases from the book. But if the actual exam asks you to <em>analyze</em> events or <em>apply</em> concepts you’ve learned, your memorization strategy might fail. You’ve overfit to the training material.</p> <p>In machine learning, overfitting happens when our model learns the training data <em>too well</em>. It doesn’t just learn the underlying signal; it memorizes the noise, the quirks, and the random fluctuations specific to that particular dataset. When confronted with new data, which inevitably has different noise and quirks, the model crumbles because it never learned the true, generalizable patterns.</p> <p>Visually, imagine fitting a line through a set of data points that roughly follow a linear trend, but have some random scatter.</p> <ul> <li>A <strong>simple linear model</strong> might be a straight line, capturing the main trend but missing some local wiggles. (Slightly underfit, high bias).</li> <li>A <strong>highly complex polynomial model</strong> might draw a crazy wiggly line that passes <em>exactly</em> through every single data point. It looks perfect on the training data! But outside of those specific points, its predictions would be erratic. This is our overfit beast. (Low bias, high variance).</li> </ul> <p>The danger of an overfit model is that it has high <strong>variance</strong>. This means its predictions are highly sensitive to small changes in the training data, leading to poor generalization on new, unseen data. Our goal is always to build models that generalize well.</p> <h3 id="what-is-regularization-really-the-art-of-adding-a-penalty">What is Regularization, Really? The Art of Adding a Penalty</h3> <p>So, how do we rein in this overzealous model? Regularization provides an elegant solution: we add a “penalty” to our model’s objective function (the thing it tries to minimize).</p> <p>Recall that most machine learning models learn by minimizing a <strong>loss function</strong>. This loss function measures how far off the model’s predictions are from the actual values. For instance, in linear regression, we often minimize the Mean Squared Error (MSE):</p> <p>$J(\theta) = \frac{1}{2m} \sum_{i=1}^{m} (h_\theta(x^{(i)}) - y^{(i)})^2$</p> <p>Here, $J(\theta)$ is our cost function, $h_\theta(x^{(i)})$ is our model’s prediction for the $i$-th example, $y^{(i)}$ is the actual value, $m$ is the number of training examples, and $\theta$ represents the model’s parameters (weights).</p> <p>Regularization modifies this cost function by adding an extra term that punishes large parameter values:</p> <p>$J_{regularized}(\theta) = \text{Loss}(\theta) + \text{Penalty}(\theta)$</p> <p>Why penalize large parameters? Because large parameters often lead to complex, wiggly models. If a parameter (weight) associated with a feature is very large, it means that feature has a disproportionately strong influence on the prediction, allowing the model to contort itself to fit every tiny detail of the training data, including the noise. By pushing these weights towards zero, regularization forces the model to be simpler and rely less on any single feature, thereby encouraging it to learn more general patterns.</p> <p>It’s like a parent telling a child, “You can have all the candy you want, but every candy you eat adds a penalty to your chores.” The child still wants candy (minimize loss), but the penalty encourages them to be moderate (smaller weights).</p> <h3 id="delving-into-the-penalties-l1-vs-l2-regularization">Delving into the Penalties: L1 vs. L2 Regularization</h3> <p>There are two primary types of regularization, distinguished by how they define this “penalty” term:</p> <h4 id="1-l2-regularization-ridge-regression">1. L2 Regularization (Ridge Regression)</h4> <p>Also known as <strong>Ridge Regression</strong> when applied to linear regression, L2 regularization adds the sum of the <em>squares</em> of the model’s weights to the loss function.</p> <p>The penalty term looks like this: $\lambda \sum_{j=1}^{n} \theta_j^2$</p> <p>So, our new regularized cost function becomes: $J_{Ridge}(\theta) = \frac{1}{2m} \sum_{i=1}^{m} (h_\theta(x^{(i)}) - y^{(i)})^2 + \lambda \sum_{j=1}^{n} \theta_j^2$</p> <p>(Note: The $\frac{1}{2}$ in the penalty term is often added for mathematical convenience during differentiation, but it doesn’t change the fundamental concept.)</p> <ul> <li> <strong>How it works:</strong> L2 regularization aims to shrink the magnitude of the coefficients towards zero, but it rarely makes them exactly zero. It spreads the “importance” more evenly across all features.</li> <li> <strong>Geometric intuition:</strong> Imagine the error surface as a bowl. The regularization term adds another bowl-shaped constraint. The optimal weights are found where these two “bowls” (the original loss and the penalty) combine to form a new minimum. Because the penalty is quadratic, it tends to keep all weights present, just smaller.</li> <li> <strong>Effect:</strong> Reduces model complexity and multicollinearity (when features are highly correlated), leading to lower variance. It’s excellent for making models more stable and less sensitive to specific training data points.</li> </ul> <h4 id="2-l1-regularization-lasso-regression">2. L1 Regularization (Lasso Regression)</h4> <p>Often called <strong>Lasso Regression</strong> (Least Absolute Shrinkage and Selection Operator), L1 regularization adds the sum of the <em>absolute values</em> of the model’s weights to the loss function.</p> <table> <tbody> <tr> <td>The penalty term looks like this: $\lambda \sum_{j=1}^{n}</td> <td>\theta_j</td> <td>$</td> </tr> </tbody> </table> <p>Our regularized cost function now looks like: $J_{Lasso}(\theta) = \frac{1}{2m} \sum_{i=1}^{m} (h_\theta(x^{(i)}) - y^{(i)})^2 + \lambda \sum_{j=1}^{n} |\theta_j|$</p> <ul> <li> <strong>How it works:</strong> Unlike L2, L1 regularization has a very interesting property: it can shrink some coefficients <em>all the way to zero</em>. This means it effectively performs <strong>feature selection</strong>, discarding features that it deems less important by giving them a weight of zero.</li> <li> <strong>Geometric intuition:</strong> The penalty term for L1 regularization forms a diamond shape (in 2D, or an octahedron in higher dimensions) around the origin. When this diamond intersects the elliptical error surface (from the loss function), it tends to do so at the vertices, where some coefficients are exactly zero.</li> <li> <strong>Effect:</strong> Reduces model complexity, reduces variance, and provides a sparse model by selecting a subset of the most important features. This is incredibly useful when dealing with datasets that have many features, some of which might be irrelevant.</li> </ul> <h4 id="the-lambda-lambda-parameter-the-regularization-dial">The $\lambda$ (Lambda) Parameter: The Regularization Dial</h4> <p>You might have noticed the $\lambda$ (lambda) symbol in both penalty terms. This is perhaps the most crucial part of regularization. $\lambda$ is a <strong>hyperparameter</strong> that controls the strength of the regularization.</p> <ul> <li> <strong>If $\lambda$ is 0:</strong> The penalty term vanishes, and we’re back to our original, unregularized model. This means high risk of overfitting.</li> <li> <strong>If $\lambda$ is very small:</strong> The penalty is minor, and the model’s weights are only slightly constrained.</li> <li> <strong>If $\lambda$ is very large:</strong> The penalty dominates the loss function. The model will prioritize making the weights small (or zero in L1’s case) even if it means sacrificing fit to the training data. This can lead to <strong>underfitting</strong>, where the model is too simple to capture the underlying patterns, performing poorly on both training and test data.</li> </ul> <p>The art of using regularization lies in finding the optimal $\lambda$ value. This is typically done through techniques like <strong>cross-validation</strong>, where you test different $\lambda$ values on various subsets of your training data to see which one yields the best generalization performance on a validation set.</p> <h3 id="the-bias-variance-trade-off-revisited">The Bias-Variance Trade-Off Revisited</h3> <p>Regularization directly impacts the famous <strong>bias-variance trade-off</strong>.</p> <ul> <li> <strong>Unregularized models</strong> (especially complex ones) often have low bias (they fit the training data very well) but high variance (they don’t generalize well).</li> <li> <strong>Regularization</strong> introduces a small amount of <strong>bias</strong> (the model might not fit the training data <em>perfectly</em> anymore) but significantly <strong>reduces variance</strong>.</li> </ul> <p>Our goal isn’t to eliminate bias or variance entirely, but to find a sweet spot that minimizes the overall error on unseen data. Regularization is a powerful tool for striking this balance.</p> <h3 id="beyond-linear-models-regularizations-ubiquitous-presence">Beyond Linear Models: Regularization’s Ubiquitous Presence</h3> <p>While we discussed Ridge and Lasso in the context of linear regression, the concept of regularization is far-reaching:</p> <ul> <li> <strong>Logistic Regression:</strong> L1 and L2 regularization (often just called L1 and L2 penalties) are standard in logistic regression to prevent overfitting.</li> <li> <strong>Neural Networks:</strong> Regularization is absolutely critical for deep learning models. <ul> <li> <strong>L1/L2 penalties</strong> are applied to the weights of neural networks, often called “weight decay.”</li> <li> <strong>Dropout</strong> is a powerful regularization technique specific to neural networks, where randomly selected neurons are “dropped out” (ignored) during training. This forces the network to learn more robust features and prevents over-reliance on any single neuron.</li> <li> <strong>Early Stopping</strong> is another common technique where you monitor the model’s performance on a validation set and stop training when performance starts to degrade (indicating overfitting).</li> </ul> </li> </ul> <h3 id="practical-takeaways--my-reflection">Practical Takeaways &amp; My Reflection</h3> <p>Regularization is not just a theoretical concept; it’s a fundamental, practical tool in the data scientist’s arsenal. I’ve seen countless models improve dramatically simply by carefully applying regularization.</p> <ul> <li> <strong>Always consider it:</strong> Especially when dealing with complex models, limited data, or high-dimensional datasets.</li> <li> <strong>Understand the types:</strong> Choose between L1 and L2 based on your needs. If feature selection is important, L1 (Lasso) is your friend. If you just want to shrink weights and keep all features, L2 (Ridge) is a solid choice. Sometimes, a combination (Elastic Net) is used.</li> <li> <strong>Tune $\lambda$ wisely:</strong> This is a hyperparameter, and finding its optimal value is crucial. Don’t guess; use cross-validation!</li> </ul> <p>My own journey with machine learning has been a continuous lesson in humility and careful experimentation. Regularization, at first, seemed like just another mathematical term to memorize. But as I built more models, wrestled with more datasets, and faced the sting of overfitting repeatedly, I came to appreciate its profound elegance and necessity. It’s not about making your model less capable, but about guiding it to be <em>wiser</em> – to learn the essence of the data, not just its fleeting surface details.</p> <p>So, the next time your model acts like an overenthusiastic student memorizing every word of the textbook, remember regularization. It’s the gentle hand that guides your model from merely memorizing to truly understanding, ensuring it’s ready for the unpredictable real world. Happy modeling!</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/cracking-the-ai-black-box-why-explainable-ai-xai-i/">Cracking the AI Black Box: Why Explainable AI (XAI) is Our Superpower</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/the-secret-life-of-states-how-markov-chains-predic/">The Secret Life of States: How Markov Chains Predict Our Next Move (Without Remembering the Past!)</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/gradient-descent-unpacking-the-engine-of-machine-l/">Gradient Descent: Unpacking the Engine of Machine Learning</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Adarsh Nair. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/blog/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/masonry.js?v=a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/zoom.js?v=85ddb88934d28b74e78031fd54cf8308"></script> <script src="/blog/assets/js/no_defer.js?v=2781658a0a2b13ed609542042a859126"></script> <script defer src="/blog/assets/js/common.js?v=c15de51d4bb57887caa2c21988d97279"></script> <script defer src="/blog/assets/js/copy_code.js?v=c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/blog/assets/js/jupyter_new_tab.js?v=d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/blog/assets/js/mathjax-setup.js?v=a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/progress-bar.js?v=2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/blog/assets/js/vanilla-back-to-top.min.js?v=f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/blog/assets/js/search/ninja-keys.min.js?v=a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/blog/assets/js/search-setup.js?v=6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/blog/assets/js/search-data.js"></script> <script src="/blog/assets/js/shortcut-key.js?v=ccc841c459bfc0e64c1c2b5acd10df02"></script> </body> </html>