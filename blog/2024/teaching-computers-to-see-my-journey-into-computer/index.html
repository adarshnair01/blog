<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Teaching Computers to See: My Journey into Computer Vision's Magic | Adarsh Nair </title> <meta name="author" content="Adarsh Nair"> <meta name="description" content="A deep dive into machine learning, AI, and data science. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <meta http-equiv="Content-Security-Policy" content="default-src 'self'; script-src 'self' 'unsafe-inline' https:; style-src 'self' 'unsafe-inline' https:; img-src 'self' data: https:; font-src 'self' data: https:; media-src 'self' https:; frame-src 'self' https:; connect-src 'self' https:;"> <link rel="stylesheet" href="/blog/assets/css/bootstrap.min.css?v=a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/blog/assets/css/academicons.min.css?v=f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/blog/assets/css/scholar-icons.css?v=62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-github.css?v=591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/blog/assets/css/main.css?v=d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://adarshnair.online/blog/blog/2024/teaching-computers-to-see-my-journey-into-computer/"> <script src="/blog/assets/js/theme.js?v=5fea5159b787642c1bbc1f334d60f883"></script> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-native.css?v=5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/blog/cv/"> Adarsh Nair </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/blog/"> </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/cv/">CV </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/repositories/">repositories </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="fa-solid fa-magnifying-glass"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-half-sun-moon" id="light-toggle-system"></i> <i class="fa-solid fa-moon" id="light-toggle-dark"></i> <i class="fa-solid fa-sun" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Teaching Computers to See: My Journey into Computer Vision's Magic</h1> <p class="post-meta"> Created on November 26, 2024 by Adarsh Nair </p> <p class="post-tags"> <a href="/blog/blog/2024"> <i class="fa-solid fa-calendar fa-sm"></i> 2024 </a>   ·   <a href="/blog/blog/tag/computer-vision"> <i class="fa-solid fa-hashtag fa-sm"></i> Computer Vision</a>   <a href="/blog/blog/tag/deep-learning"> <i class="fa-solid fa-hashtag fa-sm"></i> Deep Learning</a>   <a href="/blog/blog/tag/machine-learning"> <i class="fa-solid fa-hashtag fa-sm"></i> Machine Learning</a>   <a href="/blog/blog/tag/data-science"> <i class="fa-solid fa-hashtag fa-sm"></i> Data Science</a>   <a href="/blog/blog/tag/ai"> <i class="fa-solid fa-hashtag fa-sm"></i> AI</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <h2 id="teaching-computers-to-see-my-journey-into-computer-visions-magic">Teaching Computers to See: My Journey into Computer Vision’s Magic</h2> <p>Hey everyone!</p> <p>As a data science enthusiast, there are few fields that captivate me quite like Computer Vision (CV). It’s a discipline that sits at the thrilling intersection of artificial intelligence, machine learning, and pure human curiosity. From the moment I first saw a computer identify a cat in a photo, I was hooked. It’s not just about cool tech demos; it’s about giving machines one of the most fundamental human senses: sight.</p> <p>But let’s be honest, “sight” for a computer is vastly different from how <em>we</em> see. When you look at an apple, you instantly recognize it, know its color, its shape, even if it’s bruised. You don’t consciously process millions of light signals, analyze edges, and then combine features. Your brain does it effortlessly. For a computer, this “effortless” task is incredibly complex, requiring sophisticated algorithms, vast amounts of data, and incredible computational power.</p> <p>So, buckle up! In this post, I want to take you on a journey through Computer Vision – how it works, why it’s so powerful, and some of the amazing things it can do. My goal is to make it accessible for anyone curious, whether you’re just starting to explore AI or are already deep into data science.</p> <h3 id="what-is-computer-vision-a-digital-eye-on-the-world">What <em>Is</em> Computer Vision? A Digital Eye on the World</h3> <p>At its core, Computer Vision is a field of artificial intelligence that trains computers to “understand” and interpret visual data from the world. This data can come in many forms: images, videos, 3D scans, etc. The ultimate goal is to enable machines to perform tasks that typically require human visual perception.</p> <p>Think about it:</p> <ul> <li>Identifying objects (Is that a car or a truck?).</li> <li>Recognizing faces (Who is this person?).</li> <li>Detecting actions (Is someone falling?).</li> <li>Navigating environments (Where am I, and where should I go?).</li> </ul> <p>These are trivial for us, but for a computer, each involves a colossal amount of data processing and intelligent decision-making.</p> <h3 id="the-evolution-from-edge-detectors-to-deep-dreams">The Evolution: From Edge Detectors to Deep Dreams</h3> <p>For decades, scientists have tried to teach computers to see. Early attempts often involved handcrafted features – essentially, programmers manually defined what an “edge” looked like, or what specific texture indicated a certain object. These methods, while ingenious for their time, were fragile. A slight change in lighting, perspective, or object deformation could completely throw them off. It was like teaching a child to recognize a specific toy, but only if it’s always in the same position and lighting.</p> <p>Then came the “Deep Learning revolution.” Around 2012, with the advent of powerful Graphics Processing Units (GPUs) and massive datasets, a new paradigm took hold: <strong>Convolutional Neural Networks (CNNs)</strong>. This was a game-changer. Instead of us telling the computer <em>what</em> features to look for, CNNs learned these features <em>automatically</em> from the data. It was like giving the child millions of pictures of toys in every imaginable scenario and letting them figure out what makes a toy a toy.</p> <h3 id="how-does-a-computer-see-the-pixel-level-story">How Does a Computer “See”? The Pixel-Level Story</h3> <p>Before we dive deeper into CNNs, let’s understand how an image is represented to a computer. Unlike our eyes, which perceive a continuous spectrum of light, computers see images as a grid of tiny squares called <strong>pixels</strong>.</p> <p>Each pixel has a numerical value representing its color and intensity. For a grayscale image, a pixel might have a single value (e.g., 0 for black, 255 for white). For a color image, it’s typically represented by three values: Red, Green, and Blue (RGB). So, an image is just a massive array (or matrix) of numbers!</p> <p>Imagine a small 3x3 image:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[[200, 180, 150],
 [170,  50, 120],
 [140, 110,  90]]
</code></pre></div></div> <p>This array represents a tiny part of an image. Now, imagine an entire 1920x1080 pixel high-definition image, with three such arrays for RGB. That’s millions of numbers! The challenge is to extract meaningful information from this sea of digits.</p> <h3 id="the-magic-of-convolutional-neural-networks-cnns">The Magic of Convolutional Neural Networks (CNNs)</h3> <p>This is where CNNs truly shine. They’re designed specifically to process data that has a known grid-like topology, like images. The core idea is to automatically learn a hierarchy of features directly from the raw pixel data.</p> <p>Let’s break down the key players:</p> <h4 id="1-convolutional-layers-the-feature-detectives">1. Convolutional Layers: The Feature Detectives</h4> <p>This is the heart of a CNN. Instead of looking at individual pixels in isolation, a convolutional layer uses a small filter (also called a <em>kernel</em> or <em>feature detector</em>) that slides across the entire image. This filter is a small matrix of numbers.</p> <p>Think of the filter as a tiny magnifying glass, looking for specific patterns – like edges, textures, or corners. At each position, it performs a mathematical operation called a <strong>convolution</strong> with the underlying pixels.</p> <p>Mathematically, a 2D convolution operation can be expressed as:</p> \[(I * K)(i, j) = \sum_m \sum_n I(i-m, j-n)K(m, n)\] <p>Where:</p> <ul> <li>$I$ is the input image (or feature map from a previous layer).</li> <li>$K$ is the kernel (filter) matrix.</li> <li>$(i, j)$ represents the coordinates of the output pixel.</li> <li>$m, n$ iterate over the dimensions of the kernel.</li> </ul> <p>What does this scary formula mean? It’s simply multiplying corresponding pixel values under the filter with the filter’s values, and then summing them up to produce a single output pixel in a new “feature map.” This process is repeated for the entire image.</p> <p>By sliding these filters, the convolutional layer generates new images (feature maps) that highlight where certain features are present. Early layers might detect simple edges, while deeper layers combine these simple features to detect more complex patterns like eyes, ears, or wheels. The beauty is that the network <em>learns</em> the optimal values for these filters during training!</p> <h4 id="2-activation-functions-adding-the-non-linear-spark">2. Activation Functions: Adding the Non-Linear Spark</h4> <p>After a convolution, an <strong>activation function</strong> (like ReLU, or Rectified Linear Unit) is applied to the output. Why? Because the real world isn’t linear! This function introduces non-linearity, allowing the network to learn more complex patterns and relationships that simple linear transformations couldn’t capture. It’s like adding gears to a bicycle – without them, you can only go so far.</p> <h4 id="3-pooling-layers-downsampling-for-efficiency">3. Pooling Layers: Downsampling for Efficiency</h4> <p>Pooling layers (most commonly Max Pooling) reduce the spatial dimensions (width and height) of the feature maps. Imagine taking a 2x2 window, sliding it across the feature map, and just picking the maximum value within each window. This achieves two things:</p> <ul> <li> <strong>Reduces computation:</strong> Less data to process in subsequent layers.</li> <li> <strong>Introduces spatial invariance:</strong> Makes the network slightly more robust to small shifts or distortions in the input image. If an object shifts a few pixels, the max-pooled output might remain the same.</li> </ul> <h4 id="4-fully-connected-layers-the-final-decision-makers">4. Fully Connected Layers: The Final Decision Makers</h4> <p>After several convolutional and pooling layers have extracted rich, hierarchical features, these features are “flattened” into a single vector and fed into one or more <strong>fully connected layers</strong>. These layers are similar to traditional neural networks, where every neuron in one layer connects to every neuron in the next. They take the high-level features learned by the CNN and use them to make final predictions, like “this is a cat” or “this is a dog.”</p> <h3 id="key-tasks-computer-vision-can-accomplish">Key Tasks Computer Vision Can Accomplish</h3> <p>With CNNs at their heart, Computer Vision systems can tackle an incredible array of tasks:</p> <ol> <li> <p><strong>Image Classification:</strong> Answering “What’s in this image?” This is the classic “cat vs. dog” problem. Given an image, the model assigns it to one of several predefined categories.</p> </li> <li> <p><strong>Object Detection:</strong> Going a step further, object detection not only identifies <em>what</em> objects are in an image but also <em>where</em> they are, usually by drawing a bounding box around them. Think self-driving cars identifying pedestrians, other vehicles, and traffic signs. Models like YOLO (You Only Look Once) and R-CNN are famous in this domain.</p> </li> <li> <strong>Image Segmentation:</strong> This is even more granular! Image segmentation assigns a label to <em>every single pixel</em> in an image. <ul> <li> <strong>Semantic Segmentation:</strong> Labels pixels belonging to a class (e.g., all pixels that are “sky” are labeled as sky, all “car” pixels as car).</li> <li> <strong>Instance Segmentation:</strong> Distinguishes between individual instances of objects (e.g., separating “car 1” from “car 2” even if they’re the same class). This is crucial for applications like robotic manipulation.</li> </ul> </li> <li> <p><strong>Facial Recognition:</strong> Identifying individuals from images or video. Found in everything from smartphone unlocks to security systems.</p> </li> <li> <p><strong>Pose Estimation:</strong> Locating key points (joints, landmarks) on a person or object to understand their spatial orientation and movement. Used in sports analysis, augmented reality, and even healthcare.</p> </li> <li> <strong>Medical Imaging Analysis:</strong> Detecting anomalies in X-rays, MRIs, and CT scans, aiding doctors in early diagnosis of diseases like cancer or identifying fractures.</li> </ol> <h3 id="the-why-now-moment-why-computer-vision-is-exploding">The “Why Now?” Moment: Why Computer Vision is Exploding</h3> <p>The rapid advancement and widespread adoption of Computer Vision can be attributed to a perfect storm of factors:</p> <ul> <li> <strong>Massive Datasets:</strong> The internet has provided an unprecedented amount of visual data (images, videos) needed to train complex deep learning models.</li> <li> <strong>Computational Power:</strong> GPUs, originally designed for gaming graphics, are perfect for the parallel computations required by CNNs, making training feasible in a reasonable timeframe.</li> <li> <strong>Algorithmic Innovations:</strong> Continuous research has led to more efficient architectures (ResNet, Inception, Transformers for vision) and training techniques that push performance boundaries.</li> <li> <strong>Open-Source Ecosystem:</strong> Frameworks like TensorFlow and PyTorch, along with pre-trained models, have democratized access to powerful CV tools, allowing data scientists and developers to experiment and build.</li> </ul> <h3 id="the-road-ahead-challenges-and-future-horizons">The Road Ahead: Challenges and Future Horizons</h3> <p>Despite the incredible progress, Computer Vision still faces exciting challenges:</p> <ul> <li> <strong>Bias:</strong> Models can inherit biases present in their training data, leading to unfair or inaccurate predictions, especially in sensitive areas like facial recognition.</li> <li> <strong>Explainability:</strong> Understanding <em>why</em> a complex deep learning model makes a particular decision can be difficult (the “black box” problem).</li> <li> <strong>Robustness:</strong> Models trained on specific datasets might perform poorly in slightly different real-world conditions (e.g., different lighting, unexpected scenarios).</li> <li> <strong>Real-time Performance:</strong> Many applications require instantaneous processing, which can be computationally intensive.</li> </ul> <p>Looking forward, the field is buzzing with innovations like self-supervised learning (training models with less labeled data), foundation models for vision (large models pre-trained on vast datasets that can adapt to many tasks), and advancements in 3D vision. We’re moving towards systems that not only “see” but also understand context, anticipate actions, and even generate realistic images.</p> <h3 id="my-personal-take">My Personal Take</h3> <p>Diving into Computer Vision has been an exhilarating experience for me. It’s a field where you can truly see the impact of your work, whether it’s building a safer autonomous vehicle, assisting in medical diagnoses, or creating more immersive augmented reality experiences.</p> <p>The journey from understanding how pixels combine to form an image, to grappling with the elegance of a convolution operation, and finally witnessing a model accurately identify complex objects, is incredibly rewarding. It’s a constant reminder of how far we’ve come in AI, and how much more there is to explore.</p> <p>If you’re interested in data science or machine learning, I highly encourage you to explore Computer Vision. Pick up a dataset, play with a pre-trained CNN, and try to make a computer see the world through your code. It’s a field brimming with possibilities, and I’m excited to continue my own adventure in it!</p> <p>Happy coding, and keep exploring!</p> <hr> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/cracking-the-ai-black-box-why-explainable-ai-xai-i/">Cracking the AI Black Box: Why Explainable AI (XAI) is Our Superpower</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/the-secret-life-of-states-how-markov-chains-predic/">The Secret Life of States: How Markov Chains Predict Our Next Move (Without Remembering the Past!)</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/gradient-descent-unpacking-the-engine-of-machine-l/">Gradient Descent: Unpacking the Engine of Machine Learning</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Adarsh Nair. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/blog/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/masonry.js?v=a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/zoom.js?v=85ddb88934d28b74e78031fd54cf8308"></script> <script src="/blog/assets/js/no_defer.js?v=2781658a0a2b13ed609542042a859126"></script> <script defer src="/blog/assets/js/common.js?v=c15de51d4bb57887caa2c21988d97279"></script> <script defer src="/blog/assets/js/copy_code.js?v=c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/blog/assets/js/jupyter_new_tab.js?v=d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/blog/assets/js/mathjax-setup.js?v=a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/progress-bar.js?v=2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/blog/assets/js/vanilla-back-to-top.min.js?v=f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/blog/assets/js/search/ninja-keys.min.js?v=a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/blog/assets/js/search-setup.js?v=6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/blog/assets/js/search-data.js"></script> <script src="/blog/assets/js/shortcut-key.js?v=ccc841c459bfc0e64c1c2b5acd10df02"></script> </body> </html>