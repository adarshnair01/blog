<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> The Goldilocks Zone of Machine Learning: Finding \\\"Just Right\\\" with Overfitting vs. Underfitting | Adarsh Nair </title> <meta name="author" content="Adarsh Nair"> <meta name="description" content="A deep dive into machine learning, AI, and data science. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <meta http-equiv="Content-Security-Policy" content="default-src 'self'; script-src 'self' 'unsafe-inline' https:; style-src 'self' 'unsafe-inline' https:; img-src 'self' data: https:; font-src 'self' data: https:; media-src 'self' https:; frame-src 'self' https:; connect-src 'self' https:;"> <link rel="stylesheet" href="/blog/assets/css/bootstrap.min.css?v=a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/blog/assets/css/academicons.min.css?v=f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/blog/assets/css/scholar-icons.css?v=62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-github.css?v=591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/blog/assets/css/main.css?v=d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://adarshnair.online/blog/blog/blog/2024/the-goldilocks-zone-of-machine-learning-finding-ju/"> <script src="/blog/assets/js/theme.js?v=5fea5159b787642c1bbc1f334d60f883"></script> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-native.css?v=5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/blog/cv/"> Adarsh Nair </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/blog/"> </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/index.html">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/cv/">CV </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/repositories/">repositories </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="fa-solid fa-magnifying-glass"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-half-sun-moon" id="light-toggle-system"></i> <i class="fa-solid fa-moon" id="light-toggle-dark"></i> <i class="fa-solid fa-sun" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">The Goldilocks Zone of Machine Learning: Finding \\\"Just Right\\\" with Overfitting vs. Underfitting</h1> <p class="post-meta"> Created on June 05, 2024 by Adarsh Nair </p> <p class="post-tags"> <a href="/blog/blog/2024"> <i class="fa-solid fa-calendar fa-sm"></i> 2024 </a>   ·   <a href="/blog/blog/tag/machine-learning"> <i class="fa-solid fa-hashtag fa-sm"></i> Machine Learning</a>   <a href="/blog/blog/tag/data-science"> <i class="fa-solid fa-hashtag fa-sm"></i> Data Science</a>   <a href="/blog/blog/tag/overfitting"> <i class="fa-solid fa-hashtag fa-sm"></i> Overfitting</a>   <a href="/blog/blog/tag/underfitting"> <i class="fa-solid fa-hashtag fa-sm"></i> Underfitting</a>   <a href="/blog/blog/tag/model-evaluation"> <i class="fa-solid fa-hashtag fa-sm"></i> Model Evaluation</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p>Hey everyone!</p> <p>As someone deeply immersed in the fascinating world of data science and machine learning, I’ve come to realize that some concepts, while seemingly simple on the surface, hold profound importance. They are the bedrock upon which all successful models are built, and understanding them is less about memorizing definitions and more about developing an intuitive feel for how models learn. Today, I want to talk about two such fundamental ideas: <strong>Overfitting</strong> and <strong>Underfitting</strong>.</p> <p>Think of it like this: building a machine learning model is a bit like learning for a really important exam. You’ve got your study materials (your training data), and you want to be able to ace the exam (perform well on new, unseen data). But there’s a trick: how do you study effectively without either knowing too little or memorizing too much?</p> <h3 id="the-study-analogy-a-high-stakes-exam">The Study Analogy: A High-Stakes Exam</h3> <p>Let’s imagine you’re studying for a big history exam.</p> <p><strong>Scenario 1: The “I didn’t study enough” Student (Underfitting)</strong> You barely skimmed the textbook, didn’t really pay attention in class, and maybe looked at a few flashcards the night before. When the exam comes, you’re lost. You can’t answer even the most basic questions, let alone the complex ones. Your understanding of history is too superficial.</p> <p><em>In ML terms:</em> Your model is <strong>underfitting</strong>. It’s too simple, too rigid, or hasn’t learned enough from the training data to capture the underlying patterns. It performs poorly not just on new data, but even on the data it was trained on!</p> <p><strong>Scenario 2: The “I memorized <em>everything</em> from the practice test” Student (Overfitting)</strong> You got your hands on a practice test and memorized every single question and answer. You can perfectly recite them! You feel confident. But then, the actual exam has slightly different wording, or new examples of the same concepts you saw on the practice test. Suddenly, you’re stumped. You can’t apply your memorized knowledge to slightly varied situations. Your “understanding” was too specific to the practice material.</p> <p><em>In ML terms:</em> Your model is <strong>overfitting</strong>. It has learned the training data <em>too well</em>, including the noise and specific quirks unique to that dataset. It’s like it memorized the answers instead of understanding the concepts. It performs brilliantly on the training data, but utterly fails when confronted with new, unseen data.</p> <p><strong>Scenario 3: The “Just Right” Student (The Goldilocks Zone)</strong> You studied diligently, understanding the key historical events, the cause-and-effect relationships, and the broader themes. You practiced different types of questions and learned to apply your knowledge to various scenarios. When the exam comes, you can answer questions, even those you haven’t seen before, because you genuinely <em>understand</em> the subject.</p> <p><em>In ML terms:</em> Your model has found the <strong>“Goldilocks Zone.”</strong> It has learned the essential patterns from the training data, can generalize well to new data, and makes accurate predictions on unseen examples. This is our ultimate goal!</p> <h3 id="diving-deeper-underfitting--the-simple-soul">Diving Deeper: Underfitting – The Simple Soul</h3> <p>Underfitting occurs when your model is too simple to capture the underlying structure of the data. It’s like trying to fit a straight line through a dataset that clearly follows a curve.</p> <p><strong>Characteristics of Underfitting:</strong></p> <ul> <li> <strong>High Bias:</strong> The model makes strong assumptions about the data’s form, which are incorrect. It consistently misses the mark.</li> <li> <strong>Poor performance on both training and test data:</strong> If your model can’t even get the answers right on the data it <em>has</em> seen, it certainly won’t on new data.</li> <li> <strong>Low Variance:</strong> Because the model is so simple, its predictions don’t change much if you give it slightly different training data. This sounds good, but it’s low variance <em>because it’s always wrong</em>.</li> </ul> <p><strong>Visualizing Underfitting:</strong> Imagine you have data points scattered in a parabolic shape. If you try to fit a linear regression model ($y = mx + c$) to this data, it will capture only a tiny fraction of the actual pattern. The line will be far from most data points.</p> <p><strong>Common Causes of Underfitting:</strong></p> <ol> <li> <strong>Model is too simple:</strong> Using a linear model for non-linear relationships.</li> <li> <strong>Insufficient features:</strong> Not providing the model with enough relevant information.</li> <li> <strong>Too much regularization:</strong> Regularization is often used to <em>prevent</em> overfitting, but too much of it can constrain the model excessively, leading to underfitting.</li> <li> <strong>Not enough training time/epochs:</strong> For iterative models like neural networks, stopping training too early can prevent the model from fully learning.</li> </ol> <p><strong>How to Fix Underfitting:</strong></p> <ul> <li> <strong>Increase model complexity:</strong> Use a more powerful model (e.g., polynomial regression instead of linear, decision tree instead of a simple perceptron, a deeper neural network).</li> <li> <strong>Add more features:</strong> Include more relevant input variables that might help the model learn the true relationships.</li> <li> <strong>Reduce regularization:</strong> If you’re using regularization techniques (like L1 or L2), try reducing their strength.</li> <li> <strong>Increase training time/epochs:</strong> Allow iterative models to learn for longer.</li> </ul> <h3 id="diving-deeper-overfitting--the-overachiever">Diving Deeper: Overfitting – The Overachiever</h3> <p>Overfitting is when your model learns the training data <em>too well</em>, essentially memorizing it along with its random fluctuations and noise. When presented with new data, which inevitably has different noise and slight variations, the overfitted model struggles because it’s looking for those exact memorized patterns.</p> <p><strong>Characteristics of Overfitting:</strong></p> <ul> <li> <strong>Low Bias:</strong> The model tries very hard to fit every single training point, so it doesn’t make strong, incorrect assumptions.</li> <li> <strong>Excellent performance on training data, poor performance on test/validation data:</strong> This is the tell-tale sign. A huge gap between training accuracy/score and test accuracy/score.</li> <li> <strong>High Variance:</strong> The model is extremely sensitive to the specific training data. If you train it on a slightly different dataset, it might produce a wildly different model.</li> </ul> <p><strong>Visualizing Overfitting:</strong> Again, imagine our parabolic data points. If you try to fit a very high-degree polynomial regression (e.g., degree 10 or 20) to this data, the curve might wiggle and bend to perfectly pass through <em>every single training point</em>. It looks amazing on the training data, but if you introduce a new point that doesn’t exactly follow one of those wiggles, the model’s prediction will be wildly off. It has effectively “memorized the noise” of the training set.</p> <p><strong>Common Causes of Overfitting:</strong></p> <ol> <li> <strong>Model is too complex:</strong> Using a model that has too many parameters or is too flexible for the amount of data available (e.g., very deep neural networks, high-degree polynomial regression).</li> <li> <strong>Insufficient training data:</strong> If you don’t have enough diverse examples, the model will struggle to find general patterns and instead memorize the few examples it has.</li> <li> <strong>Too many features:</strong> A large number of features, especially noisy or irrelevant ones, can give the model too many opportunities to find spurious correlations in the training data. This is often called the “curse of dimensionality.”</li> <li> <strong>Training for too long:</strong> For iterative models, continuing to train after the optimal point will lead to the model starting to learn noise rather than underlying patterns.</li> </ol> <p><strong>How to Fix Overfitting:</strong></p> <ol> <li> <strong>Simplify the model:</strong> Reduce the complexity. This could mean using a lower-degree polynomial, fewer layers or neurons in a neural network, or pruning a decision tree.</li> <li> <strong>Gather more training data:</strong> More data helps the model see a broader range of patterns and reduces its reliance on specific data points.</li> <li> <strong>Feature selection/dimensionality reduction:</strong> Remove irrelevant or redundant features. Techniques like PCA (Principal Component Analysis) can help reduce the number of dimensions.</li> <li> <strong>Regularization:</strong> This is a crucial technique. It adds a penalty term to the model’s loss function for having large parameter values, effectively discouraging overly complex models. <ul> <li> <table> <tbody> <tr> <td> <strong>L1 Regularization (Lasso):</strong> Adds the sum of the absolute values of the coefficients to the loss: $Loss_{new} = Loss_{original} + \lambda \sum_{i=1}^{n}</td> <td>\theta_i</td> <td>$. It can lead to sparse models, effectively performing feature selection by driving some coefficients to zero.</td> </tr> </tbody> </table> </li> <li> <strong>L2 Regularization (Ridge):</strong> Adds the sum of the squared values of the coefficients to the loss: $Loss_{new} = Loss_{original} + \lambda \sum_{i=1}^{n} \theta_i^2$. It penalizes large weights, encouraging smaller, more distributed weights.</li> </ul> </li> <li> <strong>Cross-validation:</strong> Instead of a single train/test split, cross-validation involves splitting the data into multiple folds and training/testing the model multiple times. This provides a more robust estimate of how the model will perform on unseen data and helps detect overfitting.</li> <li> <strong>Early Stopping:</strong> For iterative models, monitor the model’s performance on a separate validation set during training. Stop training when the validation error starts to increase, even if the training error is still decreasing. This prevents the model from memorizing noise.</li> <li> <strong>Dropout (for Neural Networks):</strong> During training, randomly “drops out” (sets to zero) a fraction of neurons at each update. This forces the network to learn more robust features that are not dependent on specific neurons, making it less prone to overfitting.</li> </ol> <h3 id="the-bias-variance-trade-off-the-heart-of-the-matter">The Bias-Variance Trade-off: The Heart of the Matter</h3> <p>Underfitting is often associated with <strong>high bias</strong> and <strong>low variance</strong>. The model is too biased in its assumptions, failing to capture the true relationships, but its predictions are stable.</p> <p>Overfitting is associated with <strong>low bias</strong> and <strong>high variance</strong>. The model is not biased in its assumptions; it tries to fit everything. However, its predictions are highly unstable and vary wildly with changes in the training data.</p> <p>The <strong>Bias-Variance Trade-off</strong> is one of the most fundamental concepts in machine learning. It states that there’s an inherent tension between these two sources of error. As you decrease bias (make the model more complex to capture more patterns), you typically increase variance (make it more sensitive to the training data). Conversely, as you decrease variance (make the model simpler and more robust), you often increase bias (make it less able to capture complex patterns).</p> <p>Our goal is to find the “sweet spot” – a model complexity level where both bias and variance are acceptably low, leading to the lowest overall generalization error.</p> <p>Imagine a U-shaped curve. On the left side, with very low model complexity, error is high (underfitting, high bias). As complexity increases, error drops, hitting a minimum. This is the sweet spot. As complexity further increases to the right, error starts rising again (overfitting, high variance).</p> <h3 id="practical-strategies-for-detection-and-management">Practical Strategies for Detection and Management</h3> <p>Knowing about overfitting and underfitting isn’t enough; you need to be able to detect and manage them in practice.</p> <ol> <li> <strong>Train/Validation/Test Split:</strong> This is non-negotiable. <ul> <li> <strong>Training Set:</strong> Used to train your model.</li> <li> <strong>Validation Set:</strong> Used to tune hyperparameters and make model selection decisions. Crucially, you <em>don’t</em> train on this. It helps you detect overfitting during model development.</li> <li> <strong>Test Set:</strong> A completely unseen dataset, used only <em>once</em> at the very end to get a final, unbiased estimate of your model’s performance. Never touch it until your model is finalized.</li> </ul> </li> <li> <strong>Learning Curves:</strong> Plotting your model’s performance (e.g., error rate or accuracy) on both the training set and the validation set as a function of either: <ul> <li> <strong>Training Set Size:</strong> Helps identify if more data is needed. If both train and validation error are high and converge, it suggests high bias (underfitting), meaning more data won’t help without increasing model complexity. If training error is low and validation error is high, it suggests high variance (overfitting), meaning more data <em>might</em> help.</li> <li> <strong>Number of Training Iterations/Epochs:</strong> Useful for iterative models. If validation error starts to increase while training error continues to decrease, it’s a clear sign of overfitting (time for early stopping!).</li> </ul> </li> <li> <strong>Performance Metrics:</strong> Always compare your chosen metrics (accuracy, precision, recall, F1-score for classification; MSE, RMSE for regression) on both the training and validation/test sets. A significant discrepancy is your warning signal.</li> </ol> <h3 id="concluding-thoughts-the-art-of-balance">Concluding Thoughts: The Art of Balance</h3> <p>Overfitting and underfitting are not just theoretical concepts; they are the everyday challenges that data scientists and machine learning engineers grapple with. Mastering the art of balancing these two extremes is crucial for building robust, reliable, and truly intelligent systems.</p> <p>It’s an ongoing process of experimentation, careful evaluation, and iterative refinement. There’s no magic bullet, but by understanding the causes, recognizing the symptoms, and applying the right techniques, you can guide your models towards that elusive “Goldilocks Zone” where they perform “just right” on unseen data. Keep learning, keep experimenting, and happy modeling!</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/cracking-the-ai-black-box-why-explainable-ai-xai-i/">Cracking the AI Black Box: Why Explainable AI (XAI) is Our Superpower</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/the-secret-life-of-states-how-markov-chains-predic/">The Secret Life of States: How Markov Chains Predict Our Next Move (Without Remembering the Past!)</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/gradient-descent-unpacking-the-engine-of-machine-l/">Gradient Descent: Unpacking the Engine of Machine Learning</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Adarsh Nair. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/blog/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/masonry.js?v=a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/zoom.js?v=85ddb88934d28b74e78031fd54cf8308"></script> <script src="/blog/assets/js/no_defer.js?v=2781658a0a2b13ed609542042a859126"></script> <script defer src="/blog/assets/js/common.js?v=c15de51d4bb57887caa2c21988d97279"></script> <script defer src="/blog/assets/js/copy_code.js?v=c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/blog/assets/js/jupyter_new_tab.js?v=d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/blog/assets/js/mathjax-setup.js?v=a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/progress-bar.js?v=2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/blog/assets/js/vanilla-back-to-top.min.js?v=f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/blog/assets/js/search/ninja-keys.min.js?v=a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/blog/assets/js/search-setup.js?v=6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/blog/assets/js/search-data.js"></script> <script src="/blog/assets/js/shortcut-key.js?v=ccc841c459bfc0e64c1c2b5acd10df02"></script> </body> </html>