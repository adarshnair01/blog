<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Unlocking Tomorrow: A Deep Dive into Time Series Analysis | Adarsh Nair </title> <meta name="author" content="Adarsh Nair"> <meta name="description" content="A deep dive into machine learning, AI, and data science. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <meta http-equiv="Content-Security-Policy" content="default-src 'self'; script-src 'self' 'unsafe-inline' https:; style-src 'self' 'unsafe-inline' https:; img-src 'self' data: https:; font-src 'self' data: https:; media-src 'self' https:; frame-src 'self' https:; connect-src 'self' https:;"> <link rel="stylesheet" href="/blog/assets/css/bootstrap.min.css?v=a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/blog/assets/css/academicons.min.css?v=f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/blog/assets/css/scholar-icons.css?v=62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-github.css?v=591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/blog/assets/css/main.css?v=d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://adarshnair.online/blog/blog/blog/2024/unlocking-tomorrow-a-deep-dive-into-time-series-an/"> <script src="/blog/assets/js/theme.js?v=5fea5159b787642c1bbc1f334d60f883"></script> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-native.css?v=5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="https://adarshnair.online" rel="external nofollow noopener" target="_blank"> Adarsh Nair </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/blog/"> </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/index.html">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/about/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/cv/">CV </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="https://adarshnair.online/books/" rel="external nofollow noopener" target="_blank">books </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="fa-solid fa-magnifying-glass"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-half-sun-moon" id="light-toggle-system"></i> <i class="fa-solid fa-moon" id="light-toggle-dark"></i> <i class="fa-solid fa-sun" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Unlocking Tomorrow: A Deep Dive into Time Series Analysis</h1> <p class="post-meta"> Created on October 14, 2024 by Adarsh Nair </p> <p class="post-tags"> <a href="/blog/blog/2024"> <i class="fa-solid fa-calendar fa-sm"></i> 2024 </a>   ·   <a href="/blog/blog/tag/time-series"> <i class="fa-solid fa-hashtag fa-sm"></i> Time Series</a>   <a href="/blog/blog/tag/forecasting"> <i class="fa-solid fa-hashtag fa-sm"></i> Forecasting</a>   <a href="/blog/blog/tag/data-science"> <i class="fa-solid fa-hashtag fa-sm"></i> Data Science</a>   <a href="/blog/blog/tag/machine-learning"> <i class="fa-solid fa-hashtag fa-sm"></i> Machine Learning</a>   <a href="/blog/blog/tag/python"> <i class="fa-solid fa-hashtag fa-sm"></i> Python</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p>My journey into data science has been a thrilling exploration of patterns, predictions, and uncovering hidden truths within numbers. But there’s one area that always felt a bit like gazing into a crystal ball, yet grounded in rigorous mathematics: <strong>Time Series Analysis</strong>. It’s not just about crunching numbers; it’s about understanding the story data tells us <em>over time</em> and using that narrative to peek into the future.</p> <h3 id="the-pulse-of-time-what-exactly-is-a-time-series">The Pulse of Time: What Exactly is a Time Series?</h3> <p>Imagine you’re tracking something—anything—that changes with time. The temperature outside your window every hour, the number of visitors to your favorite website each day, the stock price of a company minute by minute, or even the amount of coffee I consume per week (a crucial metric, I assure you!). Each of these is a <strong>time series</strong>: a sequence of data points indexed, or listed, in time order.</p> <p>What makes time series special? Unlike standard datasets where each observation is often assumed to be independent, in a time series, <em>the order matters</em>. The value today is often influenced by the value yesterday, or last week, or even last year. This dependency is both the challenge and the magic of time series analysis.</p> <h3 id="why-should-we-care-about-time-series">Why Should We Care About Time Series?</h3> <p>The applications are everywhere, weaving through our daily lives:</p> <ul> <li> <strong>Business &amp; Economics:</strong> Forecasting sales, predicting stock market fluctuations, analyzing economic indicators like GDP or inflation.</li> <li> <strong>Weather &amp; Climate:</strong> Predicting hurricane paths, understanding global warming trends, daily temperature forecasts.</li> <li> <strong>Healthcare:</strong> Modeling disease outbreaks, predicting patient demand.</li> <li> <strong>Engineering:</strong> Monitoring sensor data for anomalies, predicting equipment failure.</li> <li> <strong>Social Sciences:</strong> Analyzing social media trends, predicting population growth.</li> </ul> <p>For me, the “aha!” moment came when I realized how profound the implications were. From optimizing supply chains to alerting us about climate change, time series analysis isn’t just an academic exercise; it’s a tool for smarter decisions and a better future.</p> <h3 id="deconstructing-time-the-fundamental-components">Deconstructing Time: The Fundamental Components</h3> <p>Before we can predict, we must first understand. Most time series data can be broken down into several core components. Think of it like dissecting a song: you have the main melody, the recurring beat, and perhaps some spontaneous improvisations.</p> <ol> <li> <strong>Trend ($T_t$):</strong> This is the long-term direction of the data. Is it generally increasing, decreasing, or staying relatively flat over time? For example, the growing number of internet users over decades shows an upward trend.</li> <li> <strong>Seasonality ($S_t$):</strong> These are patterns that repeat over a fixed period, like a day, week, month, or year. Retail sales often spike during holidays (yearly seasonality), and electricity consumption typically peaks in the afternoon (daily seasonality).</li> <li> <strong>Cyclical ($C_t$):</strong> Similar to seasonality, but these patterns don’t have a fixed period. They usually last longer than a seasonal period (e.g., several years) and are often associated with economic cycles (boom and bust). It’s harder to predict than seasonality.</li> <li> <strong>Irregular/Residual ($R_t$ or $\epsilon_t$):</strong> This is the “noise” or random variation in the data that can’t be explained by trend, seasonality, or cyclical components. It’s the unpredictable part, the spontaneous improvisation in our song analogy.</li> </ol> <p>These components can combine in two main ways:</p> <ul> <li> <strong>Additive Model:</strong> $Y_t = T_t + S_t + C_t + R_t$ (when the magnitude of seasonal fluctuations doesn’t change with the level of the series).</li> <li> <strong>Multiplicative Model:</strong> $Y_t = T_t \times S_t \times C_t \times R_t$ (when the magnitude of seasonal fluctuations increases with the level of the series).</li> </ul> <p>Visualizing these components is often the first step in any time series project. Libraries like <code class="language-plaintext highlighter-rouge">statsmodels</code> in Python provide excellent tools for decomposition, allowing us to peek under the hood of our data.</p> <h3 id="the-holy-grail-stationarity">The Holy Grail: Stationarity</h3> <p>This is arguably the most crucial concept in classical time series modeling. A time series is said to be <strong>stationary</strong> if its statistical properties—like mean, variance, and autocorrelation—remain constant over time.</p> <p>Why is stationarity so important? Most traditional time series models (like ARIMA, which we’ll get to!) assume that the underlying process generating the series is stationary. If your data isn’t stationary, your forecasts might be biased, inaccurate, or simply unreliable.</p> <p><strong>What makes a series non-stationary?</strong></p> <ul> <li> <strong>Trend:</strong> A changing mean over time.</li> <li> <strong>Seasonality:</strong> Periodic fluctuations.</li> <li> <strong>Changing Variance:</strong> The spread of data points changes over time.</li> </ul> <p><strong>How do we achieve stationarity?</strong> The most common technique is <strong>differencing</strong>. This involves calculating the difference between consecutive observations ($Y_t - Y_{t-1}$). Sometimes, you might need to difference multiple times (e.g., second-order differencing: $(Y_t - Y_{t-1}) - (Y_{t-1} - Y_{t-2})$) or apply seasonal differencing to remove seasonal patterns. Another technique is applying transformations like logarithmic transformations to stabilize variance.</p> <p>To test for stationarity, we often use statistical tests like the <strong>Augmented Dickey-Fuller (ADF) test</strong>. It helps us determine if a unit root is present in the time series, which is an indicator of non-stationarity.</p> <h3 id="peeking-into-the-past-autocorrelation-functions-acf--pacf">Peeking into the Past: Autocorrelation Functions (ACF &amp; PACF)</h3> <p>Once we have a stationary series, how do we choose the right model? This is where <strong>Autocorrelation Function (ACF)</strong> and <strong>Partial Autocorrelation Function (PACF)</strong> plots become our best friends.</p> <ul> <li> <strong>Autocorrelation (ACF):</strong> Measures the correlation between a time series and a lagged version of itself. Essentially, how much does $Y_t$ depend on $Y_{t-1}$, $Y_{t-2}$, and so on?</li> <li> <strong>Partial Autocorrelation (PACF):</strong> Measures the correlation between a time series and a lagged version of itself, <em>after removing the effects of the intermediate lags</em>. For example, PACF at lag 2 shows the correlation between $Y_t$ and $Y_{t-2}$ that isn’t explained by $Y_{t-1}$.</li> </ul> <p>These plots provide visual clues about the order of AR (Autoregressive) and MA (Moving Average) components needed for our models. A common pattern in ACF/PACF plots might be a sharp drop after a few lags, indicating the strength of past observations’ influence.</p> <h3 id="forecasting-the-future-the-arima-family">Forecasting the Future: The ARIMA Family</h3> <p>Now for the main event! The <strong>ARIMA</strong> (AutoRegressive Integrated Moving Average) model is a cornerstone of time series forecasting. Its name tells us exactly what it does:</p> <ul> <li> <strong>AR (AutoRegressive):</strong> This part means the model uses a linear combination of past values of the variable to predict future values. It’s like saying, “What I do today is influenced by what I did yesterday, the day before, etc.” <ul> <li>The AR(p) model is expressed as: $Y_t = c + \sum_{i=1}^p \phi_i Y_{t-i} + \epsilon_t$</li> <li>Here, $Y_t$ is the value at time $t$, $c$ is a constant, $\phi_i$ are the autoregressive coefficients, $Y_{t-i}$ are past values, and $\epsilon_t$ is white noise (random error).</li> <li>The ‘p’ denotes the order of the AR component (how many past observations to include).</li> </ul> </li> <li> <strong>I (Integrated):</strong> This refers to the differencing we discussed earlier. If our series isn’t stationary, we “integrate” it by differencing it ‘d’ times to make it stationary. <ul> <li>The ‘d’ denotes the order of differencing.</li> </ul> </li> <li> <strong>MA (Moving Average):</strong> This part means the model uses a linear combination of past forecast errors (residuals) to predict future values. It’s like saying, “My forecast today is influenced by how wrong my forecasts were yesterday, the day before, etc.” <ul> <li>The MA(q) model is expressed as: $Y_t = \mu + \epsilon_t + \sum_{j=1}^q \theta_j \epsilon_{t-j}$</li> <li>Here, $\mu$ is the mean of the series, $\epsilon_t$ is the current error, $\theta_j$ are the moving average coefficients, and $\epsilon_{t-j}$ are past error terms.</li> <li>The ‘q’ denotes the order of the MA component (how many past error terms to include).</li> </ul> </li> </ul> <p>Putting it all together, an ARIMA model is denoted as <strong>ARIMA(p, d, q)</strong>, where p, d, and q are the orders of the AR, I, and MA components, respectively.</p> <h4 id="sarima-handling-seasonality">SARIMA: Handling Seasonality</h4> <p>What if your data has strong seasonal patterns? ARIMA alone might not capture them effectively. That’s where <strong>SARIMA (Seasonal ARIMA)</strong> comes in. It extends ARIMA by adding seasonal components: <strong>SARIMA(p, d, q)(P, D, Q)m</strong>.</p> <ul> <li> <strong>(p, d, q)</strong> are the non-seasonal orders.</li> <li> <strong>(P, D, Q)</strong> are the seasonal orders (P for seasonal AR, D for seasonal differencing, Q for seasonal MA).</li> <li> <strong>m</strong> is the number of periods in each season (e.g., 12 for monthly data, 4 for quarterly data, 24 for hourly data with a daily season).</li> </ul> <p>SARIMA models can be incredibly powerful for capturing complex, repeating patterns.</p> <h3 id="beyond-arima-a-glimpse-at-other-models">Beyond ARIMA: A Glimpse at Other Models</h3> <p>While ARIMA is a workhorse, the world of time series forecasting is vast:</p> <ul> <li> <strong>Exponential Smoothing (ETS):</strong> Models like Holt-Winters are excellent for capturing trend and seasonality, especially when the underlying patterns change over time. Simpler than ARIMA but very effective for many datasets.</li> <li> <strong>Prophet (by Facebook):</strong> A forecasting tool designed for business time series that often have strong seasonal effects and missing data. It’s robust to outliers and easy to use, making it popular for many practical applications.</li> <li> <strong>Machine Learning &amp; Deep Learning:</strong> For very complex patterns, especially with multiple related time series (multivariate time series) or long dependencies, models like <strong>Recurrent Neural Networks (RNNs)</strong>, specifically <strong>Long Short-Term Memory (LSTMs)</strong> networks, have shown remarkable promise. These models can learn intricate patterns without explicit feature engineering for trend or seasonality, though they often require more data and computational resources.</li> </ul> <h3 id="my-workflow-a-practical-approach">My Workflow: A Practical Approach</h3> <p>When I tackle a time series problem, here’s a general roadmap I follow:</p> <ol> <li> <strong>Data Loading &amp; Initial Exploration:</strong> Get the data into Python (usually with <code class="language-plaintext highlighter-rouge">pandas</code>), check for missing values, and ensure the time index is correctly formatted.</li> <li> <strong>Visualization is Key:</strong> Plot the time series! This immediately tells you about trends, seasonality, and any glaring anomalies. Use <code class="language-plaintext highlighter-rouge">matplotlib</code> or <code class="language-plaintext highlighter-rouge">seaborn</code>.</li> <li> <strong>Decomposition:</strong> Decompose the series into its trend, seasonal, and residual components. This helps confirm what you see in the raw plot and informs your differencing strategy.</li> <li> <strong>Check for Stationarity:</strong> Perform the ADF test. If non-stationary, apply differencing (and re-test) until it’s stationary.</li> <li> <strong>ACF &amp; PACF Plots:</strong> Generate these plots for the stationary series to help identify potential p and q orders for ARIMA/SARIMA. This step can feel a bit like art mixed with science – matching patterns to known theoretical ACF/PACF behaviors.</li> <li> <strong>Model Selection &amp; Training:</strong> Choose a model (ARIMA, SARIMA, Prophet, etc.). For ARIMA, you might iterate through different (p, d, q) orders, often using an “auto_arima” function from libraries like <code class="language-plaintext highlighter-rouge">pmdarima</code> to automate the search for the best parameters based on criteria like AIC (Akaike Information Criterion).</li> <li> <strong>Model Evaluation:</strong> Split your data into training and testing sets. Train the model on the training data and evaluate its performance on the unseen test data using metrics like RMSE (Root Mean Squared Error), MAE (Mean Absolute Error), or MAPE (Mean Absolute Percentage Error).</li> <li> <strong>Forecasting:</strong> Once you’re satisfied with the model, use it to make future predictions!</li> </ol> <h3 id="conclusion-the-endless-dance-of-data">Conclusion: The Endless Dance of Data</h3> <p>Time Series Analysis is a captivating field. It’s a blend of statistical rigor, domain expertise, and a touch of creative problem-solving. It’s about recognizing that the past holds clues for the future, but also acknowledging that the future always contains an element of uncertainty.</p> <p>From my personal perspective, each time series project has felt like a mini-mystery to solve. Uncovering the hidden trends, discerning the seasonal rhythms, and then building a model that can predict what’s next is incredibly rewarding. It’s a skill that empowers you to not just understand data, but to shape decisions based on intelligent predictions.</p> <p>So, whether you’re a high school student fascinated by patterns, or an aspiring data scientist building your portfolio, I encourage you to dive into time series analysis. Grab a dataset (there are tons available online, like climate data, stock prices, or even daily active users of a fictional app), fire up a Python notebook, and start your own journey into unlocking tomorrow!</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/cracking-the-ai-black-box-why-explainable-ai-xai-i/">Cracking the AI Black Box: Why Explainable AI (XAI) is Our Superpower</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/the-secret-life-of-states-how-markov-chains-predic/">The Secret Life of States: How Markov Chains Predict Our Next Move (Without Remembering the Past!)</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/gradient-descent-unpacking-the-engine-of-machine-l/">Gradient Descent: Unpacking the Engine of Machine Learning</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Adarsh Nair. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/blog/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/masonry.js?v=a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/zoom.js?v=85ddb88934d28b74e78031fd54cf8308"></script> <script src="/blog/assets/js/no_defer.js?v=2781658a0a2b13ed609542042a859126"></script> <script defer src="/blog/assets/js/common.js?v=c15de51d4bb57887caa2c21988d97279"></script> <script defer src="/blog/assets/js/copy_code.js?v=c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/blog/assets/js/jupyter_new_tab.js?v=d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/blog/assets/js/mathjax-setup.js?v=a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/progress-bar.js?v=2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/blog/assets/js/vanilla-back-to-top.min.js?v=f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/blog/assets/js/search/ninja-keys.min.js?v=a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/blog/assets/js/search-setup.js?v=6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/blog/assets/js/search-data.js"></script> <script src="/blog/assets/js/shortcut-key.js?v=ccc841c459bfc0e64c1c2b5acd10df02"></script> </body> </html>