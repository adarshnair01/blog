<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> The Great Deep Learning Debate: PyTorch vs. TensorFlow - A Personal Journey | Adarsh Nair </title> <meta name="author" content="Adarsh Nair"> <meta name="description" content="A deep dive into machine learning, AI, and data science. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <meta http-equiv="Content-Security-Policy" content="default-src 'self'; script-src 'self' 'unsafe-inline' https:; style-src 'self' 'unsafe-inline' https:; img-src 'self' data: https:; font-src 'self' data: https:; media-src 'self' https:; frame-src 'self' https:; connect-src 'self' https:;"> <link rel="stylesheet" href="/blog/assets/css/bootstrap.min.css?v=a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/blog/assets/css/academicons.min.css?v=f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/blog/assets/css/scholar-icons.css?v=62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-github.css?v=591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/blog/assets/css/main.css?v=d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://adarshnair.online/blog/blog/blog/2024/the-great-deep-learning-debate-pytorch-vs-tensorfl/"> <script src="/blog/assets/js/theme.js?v=5fea5159b787642c1bbc1f334d60f883"></script> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-native.css?v=5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="https://adarshnair.online" rel="external nofollow noopener" target="_blank"> Adarsh Nair </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/blog/"> </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/index.html">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/cv/">CV </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="https://adarshnair.online/books/" rel="external nofollow noopener" target="_blank">books </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="fa-solid fa-magnifying-glass"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-half-sun-moon" id="light-toggle-system"></i> <i class="fa-solid fa-moon" id="light-toggle-dark"></i> <i class="fa-solid fa-sun" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">The Great Deep Learning Debate: PyTorch vs. TensorFlow - A Personal Journey</h1> <p class="post-meta"> Created on July 10, 2024 by Adarsh Nair </p> <p class="post-tags"> <a href="/blog/blog/2024"> <i class="fa-solid fa-calendar fa-sm"></i> 2024 </a>   ·   <a href="/blog/blog/tag/machine-learning"> <i class="fa-solid fa-hashtag fa-sm"></i> Machine Learning</a>   <a href="/blog/blog/tag/deep-learning"> <i class="fa-solid fa-hashtag fa-sm"></i> Deep Learning</a>   <a href="/blog/blog/tag/pytorch"> <i class="fa-solid fa-hashtag fa-sm"></i> PyTorch</a>   <a href="/blog/blog/tag/tensorflow"> <i class="fa-solid fa-hashtag fa-sm"></i> TensorFlow</a>   <a href="/blog/blog/tag/python"> <i class="fa-solid fa-hashtag fa-sm"></i> Python</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p>Hello, fellow explorers of the digital frontier!</p> <p>If you’ve spent any time peering into the dazzling world of deep learning, you’ve undoubtedly encountered two names that echo through the corridors of data science labs and tech companies alike: PyTorch and TensorFlow. For many, especially when you’re just starting out, this choice can feel monumental. It certainly did for me!</p> <p>I remember those early days, poring over documentation, watching tutorials, and feeling a distinct pull in different directions. Was I to pledge allegiance to the well-established TensorFlow, with its impressive industry footprint? Or would I be drawn to the burgeoning, researcher-friendly PyTorch? It felt like a classic superhero showdown, a battle for the heart of my deep learning projects.</p> <p>But here’s the spoiler: it’s not a battle. It’s more like choosing the right tool from an incredibly well-stocked toolbox. Both PyTorch and TensorFlow are phenomenal open-source deep learning frameworks that have revolutionized how we build, train, and deploy neural networks. They empower us to create everything from image recognition systems that can spot cats in a crowd to natural language models that can write poetry. The real question isn’t “which one is better?” but rather, “which one is better <em>for your specific needs and preferences</em>?”</p> <p>Let’s embark on a journey to understand their core philosophies, dissect their strengths, and ultimately, help you make an informed choice.</p> <h3 id="the-core-idea-what-are-we-even-talking-about">The Core Idea: What Are We Even Talking About?</h3> <p>At their heart, both PyTorch and TensorFlow provide a powerful set of tools to perform numerical computations, especially those involving multi-dimensional arrays, which are called <strong>tensors</strong>. Think of tensors as super-powered matrices – they are the fundamental building blocks of all data and operations in deep learning.</p> \[\text{A simple tensor example (a 2x3 matrix):} \\ T = \begin{pmatrix} 1 &amp; 2 &amp; 3 \\ 4 &amp; 5 &amp; 6 \end{pmatrix}\] <p>On top of these tensor operations, they offer high-level APIs to construct neural network layers (like convolutional layers, recurrent layers), optimization algorithms (Adam, SGD), and utilities for data loading and preprocessing.</p> <h3 id="the-elephant-in-the-room-dynamic-vs-static-computation-graphs-the-historical-divide">The Elephant in the Room: Dynamic vs. Static Computation Graphs (The Historical Divide)</h3> <p>This is perhaps the most significant historical differentiator between PyTorch and TensorFlow, although it’s crucial to understand how TensorFlow has evolved.</p> <h4 id="tensorflow-1x-the-define-and-run-philosophy-static-graphs">TensorFlow 1.x: The “Define and Run” Philosophy (Static Graphs)</h4> <p>In its original incarnation (TensorFlow 1.x), TensorFlow championed what’s known as a <strong>static computation graph</strong>. Imagine you’re an architect designing a building. You’d first draw up the entire blueprint, detailing every beam, wall, and wire. Only <em>after</em> the blueprint is complete and approved would you start actual construction.</p> <p>This is how TF1.x worked:</p> <ol> <li> <strong>Define the graph:</strong> You’d first construct the entire neural network structure as an abstract graph of operations. This graph represented the flow of data.</li> <li> <strong>Initialize a session:</strong> You’d then create a <code class="language-plaintext highlighter-rouge">tf.Session</code> object.</li> <li> <strong>Feed data and run:</strong> Only then would you feed actual data into this session, which would execute the operations defined in the graph.</li> </ol> <p><strong>Pros of Static Graphs (TF1.x):</strong></p> <ul> <li> <strong>Optimization:</strong> The framework could perform global optimizations on the entire graph <em>before</em> execution, leading to highly efficient models, especially in production.</li> <li> <strong>Deployment:</strong> The graph could be saved and deployed without the Python code, making it excellent for cross-platform deployment (mobile, web, embedded devices) and production environments.</li> <li> <strong>Distributed Training:</strong> Easier to distribute computation across multiple GPUs or machines once the graph was defined.</li> </ul> <p><strong>Cons of Static Graphs (TF1.x):</strong></p> <ul> <li> <strong>Debugging Nightmare:</strong> If something went wrong, debugging was notoriously difficult. You couldn’t easily inspect intermediate values within the graph using standard Python debuggers (<code class="language-plaintext highlighter-rouge">pdb</code>) because the operations hadn’t <em>actually</em> executed yet. It felt like trying to debug a blueprint!</li> <li> <strong>Lack of Flexibility:</strong> Conditional logic ($if$ statements) or loops could be clunky to implement within the graph, making research and experimentation more complex.</li> </ul> <h4 id="pytorch-the-define-by-run-philosophy-dynamic-graphs--eager-execution">PyTorch: The “Define by Run” Philosophy (Dynamic Graphs / Eager Execution)</h4> <p>PyTorch took a different approach from the beginning, embracing <strong>dynamic computation graphs</strong>, often referred to as “eager execution.” Sticking with our building analogy, this is like building a house brick by brick. You lay a brick, you see it immediately. You can decide where the next brick goes based on what you just did.</p> <p>With PyTorch:</p> <ol> <li> <strong>Define and Execute:</strong> Operations are executed immediately as they are called.</li> <li> <strong>Graph Builds on the Fly:</strong> The computation graph is built dynamically as your code runs.</li> </ol> <p><strong>Pros of Dynamic Graphs (PyTorch):</strong></p> <ul> <li> <strong>Pythonic &amp; Intuitive:</strong> It feels much more like writing standard Python code. You can use native Python debugging tools (<code class="language-plaintext highlighter-rouge">pdb</code>) to inspect tensors at any point.</li> <li> <strong>Flexibility:</strong> Ideal for research and rapid prototyping, as you can easily change network architectures or control flow on the fly. This makes models with variable inputs or complex conditional logic much simpler to implement.</li> <li> <strong>Easier Learning Curve:</strong> Many developers find PyTorch easier to pick up, especially if they are already comfortable with Python.</li> </ul> <p><strong>Cons of Dynamic Graphs (Early PyTorch):</strong></p> <ul> <li> <strong>Deployment Challenges:</strong> Initially, deploying PyTorch models to production without the Python interpreter was harder compared to TF1’s saved graphs.</li> <li> <strong>Fewer Built-in Production Tools:</strong> TensorFlow historically had a richer ecosystem for deployment, monitoring, and mobile inference.</li> </ul> <h3 id="the-convergence-tensorflow-2x-blurs-the-lines">The Convergence: TensorFlow 2.x Blurs the Lines</h3> <p>Here’s where the story gets really interesting! Google, recognizing the immense popularity and user-friendliness of PyTorch’s eager execution, made a monumental shift with <strong>TensorFlow 2.x</strong>.</p> <p><strong>TensorFlow 2.x defaults to eager execution!</strong> This means it now behaves much like PyTorch by default, executing operations immediately. It also heavily promotes <strong>Keras</strong> as its high-level API, making model building much more intuitive and Pythons-friendly. You can still compile a graph using <code class="language-plaintext highlighter-rouge">@tf.function</code> decorators for performance and deployment benefits, giving you the best of both worlds.</p> <p>This move effectively addressed many of the historical complaints about TF1.x’s steep learning curve and debugging difficulties.</p> <h3 id="key-differentiators-post-tf2x-and-general-impressions">Key Differentiators (Post TF2.x and General Impressions)</h3> <p>Even with TF2.x’s convergence, subtle differences and ecosystem strengths remain:</p> <ol> <li> <strong>Debugging &amp; Pythonic Feel:</strong> <ul> <li> <strong>PyTorch:</strong> Still generally feels more “Pythonic.” Its tight integration with standard Python control flow and debugging tools makes it a joy for many researchers. When you’re dealing with tensors, it often feels like you’re working with NumPy arrays.</li> <li> <strong>TensorFlow 2.x:</strong> Has made massive strides. Keras, its high-level API, is extremely Pythonic. Eager execution allows for much better debugging. However, some lower-level TensorFlow operations can still feel a bit less intuitive than their PyTorch counterparts for pure Python developers.</li> </ul> </li> <li> <strong>Learning Curve:</strong> <ul> <li> <strong>PyTorch:</strong> Often perceived as having a shallower learning curve for those familiar with Python and NumPy.</li> <li> <strong>TensorFlow 2.x:</strong> The Keras API makes it very easy to get started. Learning the full breadth of TensorFlow’s ecosystem can still be a larger undertaking, but the entry barrier has been significantly lowered.</li> </ul> </li> <li> <strong>Deployment &amp; Production Readiness:</strong> <ul> <li> <strong>TensorFlow:</strong> Historically, TensorFlow had a massive advantage here with tools like TensorFlow Serving (for deploying models as REST APIs), TensorFlow Lite (for mobile and embedded devices), and TensorFlow.js (for web browsers). Its <code class="language-plaintext highlighter-rouge">SavedModel</code> format is incredibly robust.</li> <li> <strong>PyTorch:</strong> Has made incredible progress. <strong>TorchScript</strong> allows for serializing models into a portable format that can be run independently of Python (e.g., in C++ applications). <strong>ONNX (Open Neural Network Exchange)</strong> provides an interoperable format that both frameworks (and others) can use, further bridging deployment gaps. PyTorch Mobile and TorchServe are also rapidly maturing.</li> </ul> </li> <li> <strong>Community &amp; Resources:</strong> <ul> <li> <strong>PyTorch:</strong> Extremely popular in academic research. Many state-of-the-art papers release their code in PyTorch. Its community is vibrant and highly responsive.</li> <li> <strong>TensorFlow:</strong> Backed by Google, it has an enormous, well-established community and extensive documentation, tutorials, and courses. It has a strong presence in large-scale industry deployments.</li> </ul> </li> <li> <strong>Data Pipelining:</strong> <ul> <li> <strong>PyTorch:</strong> Uses custom <code class="language-plaintext highlighter-rouge">torch.utils.data.Dataset</code> and <code class="language-plaintext highlighter-rouge">DataLoader</code> classes. These are very flexible and can easily integrate with standard Python data processing libraries.</li> <li> <strong>TensorFlow:</strong> Provides <code class="language-plaintext highlighter-rouge">tf.data</code>, a powerful and highly optimized API for building complex and efficient data input pipelines. It can be a bit more opinionated but offers significant performance benefits for large datasets.</li> </ul> </li> </ol> <h3 id="a-glimpse-at-the-code-conceptual">A Glimpse at the Code (Conceptual)</h3> <p>Let’s look at a simple linear layer, $y = Wx + b$, in both frameworks to illustrate the feel.</p> <p><strong>PyTorch:</strong></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">torch</span>
<span class="kn">import</span> <span class="n">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>

<span class="c1"># Define a simple linear layer
# Input features: 10, Output features: 1
</span><span class="n">linear_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="c1"># Example input tensor
</span><span class="n">input_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span> <span class="c1"># 1 sample, 10 features
</span>
<span class="c1"># Forward pass (executes immediately)
</span><span class="n">output_tensor</span> <span class="o">=</span> <span class="nf">linear_layer</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">PyTorch output: </span><span class="si">{</span><span class="n">output_tensor</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <p><strong>TensorFlow 2.x (using Keras API):</strong></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>

<span class="c1"># Define a simple linear layer using Keras
# Input features: 10, Output features: 1
# Keras automatically infers input shape if not specified for first layer
</span><span class="n">linear_layer</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="nc">Dense</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,))</span>

<span class="c1"># Example input tensor
</span><span class="n">input_tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">normal</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span> <span class="c1"># 1 sample, 10 features
</span>
<span class="c1"># Forward pass (executes immediately due to eager execution)
</span><span class="n">output_tensor</span> <span class="o">=</span> <span class="nf">linear_layer</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">TensorFlow output: </span><span class="si">{</span><span class="n">output_tensor</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <p>Notice how similar they look now, especially at this high level! The underlying implementation details differ, but the user experience for simple operations has converged significantly.</p> <h3 id="when-to-choose-which-a-personal-recommendation">When to Choose Which (A Personal Recommendation)</h3> <p>After navigating both frameworks through various projects, here’s my take:</p> <p><strong>Choose PyTorch if:</strong></p> <ul> <li> <strong>You’re an academic researcher or working on bleeding-edge models:</strong> PyTorch’s flexibility, ease of debugging, and “Pythonic” nature make it ideal for rapid prototyping and exploring novel architectures where you might need to frequently alter your model’s computational graph.</li> <li> <strong>You prioritize a native Python development experience:</strong> If you love <code class="language-plaintext highlighter-rouge">pdb</code> and the standard Python ecosystem, PyTorch will likely feel more natural.</li> <li> <strong>You’re just starting out and want a quick entry point for experimentation:</strong> Many beginners find PyTorch’s API more intuitive.</li> </ul> <p><strong>Choose TensorFlow 2.x if:</strong></p> <ul> <li> <strong>You need robust, large-scale production deployment capabilities:</strong> While PyTorch is catching up, TensorFlow’s ecosystem for deployment (serving, mobile, web) is still incredibly mature and comprehensive.</li> <li> <strong>You are working in a team or company that already uses TensorFlow:</strong> Consistency is key in collaborative environments.</li> <li> <strong>You need more tools beyond just deep learning:</strong> TensorFlow Extended (TFX) offers a suite of tools for MLOps (Machine Learning Operations) that cover the entire machine learning lifecycle, from data validation to model monitoring.</li> <li> <strong>You want a high-level API (Keras) for quick development and also the option to dive deep into lower-level graph optimizations ($@tf.function$):</strong> TF2.x truly offers the best of both worlds.</li> </ul> <h3 id="the-verdict-theres-no-silver-bullet">The Verdict: There’s No Silver Bullet</h3> <p>The “PyTorch vs. TensorFlow” debate, in its original fiery form, is largely a thing of the past. TensorFlow 2.x, by embracing eager execution and promoting Keras, has learned immensely from PyTorch’s strengths. Simultaneously, PyTorch has invested heavily in improving its production story with TorchScript and TorchServe.</p> <p>Both are incredibly powerful, actively developed, and backed by major tech giants (Meta for PyTorch, Google for TensorFlow). Both have excellent documentation, vibrant communities, and are capable of building any deep learning model you can imagine.</p> <p>My personal advice? If you’re starting, pick one based on what resonates with you most after a quick dive into both. Get comfortable with it, build some projects, and understand its philosophy. Then, as you advance, challenge yourself to build a project in the <em>other</em> framework. You’ll find that many core deep learning concepts are transferable, and learning both will only make you a more versatile and valuable data scientist or MLE.</p> <p>The deep learning landscape is exciting and ever-evolving. Happy coding!</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/cracking-the-ai-black-box-why-explainable-ai-xai-i/">Cracking the AI Black Box: Why Explainable AI (XAI) is Our Superpower</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/the-secret-life-of-states-how-markov-chains-predic/">The Secret Life of States: How Markov Chains Predict Our Next Move (Without Remembering the Past!)</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/gradient-descent-unpacking-the-engine-of-machine-l/">Gradient Descent: Unpacking the Engine of Machine Learning</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Adarsh Nair. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/blog/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/masonry.js?v=a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/zoom.js?v=85ddb88934d28b74e78031fd54cf8308"></script> <script src="/blog/assets/js/no_defer.js?v=2781658a0a2b13ed609542042a859126"></script> <script defer src="/blog/assets/js/common.js?v=c15de51d4bb57887caa2c21988d97279"></script> <script defer src="/blog/assets/js/copy_code.js?v=c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/blog/assets/js/jupyter_new_tab.js?v=d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/blog/assets/js/mathjax-setup.js?v=a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/progress-bar.js?v=2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/blog/assets/js/vanilla-back-to-top.min.js?v=f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/blog/assets/js/search/ninja-keys.min.js?v=a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/blog/assets/js/search-setup.js?v=6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/blog/assets/js/search-data.js"></script> <script src="/blog/assets/js/shortcut-key.js?v=ccc841c459bfc0e64c1c2b5acd10df02"></script> </body> </html>