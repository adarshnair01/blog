<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> The Future Has No Memory: Unraveling the Magic of Markov Chains | Adarsh Nair </title> <meta name="author" content="Adarsh Nair"> <meta name="description" content="A deep dive into machine learning, AI, and data science. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <meta http-equiv="Content-Security-Policy" content="default-src 'self'; script-src 'self' 'unsafe-inline' https:; style-src 'self' 'unsafe-inline' https:; img-src 'self' data: https:; font-src 'self' data: https:; media-src 'self' https:; frame-src 'self' https:; connect-src 'self' https:;"> <link rel="stylesheet" href="/blog/assets/css/bootstrap.min.css?v=a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/blog/assets/css/academicons.min.css?v=f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/blog/assets/css/scholar-icons.css?v=62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-github.css?v=591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/blog/assets/css/main.css?v=d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://adarshnair.online/blog/blog/blog/2024/the-future-has-no-memory-unraveling-the-magic-of-m/"> <script src="/blog/assets/js/theme.js?v=5fea5159b787642c1bbc1f334d60f883"></script> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-native.css?v=5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="https://adarshnair.online" rel="external nofollow noopener" target="_blank"> Adarsh Nair </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/blog/"> </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/index.html">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/cv/">CV </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="https://adarshnair.online/books/" rel="external nofollow noopener" target="_blank">books </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="fa-solid fa-magnifying-glass"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-half-sun-moon" id="light-toggle-system"></i> <i class="fa-solid fa-moon" id="light-toggle-dark"></i> <i class="fa-solid fa-sun" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">The Future Has No Memory: Unraveling the Magic of Markov Chains</h1> <p class="post-meta"> Created on May 06, 2024 by Adarsh Nair </p> <p class="post-tags"> <a href="/blog/blog/2024"> <i class="fa-solid fa-calendar fa-sm"></i> 2024 </a>   ·   <a href="/blog/blog/tag/markov-chains"> <i class="fa-solid fa-hashtag fa-sm"></i> Markov Chains</a>   <a href="/blog/blog/tag/probability"> <i class="fa-solid fa-hashtag fa-sm"></i> Probability</a>   <a href="/blog/blog/tag/data-science"> <i class="fa-solid fa-hashtag fa-sm"></i> Data Science</a>   <a href="/blog/blog/tag/machine-learning"> <i class="fa-solid fa-hashtag fa-sm"></i> Machine Learning</a>   <a href="/blog/blog/tag/stochastic-processes"> <i class="fa-solid fa-hashtag fa-sm"></i> Stochastic Processes</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p>Hello fellow data enthusiasts and curious minds!</p> <p>Today, I want to take you on a journey into one of the most elegant and surprisingly powerful concepts in probability theory and data science: <strong>Markov Chains</strong>. It’s a concept that sounds complex, but at its heart, it’s about making predictions in systems where the past only matters insofar as it affects the current state. Think of it as a system with a very short-term memory.</p> <h3 id="a-walk-in-the-park-or-why-my-future-doesnt-depend-on-my-great-grandfathers-weather">A Walk in the Park: Or, Why My Future Doesn’t Depend on My Great-Grandfather’s Weather</h3> <p>Imagine you’re trying to predict tomorrow’s weather. Do you need to know if it rained on this exact day 200 years ago? Probably not. You’re much more interested in <em>today’s</em> weather. If it’s sunny today, there’s a certain chance it will be sunny tomorrow. If it’s raining, the chances might shift. The key insight here is that <strong>the future state of the system depends only on its current state, not on the sequence of events that led to the current state.</strong> This, my friends, is the essence of the <strong>Markov Property</strong>.</p> <h3 id="what-exactly-is-a-markov-chain">What Exactly is a Markov Chain?</h3> <p>Formally, a Markov Chain is a <strong>stochastic process</strong> (a sequence of random variables) that satisfies the Markov property. In simpler terms, it’s a sequence of “states” that a system can be in, where the probability of moving to any future state depends <em>only</em> on the current state. It’s like a choose-your-own-adventure book where you only ever look at the page you’re currently on to decide your next move, never at the chapters you’ve already read.</p> <p>Let’s break down the key components:</p> <ol> <li> <strong>States ($S$):</strong> These are the distinct conditions or categories the system can be in. For weather, states could be {Sunny, Cloudy, Rainy}. For a board game, states could be {Square 1, Square 2, …, Square N}.</li> <li> <strong>Transitions:</strong> These are the movements or changes from one state to another. If it’s sunny today and cloudy tomorrow, that’s a transition from “Sunny” to “Cloudy.”</li> <li> <table> <tbody> <tr> <td> <strong>Transition Probabilities:</strong> This is where the “magic” happens. For every possible pair of states (from state $i$ to state $j$), there’s a probability $P(X_{n+1} = j</td> <td>X_n = i)$ that the system will transition from state $i$ to state $j$ in the next step. Crucially, as per the Markov Property, this probability doesn’t depend on $X_{n-1}, X_{n-2}$, and so on.</td> </tr> </tbody> </table> </li> </ol> <h3 id="the-heart-of-the-chain-the-transition-matrix-p">The Heart of the Chain: The Transition Matrix ($P$)</h3> <p>To organize all these transition probabilities, we use something called a <strong>Transition Matrix</strong>, often denoted by $P$. If our system has $N$ states, this matrix will be $N \times N$.</p> <p>Let’s stick with our weather example. Suppose we have three states: Sunny (S), Cloudy (C), and Rainy (R). Our transition matrix might look something like this:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>        To:
        S       C       R
From S [0.7     0.2     0.1]
From C [0.3     0.4     0.3]
From R [0.2     0.3     0.5]
</code></pre></div></div> <p>What does this matrix tell us?</p> <ul> <li>If today is Sunny (row S), there’s a 70% chance it will be Sunny tomorrow, a 20% chance it will be Cloudy, and a 10% chance it will be Rainy.</li> <li>If today is Cloudy (row C), there’s a 30% chance it will be Sunny tomorrow, a 40% chance it will be Cloudy, and a 30% chance it will be Rainy.</li> <li>And so on for Rainy days.</li> </ul> <p>Notice an important property: <strong>each row of the transition matrix must sum to 1</strong>. This makes sense, right? If you’re in a given state, you <em>must</em> transition to one of the possible states (including staying in the same state), so the probabilities of all possible next states must add up to 100%.</p> <h3 id="predicting-the-future-a-step-by-step-example">Predicting the Future: A Step-by-Step Example</h3> <p>Let’s say today is <strong>Sunny</strong>. What’s the probability distribution of weather states two days from now?</p> <ol> <li> <p><strong>Current State (Day 0):</strong> Today is Sunny. Our initial state vector (a row vector representing probabilities of being in each state) is $\pi^{(0)} = [1.0, 0.0, 0.0]$ (100% chance of Sunny, 0% Cloudy, 0% Rainy).</p> </li> <li> <p><strong>Tomorrow’s Weather (Day 1):</strong> To find the probabilities for tomorrow, we multiply our initial state vector by the transition matrix: $\pi^{(1)} = \pi^{(0)} P$</p> <p>$[1.0, 0.0, 0.0] \begin{bmatrix} 0.7 &amp; 0.2 &amp; 0.1 \ 0.3 &amp; 0.4 &amp; 0.3 \ 0.2 &amp; 0.3 &amp; 0.5 \end{bmatrix}$ $= [(1.0 \times 0.7) + (0.0 \times 0.3) + (0.0 \times 0.2), \ (1.0 \times 0.2) + (0.0 \times 0.4) + (0.0 \times 0.3), \ (1.0 \times 0.1) + (0.0 \times 0.3) + (0.0 \times 0.5)]$ $= [0.7, 0.2, 0.1]$</p> <p>So, tomorrow, there’s a 70% chance of Sunny, 20% Cloudy, and 10% Rainy. (This is just the first row of P, as expected, since we started 100% in ‘Sunny’).</p> </li> <li> <p><strong>Day After Tomorrow’s Weather (Day 2):</strong> Now, we use the probabilities from Day 1 as our new starting point and multiply by the transition matrix again: $\pi^{(2)} = \pi^{(1)} P$</p> <p>$[0.7, 0.2, 0.1] \begin{bmatrix} 0.7 &amp; 0.2 &amp; 0.1 \ 0.3 &amp; 0.4 &amp; 0.3 \ 0.2 &amp; 0.3 &amp; 0.5 \end{bmatrix}$ $= [ (0.7 \times 0.7) + (0.2 \times 0.3) + (0.1 \times 0.2), \ (0.7 \times 0.2) + (0.2 \times 0.4) + (0.1 \times 0.3), \ (0.7 \times 0.1) + (0.2 \times 0.3) + (0.1 \times 0.5) ]$ $= [ (0.49 + 0.06 + 0.02), \ (0.14 + 0.08 + 0.03), \ (0.07 + 0.06 + 0.05) ]$ $= [0.57, 0.25, 0.18]$</p> <p>So, two days from now, there’s a 57% chance of Sunny, 25% Cloudy, and 18% Rainy. We can keep doing this for $n$ steps by calculating $\pi^{(n)} = \pi^{(0)} P^n$. Pretty cool, right?</p> </li> </ol> <h3 id="the-long-run-stationary-distribution">The Long Run: Stationary Distribution</h3> <p>What happens if we let this process run for a very, very long time? Does the weather pattern eventually settle into a stable probability distribution, regardless of what the weather was on Day 0? For many Markov Chains, the answer is yes! This is called the <strong>stationary distribution</strong> (or steady-state distribution), denoted by $\pi$.</p> <p>If a stationary distribution exists, it means that after enough time steps, the probability of being in any given state remains constant from one step to the next. Mathematically, this means:</p> <p>$\pi = \pi P$</p> <p>Where $\pi$ is a row vector representing the long-term probabilities of being in each state, and $P$ is our transition matrix. This equation effectively says: “If we’re already in the long-term distribution $\pi$, then applying one more transition ($P$) will keep us in that same distribution ($\pi$).”</p> <p>Finding this $\pi$ often involves solving a system of linear equations (including the constraint that the probabilities must sum to 1). For our weather example, if you were to solve it, you’d find a long-term probability for Sunny, Cloudy, and Rainy days that the system eventually gravitates towards. This tells us the overall climate or average weather pattern over time.</p> <h3 id="where-do-we-use-these-memoryless-chains">Where Do We Use These “Memoryless” Chains?</h3> <p>Markov Chains are far from just a theoretical curiosity. They power many real-world applications in diverse fields:</p> <ul> <li> <strong>Google’s PageRank Algorithm:</strong> One of the most famous applications! Google originally used a Markov Chain model to rank web pages. Each webpage is a state, and links between pages are transitions. The stationary distribution of this Markov Chain represents the “importance” of each page – the more likely you are to end up on a page during a random walk, the higher its rank.</li> <li> <strong>Natural Language Processing (NLP):</strong> <ul> <li> <strong>Text Generation:</strong> Markov Chains can model the probability of the next word given the current word, leading to surprisingly coherent (and sometimes hilarious) generated text.</li> <li> <strong>Part-of-Speech Tagging:</strong> Predicting if a word is a noun, verb, etc., based on the preceding word’s tag.</li> <li> <strong>Speech Recognition:</strong> Modeling sequences of phonemes or words.</li> </ul> </li> <li> <strong>Bioinformatics &amp; Genetics:</strong> Modeling DNA sequences, protein folding, and evolutionary processes where changes happen step-by-step.</li> <li> <strong>Financial Modeling:</strong> Predicting stock prices (though the “memoryless” property can be a strong assumption here!), modeling credit risk, and simulating market behavior.</li> <li> <strong>Reinforcement Learning (RL):</strong> Markov Decision Processes (MDPs), which are fundamental to RL, are essentially Markov Chains with an added layer of actions and rewards.</li> <li> <strong>Queueing Theory:</strong> Analyzing waiting lines in call centers, supermarkets, or computer networks.</li> </ul> <h3 id="limitations-and-extensions">Limitations and Extensions</h3> <p>While incredibly powerful, the strict “memoryless” Markov Property can sometimes be a limitation. What if the next state <em>does</em> depend on the last two states, or three?</p> <ul> <li> <table> <tbody> <tr> <td> <strong>Higher-Order Markov Chains:</strong> We can extend the definition to include more past states. For instance, a second-order Markov Chain would consider $P(X_{n+1}</td> <td>X_n, X_{n-1})$. This increases the number of states dramatically (e.g., if states are words, now states are pairs of words), making the transition matrix much larger.</td> </tr> </tbody> </table> </li> <li> <strong>Hidden Markov Models (HMMs):</strong> This is a significant extension where the states themselves are not directly observable (“hidden”). We only observe some output that is probabilistically related to the hidden state. HMMs are foundational in speech recognition, bioinformatics, and many sequence modeling tasks.</li> </ul> <h3 id="conclusion">Conclusion</h3> <p>Markov Chains offer a beautifully simple yet profoundly effective way to model sequential data and predict future probabilities. Their core idea – that the future depends only on the present – unlocks a world of applications, from understanding the weather to powering search engines.</p> <p>As you delve deeper into data science and machine learning, you’ll find variations and generalizations of Markov Chains appearing everywhere. Understanding this fundamental concept gives you a powerful tool for thinking about dynamic systems and making probabilistic predictions. So, next time you check the weather, spare a thought for those humble, memoryless Markov Chains working behind the scenes!</p> <p>What are your thoughts on Markov Chains? Have you encountered them in any surprising contexts? Let me know in the comments!</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/cracking-the-ai-black-box-why-explainable-ai-xai-i/">Cracking the AI Black Box: Why Explainable AI (XAI) is Our Superpower</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/the-secret-life-of-states-how-markov-chains-predic/">The Secret Life of States: How Markov Chains Predict Our Next Move (Without Remembering the Past!)</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/gradient-descent-unpacking-the-engine-of-machine-l/">Gradient Descent: Unpacking the Engine of Machine Learning</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Adarsh Nair. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/blog/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/masonry.js?v=a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/zoom.js?v=85ddb88934d28b74e78031fd54cf8308"></script> <script src="/blog/assets/js/no_defer.js?v=2781658a0a2b13ed609542042a859126"></script> <script defer src="/blog/assets/js/common.js?v=c15de51d4bb57887caa2c21988d97279"></script> <script defer src="/blog/assets/js/copy_code.js?v=c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/blog/assets/js/jupyter_new_tab.js?v=d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/blog/assets/js/mathjax-setup.js?v=a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/progress-bar.js?v=2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/blog/assets/js/vanilla-back-to-top.min.js?v=f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/blog/assets/js/search/ninja-keys.min.js?v=a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/blog/assets/js/search-setup.js?v=6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/blog/assets/js/search-data.js"></script> <script src="/blog/assets/js/shortcut-key.js?v=ccc841c459bfc0e64c1c2b5acd10df02"></script> </body> </html>