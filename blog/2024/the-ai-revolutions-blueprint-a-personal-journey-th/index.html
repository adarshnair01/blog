<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> The AI Revolution's Blueprint: A Personal Journey Through Transformers | Adarsh Nair </title> <meta name="author" content="Adarsh Nair"> <meta name="description" content="A deep dive into machine learning, AI, and data science. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <meta http-equiv="Content-Security-Policy" content="default-src 'self'; script-src 'self' 'unsafe-inline' https:; style-src 'self' 'unsafe-inline' https:; img-src 'self' data: https:; font-src 'self' data: https:; media-src 'self' https:; frame-src 'self' https:; connect-src 'self' https:;"> <link rel="stylesheet" href="/blog/assets/css/bootstrap.min.css?v=a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/blog/assets/css/academicons.min.css?v=f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/blog/assets/css/scholar-icons.css?v=62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-github.css?v=591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/blog/assets/css/main.css?v=d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://adarshnair.online/blog/blog/blog/2024/the-ai-revolutions-blueprint-a-personal-journey-th/"> <script src="/blog/assets/js/theme.js?v=5fea5159b787642c1bbc1f334d60f883"></script> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-native.css?v=5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="https://adarshnair.online" rel="external nofollow noopener" target="_blank"> Adarsh Nair </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/blog/"> </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/index.html">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/cv/">CV </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/repositories/">repositories </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="fa-solid fa-magnifying-glass"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-half-sun-moon" id="light-toggle-system"></i> <i class="fa-solid fa-moon" id="light-toggle-dark"></i> <i class="fa-solid fa-sun" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">The AI Revolution's Blueprint: A Personal Journey Through Transformers</h1> <p class="post-meta"> Created on June 02, 2024 by Adarsh Nair </p> <p class="post-tags"> <a href="/blog/blog/2024"> <i class="fa-solid fa-calendar fa-sm"></i> 2024 </a>   ·   <a href="/blog/blog/tag/machine-learning"> <i class="fa-solid fa-hashtag fa-sm"></i> Machine Learning</a>   <a href="/blog/blog/tag/nlp"> <i class="fa-solid fa-hashtag fa-sm"></i> NLP</a>   <a href="/blog/blog/tag/deep-learning"> <i class="fa-solid fa-hashtag fa-sm"></i> Deep Learning</a>   <a href="/blog/blog/tag/transformers"> <i class="fa-solid fa-hashtag fa-sm"></i> Transformers</a>   <a href="/blog/blog/tag/ai-architecture"> <i class="fa-solid fa-hashtag fa-sm"></i> AI Architecture</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p>My journey into the world of artificial intelligence has been a series of “aha!” moments, but few have been as impactful as understanding the Transformer architecture. It felt like discovering the secret blueprint behind the most advanced AI systems we use today. For anyone who’s ever marvelled at the fluent conversations with ChatGPT, the creative images from DALL-E, or the nuanced sentiment analysis powering modern applications, the Transformer is the unsung hero.</p> <p>But what exactly is a Transformer? And why did it cause such a stir in the deep learning community? Let’s take a personal dive into its mechanics, breaking down why it works, and how it came to dominate the AI landscape.</p> <h3 id="the-world-before-transformers-when-ai-had-short-term-memory">The World Before Transformers: When AI Had Short-Term Memory</h3> <p>Before we talk about the future, let’s briefly glance at the past. For a long time, the go-to architecture for processing sequential data like text or speech was Recurrent Neural Networks (RNNs) and their more sophisticated cousins, LSTMs (Long Short-Term Memory networks).</p> <p>Imagine you’re reading a very long novel. RNNs process text word by word, carrying a little “memory” (a hidden state) of what they’ve seen so far. It’s like reading one sentence, trying to summarize its essence, and then using that summary to understand the next sentence.</p> <p>While revolutionary at the time, RNNs had some pretty significant limitations:</p> <ol> <li> <strong>Slow and Sequential:</strong> Each word had to be processed <em>after</em> the previous one. This meant no parallelization – you couldn’t speed things up by processing multiple parts of the text at once.</li> <li> <strong>The Long-Term Memory Problem:</strong> Remembering the crucial context from the beginning of a very long text was incredibly hard. By the time the model got to the end, the initial “memory” often faded or got diluted, leading to what we call “vanishing gradients.”</li> <li> <strong>Information Bottleneck:</strong> All information had to be squeezed into a fixed-size hidden state, which sometimes just wasn’t enough to capture complex relationships across long sentences.</li> </ol> <p>I remember grappling with these issues in my own projects. Trying to build a model that could understand a long paragraph’s nuance felt like an uphill battle. Then, in 2017, a paper dropped that changed everything: “Attention Is All You Need.”</p> <h3 id="the-big-idea-attention-is-all-you-need">The Big Idea: Attention is All You Need</h3> <p>The title of that seminal paper said it all. Forget recurrence; what if an AI model could simply <em>look</em> at all parts of an input sequence at once and decide which parts were most important for understanding any given part? This is the core idea behind <strong>Attention</strong>.</p> <p>Think of it like studying for a big exam. You don’t just read the textbook linearly, trying to summarize each page sequentially. Instead, when you’re trying to understand a specific concept, you might skim the entire chapter, highlighting key terms, looking at diagrams, and jumping back to previous sections that seem relevant. You <em>attend</em> to the most important parts.</p> <p>The Transformer model took this concept and made it the cornerstone of its architecture. It completely abandoned recurrence, relying solely on attention mechanisms to draw global dependencies between input and output.</p> <h3 id="how-attention-works-the-query-key-value-play">How Attention Works: The Query, Key, Value Play</h3> <p>Let’s demystify the attention mechanism itself. It’s often explained using an analogy from information retrieval, like searching a database:</p> <ul> <li> <strong>Query (Q):</strong> What information are you looking for? (e.g., “Show me sci-fi movies.”)</li> <li> <strong>Keys (K):</strong> Labels or descriptions of available information. (e.g., Each movie has a “genre” key.)</li> <li> <strong>Values (V):</strong> The actual information you get back. (e.g., The movie title, director, year, etc.)</li> </ul> <p>In the context of a Transformer, for each word in a sentence (let’s say we’re trying to understand the word “bank” in “river bank”):</p> <ol> <li>We have a <strong>Query</strong> vector for the word “bank.”</li> <li>We compare this Query vector to <strong>Key</strong> vectors for <em>every other word</em> in the sentence (and “bank” itself).</li> <li>The comparison (usually a dot product) gives us a <strong>score</strong> indicating how relevant each other word is to “bank.”</li> <li>These scores are then passed through a <strong>softmax</strong> function to turn them into probabilities (weights), ensuring they sum up to 1. Words highly relevant to “bank” get higher weights.</li> <li>Finally, these weights are used to create a weighted sum of the <strong>Value</strong> vectors of all words. This weighted sum is the “attended” representation of “bank,” now enriched with context from the most relevant words.</li> </ol> <p>Mathematically, this looks something like:</p> <p>$Attention(Q, K, V) = \text{softmax}(\frac{QK^T}{\sqrt{d_k}})V$</p> <p>Here, $Q$, $K$, and $V$ are matrices where each row represents the Query, Key, or Value vector for a word in the sequence. $d_k$ is the dimension of the key vectors; we divide by its square root to prevent large dot products from pushing the softmax into regions with tiny gradients, which can hinder training.</p> <h3 id="self-attention-looking-inward">Self-Attention: Looking Inward</h3> <p>The attention mechanism described above is specifically <strong>Self-Attention</strong> because the Queries, Keys, and Values all come from the <em>same</em> input sequence. Each word attends to <em>itself</em> and <em>all other words</em> in the sentence to build a richer representation of itself. This is what allows the model to understand the role of “bank” in “river bank” versus “money bank.”</p> <h3 id="multi-head-attention-diverse-perspectives">Multi-Head Attention: Diverse Perspectives</h3> <p>One attention mechanism is good, but multiple are even better! <strong>Multi-Head Attention</strong> extends the idea by running several self-attention mechanisms in parallel. Each “head” learns to focus on different parts of the input or different types of relationships.</p> <p>Imagine you’re solving a puzzle. One part of your brain might focus on colors, another on shapes, and another on edges. Multi-Head Attention is similar: each head can learn to capture different aspects of the input’s relationships (e.g., one head might focus on grammatical dependencies, another on semantic connections).</p> <p>The outputs from these parallel attention heads are then concatenated and linearly transformed, allowing the model to combine these diverse perspectives into a single, comprehensive representation.</p> <h3 id="building-the-transformer-encoder-and-decoder-stacks">Building the Transformer: Encoder and Decoder Stacks</h3> <p>The full Transformer architecture is built upon these attention mechanisms, typically in an <strong>encoder-decoder</strong> structure.</p> <h4 id="the-encoder">The Encoder</h4> <p>The encoder’s job is to process the input sequence and produce a rich, contextual representation. It’s comprised of multiple identical layers stacked on top of each other. Each layer has two main sub-layers:</p> <ol> <li> <strong>Multi-Head Self-Attention:</strong> As discussed, this allows each word to attend to all other words in the input.</li> <li> <strong>Position-wise Feed-Forward Network:</strong> A simple fully connected neural network applied independently to each position. It helps the model process the information gathered by the attention mechanism.</li> </ol> <p>Crucially, each sub-layer is followed by a <strong>residual connection</strong> (meaning we add the input of the sub-layer to its output) and <strong>layer normalization</strong>. Residual connections help with training very deep networks by allowing gradients to flow more easily, preventing them from vanishing. Layer Normalization stabilizes training.</p> <h4 id="the-decoder">The Decoder</h4> <p>The decoder’s role is to generate the output sequence, word by word, based on the encoder’s output and the words it has already generated. It also has multiple identical layers, but each has three sub-layers:</p> <ol> <li> <strong>Masked Multi-Head Self-Attention:</strong> This is similar to the encoder’s self-attention, but with a crucial difference: it’s “masked.” When generating a word, the decoder can only attend to words <em>it has already generated</em> (and the current word itself). This prevents it from “cheating” by looking at future words in the target sequence.</li> <li> <strong>Multi-Head Attention (Encoder-Decoder Attention):</strong> This sub-layer queries the output of the <em>encoder</em>. Here, the Queries come from the decoder’s previous layer, and the Keys and Values come from the <em>encoder’s output</em>. This is where the decoder “looks back” at the original input sentence to gather relevant information for generating the next word.</li> <li> <strong>Position-wise Feed-Forward Network:</strong> Same as in the encoder.</li> </ol> <p>Again, each sub-layer is followed by a residual connection and layer normalization.</p> <h3 id="the-missing-piece-positional-encoding">The Missing Piece: Positional Encoding</h3> <p>“If attention looks at everything at once, how does the Transformer know the order of words?” This was one of my first questions when I understood attention. Since attention itself is permutation-invariant (meaning shuffling the words wouldn’t change the attention scores if the QKV values were fixed), we need a way to inject information about the word’s position in the sequence.</p> <p>This is where <strong>Positional Encoding</strong> comes in. Before passing the word embeddings to the encoder (and decoder), we add a special vector to each word embedding that encodes its absolute position. These vectors are learned patterns of sine and cosine functions:</p> <p>$PE_{(pos, 2i)} = \sin(pos / 10000^{2i/d_{model}})$ $PE_{(pos, 2i+1)} = \cos(pos / 10000^{2i/d_{model}})$</p> <p>Where $pos$ is the position of the word, $i$ is the dimension within the positional encoding vector, and $d_{model}$ is the dimension of the embedding space.</p> <p>This ingenious method allows the model to learn not just absolute positions, but also relative positions, as a fixed offset between positions $pos$ and $pos+k$ will always result in a linear transformation of the positional embeddings. It’s like giving each word a unique GPS coordinate in the sentence.</p> <h3 id="why-transformers-changed-everything">Why Transformers Changed Everything</h3> <p>So, what made this architecture so revolutionary?</p> <ol> <li> <strong>Parallelization Power:</strong> By eliminating recurrence, Transformers can process entire sequences simultaneously. This makes them incredibly fast to train on modern hardware (GPUs, TPUs).</li> <li> <strong>Long-Range Dependencies:</strong> The attention mechanism allows the model to directly connect any two words in a sequence, regardless of their distance. This dramatically improved performance on tasks requiring an understanding of long-range context.</li> <li> <strong>Scalability:</strong> The architecture scales incredibly well. Give it more data and more parameters, and it just keeps getting better. This led to the era of massive pre-trained models like BERT, GPT-2, GPT-3, and now GPT-4.</li> <li> <strong>Transfer Learning:</strong> Pre-training large Transformers on vast amounts of text data (e.g., the entire internet) to learn general language understanding, and then fine-tuning them for specific tasks (like sentiment analysis or translation), became the dominant paradigm in NLP.</li> <li> <strong>Beyond Language:</strong> While born in NLP, Transformers have shown incredible versatility, being adapted for computer vision (Vision Transformers, ViT), speech recognition, and even robotics.</li> </ol> <h3 id="my-aha-moment-and-beyond">My “Aha!” Moment and Beyond</h3> <p>For me, the “aha!” moment wasn’t just understanding the math, but seeing how elegantly all these pieces – QKV, multi-head attention, positional encoding, residual connections – fit together to solve the fundamental problems of sequence modeling. It felt like watching a master clockmaker assemble an intricate mechanism.</p> <p>The Transformer isn’t just a model; it’s a paradigm shift. It showed us that with the right architecture, we could build AI systems that truly understand and generate complex human-like text and other forms of data. It unlocked an explosion of research and applications that continue to redefine what’s possible with AI.</p> <p>As you explore the fascinating world of data science and machine learning, understanding the Transformer is no longer just a specialization – it’s foundational. It’s the blueprint that continues to shape the future of AI, and I encourage you to keep building, experimenting, and discovering its endless possibilities.</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/cracking-the-ai-black-box-why-explainable-ai-xai-i/">Cracking the AI Black Box: Why Explainable AI (XAI) is Our Superpower</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/the-secret-life-of-states-how-markov-chains-predic/">The Secret Life of States: How Markov Chains Predict Our Next Move (Without Remembering the Past!)</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/gradient-descent-unpacking-the-engine-of-machine-l/">Gradient Descent: Unpacking the Engine of Machine Learning</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Adarsh Nair. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/blog/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/masonry.js?v=a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/zoom.js?v=85ddb88934d28b74e78031fd54cf8308"></script> <script src="/blog/assets/js/no_defer.js?v=2781658a0a2b13ed609542042a859126"></script> <script defer src="/blog/assets/js/common.js?v=c15de51d4bb57887caa2c21988d97279"></script> <script defer src="/blog/assets/js/copy_code.js?v=c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/blog/assets/js/jupyter_new_tab.js?v=d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/blog/assets/js/mathjax-setup.js?v=a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/progress-bar.js?v=2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/blog/assets/js/vanilla-back-to-top.min.js?v=f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/blog/assets/js/search/ninja-keys.min.js?v=a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/blog/assets/js/search-setup.js?v=6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/blog/assets/js/search-data.js"></script> <script src="/blog/assets/js/shortcut-key.js?v=ccc841c459bfc0e64c1c2b5acd10df02"></script> </body> </html>