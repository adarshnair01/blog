<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> The Tightrope Walk: Why Precision and Recall Are More Than Just Numbers (and Why Accuracy Isn't Enough) | Adarsh Nair </title> <meta name="author" content="Adarsh Nair"> <meta name="description" content="A deep dive into machine learning, AI, and data science. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <meta http-equiv="Content-Security-Policy" content="default-src 'self'; script-src 'self' 'unsafe-inline' https:; style-src 'self' 'unsafe-inline' https:; img-src 'self' data: https:; font-src 'self' data: https:; media-src 'self' https:; frame-src 'self' https:; connect-src 'self' https:;"> <link rel="stylesheet" href="/blog/assets/css/bootstrap.min.css?v=a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/blog/assets/css/academicons.min.css?v=f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/blog/assets/css/scholar-icons.css?v=62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-github.css?v=591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/blog/assets/css/main.css?v=d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://adarshnair.online/blog/blog/blog/2024/the-tightrope-walk-why-precision-and-recall-are-mo/"> <script src="/blog/assets/js/theme.js?v=5fea5159b787642c1bbc1f334d60f883"></script> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-native.css?v=5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="https://adarshnair.online" rel="external nofollow noopener" target="_blank"> Adarsh Nair </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/blog/"> </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/index.html">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/cv/">CV </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="https://adarshnair.online/books/" rel="external nofollow noopener" target="_blank">books </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="fa-solid fa-magnifying-glass"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-half-sun-moon" id="light-toggle-system"></i> <i class="fa-solid fa-moon" id="light-toggle-dark"></i> <i class="fa-solid fa-sun" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">The Tightrope Walk: Why Precision and Recall Are More Than Just Numbers (and Why Accuracy Isn't Enough)</h1> <p class="post-meta"> Created on June 13, 2024 by Adarsh Nair </p> <p class="post-tags"> <a href="/blog/blog/2024"> <i class="fa-solid fa-calendar fa-sm"></i> 2024 </a>   ·   <a href="/blog/blog/tag/machine-learning"> <i class="fa-solid fa-hashtag fa-sm"></i> Machine Learning</a>   <a href="/blog/blog/tag/model-evaluation"> <i class="fa-solid fa-hashtag fa-sm"></i> Model Evaluation</a>   <a href="/blog/blog/tag/classification"> <i class="fa-solid fa-hashtag fa-sm"></i> Classification</a>   <a href="/blog/blog/tag/data-science"> <i class="fa-solid fa-hashtag fa-sm"></i> Data Science</a>   <a href="/blog/blog/tag/metrics"> <i class="fa-solid fa-hashtag fa-sm"></i> Metrics</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p>Hey there, fellow explorers of the data universe!</p> <p>Today, I want to talk about something that often gets glossed over when we first dive into machine learning: model evaluation. When I started, I thought, “Accuracy! That’s it, right? If my model is 95% accurate, it’s amazing!” Oh, how naive I was.</p> <p>It turns out, the world isn’t always so straightforward. Sometimes, being “mostly right” isn’t good enough, especially when the cost of making a specific type of mistake is astronomically high. This is where the dynamic duo of <strong>Precision</strong> and <strong>Recall</strong> stride onto the stage, ready to reveal the nuances that raw accuracy often hides.</p> <p>Imagine you’re building a system, whether it’s for detecting spam emails, diagnosing a rare disease, or flagging fraudulent transactions. In each of these scenarios, the type of mistake your model makes can have vastly different consequences. Missing a crucial email (a legitimate email wrongly classified as spam) feels different from missing an actual spam email. Missing a disease feels catastrophic compared to a false alarm.</p> <p>This isn’t just about numbers; it’s about understanding the real-world impact of our algorithms.</p> <h3 id="the-foundation-understanding-the-confusion-matrix">The Foundation: Understanding the Confusion Matrix</h3> <p>Before we can truly appreciate Precision and Recall, we need to get cozy with their birthplace: the <strong>Confusion Matrix</strong>. Don’t let the name scare you; it’s quite elegant once you see it. Think of it as a scorecard that breaks down all the possible outcomes of your classification model.</p> <p>Let’s simplify. When your model tries to predict if something is <code class="language-plaintext highlighter-rouge">Positive</code> (e.g., spam, disease, fraud) or <code class="language-plaintext highlighter-rouge">Negative</code> (e.g., not spam, healthy, legitimate), there are four possible outcomes:</p> <ol> <li> <strong>True Positive (TP):</strong> The model predicted <code class="language-plaintext highlighter-rouge">Positive</code>, and it was actually <code class="language-plaintext highlighter-rouge">Positive</code>. (Good job!) <ul> <li> <em>Example:</em> Model says “This is spam,” and it <em>is</em> spam.</li> </ul> </li> <li> <strong>True Negative (TN):</strong> The model predicted <code class="language-plaintext highlighter-rouge">Negative</code>, and it was actually <code class="language-plaintext highlighter-rouge">Negative</code>. (Also good job!) <ul> <li> <em>Example:</em> Model says “This is <em>not</em> spam,” and it <em>is not</em> spam.</li> </ul> </li> <li> <strong>False Positive (FP):</strong> The model predicted <code class="language-plaintext highlighter-rouge">Positive</code>, but it was actually <code class="language-plaintext highlighter-rouge">Negative</code>. (Uh oh, a Type I error!) <ul> <li> <em>Example:</em> Model says “This is spam,” but it’s actually a legitimate email. This is often called a “false alarm.”</li> </ul> </li> <li> <strong>False Negative (FN):</strong> The model predicted <code class="language-plaintext highlighter-rouge">Negative</code>, but it was actually <code class="language-plaintext highlighter-rouge">Positive</code>. (Big uh oh, a Type II error!) <ul> <li> <em>Example:</em> Model says “This is <em>not</em> spam,” but it <em>is</em> spam. This is often called a “miss.”</li> </ul> </li> </ol> <p>Here’s how we often visualize it:</p> <table> <thead> <tr> <th style="text-align: left"> </th> <th style="text-align: left"><strong>Actual Positive</strong></th> <th style="text-align: left"><strong>Actual Negative</strong></th> </tr> </thead> <tbody> <tr> <td style="text-align: left"><strong>Predicted Positive</strong></td> <td style="text-align: left">True Positive (TP)</td> <td style="text-align: left">False Positive (FP)</td> </tr> <tr> <td style="text-align: left"><strong>Predicted Negative</strong></td> <td style="text-align: left">False Negative (FN)</td> <td style="text-align: left">True Negative (TN)</td> </tr> </tbody> </table> <p>Now, with the Confusion Matrix laid out, we can finally dive into our heroes!</p> <h3 id="precision-the-careful-classifier">Precision: The Careful Classifier</h3> <p>Imagine you’re a highly discerning art critic. When you declare a painting a “masterpiece,” you want to be <em>absolutely sure</em> it truly is one. You’d rather miss a few potential masterpieces than wrongly praise a mediocre piece. That, my friends, is the spirit of <strong>Precision</strong>.</p> <p>Precision answers the question: <strong>“When your model predicts something is positive, how often is it <em>actually</em> positive?”</strong></p> <p>It focuses on the quality of your positive predictions. If your model makes a positive prediction, how trustworthy is that prediction?</p> <p>The formula for Precision is:</p> <p>$Precision = \frac{TP}{TP + FP}$</p> <p>Let’s break that down:</p> <ul> <li> <strong>TP (True Positives):</strong> The number of times your model correctly identified a positive case.</li> <li> <strong>FP (False Positives):</strong> The number of times your model incorrectly identified a negative case as positive (the “false alarms”).</li> </ul> <p>A high precision score means that when your model says “yes,” you can be quite confident that it’s right.</p> <p><strong>When is Precision super important?</strong></p> <p>Think about scenarios where False Positives are very costly or undesirable:</p> <ul> <li> <strong>Spam Detection:</strong> If your spam filter has low precision, it might flag important work emails or family photos as spam. This is incredibly frustrating and can lead to lost information. You’d rather get a bit more spam than miss a critical email.</li> <li> <strong>Product Recommendations:</strong> Recommending a product that a user truly <em>doesn’t</em> want. Too many irrelevant recommendations can annoy users and make them distrust your system.</li> <li> <strong>Medical Diagnosis (for severe treatments):</strong> Imagine a model suggesting a highly invasive surgery for a disease the patient doesn’t actually have. A false positive here is a huge problem.</li> </ul> <p>In these cases, we prioritize minimizing False Positives, even if it means we might miss some actual positive cases (accepting a bit more spam, for instance).</p> <h3 id="recall-the-thorough-net">Recall: The Thorough Net</h3> <p>Now, shift gears. Imagine you’re a lifeguard scanning the beach for swimmers in distress. Your absolute priority is to spot <em>every single person</em> who needs help. You’d rather initiate a few false alarms (thinking someone is drowning when they’re just playing) than miss a single person genuinely in trouble. This is the essence of <strong>Recall</strong>.</p> <p>Recall answers the question: <strong>“Of all the actual positive cases out there, how many did your model correctly identify?”</strong></p> <p>It focuses on the coverage of your positive predictions. Did your model catch all the real ‘positives’?</p> <p>The formula for Recall is:</p> <p>$Recall = \frac{TP}{TP + FN}$</p> <p>Let’s break that down:</p> <ul> <li> <strong>TP (True Positives):</strong> The number of times your model correctly identified a positive case.</li> <li> <strong>FN (False Negatives):</strong> The number of times your model failed to identify an actual positive case (the “misses”).</li> </ul> <p>A high recall score means your model is very good at finding all the positive cases. It’s thorough.</p> <p><strong>When is Recall super important?</strong></p> <p>Think about scenarios where False Negatives are very costly or dangerous:</p> <ul> <li> <strong>Disease Detection (for early diagnosis):</strong> Missing a cancerous tumor (False Negative) could have life-threatening consequences. Here, you’d rather have a few false alarms (False Positives) that require further testing than miss a real case.</li> <li> <strong>Fraud Detection:</strong> If a model misses a fraudulent transaction (False Negative), the company loses money. Catching all fraud is paramount.</li> <li> <strong>Security Breach Detection:</strong> Failing to detect a cyber attack (False Negative) could lead to data loss, financial ruin, or reputational damage.</li> </ul> <p>In these situations, our primary goal is to minimize False Negatives, even if it means we might generate a few more false positives.</p> <h3 id="the-inevitable-trade-off-a-tightrope-walk">The Inevitable Trade-Off: A Tightrope Walk</h3> <p>Here’s the kicker: Precision and Recall often have an inverse relationship. It’s a fundamental trade-off, like a seesaw.</p> <ul> <li> <strong>Want higher Recall?</strong> You’ll likely have to lower your standards for what you classify as ‘Positive’. This might mean casting a wider net, being more sensitive. But casting a wider net means you’re more likely to catch things that aren’t actually positive, increasing your False Positives, and thus <em>lowering your Precision</em>.</li> <li> <strong>Want higher Precision?</strong> You’ll raise your standards, only declaring something ‘Positive’ if you’re very, very sure. This means being more selective. While this reduces False Positives, it also means you’re more likely to miss some actual positive cases that don’t meet your strict criteria, increasing your False Negatives, and thus <em>lowering your Recall</em>.</li> </ul> <p>Imagine our spam filter again:</p> <ul> <li>To get 100% Recall (catch <em>all</em> spam), you might have to classify almost everything as spam. This would lead to terrible Precision (flagging important emails as spam).</li> <li>To get 100% Precision (never flag a legitimate email as spam), you might only classify emails as spam if they are <em>blatantly obvious</em>. This would lead to terrible Recall (missing a lot of actual spam).</li> </ul> <p>As a data scientist, much of your work involves understanding this trade-off for your specific problem and finding the optimal balance. This usually involves adjusting the <strong>classification threshold</strong> of your model (the point at which it switches from predicting ‘negative’ to ‘positive’).</p> <h3 id="beyond-pr-the-f1-score">Beyond P&amp;R: The F1-Score</h3> <p>Sometimes, you need a single metric that gives a balanced view of both Precision and Recall, especially when one doesn’t heavily outweigh the other in importance, or when your dataset has an imbalanced class distribution (e.g., very few positive cases compared to negative ones).</p> <p>Enter the <strong>F1-Score</strong>. It’s the harmonic mean of Precision and Recall:</p> <p>$F1 = 2 \cdot \frac{Precision \cdot Recall}{Precision + Recall}$</p> <p>The F1-Score penalizes extreme values. If either Precision or Recall is very low, the F1-Score will also be low. It provides a good single number to compare models when you want a decent balance of both without favoring one over the other.</p> <h3 id="choosing-your-battles-wisely-the-art-of-model-evaluation">Choosing Your Battles Wisely: The Art of Model Evaluation</h3> <p>So, which metric should you care about more? Precision or Recall?</p> <p>The answer, as with most things in data science, is: <strong>It depends entirely on the problem you’re trying to solve and the real-world consequences of your model’s mistakes.</strong></p> <p>There’s no universally “best” metric. A truly effective data scientist doesn’t just build models; they understand the domain deeply enough to choose the right evaluation metrics.</p> <ul> <li> <strong>Building a search engine for rare documents?</strong> You’d likely prioritize <strong>Recall</strong> to ensure users find all relevant documents, even if a few irrelevant ones slip in (lower Precision).</li> <li> <strong>Developing an AI to autonomously make crucial financial investments?</strong> You’d likely demand very high <strong>Precision</strong> to avoid losing money, even if it means missing some potential investment opportunities (lower Recall).</li> <li> <strong>Developing a model to identify potential threats in a surveillance system?</strong> <strong>Recall</strong> is critical. You absolutely cannot miss a threat, even if it means a few false alarms for a blowing leaf.</li> </ul> <p>My journey through data science has taught me that the metrics are not just numbers for our dashboards; they are reflections of the ethical considerations, business objectives, and human impact of our work.</p> <h3 id="bringing-it-all-together">Bringing it All Together</h3> <p>As you continue your journey into machine learning, I urge you to look beyond the seemingly simple “accuracy” score. Dive into the Confusion Matrix, understand the definitions of True/False Positives/Negatives, and critically ask yourself: “What kind of mistake is more costly in <em>this specific situation</em>?”</p> <p>Precision and Recall aren’t just technical terms; they are powerful lenses through which we can truly understand our models’ behavior and, more importantly, align them with the real-world needs and values of the people and systems they serve. They remind us that building intelligent systems is about more than just prediction – it’s about informed decision-making and responsible impact. Keep exploring, keep questioning, and keep learning!</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/cracking-the-ai-black-box-why-explainable-ai-xai-i/">Cracking the AI Black Box: Why Explainable AI (XAI) is Our Superpower</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/the-secret-life-of-states-how-markov-chains-predic/">The Secret Life of States: How Markov Chains Predict Our Next Move (Without Remembering the Past!)</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/gradient-descent-unpacking-the-engine-of-machine-l/">Gradient Descent: Unpacking the Engine of Machine Learning</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Adarsh Nair. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/blog/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/masonry.js?v=a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/zoom.js?v=85ddb88934d28b74e78031fd54cf8308"></script> <script src="/blog/assets/js/no_defer.js?v=2781658a0a2b13ed609542042a859126"></script> <script defer src="/blog/assets/js/common.js?v=c15de51d4bb57887caa2c21988d97279"></script> <script defer src="/blog/assets/js/copy_code.js?v=c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/blog/assets/js/jupyter_new_tab.js?v=d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/blog/assets/js/mathjax-setup.js?v=a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/progress-bar.js?v=2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/blog/assets/js/vanilla-back-to-top.min.js?v=f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/blog/assets/js/search/ninja-keys.min.js?v=a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/blog/assets/js/search-setup.js?v=6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/blog/assets/js/search-data.js"></script> <script src="/blog/assets/js/shortcut-key.js?v=ccc841c459bfc0e64c1c2b5acd10df02"></script> </body> </html>