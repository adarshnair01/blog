<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> The Whisper of the Unusual: Unmasking Anomalies in Our Data | Adarsh Nair </title> <meta name="author" content="Adarsh Nair"> <meta name="description" content="A deep dive into machine learning, AI, and data science. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <meta http-equiv="Content-Security-Policy" content="default-src 'self'; script-src 'self' 'unsafe-inline' https:; style-src 'self' 'unsafe-inline' https:; img-src 'self' data: https:; font-src 'self' data: https:; media-src 'self' https:; frame-src 'self' https:; connect-src 'self' https:;"> <link rel="stylesheet" href="/blog/assets/css/bootstrap.min.css?v=a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/blog/assets/css/academicons.min.css?v=f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/blog/assets/css/scholar-icons.css?v=62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-github.css?v=591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/blog/assets/css/main.css?v=d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://adarshnair.online/blog/blog/blog/2024/the-whisper-of-the-unusual-unmasking-anomalies-in/"> <script src="/blog/assets/js/theme.js?v=5fea5159b787642c1bbc1f334d60f883"></script> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-native.css?v=5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="https://adarshnair.online" rel="external nofollow noopener" target="_blank"> Adarsh Nair </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/blog/"> </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/index.html">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/about/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/cv/">CV </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="https://adarshnair.online/books/" rel="external nofollow noopener" target="_blank">books </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="fa-solid fa-magnifying-glass"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-half-sun-moon" id="light-toggle-system"></i> <i class="fa-solid fa-moon" id="light-toggle-dark"></i> <i class="fa-solid fa-sun" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">The Whisper of the Unusual: Unmasking Anomalies in Our Data</h1> <p class="post-meta"> Created on June 27, 2024 by Adarsh Nair </p> <p class="post-tags"> <a href="/blog/blog/2024"> <i class="fa-solid fa-calendar fa-sm"></i> 2024 </a>   ·   <a href="/blog/blog/tag/anomaly-detection"> <i class="fa-solid fa-hashtag fa-sm"></i> Anomaly Detection</a>   <a href="/blog/blog/tag/machine-learning"> <i class="fa-solid fa-hashtag fa-sm"></i> Machine Learning</a>   <a href="/blog/blog/tag/data-science"> <i class="fa-solid fa-hashtag fa-sm"></i> Data Science</a>   <a href="/blog/blog/tag/outliers"> <i class="fa-solid fa-hashtag fa-sm"></i> Outliers</a>   <a href="/blog/blog/tag/ai"> <i class="fa-solid fa-hashtag fa-sm"></i> AI</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p>Hey everyone!</p> <p>Ever had that gut feeling that something was just… off? A strange pattern in your routine, a weird temperature reading from a sensor, or a transaction that looked a little too good (or bad) to be true? That intuitive sense of detecting something unusual is exactly what we, as data scientists and machine learning engineers, try to capture and automate. Welcome to the fascinating world of <strong>Anomaly Detection</strong>.</p> <p>For a long time, the idea of finding “weird stuff” in data seemed almost magical. But as I dove deeper into machine learning, I realized it’s less magic and more a blend of statistical rigor, clever algorithms, and a keen understanding of context. It’s about building systems that act like vigilant guardians, constantly scanning for deviations from the norm. And trust me, it’s one of the most impactful things you can add to your data science toolkit.</p> <h3 id="what-even-is-an-anomaly-the-what-and-why">What Even <em>Is</em> an Anomaly? The “What” and “Why”</h3> <p>At its core, an <strong>anomaly</strong> (also known as an outlier, novelty, or rare event) is a data point or a set of data points that deviates significantly from the majority of the data. It’s the black sheep in a flock of white ones, the unexpected note in a familiar melody.</p> <p>Why do we care? Because these “unusual” data points often carry critical information:</p> <ul> <li> <strong>Fraud Detection:</strong> An anomaly might be a fraudulent credit card transaction or an insurance claim.</li> <li> <strong>System Health Monitoring:</strong> A sudden spike in server CPU usage or a dip in network traffic could signal a system failure or an attack.</li> <li> <strong>Medical Diagnostics:</strong> Unusual patterns in patient data might indicate a rare disease or an adverse reaction to medication.</li> <li> <strong>Manufacturing Quality Control:</strong> Detecting defects in products on an assembly line.</li> <li> <strong>Cybersecurity:</strong> Spotting unusual network activity that could signify an intrusion.</li> </ul> <p>It’s about finding the needles in haystacks, but often, those needles are the <em>most important</em> part of the haystack!</p> <p>Anomalies aren’t all the same, though. Here are a few common types:</p> <ol> <li> <strong>Point Anomalies:</strong> This is the simplest type. A single data instance is anomalous relative to the rest of the data. <ul> <li> <em>Example:</em> A credit card transaction of $10,000 in a user’s account where typical transactions are under $100.</li> </ul> </li> <li> <strong>Contextual Anomalies:</strong> A data instance is anomalous in a specific context, but not necessarily otherwise. The <em>value</em> itself might be normal, but its occurrence under certain conditions makes it an anomaly. <ul> <li> <em>Example:</em> A high electricity usage reading at 3 AM is anomalous for a typical home, but perfectly normal at 3 PM. The context (time of day) matters.</li> </ul> </li> <li> <strong>Collective Anomalies:</strong> A collection of related data instances is anomalous with respect to the entire dataset, even if individual instances within the collection might not be. <ul> <li> <em>Example:</em> A sustained decrease in network traffic volume followed by a sudden, massive surge over several minutes could collectively indicate a DDoS (Distributed Denial of Service) attack, even if no single data point (individual packet size or number) is abnormal on its own.</li> </ul> </li> </ol> <h3 id="the-great-challenge-why-finding-the-weird-is-hard">The Great Challenge: Why Finding the “Weird” is Hard</h3> <p>If anomaly detection is so important, why isn’t it trivial? Ah, here’s where the fun begins. Anomalies are tricky for several reasons:</p> <ul> <li> <strong>Rarity:</strong> By definition, anomalies are rare. This means we often have very few examples of “weird” data, making it hard for supervised machine learning models to learn what an anomaly looks like.</li> <li> <strong>Defining “Normal”:</strong> What constitutes “normal” can be subjective and can evolve over time. A system’s normal behavior today might be different next month.</li> <li> <strong>High Dimensionality:</strong> In datasets with many features (columns), the “curse of dimensionality” makes it incredibly difficult to understand densities and distances, which are crucial for many anomaly detection techniques.</li> <li> <strong>Lack of Labeled Data:</strong> In many real-world scenarios, we don’t have historical examples of labeled anomalies. We’re often looking for <em>unknown unknowns</em>.</li> <li> <strong>Noise vs. Anomaly:</strong> Distinguishing genuine anomalies from random noise or data entry errors can be tough.</li> </ul> <h3 id="how-we-spot-the-unusual-common-approaches">How We Spot the Unusual: Common Approaches</h3> <p>Despite the challenges, smart people have developed ingenious ways to unmask anomalies. Let’s look at some popular methods, moving from simple statistical tests to more complex machine learning algorithms.</p> <h4 id="1-statistical-methods-the-foundational-tools">1. Statistical Methods: The Foundational Tools</h4> <p>These are often your first line of defense, especially for numerical, univariate data (data with a single feature).</p> <ul> <li> <strong>Z-score (Standard Score):</strong> This method assumes your data is normally distributed (or close to it). It measures how many standard deviations a data point is from the mean. <ul> <li>The formula is: $Z = \frac{x - \mu}{\sigma}$</li> <li>Where $x$ is the data point, $\mu$ is the mean, and $\sigma$ is the standard deviation.</li> <li> <table> <tbody> <tr> <td> <em>How it works:</em> If a data point’s Z-score exceeds a certain threshold (e.g., $</td> <td>Z</td> <td>&gt; 2$ or $</td> <td>Z</td> <td>&gt; 3$), it’s considered an anomaly. Points far from the mean are unusual.</td> </tr> </tbody> </table> </li> <li> <em>My take:</em> Simple, intuitive, and a great starting point, but sensitive to extreme outliers themselves and assumes normality.</li> </ul> </li> <li> <strong>Interquartile Range (IQR):</strong> A robust method that doesn’t assume a normal distribution. It’s often used in box plots. <ul> <li>The IQR is the range between the first quartile ($Q_1$) and the third quartile ($Q_3$).</li> <li> <em>How it works:</em> Anomalies are often defined as data points that fall below $Q_1 - 1.5 \times \text{IQR}$ or above $Q_3 + 1.5 \times \text{IQR}$.</li> <li> <em>My take:</em> More robust to skewed data and extreme values than the Z-score, as it uses percentiles rather than the mean and standard deviation.</li> </ul> </li> </ul> <h4 id="2-proximity-based-methods-getting-cozy-or-not">2. Proximity-Based Methods: Getting Cozy (or Not)</h4> <p>These methods look at how “close” a data point is to its neighbors. If it’s far from everyone else, it’s probably an anomaly.</p> <ul> <li> <strong>K-Nearest Neighbors (KNN):</strong> While typically used for classification, KNN’s underlying distance metric is fantastic for anomaly detection. <ul> <li> <em>How it works:</em> For each data point, calculate its distance to its <em>k</em> nearest neighbors. If this average distance (or the distance to the <em>k</em>-th neighbor) is significantly larger than for other points, it’s an anomaly. It suggests the point is isolated.</li> <li> <em>My take:</em> Conceptually simple, effective in lower dimensions, but can become computationally expensive and less reliable in very high-dimensional spaces.</li> </ul> </li> <li> <strong>Local Outlier Factor (LOF):</strong> This is one of my favorites for its nuance. Instead of just absolute distance, LOF considers the <em>local density</em> around a point. <ul> <li> <em>How it works:</em> A point is an outlier if its local density is significantly lower than that of its neighbors. Imagine a tightly packed cluster of data points and one point slightly outside but near it. KNN might say it’s not an anomaly because it’s still relatively close to the cluster. LOF, however, would notice that the <em>density</em> around that point is much lower than the density within the cluster, correctly identifying it as an anomaly.</li> <li> <em>My take:</em> Excellent for identifying anomalies that are “local” to certain regions rather than globally distant. It’s a powerful unsupervised technique.</li> </ul> </li> </ul> <h4 id="3-tree-based-methods-building-isolation">3. Tree-Based Methods: Building Isolation</h4> <p>These methods partition data space to isolate anomalies.</p> <ul> <li> <strong>Isolation Forest:</strong> This algorithm is incredibly elegant and surprisingly effective. <ul> <li> <em>How it works:</em> Imagine randomly selecting a feature and then a random split point within its range. You repeat this, creating “trees.” Anomalies, being rare and different, typically require fewer random splits to be isolated in a tree compared to “normal” points that are deeply nestled within dense clusters.</li> <li> <em>My take:</em> Fast, scalable, and performs well on high-dimensional data. It’s a go-to for many real-world anomaly detection tasks. The intuition just <em>clicks</em> once you get it.</li> </ul> </li> </ul> <h4 id="4-advanced-methods-diving-deeper-briefly">4. Advanced Methods: Diving Deeper (Briefly)</h4> <p>For highly complex, high-dimensional data, especially with temporal components, deep learning approaches are gaining traction:</p> <ul> <li> <strong>Autoencoders:</strong> These are neural networks designed to learn a compressed representation of the input data and then reconstruct it. <ul> <li> <em>How it works:</em> Train an autoencoder on “normal” data. When an anomalous input comes in, the autoencoder struggles to reconstruct it accurately because it hasn’t learned that pattern. The “reconstruction error” (difference between original and reconstructed) will be high for anomalies.</li> <li> <em>My take:</em> Powerful for complex data types like time series or images, but require more data and computational resources.</li> </ul> </li> </ul> <h3 id="a-personal-project-idea-smart-home-energy-detective">A Personal Project Idea: Smart Home Energy Detective</h3> <p>Let’s imagine you want to build an anomaly detector for your smart home’s energy consumption. This is a classic example!</p> <ol> <li> <strong>Data Collection:</strong> You’d collect readings like electricity usage (kWh), temperature, time of day, day of week, presence detection, etc.</li> <li> <strong>Feature Engineering:</strong> This is crucial. Instead of just raw usage, you might create features like: <ul> <li>Hourly average usage.</li> <li>Deviation from the average for that specific hour and day of the week.</li> <li>Rate of change in usage.</li> </ul> </li> <li> <strong>Choosing a Method:</strong> <ul> <li>You might start with simple <strong>IQR</strong> or <strong>Z-score</strong> on individual features like <code class="language-plaintext highlighter-rouge">hourly_usage_deviation</code>. This could flag sudden, massive spikes.</li> <li>For a more holistic view, an <strong>Isolation Forest</strong> could be excellent. It would consider multiple features simultaneously (time, day, temperature, usage) and identify patterns that collectively look unusual. For example, high usage at 3 AM with no one home and low outside temperature might be flagged.</li> </ul> </li> <li> <strong>Thresholding:</strong> After training your model, you’d get “anomaly scores.” The next challenge is setting a threshold. What score is high enough to trigger an alert? This often requires domain expertise and some trial and error, monitoring false positives and false negatives.</li> <li> <strong>Action:</strong> If an anomaly is detected (e.g., an unusually high consumption for hours when everyone is away), you could get an alert on your phone, prompting you to check if you left something on or if there’s a malfunction.</li> </ol> <h3 id="practical-considerations-and-pitfalls">Practical Considerations and Pitfalls</h3> <p>Before you rush off to build your own anomaly detector, here are some nuggets of wisdom I’ve picked up:</p> <ul> <li> <strong>Data Quality is Paramount:</strong> Garbage in, garbage out! Clean your data, handle missing values, and scale your features (e.g., using <code class="language-plaintext highlighter-rouge">MinMaxScaler</code> or <code class="language-plaintext highlighter-rouge">StandardScaler</code>) for distance-based algorithms.</li> <li> <strong>The “Normal” Baseline:</strong> Ensure your training data truly represents “normal” behavior. If it contains subtle anomalies, your model might learn them as normal.</li> <li> <strong>Threshold Selection is an Art:</strong> There’s rarely a perfect threshold. It’s a trade-off between detecting all true anomalies (high recall) and avoiding too many false alarms (high precision). Business context often dictates which is more important.</li> <li> <strong>Evolving Systems:</strong> “Normal” isn’t static. A server’s normal load will increase as user traffic grows. Your anomaly detection system needs to adapt, either by retraining periodically or using adaptive algorithms.</li> <li> <strong>Explainability:</strong> When an anomaly is detected, why was it flagged? Can you pinpoint the features that contributed most to its anomalous score? This is crucial for taking effective action.</li> </ul> <h3 id="the-silent-guardian">The Silent Guardian</h3> <p>Anomaly detection isn’t just a technical challenge; it’s about building intelligent systems that act as silent guardians. They sift through mountains of data to whisper when something is amiss, often preventing disaster, identifying opportunities, or simply making systems more robust and reliable.</p> <p>Whether you’re safeguarding financial transactions, monitoring critical infrastructure, or just trying to understand your own data better, the ability to spot the unusual is an indispensable skill. So, go forth, explore these algorithms, and start listening for those whispers in your data – they might just be telling you something truly important!</p> <p>Happy detecting!</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/cracking-the-ai-black-box-why-explainable-ai-xai-i/">Cracking the AI Black Box: Why Explainable AI (XAI) is Our Superpower</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/the-secret-life-of-states-how-markov-chains-predic/">The Secret Life of States: How Markov Chains Predict Our Next Move (Without Remembering the Past!)</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/gradient-descent-unpacking-the-engine-of-machine-l/">Gradient Descent: Unpacking the Engine of Machine Learning</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Adarsh Nair. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/blog/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/masonry.js?v=a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/zoom.js?v=85ddb88934d28b74e78031fd54cf8308"></script> <script src="/blog/assets/js/no_defer.js?v=2781658a0a2b13ed609542042a859126"></script> <script defer src="/blog/assets/js/common.js?v=c15de51d4bb57887caa2c21988d97279"></script> <script defer src="/blog/assets/js/copy_code.js?v=c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/blog/assets/js/jupyter_new_tab.js?v=d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/blog/assets/js/mathjax-setup.js?v=a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/progress-bar.js?v=2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/blog/assets/js/vanilla-back-to-top.min.js?v=f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/blog/assets/js/search/ninja-keys.min.js?v=a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/blog/assets/js/search-setup.js?v=6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/blog/assets/js/search-data.js"></script> <script src="/blog/assets/js/shortcut-key.js?v=ccc841c459bfc0e64c1c2b5acd10df02"></script> </body> </html>