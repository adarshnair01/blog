<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Unlocking Tomorrow by Forgetting Yesterday: A Deep Dive into Markov Chains | Adarsh Nair </title> <meta name="author" content="Adarsh Nair"> <meta name="description" content="A deep dive into machine learning, AI, and data science. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <meta http-equiv="Content-Security-Policy" content="default-src 'self'; script-src 'self' 'unsafe-inline' https:; style-src 'self' 'unsafe-inline' https:; img-src 'self' data: https:; font-src 'self' data: https:; media-src 'self' https:; frame-src 'self' https:; connect-src 'self' https:;"> <link rel="stylesheet" href="/blog/assets/css/bootstrap.min.css?v=a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/blog/assets/css/academicons.min.css?v=f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/blog/assets/css/scholar-icons.css?v=62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-github.css?v=591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/blog/assets/css/main.css?v=d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://adarshnair.online/blog/blog/blog/2024/unlocking-tomorrow-by-forgetting-yesterday-a-deep/"> <script src="/blog/assets/js/theme.js?v=5fea5159b787642c1bbc1f334d60f883"></script> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-native.css?v=5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/blog/cv/"> Adarsh Nair </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/blog/"> </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/index.html">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/cv/">CV </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/repositories/">repositories </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="fa-solid fa-magnifying-glass"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-half-sun-moon" id="light-toggle-system"></i> <i class="fa-solid fa-moon" id="light-toggle-dark"></i> <i class="fa-solid fa-sun" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Unlocking Tomorrow by Forgetting Yesterday: A Deep Dive into Markov Chains</h1> <p class="post-meta"> Created on March 29, 2024 by Adarsh Nair </p> <p class="post-tags"> <a href="/blog/blog/2024"> <i class="fa-solid fa-calendar fa-sm"></i> 2024 </a>   ·   <a href="/blog/blog/tag/markov-chains"> <i class="fa-solid fa-hashtag fa-sm"></i> Markov Chains</a>   <a href="/blog/blog/tag/stochastic-processes"> <i class="fa-solid fa-hashtag fa-sm"></i> Stochastic Processes</a>   <a href="/blog/blog/tag/probability"> <i class="fa-solid fa-hashtag fa-sm"></i> Probability</a>   <a href="/blog/blog/tag/data-science"> <i class="fa-solid fa-hashtag fa-sm"></i> Data Science</a>   <a href="/blog/blog/tag/machine-learning"> <i class="fa-solid fa-hashtag fa-sm"></i> Machine Learning</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p>Imagine you’re playing a board game where your next move depends <em>only</em> on where you are right now, not on all the squares you’ve landed on before. Or perhaps you’re trying to predict tomorrow’s weather, and you realize that the best predictor is simply today’s weather, not what it was like a week ago. This seemingly simple idea forms the bedrock of a powerful mathematical tool called <strong>Markov Chains</strong>.</p> <p>As a data science enthusiast, I often find myself fascinated by elegant mathematical concepts that have profound real-world implications. Markov Chains are one such concept—simple in premise, yet incredibly versatile. They are the hidden engines behind everything from Google’s PageRank algorithm to predicting stock movements (with caveats!) and even generating human-like text.</p> <p>So, grab your thinking caps, because we’re about to embark on a journey into the heart of these “memoryless” marvels!</p> <h3 id="whats-a-markov-chain-anyway-the-memoryless-magic">What’s a Markov Chain, Anyway? The “Memoryless” Magic</h3> <p>At its core, a Markov Chain describes a sequence of possible events where the probability of each event depends <em>only</em> on the state attained in the previous event. This is the famous <strong>Markov Property</strong> (or the memoryless property).</p> <p>Let’s break that down: If we have a system that moves from one “state” to another over time, a Markov Chain says that the probability of moving to the next state ($X_{n+1}$) depends <em>only</em> on the current state ($X_n$), and <em>not</em> on any of the states that came before it ($X_{n-1}, X_{n-2}, \dots, X_0$).</p> <p>Mathematically, if $X_n$ represents the state of our system at time $n$, then the Markov property can be written as:</p> <table> <tbody> <tr> <td>$ P(X_{n+1} = x</td> <td>X_n = x_n, X_{n-1} = x_{n-1}, \dots, X_0 = x_0) = P(X_{n+1} = x</td> <td>X_n = x_n) $</td> </tr> </tbody> </table> <p>Think about it: this is a huge simplification! Instead of needing to remember the entire history of the system, we only need to know its current status. This simplification is what makes Markov Chains so elegant and computationally tractable.</p> <h3 id="building-our-first-markov-chain-states-and-transitions">Building Our First Markov Chain: States and Transitions</h3> <p>To construct a Markov Chain, we need two key ingredients:</p> <ol> <li> <strong>States</strong>: A finite (or countably infinite) set of possible conditions or outcomes our system can be in.</li> <li> <strong>Transition Probabilities</strong>: The probabilities of moving from one state to another. These probabilities remain constant over time (this is a <em>time-homogeneous</em> Markov Chain, which is what we typically discuss).</li> </ol> <p>Let’s use a classic example: <strong>Weather Forecasting</strong>. Suppose the weather in our imaginary world can only be one of three states:</p> <ul> <li> <strong>S</strong>: Sunny</li> <li> <strong>C</strong>: Cloudy</li> <li> <strong>R</strong>: Rainy</li> </ul> <p>Now, we need to define the probabilities of transitioning between these states. Let’s say, based on historical data, we’ve observed the following patterns:</p> <ul> <li>If today is <strong>Sunny (S)</strong>: <ul> <li>There’s a 70% chance tomorrow will be Sunny.</li> <li>A 20% chance tomorrow will be Cloudy.</li> <li>A 10% chance tomorrow will be Rainy.</li> </ul> </li> <li>If today is <strong>Cloudy (C)</strong>: <ul> <li>There’s a 30% chance tomorrow will be Sunny.</li> <li>A 40% chance tomorrow will be Cloudy.</li> <li>A 30% chance tomorrow will be Rainy.</li> </ul> </li> <li>If today is <strong>Rainy (R)</strong>: <ul> <li>There’s a 20% chance tomorrow will be Sunny.</li> <li>A 40% chance tomorrow will be Cloudy.</li> <li>A 40% chance tomorrow will be Rainy.</li> </ul> </li> </ul> <p>We can neatly represent these transition probabilities in a <strong>Transition Matrix</strong>, often denoted by $P$:</p> <p>$ P = \begin{pmatrix} P_{SS} &amp; P_{SC} &amp; P_{SR} \ P_{CS} &amp; P_{CC} &amp; P_{CR} \ P_{RS} &amp; P_{RC} &amp; P_{RR} \end{pmatrix} $</p> <p>Plugging in our values:</p> <p>$ P = \begin{pmatrix} 0.7 &amp; 0.2 &amp; 0.1 \ 0.3 &amp; 0.4 &amp; 0.3 \ 0.2 &amp; 0.4 &amp; 0.4 \end{pmatrix} $</p> <p>Notice a crucial property: the probabilities in each row must sum to 1. Why? Because if you are in a particular state, you <em>must</em> transition to <em>some</em> state (including staying in the same state).</p> <h3 id="predicting-the-future-how-markov-chains-evolve">Predicting the Future: How Markov Chains Evolve</h3> <p>Let’s say we know the current state distribution. For example, if today is definitely Sunny, our initial state distribution $\pi_0$ would be $[1, 0, 0]$ (100% Sunny, 0% Cloudy, 0% Rainy). If we had a 50/50 chance of being Sunny or Cloudy, it would be $[0.5, 0.5, 0]$.</p> <p>How do we predict the probability distribution for tomorrow, the day after, and so on? This is where matrix multiplication comes in handy.</p> <p>If $\pi_n$ is a row vector representing the probability distribution of being in each state at time $n$, then the distribution at time $n+1$ is given by:</p> <p>$ \pi_{n+1} = \pi_n P $</p> <p>So, if today is Sunny ($\pi_0 = [1, 0, 0]$):</p> <p>$ \pi_1 = [1, 0, 0] \begin{pmatrix} 0.7 &amp; 0.2 &amp; 0.1 \ 0.3 &amp; 0.4 &amp; 0.3 \ 0.2 &amp; 0.4 &amp; 0.4 \end{pmatrix} = [0.7, 0.2, 0.1] $</p> <p>This tells us that tomorrow, there’s a 70% chance of Sunny, 20% of Cloudy, and 10% of Rainy. This makes sense—it’s just the first row of our transition matrix!</p> <p>What about two days from now ($\pi_2$)?</p> <p>$ \pi_2 = \pi_1 P = ([1, 0, 0] P) P = [1, 0, 0] P^2 $</p> <p>So, to find the distribution after $k$ steps, we simply multiply the initial distribution by the transition matrix $P$ raised to the power of $k$:</p> <p>$ \pi_k = \pi_0 P^k $</p> <p>Calculating $P^2$:</p> <p>$ P^2 = \begin{pmatrix} 0.7 &amp; 0.2 &amp; 0.1 \ 0.3 &amp; 0.4 &amp; 0.3 \ 0.2 &amp; 0.4 &amp; 0.4 \end{pmatrix} \begin{pmatrix} 0.7 &amp; 0.2 &amp; 0.1 \ 0.3 &amp; 0.4 &amp; 0.3 \ 0.2 &amp; 0.4 &amp; 0.4 \end{pmatrix} = \begin{pmatrix} 0.7<em>0.7 + 0.2</em>0.3 + 0.1<em>0.2 &amp; 0.7</em>0.2 + 0.2<em>0.4 + 0.1</em>0.4 &amp; 0.7<em>0.1 + 0.2</em>0.3 + 0.1*0.4 \ \dots &amp; \dots &amp; \dots \ \dots &amp; \dots &amp; \dots \end{pmatrix} $</p> <p>$ P^2 = \begin{pmatrix} 0.49 + 0.06 + 0.02 &amp; 0.14 + 0.08 + 0.04 &amp; 0.07 + 0.06 + 0.04 \ \dots &amp; \dots &amp; \dots \ \dots &amp; \dots &amp; \dots \end{pmatrix} = \begin{pmatrix} 0.57 &amp; 0.26 &amp; 0.17 \ 0.37 &amp; 0.34 &amp; 0.29 \ 0.32 &amp; 0.36 &amp; 0.32 \end{pmatrix} $</p> <p>So, if today is Sunny, the probability distribution for two days from now is: $ \pi_2 = [1, 0, 0] P^2 = [0.57, 0.26, 0.17] $ Meaning a 57% chance of Sunny, 26% of Cloudy, and 17% of Rainy. The influence of the initial “Sunny” state is beginning to dissipate, and the probabilities are becoming more distributed across the states.</p> <h3 id="the-long-run-stationary-distribution-steady-state">The Long Run: Stationary Distribution (Steady State)</h3> <p>What happens if we keep predicting further and further into the future ($k \to \infty$)? Does the distribution $\pi_k$ eventually stabilize? For many types of Markov Chains, the answer is a resounding <strong>yes!</strong></p> <p>If a Markov Chain is <strong>irreducible</strong> (you can get from any state to any other state, possibly in multiple steps) and <strong>aperiodic</strong> (it doesn’t return to states in a fixed, cyclic pattern), it will converge to a unique <strong>stationary distribution</strong> (or steady-state distribution), denoted by $\pi$.</p> <p>This stationary distribution $\pi$ has a remarkable property: if the system starts in this distribution, it will remain in this distribution after any number of transitions. Mathematically:</p> <p>$ \pi = \pi P $</p> <p>This means that $\pi$ is an eigenvector of the transition matrix $P$ corresponding to an eigenvalue of 1. To find $\pi$, we solve this system of linear equations, along with the constraint that the probabilities must sum to 1:</p> <p>$ \sum_{i} \pi_i = 1 $</p> <p>For our weather example, solving this system (which is beyond a quick manual calculation, but easily done with software like NumPy in Python) would give us a vector like, say, $\pi = [0.45, 0.35, 0.20]$. This would mean that, in the very long run, the weather will be Sunny 45% of the time, Cloudy 35% of the time, and Rainy 20% of the time, regardless of what the weather was like today. It’s the intrinsic long-term behavior of the system!</p> <p>The concept of a stationary distribution is incredibly powerful because it tells us about the <em>equilibrium</em> state of a system.</p> <h3 id="real-world-applications-where-markov-chains-shine">Real-World Applications: Where Markov Chains Shine</h3> <p>Markov Chains are not just theoretical constructs; they are practical tools used across many domains:</p> <ol> <li> <p><strong>Google PageRank</strong>: This is perhaps the most famous application. Each web page is a “state.” A link from one page to another represents a “transition.” If a user randomly clicks links, their browsing path forms a Markov Chain. The stationary distribution of this chain gives the long-term probability of being on any given page, which Google used as a measure of a page’s importance (PageRank). Pages with higher stationary probabilities are considered more authoritative.</p> </li> <li> <strong>Natural Language Processing (NLP)</strong>: <ul> <li> <strong>Text Generation</strong>: Markov Chains can predict the next word in a sequence given the current word (or previous <code class="language-plaintext highlighter-rouge">k</code> words for higher-order chains). For example, after “The quick brown,” what’s the most probable next word? “fox.” This is how simple predictive text models or even early chatbots worked.</li> <li> <strong>Speech Recognition</strong>: Hidden Markov Models (an extension of Markov Chains) are fundamental to converting spoken audio into text, where the observed sounds are related to hidden phonetic states.</li> </ul> </li> <li> <p><strong>Weather Modeling</strong>: As we saw, predicting tomorrow’s weather based on today’s. While real-world weather is far more complex, simplified models can use Markov Chains.</p> </li> <li> <p><strong>Genetics</strong>: Modeling the evolution of DNA sequences, where each base pair (A, T, C, G) is a state, and transitions represent mutations over time.</p> </li> <li> <p><strong>Finance</strong>: Modeling stock prices or market states (e.g., bull vs. bear market), though the “memoryless” property is often a significant limitation here, as market history often <em>does</em> influence future behavior.</p> </li> <li> <strong>Customer Behavior</strong>: Predicting customer churn (moving from “active” to “inactive” states), website navigation patterns (from one page to another), or product purchase sequences.</li> </ol> <h3 id="limitations-and-beyond">Limitations and Beyond</h3> <p>While incredibly useful, the strict “memoryless” property is also the biggest limitation of simple Markov Chains. Many real-world phenomena exhibit “longer memory.” For instance, a customer’s purchasing decision might be influenced by their last <em>five</em> purchases, not just the very last one.</p> <p>This is where extensions come in:</p> <ul> <li> <strong>Higher-Order Markov Chains</strong>: These models consider the last $k$ states to predict the next, thus incorporating more memory into the system.</li> <li> <strong>Hidden Markov Models (HMMs)</strong>: Here, the underlying states are not directly observable. Instead, we observe outputs (emissions) that are probabilistically related to the hidden states. HMMs are powerful for problems like speech recognition or bioinformatics, where the true process is obscured.</li> </ul> <h3 id="conclusion">Conclusion</h3> <p>Markov Chains are a beautiful blend of simplicity and power. By distilling complex sequential processes down to their immediate dependencies, they offer a tractable way to model and understand systems that evolve over time. From the humble flip of a coin to the intricate web of global information, the memoryless marvel continues to provide profound insights into the patterns that shape our world.</p> <p>So, the next time you see a weather forecast, or marvel at how a search engine understands relevance, remember the elegant mathematical dance of Markov Chains, diligently working behind the scenes, predicting the future one state at a time. It’s a fundamental concept that every aspiring data scientist or machine learning engineer should have in their toolkit!</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/cracking-the-ai-black-box-why-explainable-ai-xai-i/">Cracking the AI Black Box: Why Explainable AI (XAI) is Our Superpower</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/the-secret-life-of-states-how-markov-chains-predic/">The Secret Life of States: How Markov Chains Predict Our Next Move (Without Remembering the Past!)</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/gradient-descent-unpacking-the-engine-of-machine-l/">Gradient Descent: Unpacking the Engine of Machine Learning</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Adarsh Nair. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/blog/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/masonry.js?v=a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/zoom.js?v=85ddb88934d28b74e78031fd54cf8308"></script> <script src="/blog/assets/js/no_defer.js?v=2781658a0a2b13ed609542042a859126"></script> <script defer src="/blog/assets/js/common.js?v=c15de51d4bb57887caa2c21988d97279"></script> <script defer src="/blog/assets/js/copy_code.js?v=c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/blog/assets/js/jupyter_new_tab.js?v=d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/blog/assets/js/mathjax-setup.js?v=a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/progress-bar.js?v=2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/blog/assets/js/vanilla-back-to-top.min.js?v=f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/blog/assets/js/search/ninja-keys.min.js?v=a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/blog/assets/js/search-setup.js?v=6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/blog/assets/js/search-data.js"></script> <script src="/blog/assets/js/shortcut-key.js?v=ccc841c459bfc0e64c1c2b5acd10df02"></script> </body> </html>