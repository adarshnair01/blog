<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Beyond the Jiggle: Unveiling the Magic of Kalman Filters | Adarsh Nair </title> <meta name="author" content="Adarsh Nair"> <meta name="description" content="A deep dive into machine learning, AI, and data science. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <meta http-equiv="Content-Security-Policy" content="default-src 'self'; script-src 'self' 'unsafe-inline' https:; style-src 'self' 'unsafe-inline' https:; img-src 'self' data: https:; font-src 'self' data: https:; media-src 'self' https:; frame-src 'self' https:; connect-src 'self' https:;"> <link rel="stylesheet" href="/blog/assets/css/bootstrap.min.css?v=a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/blog/assets/css/academicons.min.css?v=f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/blog/assets/css/scholar-icons.css?v=62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-github.css?v=591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/blog/assets/css/main.css?v=d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://adarshnair.online/blog/blog/blog/2025/beyond-the-jiggle-unveiling-the-magic-of-kalman-fi/"> <script src="/blog/assets/js/theme.js?v=5fea5159b787642c1bbc1f334d60f883"></script> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-native.css?v=5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/blog/cv/"> Adarsh Nair </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/blog/"> </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/index.html">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/cv/">CV </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/repositories/">repositories </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="fa-solid fa-magnifying-glass"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-half-sun-moon" id="light-toggle-system"></i> <i class="fa-solid fa-moon" id="light-toggle-dark"></i> <i class="fa-solid fa-sun" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Beyond the Jiggle: Unveiling the Magic of Kalman Filters</h1> <p class="post-meta"> Created on June 27, 2025 by Adarsh Nair </p> <p class="post-tags"> <a href="/blog/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/blog/tag/kalman-filter"> <i class="fa-solid fa-hashtag fa-sm"></i> Kalman Filter</a>   <a href="/blog/blog/tag/state-estimation"> <i class="fa-solid fa-hashtag fa-sm"></i> State Estimation</a>   <a href="/blog/blog/tag/sensor-fusion"> <i class="fa-solid fa-hashtag fa-sm"></i> Sensor Fusion</a>   <a href="/blog/blog/tag/control-systems"> <i class="fa-solid fa-hashtag fa-sm"></i> Control Systems</a>   <a href="/blog/blog/tag/time-series"> <i class="fa-solid fa-hashtag fa-sm"></i> Time Series</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p>As a budding data scientist, I’ve always been fascinated by how we extract meaningful signals from the cacophony of real-world data. Our sensors, whether in a smartphone, a satellite, or an industrial robot, are constantly bombarded by noise, interference, and imperfections. Imagine trying to track a moving object – a drone, a car, or even a stock price – when every piece of information you receive is a little bit wrong. It’s like trying to hit a moving target while wearing blurry glasses and being nudged by an invisible force.</p> <p>This is precisely the problem that the <strong>Kalman Filter</strong> was designed to solve. It’s an incredibly elegant and powerful algorithm that, in essence, makes an “intelligent guess” about the true state of a system, even when faced with uncertain measurements and an imperfect model of how the system behaves. It’s the reason your GPS works so well, why missiles hit their targets, and why autonomous vehicles can navigate complex environments. And once you grasp its core idea, you’ll see its potential everywhere.</p> <h3 id="the-problem-when-everything-lies-just-a-little-bit">The Problem: When Everything Lies (Just a Little Bit)</h3> <p>Let’s ground this with a simple scenario: you’re trying to track the position and velocity of a small robot moving on a flat surface. You have two sources of information:</p> <ol> <li> <strong>A motion model:</strong> You know the robot’s last command (e.g., “move forward 1 meter per second”). From basic physics, you can <em>predict</em> where it should be next.</li> <li> <strong>A sensor:</strong> You have a GPS-like sensor that gives you a measurement of the robot’s current position.</li> </ol> <p>The catch? Both sources are imperfect:</p> <ul> <li> <strong>Your motion model isn’t perfect:</strong> The robot might slip, the floor might be uneven, or its motor might not be perfectly calibrated. Your prediction will have some <strong>process noise</strong>.</li> <li> <strong>Your sensor isn’t perfect:</strong> GPS signals can be bouncy, Wi-Fi triangulation can be imprecise, and any sensor will have its own <strong>measurement noise</strong>.</li> </ul> <p>So, at any given moment, you have a prediction from your model and a measurement from your sensor, and neither is perfectly accurate. What do you do? Just average them? Throw away the noisy one? The Kalman Filter provides a mathematically optimal way to combine these imperfect sources of information to get the <em>best possible estimate</em> of the robot’s true position and velocity.</p> <h3 id="the-core-idea-predict-and-update-like-a-smart-detective">The Core Idea: Predict and Update (Like a Smart Detective)</h3> <p>Think of the Kalman Filter as a super-smart detective who works in a two-step cycle:</p> <ol> <li> <strong>Prediction Phase:</strong> Based on its last best guess and its understanding of how things usually move, the detective <em>predicts</em> where the suspect (your robot) should be right now. It also predicts how uncertain this guess is.</li> <li> <strong>Update Phase:</strong> A new piece of evidence (a sensor measurement) comes in. The detective compares this new evidence to their prediction. They then <em>update</em> their initial guess, taking into account how reliable both their prediction and the new evidence are. The more reliable the evidence, the more they adjust their prediction towards it.</li> </ol> <p>This cycle repeats indefinitely, constantly refining the estimate. It’s a continuous feedback loop that minimizes uncertainty.</p> <h3 id="diving-deeper-the-math-behind-the-magic">Diving Deeper: The Math Behind the Magic</h3> <p>Let’s peek under the hood a bit. While the full derivation can be complex, the core equations are surprisingly elegant.</p> <p>We want to estimate the <strong>state</strong> of our system, which is a collection of variables we care about (e.g., position, velocity, acceleration). We represent this state as a vector $\mathbf{x}$. Our uncertainty about this state is captured by a <strong>covariance matrix</strong> $\mathbf{P}$. A covariance matrix describes how much the variables in our state vector vary together and how spread out they are. A larger $\mathbf{P}$ means more uncertainty.</p> <h4 id="1-the-prediction-step-time-update">1. The Prediction Step (Time Update)</h4> <p>In this step, we project the state and its uncertainty forward in time.</p> <ul> <li> <p><strong>Predicted State Estimate:</strong> We use a state transition model to predict the next state. Imagine if you know your robot’s current position and velocity, and you know it’s going to move forward at a certain speed. You can predict its next position.</p> <p>$\mathbf{\hat{x}}<em>k^- = \mathbf{F}_k \mathbf{\hat{x}}</em>{k-1} + \mathbf{B}_k \mathbf{u}_k$</p> <ul> <li>$\mathbf{\hat{x}}_k^-$: The <em>a priori</em> (predicted) state estimate at time $k$.</li> <li>$\mathbf{\hat{x}}_{k-1}$: The <em>a posteriori</em> (updated) state estimate from the previous time step $k-1$.</li> <li>$\mathbf{F}_k$: The <strong>state transition matrix</strong>. This matrix describes how the state evolves from $k-1$ to $k$ in the absence of external forces. For constant velocity, it might look like $\begin{pmatrix} 1 &amp; \Delta t \ 0 &amp; 1 \end{pmatrix}$ for position and velocity.</li> <li>$\mathbf{B}_k$: The <strong>control input matrix</strong>. This matrix relates the control input to the state.</li> <li>$\mathbf{u}_k$: The <strong>control vector</strong> (e.g., motor commands given to the robot).</li> </ul> </li> <li> <p><strong>Predicted Covariance Estimate:</strong> Our uncertainty also grows over time because our prediction model isn’t perfect.</p> <p>$\mathbf{P}<em>k^- = \mathbf{F}_k \mathbf{P}</em>{k-1} \mathbf{F}_k^T + \mathbf{Q}_k$</p> <ul> <li>$\mathbf{P}_k^-$: The <em>a priori</em> (predicted) error covariance matrix.</li> <li>$\mathbf{P}_{k-1}$: The <em>a posteriori</em> (updated) error covariance matrix from the previous step.</li> <li>$\mathbf{Q}_k$: The <strong>process noise covariance matrix</strong>. This matrix represents the uncertainty introduced by the prediction model itself (e.g., robot slipping, wind affecting a drone). A larger $\mathbf{Q}_k$ means you trust your model less.</li> </ul> </li> </ul> <p>After this step, we have our best <em>prediction</em> of the state and its uncertainty, <em>before</em> we’ve seen any new measurements.</p> <h4 id="2-the-update-step-measurement-update">2. The Update Step (Measurement Update)</h4> <p>Now, a new measurement comes in. We use this measurement to refine our prediction.</p> <ul> <li> <p><strong>Measurement Residual (Innovation):</strong> First, we figure out how “wrong” our prediction was by comparing it to the actual measurement.</p> <p>$\mathbf{y}_k = \mathbf{z}_k - \mathbf{H}_k \mathbf{\hat{x}}_k^-$</p> <ul> <li>$\mathbf{y}_k$: The <strong>measurement residual</strong> (or innovation). This is the difference between the actual measurement and what we <em>expected</em> to measure based on our prediction.</li> <li>$\mathbf{z}_k$: The actual <strong>measurement</strong> from our sensor at time $k$.</li> <li>$\mathbf{H}_k$: The <strong>measurement matrix</strong>. This matrix maps the state space into the measurement space. For example, if your state is (position, velocity) but your sensor only measures position, $\mathbf{H}_k$ would extract the position component.</li> </ul> </li> <li> <p><strong>Kalman Gain ($\mathbf{K}_k$): The “Trust Factor”</strong> This is the heart of the Kalman Filter. The Kalman Gain determines how much we trust the new measurement versus our prediction. It’s a weighting factor.</p> <p>$\mathbf{K}_k = \mathbf{P}_k^- \mathbf{H}_k^T (\mathbf{H}_k \mathbf{P}_k^- \mathbf{H}_k^T + \mathbf{R}_k)^{-1}$</p> <ul> <li>$\mathbf{K}_k$: The <strong>Kalman Gain</strong>.</li> <li>$\mathbf{R}_k$: The <strong>measurement noise covariance matrix</strong>. This describes the uncertainty in the sensor itself. A larger $\mathbf{R}_k$ means you trust your sensor less.</li> </ul> <p><strong>Think of it this way:</strong></p> <ul> <li>If $\mathbf{P}_k^-$ (predicted uncertainty) is very high, and $\mathbf{R}_k$ (measurement uncertainty) is low, $\mathbf{K}_k$ will be large. This means we trust the new measurement a lot and adjust our state heavily towards it.</li> <li>If $\mathbf{P}_k^-$ is low, and $\mathbf{R}_k$ is high, $\mathbf{K}_k$ will be small. This means we trust our prediction more, and only slightly adjust our state based on the noisy measurement.</li> </ul> </li> <li> <p><strong>Updated State Estimate:</strong> Now, we update our state estimate using the measurement residual and the Kalman Gain.</p> <p>$\mathbf{\hat{x}}_k = \mathbf{\hat{x}}_k^- + \mathbf{K}_k \mathbf{y}_k$</p> <ul> <li>$\mathbf{\hat{x}}_k$: The <em>a posteriori</em> (updated) state estimate at time $k$. This is our new “best guess.” We take our prediction and add a weighted correction based on how “wrong” our prediction was compared to the measurement.</li> </ul> </li> <li> <p><strong>Updated Covariance Estimate:</strong> Finally, we update our uncertainty. Our uncertainty <em>decreases</em> after incorporating a new measurement (unless the measurement is extremely noisy).</p> <p>$\mathbf{P}_k = (\mathbf{I} - \mathbf{K}_k \mathbf{H}_k) \mathbf{P}_k^-$</p> <ul> <li>$\mathbf{P}_k$: The <em>a posteriori</em> (updated) error covariance matrix. $\mathbf{I}$ is the identity matrix.</li> </ul> </li> </ul> <p>And there you have it! With $\mathbf{\hat{x}}_k$ and $\mathbf{P}_k$, we are ready for the next prediction cycle. The algorithm is recursive, meaning it only needs the previous state and covariance to compute the next. This makes it incredibly efficient for real-time applications.</p> <h3 id="the-power-and-practicality">The Power and Practicality</h3> <p>Why has the Kalman Filter endured for over six decades since Rudolf Kalman first published his seminal paper in 1960?</p> <ul> <li> <strong>Optimal Estimator:</strong> For linear systems with Gaussian noise, the Kalman Filter is the <em>optimal</em> linear unbiased estimator. No other linear filter can do better.</li> <li> <strong>Recursive Nature:</strong> It doesn’t need to store all historical data. It only needs the previous state estimate to compute the current one, making it incredibly efficient for real-time processing and systems with limited memory.</li> <li> <strong>Handles Missing Data:</strong> If a measurement is missed, the filter can continue predicting, albeit with increasing uncertainty, until new measurements arrive.</li> <li> <strong>Sensor Fusion:</strong> It’s a foundational technique for combining data from multiple, diverse sensors (e.g., GPS, accelerometer, gyroscope, LiDAR, radar) to get a more robust estimate than any single sensor could provide. This is critical for self-driving cars and robotics.</li> </ul> <h3 id="where-do-we-see-kalman-filters">Where Do We See Kalman Filters?</h3> <p>The list is truly extensive:</p> <ul> <li> <strong>Navigation:</strong> Your phone’s GPS, aircraft navigation, maritime vessels, drones, spacecraft.</li> <li> <strong>Robotics:</strong> Tracking robot position, mapping environments (SLAM - Simultaneous Localization and Mapping), object tracking.</li> <li> <strong>Financial Modeling:</strong> Estimating latent variables, predicting stock prices, portfolio optimization.</li> <li> <strong>Weather Forecasting:</strong> Combining atmospheric models with sensor data.</li> <li> <strong>Medical Imaging:</strong> Denoising signals in MRI or EEG.</li> <li> <strong>Control Systems:</strong> Stabilizing aircraft, controlling industrial processes.</li> <li> <strong>Computer Vision:</strong> Tracking objects in video streams.</li> </ul> <p>For systems that are not strictly linear or have non-Gaussian noise, more advanced variants like the <strong>Extended Kalman Filter (EKF)</strong> or the <strong>Unscented Kalman Filter (UKF)</strong> are used. These essentially linearize the non-linear system or approximate the probability distributions more effectively.</p> <h3 id="my-personal-takeaway">My Personal Takeaway</h3> <p>Learning about Kalman Filters felt like discovering a secret language that the universe uses to make sense of itself. It beautifully demonstrates how combining simple probabilistic thinking with linear algebra can lead to profoundly powerful results. It’s not just about filtering noise; it’s about building a robust internal model of reality, constantly questioning it with new evidence, and refining that model to achieve optimal understanding.</p> <p>For anyone in data science or machine learning, understanding Kalman Filters opens up a whole new paradigm for dealing with time-series data, uncertainty, and real-time state estimation. It’s a testament to the fact that some of the most elegant solutions come from a deep understanding of the problem’s underlying mathematical structure.</p> <p>So, the next time your phone tells you your exact location or a drone hovers steadily in the wind, give a little nod to Rudolf Kalman and his brilliant filter, tirelessly working “beyond the jiggle” to bring clarity to our noisy world.</p> <hr> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/cracking-the-ai-black-box-why-explainable-ai-xai-i/">Cracking the AI Black Box: Why Explainable AI (XAI) is Our Superpower</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/the-secret-life-of-states-how-markov-chains-predic/">The Secret Life of States: How Markov Chains Predict Our Next Move (Without Remembering the Past!)</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/gradient-descent-unpacking-the-engine-of-machine-l/">Gradient Descent: Unpacking the Engine of Machine Learning</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Adarsh Nair. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/blog/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/masonry.js?v=a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/zoom.js?v=85ddb88934d28b74e78031fd54cf8308"></script> <script src="/blog/assets/js/no_defer.js?v=2781658a0a2b13ed609542042a859126"></script> <script defer src="/blog/assets/js/common.js?v=c15de51d4bb57887caa2c21988d97279"></script> <script defer src="/blog/assets/js/copy_code.js?v=c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/blog/assets/js/jupyter_new_tab.js?v=d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/blog/assets/js/mathjax-setup.js?v=a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/progress-bar.js?v=2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/blog/assets/js/vanilla-back-to-top.min.js?v=f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/blog/assets/js/search/ninja-keys.min.js?v=a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/blog/assets/js/search-setup.js?v=6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/blog/assets/js/search-data.js"></script> <script src="/blog/assets/js/shortcut-key.js?v=ccc841c459bfc0e64c1c2b5acd10df02"></script> </body> </html>