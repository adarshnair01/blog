<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> The Goldilocks Zone of Machine Learning: Taming Overfitting and Underfitting | Adarsh Nair </title> <meta name="author" content="Adarsh Nair"> <meta name="description" content="A deep dive into machine learning, AI, and data science. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <meta http-equiv="Content-Security-Policy" content="default-src 'self'; script-src 'self' 'unsafe-inline' https:; style-src 'self' 'unsafe-inline' https:; img-src 'self' data: https:; font-src 'self' data: https:; media-src 'self' https:; frame-src 'self' https:; connect-src 'self' https:;"> <link rel="stylesheet" href="/blog/assets/css/bootstrap.min.css?v=a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/blog/assets/css/academicons.min.css?v=f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/blog/assets/css/scholar-icons.css?v=62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-github.css?v=591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/blog/assets/css/main.css?v=d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://adarshnair.online/blog/blog/blog/2025/the-goldilocks-zone-of-machine-learning-taming-ove/"> <script src="/blog/assets/js/theme.js?v=5fea5159b787642c1bbc1f334d60f883"></script> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-native.css?v=5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/blog/cv/"> Adarsh Nair </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/blog/"> </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/index.html">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/cv/">CV </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/repositories/">repositories </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="fa-solid fa-magnifying-glass"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-half-sun-moon" id="light-toggle-system"></i> <i class="fa-solid fa-moon" id="light-toggle-dark"></i> <i class="fa-solid fa-sun" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">The Goldilocks Zone of Machine Learning: Taming Overfitting and Underfitting</h1> <p class="post-meta"> Created on March 05, 2025 by Adarsh Nair </p> <p class="post-tags"> <a href="/blog/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/blog/tag/machine-learning"> <i class="fa-solid fa-hashtag fa-sm"></i> Machine Learning</a>   <a href="/blog/blog/tag/overfitting"> <i class="fa-solid fa-hashtag fa-sm"></i> Overfitting</a>   <a href="/blog/blog/tag/underfitting"> <i class="fa-solid fa-hashtag fa-sm"></i> Underfitting</a>   <a href="/blog/blog/tag/bias-variance-trade-off"> <i class="fa-solid fa-hashtag fa-sm"></i> Bias-Variance Trade-off</a>   <a href="/blog/blog/tag/data-science"> <i class="fa-solid fa-hashtag fa-sm"></i> Data Science</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p>Hey there, fellow data explorer!</p> <p>Have you ever studied for an exam, felt like you knew <em>everything</em>, only to get stumped by a slightly different question? Or, on the flip side, maybe you barely skimmed the material and felt completely lost? These common human experiences perfectly encapsulate two of the most fundamental challenges we face in machine learning: <strong>underfitting</strong> and <strong>overfitting</strong>.</p> <p>As aspiring data scientists and MLEs, our goal isn’t just to build models; it’s to build <em>smart</em> models. Models that don’t just memorize, but genuinely <em>understand</em> the underlying patterns in data, allowing them to make accurate predictions on new, unseen information. This journey, as you’ll soon discover, is often about finding that “just right” balance – the Goldilocks Zone – between two extremes.</p> <h3 id="the-art-of-learning-what-models-really-do">The Art of Learning: What Models Really Do</h3> <p>Before diving into the pitfalls, let’s quickly recap what a machine learning model <em>aims</em> to do. At its core, a model learns a mapping from input features ($X$) to output targets ($Y$) by analyzing a dataset. It tries to identify underlying relationships, trends, and structures within that data.</p> <p>Imagine you’re trying to predict house prices. Your input features ($X$) might be square footage, number of bedrooms, location, and age. Your output target ($Y$) is the price. The model learns how these features relate to the price from historical sales data.</p> <p>The ultimate test of a model’s intelligence isn’t how well it performs on the data it <em>saw</em> during training, but how well it performs on data it has <em>never encountered before</em>. This is the concept of <strong>generalization</strong>. A truly intelligent model generalizes well.</p> <p>Now, let’s meet the two arch-nemeses of generalization.</p> <h3 id="underfitting-the-didnt-study-enough-syndrome">Underfitting: The “Didn’t Study Enough” Syndrome</h3> <p>Imagine you’re trying to learn about the history of the world, but you only read a single paragraph summary. You’d likely miss most of the nuance, the intricate connections, and the major events. If someone then asked you a detailed question, you’d probably give a very simplistic, often wrong, answer.</p> <p>That, my friend, is underfitting.</p> <p><strong>What it is:</strong> Underfitting occurs when your model is too simple to capture the underlying structure of the data. It hasn’t learned enough from the training data, failing to identify the relevant patterns. It’s like trying to fit a complex curve with a straight line.</p> <p><strong>Symptoms:</strong> The tell-tale sign of an underfit model is high error on <em>both</em> the training data and the test (unseen) data. It performs poorly across the board because it hasn’t even grasped the basics.</p> <p>Let’s visualize this. Suppose our actual data points form a curve, but our model tries to fit a simple straight line through them:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>      .     .
   .         .
  .           .
 .             .
-------------------- (Underfit line)
</code></pre></div></div> <p>As you can see, the straight line doesn’t capture the true shape of the data points. It’s too rigid.</p> <p><strong>Causes of Underfitting:</strong></p> <ol> <li> <strong>Model is too simple:</strong> Using a linear model (e.g., linear regression) for inherently non-linear data is a classic example.</li> <li> <strong>Insufficient features:</strong> You haven’t given the model enough relevant information (features) to make informed decisions. For our house price example, perhaps you only included “number of bathrooms” but not “square footage” or “location.”</li> <li> <strong>Insufficient training time:</strong> Especially with iterative models like neural networks, stopping training too early can lead to the model not having enough time to converge and learn patterns.</li> <li> <strong>Too much regularization:</strong> While usually a cure for overfitting, excessive regularization can sometimes lead to underfitting by making the model <em>too</em> simple.</li> </ol> <p><strong>How to combat Underfitting:</strong></p> <ul> <li> <strong>Increase model complexity:</strong> Switch to a more flexible model (e.g., polynomial regression, decision trees, random forests, neural networks).</li> <li> <strong>Add more features:</strong> Brainstorm and engineer new features from your existing data or collect more relevant data.</li> <li> <strong>Reduce regularization:</strong> If you’re using regularization techniques, try reducing their strength.</li> <li> <strong>Train longer:</strong> For iterative models, allow them more epochs to learn.</li> </ul> <h3 id="overfitting-the-memorized-the-test-syndrome">Overfitting: The “Memorized the Test” Syndrome</h3> <p>Now, let’s swing to the other extreme. Imagine a student who meticulously memorizes every single question and answer from a practice exam. They ace that specific practice exam. But give them a <em>slightly different</em> exam, even on the same topic, and they fall apart. Why? Because they memorized the specifics, including the tiny quirks and typos, rather than understanding the underlying concepts.</p> <p>This, my friend, is overfitting.</p> <p><strong>What it is:</strong> Overfitting occurs when your model learns the training data <em>too well</em> – so well that it starts to memorize the noise and specific idiosyncratic patterns unique to the training set. It becomes hyper-specialized in its training data and loses its ability to generalize to new, unseen data. It essentially “confuses noise for signal.”</p> <p><strong>Symptoms:</strong> The signature of an overfit model is low error on the training data, but <em>high error</em> on the test (unseen) data. It’s fantastic at predicting what it has seen before, but terrible at predicting anything new.</p> <p>Let’s revisit our data visualization. This time, our model is a squiggly line trying to hit every single data point, even the outliers:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code> _ . _    _ . _
/     \ /     \
       .         .
      /           \
     .             .
_.-` `-._.-` `-._.-` `-._ (Overfit line)
</code></pre></div></div> <p>This line might pass through every single training point, but it’s wildly erratic. If you get a new data point slightly off this path, its prediction will be way off because the model has learned the “noise” or specific coordinates of the training points rather than the general trend.</p> <p><strong>Causes of Overfitting:</strong></p> <ol> <li> <strong>Model is too complex:</strong> Having too many parameters, deep layers in neural networks, or a decision tree that’s allowed to grow too deep can make a model overly flexible.</li> <li> <strong>Insufficient training data:</strong> If you have a very complex model but only a small amount of training data, the model will struggle to find general patterns and will instead just memorize the limited examples it has.</li> <li> <strong>Noisy data:</strong> If your training data contains a lot of irrelevant information or errors, an overfit model will try to learn these anomalies as if they were significant patterns.</li> <li> <strong>Training for too long:</strong> In iterative algorithms, if you continue training after the model has found the optimal patterns, it will start learning the noise in the data, leading to overfitting.</li> </ol> <p><strong>How to combat Overfitting:</strong></p> <ul> <li> <strong>More training data:</strong> This is often the best solution. With more data, it’s harder for a model to just memorize; it’s forced to find general patterns.</li> <li> <strong>Simplify the model:</strong> Reduce the complexity. This could mean fewer layers in a neural network, pruning a decision tree, or using a simpler algorithm.</li> <li> <strong>Feature selection/engineering:</strong> Remove irrelevant or redundant features. Focus on only the most impactful ones.</li> <li> <strong>Regularization:</strong> This is a cornerstone technique for fighting overfitting. Regularization adds a penalty term to the model’s loss function, discouraging it from assigning excessively large weights to features. The idea is that simpler models (with smaller weights) are less likely to overfit. <ul> <li> <strong>L1 Regularization (Lasso):</strong> Adds the absolute value of the magnitude of the coefficients as a penalty term. \(Loss = OriginalLoss + \lambda \sum_{i=1}^n |\beta_i|\) It encourages sparsity, meaning it can drive some feature weights to exactly zero, effectively performing feature selection.</li> <li> <strong>L2 Regularization (Ridge):</strong> Adds the square of the magnitude of the coefficients as a penalty term. \(Loss = OriginalLoss + \lambda \sum_{i=1}^n \beta_i^2\) It shrinks all the coefficients by the same factor, reducing their impact but rarely driving them to absolute zero.</li> <li> <strong>Dropout (for Neural Networks):</strong> Randomly “switches off” a fraction of neurons during each training step, preventing any single neuron from becoming too reliant on others and forcing the network to learn more robust features.</li> </ul> </li> <li> <strong>Cross-validation:</strong> Instead of a single train/test split, cross-validation techniques (like k-fold cross-validation) allow you to train and evaluate your model on different subsets of your data, providing a more robust estimate of its generalization performance and helping detect overfitting earlier.</li> <li> <strong>Early Stopping:</strong> When training iterative models, monitor the model’s performance on a separate validation set. Stop training when the validation error starts to increase, even if the training error is still decreasing. This signals the point where the model begins to overfit.</li> </ul> <h3 id="the-bias-variance-trade-off-the-heart-of-the-matter">The Bias-Variance Trade-off: The Heart of the Matter</h3> <p>This is where things get a bit deeper, and it’s crucial for understanding the interplay between underfitting and overfitting. Any error in a machine learning model can typically be decomposed into three components:</p> \[Total Error = Bias^2 + Variance + Irreducible Error\] <ol> <li> <strong>Bias:</strong> The error introduced by approximating a real-world problem (which might be complex) with a simplified model. <ul> <li>High Bias = Underfitting. Your model is making strong assumptions about the data and is too rigid. It can’t capture the true underlying patterns. (The student who only read the summary has high bias).</li> </ul> </li> <li> <strong>Variance:</strong> The error introduced by the model’s sensitivity to small fluctuations in the training set. A high-variance model pays too much attention to the specific details and noise of the training data, rather than the general trend. <ul> <li>High Variance = Overfitting. Your model is too flexible and learns the noise in the training data. (The student who memorized the practice test has high variance).</li> </ul> </li> <li> <strong>Irreducible Error:</strong> This is the noise inherent in the data itself that no model, no matter how perfect, can eliminate. It’s the fundamental limit to how well we can predict.</li> </ol> <p>The <strong>Bias-Variance Trade-off</strong> states that there’s an inverse relationship between bias and variance.</p> <ul> <li>As you make your model more complex (e.g., add more features, use a deeper neural network), you typically <em>decrease bias</em> (the model can better capture true patterns) but <em>increase variance</em> (it becomes more sensitive to noise).</li> <li>Conversely, as you simplify your model, you generally <em>increase bias</em> (it might miss true patterns) but <em>decrease variance</em> (it becomes more robust to noise).</li> </ul> <p>Our goal is to find the “sweet spot” – the model complexity that minimizes the total error by balancing bias and variance. This is the <strong>Goldilocks Zone</strong> we talked about earlier: not too simple (high bias, underfitting), not too complex (high variance, overfitting), but just right.</p> <h3 id="the-data-scientists-toolkit-finding-the-balance">The Data Scientist’s Toolkit: Finding the Balance</h3> <p>As data scientists, our job isn’t just to pick an algorithm; it’s to act as detectives, diagnosticians, and tuners.</p> <ol> <li> <strong>Data Splitting:</strong> Always, always, always split your data into training, validation, and test sets. <ul> <li> <strong>Training Set:</strong> Used to train the model.</li> <li> <strong>Validation Set:</strong> Used to tune hyperparameters and make decisions about model complexity (e.g., how deep a tree should be, how much regularization to apply) <em>without</em> touching the final test set. This is where you monitor for early stopping to prevent overfitting.</li> <li> <strong>Test Set:</strong> Used <em>only once</em> at the very end to get an unbiased estimate of your model’s final performance on truly unseen data.</li> </ul> </li> <li> <p><strong>Hyperparameter Tuning:</strong> This is the iterative process of adjusting settings (hyperparameters) of your model (e.g., learning rate, number of layers, regularization strength) to find the optimal balance. Techniques like Grid Search and Random Search, often combined with cross-validation on the training data, are invaluable here.</p> </li> <li> <strong>Error Analysis:</strong> Don’t just look at the final accuracy. Dive into <em>where</em> and <em>why</em> your model is making mistakes. Are there specific classes it struggles with? Are the errors concentrated in certain feature ranges? This can give clues for feature engineering or model improvements.</li> </ol> <h3 id="conclusion-the-journey-continues">Conclusion: The Journey Continues</h3> <p>Understanding overfitting and underfitting isn’t just theoretical knowledge; it’s perhaps the most practical skill you’ll develop in machine learning. It guides every decision you make, from choosing an algorithm to preparing your data and tuning your model.</p> <p>Remember the Goldilocks Zone. Your models are seeking that perfect fit: complex enough to learn the true signal, but simple enough to ignore the noise. The journey to building truly intelligent, generalizable models is an exciting one, filled with continuous learning, experimentation, and a persistent quest for that “just right” balance.</p> <p>Keep exploring, keep building, and never stop questioning! The path to machine learning mastery is paved with these fundamental insights.</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/cracking-the-ai-black-box-why-explainable-ai-xai-i/">Cracking the AI Black Box: Why Explainable AI (XAI) is Our Superpower</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/the-secret-life-of-states-how-markov-chains-predic/">The Secret Life of States: How Markov Chains Predict Our Next Move (Without Remembering the Past!)</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/gradient-descent-unpacking-the-engine-of-machine-l/">Gradient Descent: Unpacking the Engine of Machine Learning</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Adarsh Nair. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/blog/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/masonry.js?v=a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/zoom.js?v=85ddb88934d28b74e78031fd54cf8308"></script> <script src="/blog/assets/js/no_defer.js?v=2781658a0a2b13ed609542042a859126"></script> <script defer src="/blog/assets/js/common.js?v=c15de51d4bb57887caa2c21988d97279"></script> <script defer src="/blog/assets/js/copy_code.js?v=c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/blog/assets/js/jupyter_new_tab.js?v=d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/blog/assets/js/mathjax-setup.js?v=a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/progress-bar.js?v=2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/blog/assets/js/vanilla-back-to-top.min.js?v=f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/blog/assets/js/search/ninja-keys.min.js?v=a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/blog/assets/js/search-setup.js?v=6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/blog/assets/js/search-data.js"></script> <script src="/blog/assets/js/shortcut-key.js?v=ccc841c459bfc0e64c1c2b5acd10df02"></script> </body> </html>