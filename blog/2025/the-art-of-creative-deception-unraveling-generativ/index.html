<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> The Art of Creative Deception: Unraveling Generative Adversarial Networks | Adarsh Nair </title> <meta name="author" content="Adarsh Nair"> <meta name="description" content="A deep dive into machine learning, AI, and data science. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <meta http-equiv="Content-Security-Policy" content="default-src 'self'; script-src 'self' 'unsafe-inline' https:; style-src 'self' 'unsafe-inline' https:; img-src 'self' data: https:; font-src 'self' data: https:; media-src 'self' https:; frame-src 'self' https:; connect-src 'self' https:;"> <link rel="stylesheet" href="/blog/assets/css/bootstrap.min.css?v=a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/blog/assets/css/academicons.min.css?v=f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/blog/assets/css/scholar-icons.css?v=62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-github.css?v=591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/blog/assets/css/main.css?v=d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://adarshnair.online/blog/blog/blog/2025/the-art-of-creative-deception-unraveling-generativ/"> <script src="/blog/assets/js/theme.js?v=5fea5159b787642c1bbc1f334d60f883"></script> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-native.css?v=5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="https://adarshnair.online" rel="external nofollow noopener" target="_blank"> Adarsh Nair </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/blog/"> </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/index.html">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/cv/">CV </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/repositories/">repositories </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="fa-solid fa-magnifying-glass"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-half-sun-moon" id="light-toggle-system"></i> <i class="fa-solid fa-moon" id="light-toggle-dark"></i> <i class="fa-solid fa-sun" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">The Art of Creative Deception: Unraveling Generative Adversarial Networks</h1> <p class="post-meta"> Created on July 14, 2025 by Adarsh Nair </p> <p class="post-tags"> <a href="/blog/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/blog/tag/generative-ai"> <i class="fa-solid fa-hashtag fa-sm"></i> Generative AI</a>   <a href="/blog/blog/tag/machine-learning"> <i class="fa-solid fa-hashtag fa-sm"></i> Machine Learning</a>   <a href="/blog/blog/tag/deep-learning"> <i class="fa-solid fa-hashtag fa-sm"></i> Deep Learning</a>   <a href="/blog/blog/tag/gans"> <i class="fa-solid fa-hashtag fa-sm"></i> GANs</a>   <a href="/blog/blog/tag/artificial-intelligence"> <i class="fa-solid fa-hashtag fa-sm"></i> Artificial Intelligence</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p>As someone deeply fascinated by the potential of artificial intelligence, I’ve always been captivated by the idea of machines that can <em>create</em>. Not just crunch numbers or classify images, but genuinely <em>generate</em> something new – a photorealistic face, an artistic masterpiece, or even a never-before-seen molecule. For a long time, this felt like science fiction, a distant dream. Then, I stumbled upon Generative Adversarial Networks, or GANs, and my perception of what AI could do was irrevocably changed.</p> <p>GANs are, without exaggeration, one of the most ingenious breakthroughs in deep learning in the last decade, first proposed by Ian Goodfellow and his colleagues in 2014. They represent a fundamental shift in how we approach generative models, moving from simply modeling data distributions to a dynamic, competitive learning process. If you’ve ever seen those incredibly realistic AI-generated faces or images of imaginary landscapes, chances are you’ve witnessed a GAN in action.</p> <p>So, how do these digital artists and master forgers work their magic? Let’s peel back the layers and discover the beautiful, adversarial dance at the heart of GANs.</p> <h3 id="the-ultimate-creative-contest-generator-vs-discriminator">The Ultimate Creative Contest: Generator vs. Discriminator</h3> <p>At its core, a GAN isn’t a single neural network but a system of <em>two</em> neural networks, locked in an ongoing, zero-sum game. Think of it like this:</p> <ol> <li> <strong>The Artist (or Forger): The Generator Network (G)</strong> <ul> <li>Its job is to create new data that looks as real as possible.</li> <li>Imagine an art student trying to mimic the style of a famous painter.</li> </ul> </li> <li> <strong>The Art Critic (or Detective): The Discriminator Network (D)</strong> <ul> <li>Its job is to distinguish between real data (genuine paintings) and fake data (the student’s forgeries).</li> <li>Imagine an expert art critic trying to spot a fake.</li> </ul> </li> </ol> <p>These two networks are trained simultaneously, constantly pushing each other to improve. It’s a bit like a student learning to forge, getting feedback from a strict critic, and gradually refining their technique until their fakes are indistinguishable from the real thing.</p> <h4 id="meet-the-players-in-detail">Meet the Players in Detail</h4> <p>Let’s get a bit more technical about our two protagonists.</p> <p><strong>1. The Generator ($G$): The Dreamer and Creator</strong></p> <p>The Generator is a neural network whose input is typically a vector of random numbers, often called a “latent vector” or “noise vector” ($z$). This noise is like the raw material or the initial spark of an idea for our artist. It doesn’t mean anything specific initially; it’s just a starting point in a high-dimensional space.</p> <p>The Generator then transforms this random noise into a data sample – an image, a piece of audio, a text snippet, whatever type of data we want to generate. For images, this often involves layers of upsampling or deconvolutional layers, starting from a tiny feature map and gradually expanding it into a full-sized image.</p> <ul> <li> <strong>Input:</strong> Random noise $z \sim p_z(z)$ (e.g., from a Gaussian distribution).</li> <li> <strong>Output:</strong> Synthesized data $G(z)$.</li> <li> <strong>Goal:</strong> To produce outputs that are so convincing, the Discriminator classifies them as “real.”</li> <li> <strong>Analogy:</strong> The art forger tries to make a painting that looks exactly like a real Monet.</li> </ul> <p><strong>2. The Discriminator ($D$): The Judge and Verifier</strong></p> <p>The Discriminator is also a neural network, usually a standard binary classifier. Its job is to tell the difference between “real” data samples (from the actual training dataset) and “fake” data samples (generated by the Generator).</p> <ul> <li> <strong>Input:</strong> Either a real data sample $x$ (from the training set $p_{data}(x)$) OR a fake data sample $G(z)$ (from the Generator).</li> <li> <strong>Output:</strong> A probability, a single number between 0 and 1. <ul> <li>A value close to 1 means the Discriminator believes the input is “real.”</li> <li>A value close to 0 means the Discriminator believes the input is “fake.”</li> </ul> </li> <li> <strong>Goal:</strong> To correctly identify real samples as real (outputting 1) and fake samples as fake (outputting 0).</li> <li> <strong>Analogy:</strong> The art critic wants to correctly identify genuine Monets and expose the forgeries.</li> </ul> <h3 id="the-adversarial-training-loop-a-dance-of-improvement">The Adversarial Training Loop: A Dance of Improvement</h3> <p>The real magic happens during the training process, which is adversarial and iterative. Here’s a simplified breakdown of each training step:</p> <p><strong>Step 1: Train the Discriminator (The Critic Gets Smarter)</strong></p> <ol> <li> <strong>Real Data:</strong> We feed the Discriminator a batch of <em>real</em> images from our training dataset. We label these as “real” (e.g., target label = 1).</li> <li> <strong>Fake Data:</strong> We then ask the Generator to produce a batch of <em>fake</em> images from its random noise inputs. We feed these fake images to the Discriminator and label them as “fake” (e.g., target label = 0).</li> <li> <strong>Update:</strong> The Discriminator’s weights are adjusted based on how well it performed. If it incorrectly identified a real image as fake, or a fake image as real, its internal parameters are tweaked to improve its accuracy in the future. The Generator’s weights are kept fixed during this step.</li> </ol> <p>After this step, the Discriminator becomes a bit better at telling real from fake.</p> <p><strong>Step 2: Train the Generator (The Artist Gets More Convincing)</strong></p> <ol> <li> <strong>Generate Fakes:</strong> We again ask the Generator to produce a batch of <em>fake</em> images.</li> <li> <strong>Fool the Discriminator:</strong> We feed these fake images to the Discriminator, but this time, the Generator’s goal is to <em>fool</em> the Discriminator. We tell the Generator that its goal is for the Discriminator to classify its creations as “real” (e.g., we set the target label for the Discriminator’s output to 1, even though the input is fake).</li> <li> <strong>Update:</strong> The Discriminator’s weights are kept fixed. Only the Generator’s weights are updated. The Generator learns to adjust its parameters so that the fake images it produces are more likely to be classified as “real” by the Discriminator.</li> </ol> <p>This back-and-forth continues for thousands, sometimes millions, of iterations. As the Generator gets better at producing convincing fakes, the Discriminator has to become even more astute to spot them. Conversely, as the Discriminator improves, the Generator is forced to generate even more realistic data to bypass the Discriminator’s scrutiny. It’s a perpetual arms race, driving both networks towards optimal performance.</p> <p>Ideally, the process stops when the Generator is so good that the Discriminator can no longer distinguish between real and fake data; it simply guesses with 50% probability (like flipping a coin). At this point, the Generator has learned to mimic the real data distribution.</p> <h3 id="the-math-behind-the-magic-a-minimax-game">The Math Behind the Magic: A Minimax Game</h3> <p>For those who like a peek under the hood, the training process of a GAN can be formulated as a minimax game between the Generator ($G$) and the Discriminator ($D$). The objective function, often called the value function $V(D, G)$, is something both networks are trying to optimize in opposing directions:</p> <p>$ \min_G \max_D V(D, G) = \mathbb{E}<em>{x \sim p</em>{data}(x)}[\log D(x)] + \mathbb{E}_{z \sim p_z(z)}[\log(1 - D(G(z)))] $</p> <p>Let’s break this intimidating-looking formula down:</p> <ul> <li>$p_{data}(x)$: This is the distribution of <em>real</em> data (the images in our training set).</li> <li>$p_z(z)$: This is the distribution of the <em>random noise</em> input to the Generator.</li> <li>$D(x)$: The Discriminator’s output probability that real data $x$ is real.</li> <li>$D(G(z))$: The Discriminator’s output probability that the generated fake data $G(z)$ is real.</li> <li>$\mathbb{E}[\cdot]$: This denotes the expectation (average value) over the given distribution.</li> </ul> <p><strong>The Discriminator’s Goal ($\max_D V(D, G)$):</strong> The Discriminator wants to maximize $V(D, G)$.</p> <ul> <li>It wants $\log D(x)$ to be large when $x$ is real, meaning $D(x)$ should be close to 1.</li> <li>It wants $\log(1 - D(G(z)))$ to be large when $G(z)$ is fake, meaning $D(G(z))$ should be close to 0 (so $1 - D(G(z))$ is close to 1). In essence, the Discriminator wants to correctly classify real data as real and fake data as fake.</li> </ul> <p><strong>The Generator’s Goal ($\min_G V(D, G)$):</strong> The Generator wants to minimize $V(D, G)$.</p> <ul> <li>It cannot directly influence the first term ($\mathbb{E}<em>{x \sim p</em>{data}(x)}[\log D(x)]$) since it only works with generated data.</li> <li>It wants to make the second term $\mathbb{E}_{z \sim p_z(z)}[\log(1 - D(G(z)))]$ as small as possible. This happens when $D(G(z))$ is close to 1 (meaning the Discriminator thinks the fake data is real), because $\log(1-\text{small number})$ is a large negative number. In short, the Generator wants to produce $G(z)$ such that $D(G(z))$ is close to 1, effectively fooling the Discriminator.</li> </ul> <p>This min-max game eventually reaches a Nash Equilibrium, where neither player can improve their outcome by unilaterally changing their strategy. At this point, the Generator has learned to perfectly replicate the real data distribution, and the Discriminator outputs 0.5 for all inputs, unsure if they are real or fake.</p> <h3 id="challenges-and-pitfalls-the-dark-side-of-creativity">Challenges and Pitfalls: The Dark Side of Creativity</h3> <p>While GANs are incredibly powerful, they are notoriously difficult to train. Some common issues include:</p> <ol> <li> <strong>Mode Collapse:</strong> This is perhaps the most frustrating problem. The Generator might discover a few types of fake images that are reliably good at fooling the Discriminator, and then it stops bothering to explore the full diversity of the real data distribution. For example, if training on images of different animals, it might only generate convincing images of cats, ignoring dogs, birds, and other animals. It essentially gets stuck in a “local optimum” of generation.</li> <li> <strong>Training Instability:</strong> The competitive nature of GANs can lead to oscillations where one network overpowers the other, or neither converges properly. It’s like a tug-of-war where neither side can get a firm footing. This often manifests as diverging losses or poor image quality.</li> <li> <strong>Vanishing Gradients:</strong> If the Discriminator becomes too powerful too quickly, its accuracy will be near perfect. This means its loss will be very small, and the gradients it passes back to the Generator will be tiny, providing almost no useful information for the Generator to improve. The Generator essentially gets no helpful feedback.</li> </ol> <p>Researchers are constantly developing new architectures and training techniques (like WGANs, LSGANs, etc.) to address these challenges and make GANs more robust.</p> <h3 id="beyond-the-basics-a-glimpse-at-the-gan-family">Beyond the Basics: A Glimpse at the GAN Family</h3> <p>The initial GAN architecture was just the beginning. The field has exploded with variations, each designed to improve performance or address specific use cases:</p> <ul> <li> <strong>DCGANs (Deep Convolutional GANs):</strong> One of the first major improvements, showing that using convolutional layers in both the Generator and Discriminator leads to much higher quality images.</li> <li> <strong>Conditional GANs (cGANs):</strong> These allow us to control the output of the Generator. By providing a condition (like a class label or another image) as input to both networks, we can generate specific types of data (e.g., “generate a dog,” or “transform this sketch into a photo”).</li> <li> <strong>CycleGANs:</strong> Incredible for unpaired image-to-image translation. Imagine converting summer photos to winter photos, or horses to zebras, without needing corresponding pairs of images.</li> <li> <strong>StyleGANs:</strong> Developed by NVIDIA, these produce astonishingly realistic human faces and other complex images, allowing for detailed control over various stylistic aspects (age, hair color, facial expression).</li> </ul> <h3 id="real-world-applications-where-gans-shine">Real-World Applications: Where GANs Shine</h3> <p>The applications of GANs are incredibly diverse and continue to expand:</p> <ol> <li> <strong>Realistic Image Synthesis:</strong> Generating faces of people who don’t exist (“This Person Does Not Exist”), creating synthetic landscapes, or designing virtual characters. This is where GANs truly capture the imagination.</li> <li> <strong>Data Augmentation:</strong> In fields where real-world data is scarce (like medical imaging), GANs can generate synthetic data to expand training datasets, helping other machine learning models perform better.</li> <li> <strong>Image-to-Image Translation:</strong> As seen with CycleGANs, tasks like converting satellite images to maps, black and white photos to color, or even turning sketches into photorealistic images.</li> <li> <strong>Super-resolution:</strong> Enhancing the resolution of low-quality images, restoring detail that wasn’t originally there.</li> <li> <strong>Art and Design:</strong> Assisting artists by generating new patterns, styles, or even entire pieces of abstract art. Some GANs can even transfer artistic styles from one image to another.</li> <li> <strong>Drug Discovery:</strong> Generating novel molecular structures with desired properties, accelerating the search for new medicines.</li> </ol> <h3 id="conclusion-the-future-is-generative">Conclusion: The Future is Generative</h3> <p>My journey into understanding Generative Adversarial Networks has been nothing short of exhilarating. It’s a field that perfectly blends theoretical elegance with practical, often astonishing, results. The concept of competitive learning to achieve creative synthesis is a powerful paradigm, and we’re only just beginning to scratch the surface of what GANs can truly accomplish.</p> <p>From photorealistic imagery to entirely new forms of data, GANs are pushing the boundaries of artificial intelligence, allowing machines to not just analyze our world, but to contribute to it creatively. While challenges like training instability and mode collapse persist, the rapid pace of research suggests that even more sophisticated and stable generative models are on the horizon.</p> <p>If you’re interested in the cutting edge of AI, I wholeheartedly encourage you to dive deeper into GANs. They are a testament to human ingenuity in designing intelligent systems, and a fascinating glimpse into a future where machines aren’t just tools, but collaborators in the act of creation. The art of deception, it turns out, can lead to incredible beauty.</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/cracking-the-ai-black-box-why-explainable-ai-xai-i/">Cracking the AI Black Box: Why Explainable AI (XAI) is Our Superpower</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/the-secret-life-of-states-how-markov-chains-predic/">The Secret Life of States: How Markov Chains Predict Our Next Move (Without Remembering the Past!)</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/gradient-descent-unpacking-the-engine-of-machine-l/">Gradient Descent: Unpacking the Engine of Machine Learning</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Adarsh Nair. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/blog/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/masonry.js?v=a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/zoom.js?v=85ddb88934d28b74e78031fd54cf8308"></script> <script src="/blog/assets/js/no_defer.js?v=2781658a0a2b13ed609542042a859126"></script> <script defer src="/blog/assets/js/common.js?v=c15de51d4bb57887caa2c21988d97279"></script> <script defer src="/blog/assets/js/copy_code.js?v=c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/blog/assets/js/jupyter_new_tab.js?v=d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/blog/assets/js/mathjax-setup.js?v=a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/progress-bar.js?v=2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/blog/assets/js/vanilla-back-to-top.min.js?v=f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/blog/assets/js/search/ninja-keys.min.js?v=a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/blog/assets/js/search-setup.js?v=6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/blog/assets/js/search-data.js"></script> <script src="/blog/assets/js/shortcut-key.js?v=ccc841c459bfc0e64c1c2b5acd10df02"></script> </body> </html>