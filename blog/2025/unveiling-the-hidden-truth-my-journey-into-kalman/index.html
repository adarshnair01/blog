<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Unveiling the Hidden Truth: My Journey into Kalman Filters | Adarsh Nair </title> <meta name="author" content="Adarsh Nair"> <meta name="description" content="A deep dive into machine learning, AI, and data science. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <meta http-equiv="Content-Security-Policy" content="default-src 'self'; script-src 'self' 'unsafe-inline' https:; style-src 'self' 'unsafe-inline' https:; img-src 'self' data: https:; font-src 'self' data: https:; media-src 'self' https:; frame-src 'self' https:; connect-src 'self' https:;"> <link rel="stylesheet" href="/blog/assets/css/bootstrap.min.css?v=a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/blog/assets/css/academicons.min.css?v=f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/blog/assets/css/scholar-icons.css?v=62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-github.css?v=591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/blog/assets/css/main.css?v=d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://adarshnair.online/blog/blog/blog/2025/unveiling-the-hidden-truth-my-journey-into-kalman/"> <script src="/blog/assets/js/theme.js?v=5fea5159b787642c1bbc1f334d60f883"></script> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-native.css?v=5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="https://adarshnair.online" rel="external nofollow noopener" target="_blank"> Adarsh Nair </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/blog/"> </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/index.html">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/cv/">CV </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="https://adarshnair.online/books/" rel="external nofollow noopener" target="_blank">books </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="fa-solid fa-magnifying-glass"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-half-sun-moon" id="light-toggle-system"></i> <i class="fa-solid fa-moon" id="light-toggle-dark"></i> <i class="fa-solid fa-sun" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Unveiling the Hidden Truth: My Journey into Kalman Filters</h1> <p class="post-meta"> Created on February 27, 2025 by Adarsh Nair </p> <p class="post-tags"> <a href="/blog/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/blog/tag/kalman-filter"> <i class="fa-solid fa-hashtag fa-sm"></i> Kalman Filter</a>   <a href="/blog/blog/tag/state-estimation"> <i class="fa-solid fa-hashtag fa-sm"></i> State Estimation</a>   <a href="/blog/blog/tag/robotics"> <i class="fa-solid fa-hashtag fa-sm"></i> Robotics</a>   <a href="/blog/blog/tag/data-science"> <i class="fa-solid fa-hashtag fa-sm"></i> Data Science</a>   <a href="/blog/blog/tag/control-systems"> <i class="fa-solid fa-hashtag fa-sm"></i> Control Systems</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p>Remember that time your GPS seemed a bit jumpy, showing you briefly in a nearby field before snapping back to the road? Or when a drone, trying to hold its position, drifted slightly in a subtle breeze? In our data-rich world, we’re constantly bombarded with information, but much of it comes with a catch: noise and uncertainty. Sensors aren’t perfect. Models of how things behave aren’t perfect. So, how do we make sense of it all and arrive at the ‘true’ picture?</p> <p>This question led me down a fascinating rabbit hole, straight into the heart of a powerful, elegant algorithm known as the Kalman Filter. It’s one of those foundational concepts that, once you grasp it, seems to unlock a new way of thinking about dynamic systems and uncertain data. Invented in 1960 by Rudolf Kálmán, its relevance in fields from aerospace to finance, and now in cutting-edge AI and autonomous systems, is stronger than ever.</p> <p>Join me as I try to unravel the magic behind this mathematical marvel, from its intuitive core to its powerful equations.</p> <h3 id="the-core-problem-navigating-a-world-of-uncertainty">The Core Problem: Navigating a World of Uncertainty</h3> <p>Let’s ground this with an example. Imagine you’re building an autonomous robot. It needs to know its exact position and velocity at all times to navigate safely. You have:</p> <ol> <li> <strong>Sensors:</strong> An onboard GPS module gives you a position reading, but it’s noisy – sometimes it’s off by a few meters. An accelerometer tells you how fast your robot is accelerating, but it also has its own errors and drift.</li> <li> <strong>A Model:</strong> You have an understanding of how your robot moves – its physics. If it was at X position with Y velocity, and you commanded its motors to do Z, you can predict where it <em>should</em> be next. But this model isn’t perfect; there’s friction, uneven terrain, or subtle motor inconsistencies you can’t account for.</li> </ol> <p>How do you combine these imperfect pieces of information to get the <em>best possible</em> estimate of your robot’s true, hidden state (its actual position and velocity)? Simply averaging the sensor readings isn’t enough, especially for a system constantly changing. This is precisely the problem the Kalman Filter solves.</p> <p>It’s a recursive estimator, meaning it only needs the previous state estimate and the current measurement to compute the current state estimate. It doesn’t need to store all past measurements, making it incredibly efficient for real-time applications.</p> <h3 id="the-intuition-behind-the-filter-the-master-blende-r">The Intuition Behind the Filter: The Master Blende r</h3> <p>At its heart, the Kalman Filter is a master blende r. It takes two pieces of information:</p> <ol> <li> <strong>A prediction</strong> of the system’s current state (where we <em>think</em> it should be).</li> <li> <strong>A measurement</strong> of the system’s current state (where our sensors <em>say</em> it is).</li> </ol> <p>Crucially, both of these come with their own levels of uncertainty. The filter then intelligently weighs these two pieces of information to produce a new, more accurate estimate of the system’s true state.</p> <p>Think of it like this: You’re trying to guess the current temperature in a room.</p> <ul> <li> <strong>Your prediction:</strong> You remember it was 20°C an hour ago, and based on the heater being on, you predict it should now be 22°C. You’re somewhat confident, say ±1°C.</li> <li> <strong>Your measurement:</strong> You look at a thermometer, and it reads 25°C. But it’s an old, somewhat unreliable thermometer, so you’re only confident to ±3°C.</li> </ul> <p>How do you combine these? You wouldn’t just average them. If your prediction was very confident (±0.1°C) and the thermometer wildly unreliable (±10°C), you’d trust your prediction more. If your prediction was very vague (±10°C) but the thermometer super accurate (±0.1°C), you’d trust the thermometer more.</p> <p>The Kalman Filter mathematically determines that “trust factor” to give you the <em>best possible</em> weighted average, leading to a more accurate estimate than either the prediction or the measurement alone.</p> <h3 id="the-two-pillars-predict-and-update">The Two Pillars: Predict and Update</h3> <p>The Kalman Filter operates in a continuous loop, cycling through two main phases:</p> <ol> <li> <p><strong>Predict (Time Update):</strong> Based on our last best estimate of the system’s state, and our understanding of how the system evolves (its physics, its dynamics), we predict its current state. Crucially, we also predict how uncertain we are about this prediction – our uncertainty <em>grows</em> when we make a prediction.</p> </li> <li> <p><strong>Update (Measurement Update):</strong> Now, a new sensor measurement arrives. We compare this measurement to our prediction. If they align well, great! If not, we use the measurement to ‘correct’ our prediction. Again, we also update our certainty about this new, corrected state – our uncertainty <em>decreases</em> as we gain new information.</p> </li> </ol> <p>This predict-update cycle continues indefinitely, constantly refining the estimate of the system’s hidden state.</p> <h3 id="peeking-under-the-hood-the-math-of-fusion">Peeking Under the Hood: The Math of Fusion</h3> <p>To talk about the Kalman Filter mathematically, we need to represent our system’s ‘state’ and our ‘uncertainty’ in a structured way using vectors and matrices. This allows us to handle multiple variables (like position AND velocity) simultaneously.</p> <ul> <li> <strong>State Vector ($\mathbf{x}$):</strong> This column vector holds all the variables we care about. For our robot, it might be $\begin{bmatrix} \text{position}_x \ \text{position}_y \ \text{velocity}_x \ \text{velocity}_y \end{bmatrix}$. For a drone, it could include orientation angles too.</li> <li> <strong>Covariance Matrix ($\mathbf{P}$):</strong> This symmetric matrix captures our uncertainty about the state variables. The diagonal elements tell us the variance (squared uncertainty) of each individual variable, and off-diagonal elements tell us how coupled the uncertainties are (e.g., if we’re uncertain about position_x, are we also uncertain about velocity_x?). A smaller $\mathbf{P}$ means higher confidence in our state estimate.</li> </ul> <p>Let’s dive into the equations for each step:</p> <h4 id="the-prediction-step-time-update">The Prediction Step (Time Update)</h4> <p>This step uses our system model to project the state and its uncertainty forward in time.</p> <ol> <li> <strong>Predicting the State:</strong> \(\hat{\mathbf{x}}_{k|k-1} = \mathbf{F}\_k \hat{\mathbf{x}}_{k-1|k-1} + \mathbf{B}\_k \mathbf{u}\_k\) <ul> <li> <table> <tbody> <tr> <td>$\hat{\mathbf{x}}_{k</td> <td>k-1}$: Our <em>a priori</em> (predicted) state estimate at time $k$, based on information up to $k-1$. It’s our best guess <em>before</em> seeing the current measurement.</td> </tr> </tbody> </table> </li> <li> <table> <tbody> <tr> <td>$\hat{\mathbf{x}}_{k-1</td> <td>k-1}$: Our <em>a posteriori</em> (updated) state estimate from the previous time step $k-1$. This was our best guess <em>after</em> incorporating the last measurement.</td> </tr> </tbody> </table> </li> <li>$\mathbf{F}_k$: The <strong>state transition model</strong> matrix. It describes how the state evolves from $k-1$ to $k$ without any external forces. Think of it as the ‘physics’ of the system.</li> <li>$\mathbf{B}_k$: The <strong>control input model</strong> matrix.</li> <li>$\mathbf{u}_k$: The <strong>control vector</strong>, representing external forces or commands (e.g., motor thrust, steering input). If there’s no control input, this term vanishes.</li> </ul> <p><em>In plain language:</em> Our best guess for the next state is where we were, propelled by our system’s inherent motion and any external forces we apply.</p> </li> <li> <strong>Predicting the Uncertainty:</strong> \(\mathbf{P}_{k|k-1} = \mathbf{F}\_k \mathbf{P}_{k-1|k-1} \mathbf{F}\_k^T + \mathbf{Q}\_k\) <ul> <li> <table> <tbody> <tr> <td>$\mathbf{P}_{k</td> <td>k-1}$: The <em>a priori</em> estimate covariance. This is our predicted uncertainty.</td> </tr> </tbody> </table> </li> <li> <table> <tbody> <tr> <td>$\mathbf{P}_{k-1</td> <td>k-1}$: The <em>a posteriori</em> estimate covariance from the previous step.</td> </tr> </tbody> </table> </li> <li>$\mathbf{Q}<em>k$: The <strong>process noise covariance matrix</strong>. This accounts for uncertainty in our system model itself – things we can’t perfectly model (e.g., un-modeled gusts of wind affecting a drone, slight inaccuracies in our physics equations). Our uncertainty _grows</em> when we make a prediction because models are never perfect.</li> </ul> <p><em>In plain language:</em> Our uncertainty for the next state increases from our previous uncertainty, influenced by how our system transitions, plus any un-modeled ‘noise’ in our system itself.</p> </li> </ol> <h4 id="the-update-step-measurement-update">The Update Step (Measurement Update)</h4> <p>This is where the new measurement comes in to refine our prediction and reduce our uncertainty.</p> <ol> <li> <strong>Measurement Residual (Innovation):</strong> \(\tilde{\mathbf{y}}_k = \mathbf{z}\_k - \mathbf{H}\_k \hat{\mathbf{x}}_{k|k-1}\) <ul> <li>$\mathbf{z}_k$: The actual <strong>measurement</strong> received from sensors at time $k$.</li> <li>$\mathbf{H}_k$: The <strong>observation model</strong> matrix. It maps the state space into the measurement space (e.g., if our state includes velocity but our sensor only measures position, $\mathbf{H}$ extracts the position component).</li> <li> <table> <tbody> <tr> <td>$\mathbf{H}<em>k \hat{\mathbf{x}}</em>{k</td> <td>k-1}$: This is our <em>predicted measurement</em> based on our predicted state.</td> </tr> </tbody> </table> </li> </ul> <p><em>In plain language:</em> The residual is simply the difference between what we <em>actually measured</em> and what we <em>expected to measure</em> based on our prediction. It’s the ‘surprise’ factor.</p> </li> <li> <strong>Residual Covariance:</strong> \(\mathbf{S}_k = \mathbf{H}\_k \mathbf{P}_{k|k-1} \mathbf{H}\_k^T + \mathbf{R}\_k\) <ul> <li>$\mathbf{R}_k$: The <strong>measurement noise covariance matrix</strong>. This represents the uncertainty inherent in our sensor measurements (e.g., GPS error, sensor jitter, reading inaccuracies).</li> </ul> <p><em>In plain language:</em> This matrix describes the uncertainty of our residual – how uncertain we are about the ‘surprise’ itself. It combines the uncertainty in our predicted state (transformed to measurement space) with the inherent uncertainty of the measurement sensor.</p> </li> <li> <p>**The Kalman Gain ($\mathbf{K}<em>k$): The Blending Factor:** \(\mathbf{K}_k = \mathbf{P}_{k|k-1} \mathbf{H}\_k^T \mathbf{S}\_k^{-1}\) This is the absolute heart of the Kalman Filter! The Kalman Gain is a matrix that tells us _how much to trust the new measurement versus our prediction</em>. It’s that crucial weighting factor we talked about earlier.</p> <table> <tbody> <tr> <td> <em>In plain language:</em> Think back to the temperature analogy. The Kalman Gain is that ‘trust factor’. If your sensor is very noisy (large $\mathbf{R}<em>k$, making $\mathbf{S}_k$ large), then $\mathbf{K}_k$ will be small, meaning we’ll trust our prediction more and adjust only slightly. If your prediction is very uncertain (large $\mathbf{P}</em>{k</td> <td>k-1}$, making $\mathbf{K}_k$ large), then we’ll trust the measurement more and make a larger adjustment. It’s an intelligent balance based on relative uncertainties.</td> </tr> </tbody> </table> </li> <li> <strong>Updating the State Estimate:</strong> \(\hat{\mathbf{x}}_{k|k} = \hat{\mathbf{x}}_{k|k-1} + \mathbf{K}\_k \tilde{\mathbf{y}}\_k\) <ul> <li> <table> <tbody> <tr> <td>$\hat{\mathbf{x}}_{k</td> <td>k}$: Our <em>a posteriori</em> (updated) state estimate at time $k$. This is our new, refined “best guess” after incorporating the measurement.</td> </tr> </tbody> </table> </li> </ul> <p><em>In plain language:</em> We take our predicted state and add a weighted version of the measurement residual. If the measurement was much higher than predicted, and we trust the measurement (large $\mathbf{K}_k$), our new state will be shifted significantly towards that higher measurement.</p> </li> <li> <strong>Updating the Covariance Estimate:</strong> \(\mathbf{P}_{k|k} = (\mathbf{I} - \mathbf{K}\_k \mathbf{H}\_k) \mathbf{P}_{k|k-1}\) <ul> <li>$\mathbf{I}$: The identity matrix.</li> </ul> <table> <tbody> <tr> <td> <em>In plain language:</em> This final step updates our uncertainty. Since we’ve incorporated a new measurement, our uncertainty should decrease (unless the measurement was completely useless or perfectly aligned with prediction). A smaller $\mathbf{P}_{k</td> <td>k}$ signifies that we are now more confident in our state estimate. And then the loop starts again, using $\hat{\mathbf{x}}_{k</td> <td>k}$ and $\mathbf{P}_{k</td> <td>k}$ as the inputs for the next prediction step.</td> </tr> </tbody> </table> </li> </ol> <h3 id="why-is-it-optimal">Why is it “Optimal”?</h3> <p>For linear systems with Gaussian (normally distributed) noise, the Kalman Filter is the <strong>optimal linear unbiased estimator</strong> in terms of minimizing the mean square error. This is a big deal! It means no other linear filter can do a better job under these specific conditions.</p> <p>What about non-linear systems? Most real-world systems aren’t perfectly linear. That’s where variations like the <strong>Extended Kalman Filter (EKF)</strong> and the <strong>Unscented Kalman Filter (UKF)</strong> come into play. They approximate the non-linear transformations (EKF using linearization, UKF using “sigma points”) to adapt the core Kalman Filter principles, but that’s a story for another time!</p> <h3 id="real-world-applications">Real-World Applications</h3> <p>The Kalman Filter’s elegance and power make it ubiquitous in countless applications:</p> <ul> <li> <strong>GPS Navigation:</strong> Your phone uses a Kalman Filter to smooth out noisy GPS signals, combine them with accelerometer and gyroscope data, and give you a more stable and accurate position estimate, even when you lose signal temporarily.</li> <li> <strong>Robotics &amp; Autonomous Vehicles:</strong> Self-driving cars, drones, and robot arms use it for Simultaneous Localization and Mapping (SLAM), object tracking, predicting the movement of other vehicles, and keeping their own position and velocity accurate.</li> <li> <strong>Aerospace:</strong> From Apollo mission spacecraft navigation to modern missile guidance systems and satellite orbit determination, precision is paramount, and Kalman Filters deliver.</li> <li> <strong>Financial Modeling:</strong> Estimating parameters in dynamic financial models and predicting asset prices in noisy markets.</li> <li> <strong>Weather Forecasting:</strong> Combining complex atmospheric models with real-time sensor readings from weather stations and satellites to improve predictions.</li> </ul> <h3 id="conclusion-embracing-the-uncertainty">Conclusion: Embracing the Uncertainty</h3> <p>My journey into the Kalman Filter unveiled a masterpiece of engineering and mathematics. It’s a testament to how elegant mathematical frameworks can cut through the noise of reality and help us perceive the hidden truth. It’s not just a set of equations; it’s a philosophical approach to dealing with uncertainty, a continuous blend of prediction and observation, giving us the most informed estimate possible at every moment.</p> <p>If you’re building systems that need to understand their state in a dynamic, uncertain world – from machine learning models that need to track evolving parameters to robots navigating complex environments – the Kalman Filter is an indispensable tool in your arsenal. Dive deeper, implement it, and witness its silent, powerful ability to bring clarity to chaos!</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/cracking-the-ai-black-box-why-explainable-ai-xai-i/">Cracking the AI Black Box: Why Explainable AI (XAI) is Our Superpower</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/the-secret-life-of-states-how-markov-chains-predic/">The Secret Life of States: How Markov Chains Predict Our Next Move (Without Remembering the Past!)</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/gradient-descent-unpacking-the-engine-of-machine-l/">Gradient Descent: Unpacking the Engine of Machine Learning</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Adarsh Nair. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/blog/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/masonry.js?v=a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/zoom.js?v=85ddb88934d28b74e78031fd54cf8308"></script> <script src="/blog/assets/js/no_defer.js?v=2781658a0a2b13ed609542042a859126"></script> <script defer src="/blog/assets/js/common.js?v=c15de51d4bb57887caa2c21988d97279"></script> <script defer src="/blog/assets/js/copy_code.js?v=c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/blog/assets/js/jupyter_new_tab.js?v=d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/blog/assets/js/mathjax-setup.js?v=a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/progress-bar.js?v=2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/blog/assets/js/vanilla-back-to-top.min.js?v=f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/blog/assets/js/search/ninja-keys.min.js?v=a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/blog/assets/js/search-setup.js?v=6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/blog/assets/js/search-data.js"></script> <script src="/blog/assets/js/shortcut-key.js?v=ccc841c459bfc0e64c1c2b5acd10df02"></script> </body> </html>