<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> The Grand AI Showdown: PyTorch vs. TensorFlow – My Journey Through the Deep Learning Giants | Adarsh Nair </title> <meta name="author" content="Adarsh Nair"> <meta name="description" content="A deep dive into machine learning, AI, and data science. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <meta http-equiv="Content-Security-Policy" content="default-src 'self'; script-src 'self' 'unsafe-inline' https:; style-src 'self' 'unsafe-inline' https:; img-src 'self' data: https:; font-src 'self' data: https:; media-src 'self' https:; frame-src 'self' https:; connect-src 'self' https:;"> <link rel="stylesheet" href="/blog/assets/css/bootstrap.min.css?v=a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/blog/assets/css/academicons.min.css?v=f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/blog/assets/css/scholar-icons.css?v=62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-github.css?v=591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/blog/assets/css/main.css?v=d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://adarshnair.online/blog/blog/blog/2025/the-grand-ai-showdown-pytorch-vs-tensorflow-my-jo/"> <script src="/blog/assets/js/theme.js?v=5fea5159b787642c1bbc1f334d60f883"></script> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-native.css?v=5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="https://adarshnair.online" rel="external nofollow noopener" target="_blank"> Adarsh Nair </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/blog/"> </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/index.html">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/cv/">CV </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="https://adarshnair.online/books/" rel="external nofollow noopener" target="_blank">books </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="fa-solid fa-magnifying-glass"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-half-sun-moon" id="light-toggle-system"></i> <i class="fa-solid fa-moon" id="light-toggle-dark"></i> <i class="fa-solid fa-sun" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">The Grand AI Showdown: PyTorch vs. TensorFlow – My Journey Through the Deep Learning Giants</h1> <p class="post-meta"> Created on June 05, 2025 by Adarsh Nair </p> <p class="post-tags"> <a href="/blog/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/blog/tag/deep-learning"> <i class="fa-solid fa-hashtag fa-sm"></i> Deep Learning</a>   <a href="/blog/blog/tag/machine-learning"> <i class="fa-solid fa-hashtag fa-sm"></i> Machine Learning</a>   <a href="/blog/blog/tag/pytorch"> <i class="fa-solid fa-hashtag fa-sm"></i> PyTorch</a>   <a href="/blog/blog/tag/tensorflow"> <i class="fa-solid fa-hashtag fa-sm"></i> TensorFlow</a>   <a href="/blog/blog/tag/ai"> <i class="fa-solid fa-hashtag fa-sm"></i> AI</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p>Welcome, fellow explorers of the digital frontier! If you’re anything like I was when I first dove headfirst into deep learning, you’ve probably faced a pivotal question that echoes through every online forum and coding tutorial: “Should I learn PyTorch or TensorFlow?” It’s a bit like choosing between two superhero teams, both incredibly powerful, both capable of saving the world (or, you know, training a killer neural network).</p> <p>For a while, this decision felt like picking a side in an epic tech rivalry. As a budding data scientist and ML engineer, I realized early on that understanding <em>both</em> was eventually necessary, but <em>starting</em> with one felt like a monumental commitment. So, I embarked on a journey to truly understand what makes these two frameworks tick, beyond just the surface-level hype. In this post, I want to share my insights, drawing on what I’ve learned, to help you navigate this choice with confidence.</p> <h3 id="a-glimpse-into-the-past-and-present-the-evolution">A Glimpse into the Past (and Present): The Evolution</h3> <p>Before we pit them against each other, it’s crucial to understand their origins and how they’ve evolved.</p> <p><strong>TensorFlow</strong>, born out of Google Brain and open-sourced in 2015, quickly became the industry standard. It was designed with large-scale production deployments in mind, focusing on efficiency and scalability. Its initial approach, however, had a steep learning curve. We’re talking about TensorFlow 1.x here, where you had to define your entire computation graph <em>before</em> you could run any calculations. Think of it like writing an entire elaborate recipe down, ingredients and steps, and only <em>then</em> starting to cook.</p> <p>Then came <strong>PyTorch</strong>, open-sourced by Facebook AI in 2016. It took a different philosophical stance, emphasizing flexibility, ease of use, and a more “Pythonic” feel. Researchers and academics quickly gravitated towards it because it mirrored the natural flow of thought during experimentation.</p> <p>The plot thickened with <strong>TensorFlow 2.x</strong>! Google listened to the community, embraced the “eager execution” paradigm that PyTorch championed, and integrated Keras (a high-level API) as its default interface. This move significantly streamlined TensorFlow, making it much more user-friendly and reducing the initial gap between the two frameworks. In many ways, they’ve started to converge in terms of user experience, but their underlying philosophies still offer distinct advantages.</p> <h3 id="the-core-difference-dynamic-vs-static-computation-graphs">The Core Difference: Dynamic vs. Static Computation Graphs</h3> <p>This is where the real magic (and initial confusion) happens. At the heart of any deep learning framework is the “computation graph.” This graph represents the sequence of operations (like matrix multiplications, additions, activations) performed on your data.</p> <h4 id="pytorchs-define-by-run-dynamic-graphs">PyTorch’s Define-by-Run (Dynamic Graphs)</h4> <p>Imagine you’re building with LEGOs. With PyTorch, you build your model piece by piece, and as you add each new block, the connection is instantly formed. If you make a mistake, you see it immediately. This is <strong>dynamic computation graphs</strong>, often called “define-by-run.”</p> <p>What does this mean? Every time you run your model, PyTorch constructs the computation graph on the fly. This brings several compelling advantages:</p> <ol> <li> <strong>Flexibility:</strong> You can change the network structure based on input data (e.g., variable sequence lengths in NLP models) or even conditions within your training loop.</li> <li> <strong>Easier Debugging:</strong> Because the graph is built dynamically, you can use standard Python debuggers (like <code class="language-plaintext highlighter-rouge">pdb</code>) to inspect variables and step through your code line by line, just like any other Python script. This is a game-changer when your model isn’t behaving as expected.</li> <li> <strong>Intuitive Pythonic Feel:</strong> It feels more like writing regular Python code.</li> </ol> <p>Let’s illustrate with a simple linear layer. In PyTorch, you might define it and apply it sequentially:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">torch</span>
<span class="kn">import</span> <span class="n">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>

<span class="c1"># Define a simple linear layer
</span><span class="n">linear_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Create some random input data
</span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span> <span class="c1"># 1 sample, 10 features
</span>
<span class="c1"># Pass the input through the layer
</span><span class="n">y</span> <span class="o">=</span> <span class="nf">linear_layer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="c1"># y is now available, and we can inspect it immediately
</span><span class="nf">print</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</code></pre></div></div> <p>Here, <code class="language-plaintext highlighter-rouge">y = linear_layer(x)</code> creates the computational path for that specific forward pass <em>at that very moment</em>. If we then calculate the loss and call <code class="language-plaintext highlighter-rouge">y.backward()</code>, PyTorch traverses this dynamically created graph backwards to compute gradients. For instance, if our output $y$ is the result of $y = Wx + b$, where $W$ is the weight matrix and $b$ is the bias vector, PyTorch dynamically calculates gradients like $\frac{\partial L}{\partial W}$ based on the loss function $L$.</p> <h4 id="tensorflows-historical-define-and-run-static-graphs">TensorFlow’s (Historical) Define-and-Run (Static Graphs)</h4> <p>Historically, TensorFlow 1.x adopted a “define-and-run” philosophy. You first had to define the <em>entire</em> computation graph – all the operations, placeholders for inputs, and variables – and only <em>then</em> could you feed data into it and run it within a TensorFlow Session. It was like drafting a complete blueprint of a building before laying a single brick.</p> <p>The benefits of this static graph approach were significant for production:</p> <ol> <li> <strong>Optimization:</strong> Since the entire graph is known upfront, TensorFlow can perform extensive global optimizations (e.g., pruning unused nodes, fusing operations) to make it run faster and consume less memory.</li> <li> <strong>Deployment:</strong> Static graphs can be easily serialized, optimized, and deployed to various environments (servers, mobile devices, web browsers) without needing the Python interpreter.</li> <li> <strong>Distributed Training:</strong> Knowing the full graph beforehand helps TensorFlow efficiently distribute computations across multiple devices or machines.</li> </ol> <p>With TensorFlow 2.x, the default mode is <strong>eager execution</strong>, which mirrors PyTorch’s define-by-run. However, TensorFlow retains the power of static graphs through <code class="language-plaintext highlighter-rouge">tf.function</code>. When you decorate a Python function with <code class="language-plaintext highlighter-rouge">@tf.function</code>, TensorFlow traces the function’s execution and converts it into a callable TensorFlow graph, compiling it for performance and deployability. This means you get the best of both worlds: ease of eager execution during development and graph performance for production.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>

<span class="c1"># Define a simple linear layer using Keras API
</span><span class="n">linear_layer</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="nc">Dense</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,))</span>

<span class="c1"># Create some random input data
</span><span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">normal</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span> <span class="c1"># 1 sample, 10 features
</span>
<span class="c1"># Pass the input through the layer (eagerly)
</span><span class="n">y</span> <span class="o">=</span> <span class="nf">linear_layer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

<span class="c1"># We can also compile this into a static graph for performance
</span><span class="nd">@tf.function</span>
<span class="k">def</span> <span class="nf">compute_output</span><span class="p">(</span><span class="n">input_data</span><span class="p">):</span>
    <span class="k">return</span> <span class="nf">linear_layer</span><span class="p">(</span><span class="n">input_data</span><span class="p">)</span>

<span class="c1"># Now, calling compute_output traces and compiles the graph
</span><span class="n">y_graph</span> <span class="o">=</span> <span class="nf">compute_output</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">y_graph</span><span class="p">)</span>
</code></pre></div></div> <p>Notice how similar the eager code now looks! The key difference lies in the underlying mechanisms and the explicit <code class="language-plaintext highlighter-rouge">tf.function</code> for graph compilation.</p> <h3 id="ease-of-use-and-learning-curve">Ease of Use and Learning Curve</h3> <p>My personal experience aligns with the general consensus here:</p> <ul> <li> <strong>PyTorch:</strong> Felt incredibly intuitive from day one. Its API is very Pythonic, using familiar classes and methods. If you’re comfortable with NumPy, PyTorch’s <code class="language-plaintext highlighter-rouge">torch.Tensor</code> operations will feel like home. It allows for explicit control, which can be liberating for researchers.</li> <li> <strong>TensorFlow:</strong> In its 1.x incarnation, the learning curve was steep. The “session” and “placeholder” concepts were often confusing for beginners. However, with TensorFlow 2.x and Keras as the default high-level API, it’s become <em>much</em> easier. Keras is fantastic for quickly building and experimenting with models, abstracting away much of the low-level complexity.</li> </ul> <p>So, while PyTorch might still feel slightly more natural for those deep into Python, TensorFlow 2.x has largely closed the gap in terms of beginner-friendliness, especially for standard models.</p> <h3 id="debugging-my-favorite-part-of-dynamic-graphs">Debugging: My Favorite Part of Dynamic Graphs</h3> <p>This is a big one for me, and often the reason I lean towards PyTorch for rapid prototyping and research.</p> <p>With PyTorch’s dynamic graphs, debugging is a breeze. When something goes wrong, a standard Python traceback points directly to the line of code that caused the error. You can use any Python debugger (like <code class="language-plaintext highlighter-rouge">pdb</code> or your IDE’s debugger) to set breakpoints, inspect variables, and step through your model’s execution, exactly as you would with any other Python program. This saves <em>hours</em> of frustration.</p> <p>In TensorFlow 1.x, debugging a static graph could be a nightmare. Errors would often only surface during the session run, and the traceback would point to obscure graph operations rather than your Python code. TensorFlow 2.x’s eager execution <em>dramatically</em> improves this, bringing debugging much closer to the PyTorch experience. However, when using <code class="language-plaintext highlighter-rouge">@tf.function</code>, you still need to be aware of the graph compilation aspect, which can sometimes make debugging compiled functions a bit trickier than pure eager code.</p> <h3 id="deployment-beyond-the-training-loop">Deployment: Beyond the Training Loop</h3> <p>Once your model is trained, you need to deploy it to make predictions in the real world. This is an area where TensorFlow historically had a strong lead.</p> <ul> <li> <strong>TensorFlow:</strong> Offers a comprehensive ecosystem for deployment. <code class="language-plaintext highlighter-rouge">TensorFlow Serving</code> allows you to deploy models at scale in production environments. <code class="language-plaintext highlighter-rouge">TensorFlow Lite</code> enables deployment on mobile and embedded devices, while <code class="language-plaintext highlighter-rouge">TensorFlow.js</code> brings models to web browsers. Its static graph nature makes models easy to optimize and package for various target platforms.</li> <li> <strong>PyTorch:</strong> Has made significant strides in deployment with <code class="language-plaintext highlighter-rouge">TorchScript</code>. TorchScript allows you to serialize your PyTorch models into a static graph representation that can be run independently of Python (e.g., in C++). It’s also increasingly integrating with <code class="language-plaintext highlighter-rouge">ONNX</code> (Open Neural Network Exchange), an open standard for representing deep learning models, which allows for easier model interchangeability between frameworks and deployment targets. While PyTorch’s deployment story is catching up rapidly, TensorFlow’s ecosystem is still more mature and broader for highly diverse production environments.</li> </ul> <h3 id="ecosystem-and-community-whos-behind-the-curtains">Ecosystem and Community: Who’s Behind the Curtains?</h3> <p>Both frameworks boast massive, vibrant communities, but with slightly different focuses:</p> <ul> <li> <strong>PyTorch:</strong> Strongly favored by the academic and research community. It’s often the framework of choice for publishing cutting-edge research papers due to its flexibility and ease of experimentation. Backed primarily by Facebook AI.</li> <li> <strong>TensorFlow:</strong> Dominant in industry, particularly with large enterprises and Google’s own internal projects. Its robust deployment tools and broader ML ecosystem (like TFX for production pipelines, TensorBoard for visualization, various pre-trained models) make it a strong contender for end-to-end ML solutions. Backed by Google Brain.</li> </ul> <p>Both have extensive documentation, online courses, and active forums, so you’ll find plenty of resources no matter which you choose.</p> <h3 id="advanced-features-scaling-up">Advanced Features: Scaling Up</h3> <p>Both PyTorch and TensorFlow offer robust features for scaling your models and training on large datasets:</p> <ul> <li> <strong>Distributed Training:</strong> Both frameworks provide powerful abstractions for training models across multiple GPUs or even multiple machines. PyTorch’s <code class="language-plaintext highlighter-rouge">torch.distributed</code> module and TensorFlow’s <code class="language-plaintext highlighter-rouge">tf.distribute.Strategy</code> API are sophisticated tools for parallelizing your deep learning workloads.</li> <li> <strong>Data Loaders &amp; Preprocessing:</strong> Handling large datasets efficiently is crucial. PyTorch’s <code class="language-plaintext highlighter-rouge">DataLoader</code> and <code class="language-plaintext highlighter-rouge">Dataset</code> APIs are excellent for creating efficient data pipelines, while TensorFlow’s <code class="language-plaintext highlighter-rouge">tf.data</code> API is equally powerful and flexible for building input pipelines.</li> <li> <strong>Optimizers &amp; Loss Functions:</strong> Both offer a wide array of built-in optimizers (like Adam, SGD, RMSprop) and loss functions (CrossEntropyLoss, MSE, etc.), and allow for easy implementation of custom ones.</li> </ul> <h3 id="when-to-choose-which-my-personal-take">When to Choose Which? My Personal Take</h3> <p>After spending significant time with both, here’s my practical advice:</p> <p><strong>Choose PyTorch if:</strong></p> <ul> <li> <strong>You’re in research or rapid prototyping:</strong> The dynamic graph and Pythonic nature make it incredibly fast to experiment, debug, and iterate on new ideas.</li> <li> <strong>You value explicit control and transparency:</strong> PyTorch often feels more like “coding Python with neural networks” rather than working with an abstract framework.</li> <li> <strong>You’re comfortable with Python and NumPy:</strong> The transition will feel seamless.</li> <li> <strong>You frequently deal with variable-length inputs or dynamic network architectures</strong> (common in NLP or certain computer vision tasks).</li> </ul> <p><strong>Choose TensorFlow (especially TF 2.x) if:</strong></p> <ul> <li> <strong>You’re building large-scale, production-ready applications:</strong> Its robust deployment ecosystem (TensorFlow Serving, TFLite, TF.js) is unparalleled.</li> <li> <strong>You need comprehensive MLOps (Machine Learning Operations) support:</strong> TensorFlow Extended (TFX) provides tools for the entire ML lifecycle, from data validation to model monitoring.</li> <li> <strong>You prefer a high-level API like Keras for quicker development:</strong> Keras makes it incredibly easy to get started and build complex models with minimal code.</li> <li> <strong>You’re already embedded in the Google Cloud ecosystem:</strong> TensorFlow integrates seamlessly with GCP services.</li> </ul> <h3 id="conclusion-its-not-a-zero-sum-game">Conclusion: It’s Not a Zero-Sum Game</h3> <p>The “PyTorch vs. TensorFlow” debate has largely softened over the years, especially with TensorFlow 2.x adopting eager execution. Both are incredibly powerful, mature, and well-supported deep learning frameworks. My journey has taught me that <strong>the core concepts of deep learning (neural networks, backpropagation, optimization) are far more important than the specific framework you use.</strong> Learning one will make learning the other significantly easier.</p> <p>My advice? Pick the one that feels more comfortable for your current project or learning style. Start building things! Don’t get stuck in analysis paralysis. If you’re a student or just starting, perhaps PyTorch’s directness might appeal. If you’re aiming for a role in a large tech company, TensorFlow’s production readiness might be a bigger draw.</p> <p>Ultimately, the best framework is the one that helps you build, learn, and deploy your amazing AI ideas effectively. Happy coding, and may your models converge swiftly!</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/cracking-the-ai-black-box-why-explainable-ai-xai-i/">Cracking the AI Black Box: Why Explainable AI (XAI) is Our Superpower</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/the-secret-life-of-states-how-markov-chains-predic/">The Secret Life of States: How Markov Chains Predict Our Next Move (Without Remembering the Past!)</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/gradient-descent-unpacking-the-engine-of-machine-l/">Gradient Descent: Unpacking the Engine of Machine Learning</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Adarsh Nair. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/blog/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/masonry.js?v=a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/zoom.js?v=85ddb88934d28b74e78031fd54cf8308"></script> <script src="/blog/assets/js/no_defer.js?v=2781658a0a2b13ed609542042a859126"></script> <script defer src="/blog/assets/js/common.js?v=c15de51d4bb57887caa2c21988d97279"></script> <script defer src="/blog/assets/js/copy_code.js?v=c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/blog/assets/js/jupyter_new_tab.js?v=d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/blog/assets/js/mathjax-setup.js?v=a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/progress-bar.js?v=2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/blog/assets/js/vanilla-back-to-top.min.js?v=f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/blog/assets/js/search/ninja-keys.min.js?v=a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/blog/assets/js/search-setup.js?v=6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/blog/assets/js/search-data.js"></script> <script src="/blog/assets/js/shortcut-key.js?v=ccc841c459bfc0e64c1c2b5acd10df02"></script> </body> </html>