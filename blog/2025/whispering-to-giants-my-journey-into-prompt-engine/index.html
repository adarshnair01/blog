<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Whispering to Giants: My Journey into Prompt Engineering and Unlocking AI's True Potential | Adarsh Nair </title> <meta name="author" content="Adarsh Nair"> <meta name="description" content="A deep dive into machine learning, AI, and data science. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <meta http-equiv="Content-Security-Policy" content="default-src 'self'; script-src 'self' 'unsafe-inline' https:; style-src 'self' 'unsafe-inline' https:; img-src 'self' data: https:; font-src 'self' data: https:; media-src 'self' https:; frame-src 'self' https:; connect-src 'self' https:;"> <link rel="stylesheet" href="/blog/assets/css/bootstrap.min.css?v=a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/blog/assets/css/academicons.min.css?v=f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/blog/assets/css/scholar-icons.css?v=62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-github.css?v=591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/blog/assets/css/main.css?v=d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://adarshnair.online/blog/blog/blog/2025/whispering-to-giants-my-journey-into-prompt-engine/"> <script src="/blog/assets/js/theme.js?v=5fea5159b787642c1bbc1f334d60f883"></script> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-native.css?v=5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="https://adarshnair.online" rel="external nofollow noopener" target="_blank"> Adarsh Nair </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/blog/"> </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/index.html">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/cv/">CV </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="https://adarshnair.online/books/" rel="external nofollow noopener" target="_blank">books </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="fa-solid fa-magnifying-glass"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-half-sun-moon" id="light-toggle-system"></i> <i class="fa-solid fa-moon" id="light-toggle-dark"></i> <i class="fa-solid fa-sun" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Whispering to Giants: My Journey into Prompt Engineering and Unlocking AI's True Potential</h1> <p class="post-meta"> Created on July 15, 2025 by Adarsh Nair </p> <p class="post-tags"> <a href="/blog/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/blog/tag/machine-learning"> <i class="fa-solid fa-hashtag fa-sm"></i> Machine Learning</a>   <a href="/blog/blog/tag/prompt-engineering"> <i class="fa-solid fa-hashtag fa-sm"></i> Prompt Engineering</a>   <a href="/blog/blog/tag/nlp"> <i class="fa-solid fa-hashtag fa-sm"></i> NLP</a>   <a href="/blog/blog/tag/large-language-models"> <i class="fa-solid fa-hashtag fa-sm"></i> Large Language Models</a>   <a href="/blog/blog/tag/ai-ethics"> <i class="fa-solid fa-hashtag fa-sm"></i> AI Ethics</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <h3 id="the-frustration-and-the-aha-moment">The Frustration and the “Aha!” Moment</h3> <p>I remember the first time I genuinely felt both amazed and utterly frustrated by a large language model (LLM). It was early on, and I was trying to get an AI to write a short story. My initial prompt was something like, “Write a story.” Predictably, I got a generic, somewhat bland narrative. I tweaked it: “Write a sci-fi story.” Better, but still not hitting the mark. It felt like I was talking to a brilliant but slightly clueless assistant who needed <em>very</em> specific instructions.</p> <p>For a data scientist or machine learning engineer, interacting with an LLM often feels like a conversation with a black box. You feed it input, it spits out output. But what if you could peek inside that box, not to change its internal gears, but to guide its existing mechanisms more effectively? This, my friends, is where Prompt Engineering enters the scene – and it’s been one of the most exciting and empowering discoveries in my journey through AI.</p> <h3 id="what-is-prompt-engineering-anyway">What <em>Is</em> Prompt Engineering, Anyway?</h3> <p>At its core, <strong>Prompt Engineering</strong> is the discipline of designing and optimizing inputs (prompts) to effectively communicate with and guide a language model to produce desired outputs. Think of it as teaching an incredibly intelligent but alien entity to understand human intent. It’s not about coding the AI itself, but about expertly <em>interrogating</em> it.</p> <p>Why is this a big deal? Because LLMs like GPT-3, LLaMA, or Bard are powerful, but they’re also highly sensitive to the way we frame our questions and instructions. A slight change in wording, the addition of an example, or a specific structural request can completely transform the quality and relevance of the output. It’s less about finding the “magic words” and more about understanding the model’s internal logic and how to align its vast knowledge base with your specific task.</p> <h3 id="the-anatomy-of-a-powerful-prompt">The Anatomy of a Powerful Prompt</h3> <p>So, how do we craft these powerful prompts? It begins with understanding the core components that make a prompt effective:</p> <ol> <li> <strong>Clarity and Specificity:</strong> This is paramount. Avoid ambiguity at all costs. <ul> <li> <em>Bad Prompt:</em> “Tell me about cars.” (Too broad, generic response)</li> <li> <em>Good Prompt:</em> “Explain the fundamental differences between internal combustion engines and electric vehicle powertrains, focusing on energy efficiency and environmental impact, suitable for a high school physics student.” (Clear topic, target audience, specific aspects)</li> </ul> </li> <li> <strong>Context:</strong> Give the AI the necessary background information. Don’t assume it knows what you know. <ul> <li>If you’re asking it to summarize a document, provide the document! If it’s about a specific event, briefly describe the event.</li> </ul> </li> <li> <strong>Role-Playing (Persona):</strong> Often, telling the AI <em>who</em> it is can drastically change the tone, style, and content of its response. <ul> <li>“You are a seasoned history professor specializing in the Roman Empire.”</li> <li>“Act as a witty marketing copywriter.”</li> <li>“You are a Python expert explaining object-oriented programming to a beginner.”</li> </ul> </li> <li> <strong>Format:</strong> Specify the desired output structure. Do you want a list, a JSON object, an essay, code, or a table? <ul> <li>“Output your answer as a JSON object with keys <code class="language-plaintext highlighter-rouge">topic</code>, <code class="language-plaintext highlighter-rouge">summary</code>, and <code class="language-plaintext highlighter-rouge">keywords</code>.”</li> <li>“Provide your response as a bulleted list.”</li> </ul> </li> <li> <strong>Constraints:</strong> Set boundaries. This includes length, tone, style, or even forbidden words. <ul> <li>“Keep the response under 200 words.”</li> <li>“Maintain a formal and objective tone.”</li> <li>“Do not use jargon.”</li> </ul> </li> </ol> <h3 id="core-prompt-engineering-techniques-my-toolkit">Core Prompt Engineering Techniques: My Toolkit</h3> <p>Beyond the basics, several established techniques have emerged to unlock even more sophisticated AI behaviors. These are the tools that have truly transformed my interactions with LLMs.</p> <h4 id="1-zero-shot-one-shot-and-few-shot-prompting">1. Zero-shot, One-shot, and Few-shot Prompting</h4> <p>This refers to how many examples you give the model:</p> <ul> <li> <strong>Zero-shot prompting:</strong> You provide no examples. The model generates a response based solely on its pre-trained knowledge. <ul> <li> <em>Prompt:</em> “Translate ‘Hello, how are you?’ into French.”</li> <li> <em>Output:</em> “Bonjour, comment allez-vous ?”</li> </ul> </li> <li> <strong>Few-shot prompting:</strong> You provide one or more examples of the desired input-output pair. This is incredibly powerful as it helps the model identify the <em>pattern</em> you want it to follow. <ul> <li>Imagine you want to classify text sentiment.</li> <li> <em>Prompt:</em> <div class="language-plaintext highlighter-rouge"> <div class="highlight"><pre class="highlight"><code>Text: "I loved that movie!"
Sentiment: Positive
###
Text: "This is terrible service."
Sentiment: Negative
###
Text: "The weather is okay today."
Sentiment: Neutral
###
Text: "The food was absolutely divine and service impeccable."
Sentiment:
</code></pre></div> </div> </li> <li> <table> <tbody> <tr> <td>The model, by seeing the examples, learns to extract the sentiment and provide a consistent label. Mathematically, you’re guiding the model to calculate the probability of the output ($O$) given the input ($I$) and the provided examples ($E_1, …, E_k$): $ P(O</td> <td>I, E_1, …, E_k) $.</td> </tr> </tbody> </table> </li> </ul> </li> </ul> <h4 id="2-chain-of-thought-cot-prompting">2. Chain-of-Thought (CoT) Prompting</h4> <p>This technique, often as simple as adding “Let’s think step by step,” revolutionized how LLMs handle complex reasoning tasks. Instead of asking the model for a direct answer, you prompt it to break down the problem and show its reasoning.</p> <ul> <li> <em>Scenario:</em> A word problem that requires multiple logical steps.</li> <li> <em>Bad Prompt:</em> “If a baker has 12 apples and uses 3 for a pie, then buys 5 more, how many apples does he have?”</li> <li> <em>CoT Prompt:</em> “If a baker has 12 apples and uses 3 for a pie, then buys 5 more, how many apples does he have? <strong>Let’s think step by step.</strong>”</li> </ul> <table> <tbody> <tr> <td>The “Let’s think step by step” phrase encourages the model to generate intermediate reasoning steps, which often leads to a more accurate final answer. It effectively transforms the problem from a single-step inference to a multi-step logical deduction. The probability of the output now depends on these intermediate thoughts ($T_1, …, T_m$): $ P(O</td> <td>I, T_1, …, T_m) $.</td> </tr> </tbody> </table> <p><em>Why it works:</em> LLMs are auto-regressive, meaning they predict the next word based on previous ones. By explicitly asking for intermediate steps, we guide the model to generate a sequence of thoughts that make its reasoning explicit, reducing the chance of errors and improving coherence.</p> <h4 id="3-self-consistency-and-generated-knowledge">3. Self-Consistency and Generated Knowledge</h4> <p>Building on CoT, <strong>Self-Consistency</strong> takes it a step further. Instead of just one CoT path, you prompt the model to generate <em>multiple</em> independent CoT paths and then aggregate them (e.g., by taking the majority vote or the most coherent explanation) to arrive at a more robust answer. This is like asking several experts for their step-by-step solutions and then combining their insights.</p> <p><strong>Generated Knowledge</strong> is another powerful technique. Before asking the model to answer a question, you first ask it to generate relevant facts or background knowledge related to the question. Then, you use <em>that generated knowledge</em> as context for the original question.</p> <ul> <li> <em>Prompt 1 (Generate Knowledge):</em> “What are the key geological processes that form mountain ranges?”</li> <li> <em>Model’s Output (Knowledge):</em> “Mountain ranges are primarily formed through tectonic plate collisions, faulting, and volcanism…”</li> <li> <em>Prompt 2 (Answer using Knowledge):</em> “Using the information above, explain how the Himalayas were formed, focusing on the specific geological processes involved.”</li> </ul> <p>This prevents the model from “hallucinating” or making assumptions by grounding its answer in self-generated, relevant facts.</p> <h3 id="advanced-considerations-the-nuances-of-control">Advanced Considerations: The Nuances of Control</h3> <p>As I delved deeper, I realized prompt engineering wasn’t just about the words I typed, but also about the underlying parameters that control the model’s behavior:</p> <ul> <li> <p><strong>Temperature ($T$):</strong> This parameter controls the randomness of the output. A higher temperature (e.g., $T=0.8$) makes the output more creative, diverse, and sometimes surprising, by increasing the probability of less likely words. A lower temperature (e.g., $T=0.2$) makes the output more deterministic and focused, sticking to the most probable words. For creative writing, higher $T$ is good; for factual summaries, lower $T$ is preferred.</p> </li> <li> <p><strong>Top-p (Nucleus Sampling):</strong> This parameter also influences randomness, but in a different way. Instead of globally increasing all probabilities like temperature, Top-p considers only the most probable words whose cumulative probability exceeds a certain threshold (e.g., $p=0.9$). This allows for diverse output while still maintaining coherence.</p> </li> <li> <p><strong>Token Limits:</strong> LLMs have a finite context window (the maximum number of words/tokens they can process at once). Understanding and managing this limit is crucial for longer tasks, often requiring techniques like summarization or breaking down tasks into smaller chunks.</p> </li> <li> <p><strong>Bias and Ethics:</strong> This is a critical point. Prompts can inadvertently (or intentionally) elicit biased or harmful responses if not carefully crafted. As prompt engineers, we have a responsibility to design prompts that promote fairness, accuracy, and ethical AI interactions. We must be mindful of the data the models were trained on and how our prompts might exacerbate existing biases. For instance, role-playing as a “doctor” without specifying gender can sometimes default to male pronouns if the training data was skewed. Explicitly stating “You are a doctor, she explains…” can mitigate this.</p> </li> </ul> <h3 id="my-toolkit--the-iterative-dance">My Toolkit &amp; The Iterative Dance</h3> <p>My personal approach to prompt engineering has become an iterative cycle:</p> <ol> <li> <strong>Define the Goal:</strong> What exactly do I want the AI to do?</li> <li> <strong>Draft Initial Prompt:</strong> Start with clarity, context, and perhaps a persona.</li> <li> <strong>Test and Evaluate:</strong> Run the prompt, analyze the output.</li> <li> <strong>Identify Gaps/Errors:</strong> Where did it go wrong? Was it vague? Did it miss a constraint?</li> <li> <strong>Refine and Iterate:</strong> Apply prompt engineering techniques (add few-shot examples, insert “think step by step,” adjust temperature, clarify instructions).</li> <li> <strong>Repeat:</strong> Keep refining until the desired quality is achieved.</li> </ol> <p>I’ve even started using version control for my more complex prompts, treating them almost like code snippets. Markdown files with clearly documented prompt versions, expected outputs, and parameters have become invaluable.</p> <h3 id="conclusion-the-art-science-and-responsibility">Conclusion: The Art, Science, and Responsibility</h3> <p>Prompt Engineering is more than just a trick; it’s a rapidly evolving field at the intersection of human language, cognitive science, and machine learning. It’s the skill that bridges the gap between raw AI power and practical, valuable applications.</p> <p>For anyone in data science or machine learning, understanding prompt engineering isn’t just an advantage – it’s becoming a necessity. It empowers us to wield these powerful new tools with precision, unlocking their potential in everything from data analysis and code generation to creative content creation and complex problem-solving.</p> <p>My journey from frustrated AI user to an intentional prompt engineer has been incredibly rewarding. It’s transformed my perception of LLMs from mysterious black boxes into collaborative partners. It’s a blend of art and science, requiring creativity, logical thinking, and a willingness to experiment. As AI continues to advance, the ability to communicate effectively with these digital giants will only become more crucial. So go forth, experiment, iterate, and discover the magic words for yourself!</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/cracking-the-ai-black-box-why-explainable-ai-xai-i/">Cracking the AI Black Box: Why Explainable AI (XAI) is Our Superpower</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/the-secret-life-of-states-how-markov-chains-predic/">The Secret Life of States: How Markov Chains Predict Our Next Move (Without Remembering the Past!)</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/gradient-descent-unpacking-the-engine-of-machine-l/">Gradient Descent: Unpacking the Engine of Machine Learning</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Adarsh Nair. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/blog/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/masonry.js?v=a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/zoom.js?v=85ddb88934d28b74e78031fd54cf8308"></script> <script src="/blog/assets/js/no_defer.js?v=2781658a0a2b13ed609542042a859126"></script> <script defer src="/blog/assets/js/common.js?v=c15de51d4bb57887caa2c21988d97279"></script> <script defer src="/blog/assets/js/copy_code.js?v=c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/blog/assets/js/jupyter_new_tab.js?v=d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/blog/assets/js/mathjax-setup.js?v=a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/progress-bar.js?v=2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/blog/assets/js/vanilla-back-to-top.min.js?v=f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/blog/assets/js/search/ninja-keys.min.js?v=a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/blog/assets/js/search-setup.js?v=6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/blog/assets/js/search-data.js"></script> <script src="/blog/assets/js/shortcut-key.js?v=ccc841c459bfc0e64c1c2b5acd10df02"></script> </body> </html>