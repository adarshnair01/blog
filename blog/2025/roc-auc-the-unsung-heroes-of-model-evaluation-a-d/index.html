<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> ROC &amp; AUC: The Unsung Heroes of Model Evaluation (A Deep Dive for Data Scientists) | Adarsh Nair </title> <meta name="author" content="Adarsh Nair"> <meta name="description" content="A deep dive into machine learning, AI, and data science. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <meta http-equiv="Content-Security-Policy" content="default-src 'self'; script-src 'self' 'unsafe-inline' https:; style-src 'self' 'unsafe-inline' https:; img-src 'self' data: https:; font-src 'self' data: https:; media-src 'self' https:; frame-src 'self' https:; connect-src 'self' https:;"> <link rel="stylesheet" href="/blog/assets/css/bootstrap.min.css?v=a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/blog/assets/css/academicons.min.css?v=f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/blog/assets/css/scholar-icons.css?v=62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-github.css?v=591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/blog/assets/css/main.css?v=d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://adarshnair.online/blog/blog/blog/2025/roc-auc-the-unsung-heroes-of-model-evaluation-a-d/"> <script src="/blog/assets/js/theme.js?v=5fea5159b787642c1bbc1f334d60f883"></script> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-native.css?v=5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="https://adarshnair.online" rel="external nofollow noopener" target="_blank"> Adarsh Nair </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/blog/"> </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/index.html">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/cv/">CV </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/repositories/">repositories </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="fa-solid fa-magnifying-glass"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-half-sun-moon" id="light-toggle-system"></i> <i class="fa-solid fa-moon" id="light-toggle-dark"></i> <i class="fa-solid fa-sun" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">ROC &amp; AUC: The Unsung Heroes of Model Evaluation (A Deep Dive for Data Scientists)</h1> <p class="post-meta"> Created on May 04, 2025 by Adarsh Nair </p> <p class="post-tags"> <a href="/blog/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/blog/tag/machine-learning"> <i class="fa-solid fa-hashtag fa-sm"></i> Machine Learning</a>   <a href="/blog/blog/tag/classification"> <i class="fa-solid fa-hashtag fa-sm"></i> Classification</a>   <a href="/blog/blog/tag/model-evaluation"> <i class="fa-solid fa-hashtag fa-sm"></i> Model Evaluation</a>   <a href="/blog/blog/tag/roc-curve"> <i class="fa-solid fa-hashtag fa-sm"></i> ROC Curve</a>   <a href="/blog/blog/tag/auc"> <i class="fa-solid fa-hashtag fa-sm"></i> AUC</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p>Hey there, fellow data explorers!</p> <p>My journey into data science has been a wild ride, filled with “aha!” moments and the occasional head-scratching puzzle. One of the biggest revelations for me, early on, was realizing that “accuracy” isn’t always the king when it comes to evaluating classification models. In fact, relying solely on accuracy can sometimes lead you down a misleading path.</p> <p>Imagine you’re building a system to detect a rare disease. Let’s say only 1% of the population has this disease. If your model simply predicts “no disease” for everyone, it would be 99% accurate! Sounds great, right? But it missed every single person with the disease, which is disastrous. This is where the dynamic duo of ROC (Receiver Operating Characteristic) curves and AUC (Area Under the Curve) comes to the rescue. They offer a much more nuanced and powerful way to understand how well our models are truly performing.</p> <p>Let’s dive in and demystify these powerful concepts!</p> <h3 id="the-confusion-matrix-unpacking-the-right-and-wrong">The Confusion Matrix: Unpacking the “Right” and “Wrong”</h3> <p>Before we can talk about ROC and AUC, we need to understand the fundamental building blocks: the <strong>Confusion Matrix</strong>. Don’t let the name intimidate you; it’s simply a table that helps us visualize the performance of a classification algorithm.</p> <p>When our model makes a prediction for a binary classification task (like “spam” or “not spam”, “disease” or “no disease”), there are four possible outcomes:</p> <ul> <li> <strong>True Positive (TP):</strong> Our model predicted ‘Positive’, and the actual class <em>was</em> ‘Positive’. (Correctly identified spam)</li> <li> <strong>True Negative (TN):</strong> Our model predicted ‘Negative’, and the actual class <em>was</em> ‘Negative’. (Correctly identified non-spam)</li> <li> <strong>False Positive (FP):</strong> Our model predicted ‘Positive’, but the actual class <em>was</em> ‘Negative’. This is a <strong>Type I error</strong> or a “false alarm.” (A non-spam email flagged as spam)</li> <li> <strong>False Negative (FN):</strong> Our model predicted ‘Negative’, but the actual class <em>was</em> ‘Positive’. This is a <strong>Type II error</strong> or a “miss.” (A spam email slipped through to your inbox)</li> </ul> <p>It’s helpful to visualize this:</p> <table> <thead> <tr> <th style="text-align: left"> </th> <th style="text-align: left"><strong>Actual Positive</strong></th> <th style="text-align: left"><strong>Actual Negative</strong></th> </tr> </thead> <tbody> <tr> <td style="text-align: left"><strong>Pred. Positive</strong></td> <td style="text-align: left">True Positive (TP)</td> <td style="text-align: left">False Positive (FP)</td> </tr> <tr> <td style="text-align: left"><strong>Pred. Negative</strong></td> <td style="text-align: left">False Negative (FN)</td> <td style="text-align: left">True Negative (TN)</td> </tr> </tbody> </table> <p>Different scenarios prioritize different errors. For our rare disease example, a False Negative (missing a diseased person) is far worse than a False Positive (a healthy person getting a follow-up test). Conversely, if you’re screening for a very common, benign condition, you might tolerate more FNs to reduce FPs (saving resources). This trade-off is central to understanding ROC curves.</p> <h3 id="from-confusion-to-clarity-metrics-that-matter">From Confusion to Clarity: Metrics that Matter</h3> <p>With the confusion matrix in hand, we can define a few crucial metrics that directly feed into the ROC curve. These metrics help us understand different aspects of our model’s performance beyond simple accuracy:</p> <ol> <li> <p><strong>True Positive Rate (TPR)</strong> – Also known as <strong>Recall</strong> or <strong>Sensitivity</strong>: This tells us, “Out of all the actual positive cases, how many did our model correctly identify?” $TPR = \frac{TP}{TP + FN}$</p> <p>A high TPR means our model is good at catching positives. In our disease example, it means we’re successfully identifying most people who actually have the disease.</p> </li> <li> <p><strong>False Positive Rate (FPR)</strong>: This tells us, “Out of all the actual negative cases, how many did our model <em>incorrectly</em> identify as positive?” $FPR = \frac{FP}{FP + TN}$</p> <p>A low FPR means our model doesn’t cry “wolf!” too often. In the disease example, it means we’re not sending too many healthy people for unnecessary follow-up tests.</p> </li> </ol> <h3 id="the-roc-star-receiver-operating-characteristic-curve">The “ROC” Star: Receiver Operating Characteristic Curve</h3> <p>Now that we have TPR and FPR, we’re ready for the star of the show: the <strong>ROC Curve</strong>.</p> <p>Most classification models don’t just spit out a “yes” or “no.” Instead, they output a <strong>probability score</strong> (e.g., “there’s an 80% chance this email is spam”). To turn this probability into a definitive class prediction, we use a <strong>threshold</strong>.</p> <p>For example:</p> <ul> <li>If the probability &gt; 0.5, predict ‘Positive’.</li> <li>If the probability &lt;= 0.5, predict ‘Negative’.</li> </ul> <p>What if we change that threshold?</p> <ul> <li>If we set a very <em>low</em> threshold (e.g., probability &gt; 0.1), we’ll catch almost all actual positives (high TPR), but we’ll also likely have many false alarms (high FPR).</li> <li>If we set a very <em>high</em> threshold (e.g., probability &gt; 0.9), we’ll have very few false alarms (low FPR), but we might miss many actual positives (low TPR).</li> </ul> <p>The ROC curve beautifully captures this trade-off. It’s a graph that plots the <strong>True Positive Rate (TPR)</strong> on the y-axis against the <strong>False Positive Rate (FPR)</strong> on the x-axis for <em>all possible classification thresholds</em>.</p> <p><strong>How to interpret the ROC Curve:</strong></p> <ul> <li> <strong>The Ideal Scenario (Top-Left Corner):</strong> A perfect classifier would have a TPR of 1 (100% sensitivity) and an FPR of 0 (no false alarms). This point (0,1) represents perfection. The closer your curve is to this top-left corner, the better your model.</li> <li> <strong>The Diagonal Line (y=x):</strong> This line represents a completely random classifier. If your model just randomly guesses whether something is positive or negative, it would perform along this diagonal. Any model below this line is actually worse than random guessing – perhaps it’s learned the opposite pattern!</li> <li> <strong>Moving Along the Curve:</strong> Each point on the curve represents a different threshold. As you move from the bottom-left to the top-right, you’re generally lowering the classification threshold. <ul> <li>Moving right and up means accepting more false positives to catch more true positives.</li> <li>Moving left and down means reducing false positives, but potentially missing more true positives.</li> </ul> </li> </ul> <p>The ROC curve helps us choose an optimal threshold based on the specific costs of FP and FN errors in our problem. Do we prioritize catching all diseases, even if it means some false alarms (high TPR, higher FPR)? Or do we prioritize minimizing false alarms, even if it means missing a few cases (low FPR, lower TPR)? The ROC curve lets us visualize these choices.</p> <h3 id="auc-the-mighty-area-under-the-curve">“AUC” the Mighty: Area Under the Curve</h3> <p>While the ROC curve gives us a visual representation of performance across all thresholds, sometimes we need a single number to summarize our model’s overall discriminatory power. That’s where <strong>AUC</strong> comes in.</p> <p><strong>AUC stands for Area Under the [ROC] Curve.</strong> As its name suggests, it literally calculates the area underneath the ROC curve.</p> <p><strong>What does AUC tell us?</strong></p> <ul> <li> <strong>It’s a single metric (0 to 1):</strong> <ul> <li>An AUC of <strong>1.0</strong> indicates a perfect classifier (it can perfectly distinguish between positive and negative classes).</li> <li>An AUC of <strong>0.5</strong> indicates a classifier that performs no better than random guessing.</li> <li>An AUC less than 0.5 suggests a model that’s worse than random, perhaps it’s learned the inverse relationship!</li> </ul> </li> <li> <strong>Probability Interpretation:</strong> A fantastic way to understand AUC is this: It represents the <strong>probability that the classifier will rank a randomly chosen positive instance higher than a randomly chosen negative instance.</strong> <ul> <li>For example, an AUC of 0.8 means there’s an 80% chance that your model will rank a randomly selected positive example higher than a randomly selected negative example. This is a profound insight into its ability to <em>separate</em> the classes.</li> </ul> </li> </ul> <p><strong>Why is AUC so powerful, especially over simple accuracy?</strong></p> <ol> <li> <strong>Threshold-Independent:</strong> Unlike metrics that require a fixed threshold (like precision, recall, or F1-score), AUC evaluates the model’s performance across <em>all</em> possible thresholds. This gives you a holistic view of the model’s discriminatory power.</li> <li> <strong>Insensitive to Class Imbalance:</strong> Remember our rare disease example? A 99% accurate model had a catastrophic flaw. AUC would reveal this immediately. Even if one class is vastly underrepresented, AUC provides a reliable measure of how well the model distinguishes between classes, focusing on the ranking of instances rather than absolute counts at a single threshold. This is because TPR and FPR are calculated based on <em>actual</em> positives and <em>actual</em> negatives separately.</li> <li> <strong>Compares Models:</strong> When comparing different classification models, the one with the higher AUC is generally considered the better performer, assuming all other factors are equal. It helps you understand which model does a better job at distinguishing between classes across the board.</li> </ol> <h3 id="putting-it-into-practice-a-glimpse-with-python">Putting it into Practice: A Glimpse with Python</h3> <p>Modern machine learning libraries make calculating ROC and AUC incredibly straightforward. Here’s a conceptual peek using <code class="language-plaintext highlighter-rouge">scikit-learn</code>:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_curve</span><span class="p">,</span> <span class="n">roc_auc_score</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="c1"># Imagine these are your true labels (0 for negative, 1 for positive)
</span><span class="n">y_true</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>

<span class="c1"># And these are the probabilities your model predicted for each instance being positive
</span><span class="n">y_scores</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.15</span><span class="p">])</span>

<span class="c1"># Calculate the False Positive Rate (FPR), True Positive Rate (TPR),
# and the thresholds used to generate them
</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="nf">roc_curve</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_scores</span><span class="p">)</span>

<span class="c1"># Calculate the Area Under the Curve (AUC)
</span><span class="n">auc_score</span> <span class="o">=</span> <span class="nf">roc_auc_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_scores</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">AUC Score: </span><span class="si">{</span><span class="n">auc_score</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="se">\n</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># You can then plot these to visualize the ROC curve:
</span><span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">darkorange</span><span class="sh">'</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="sh">'</span><span class="s">ROC curve (AUC = </span><span class="si">{</span><span class="n">auc_score</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s">)</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">navy</span><span class="sh">'</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="sh">'</span><span class="s">--</span><span class="sh">'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">Random Classifier</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.05</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">False Positive Rate (FPR)</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">True Positive Rate (TPR)</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">Receiver Operating Characteristic (ROC) Curve</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="sh">'</span><span class="s">lower right</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">grid</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">FPR values at various thresholds:</span><span class="sh">"</span><span class="p">,</span> <span class="n">fpr</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">TPR values at various thresholds:</span><span class="sh">"</span><span class="p">,</span> <span class="n">tpr</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Thresholds used:</span><span class="sh">"</span><span class="p">,</span> <span class="n">thresholds</span><span class="p">)</span>
</code></pre></div></div> <p><em>(Note: To run the plotting code, you’d need <code class="language-plaintext highlighter-rouge">matplotlib</code> installed. The print statements will show you the raw values)</em></p> <p>In this simple example, we see how <code class="language-plaintext highlighter-rouge">roc_curve</code> provides the points needed to draw the curve, and <code class="language-plaintext highlighter-rouge">roc_auc_score</code> gives us that single, powerful summary number. My own journey through data science has shown me that being able to quickly generate and interpret these plots is invaluable for understanding and comparing models.</p> <h3 id="conclusion-your-models-true-compass">Conclusion: Your Model’s True Compass</h3> <p>The next time you’re evaluating a classification model, remember the dynamic duo of ROC and AUC. They are far more than just fancy terms; they are essential tools that provide a deeper, more robust understanding of your model’s performance than simple accuracy ever could.</p> <p>By understanding the trade-offs captured by the ROC curve and the holistic performance summarized by AUC, you’ll be equipped to make smarter decisions about which models to deploy, how to tune them, and ultimately, build more reliable and impactful AI systems. Keep exploring, keep questioning, and happy modeling!</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/cracking-the-ai-black-box-why-explainable-ai-xai-i/">Cracking the AI Black Box: Why Explainable AI (XAI) is Our Superpower</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/the-secret-life-of-states-how-markov-chains-predic/">The Secret Life of States: How Markov Chains Predict Our Next Move (Without Remembering the Past!)</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/gradient-descent-unpacking-the-engine-of-machine-l/">Gradient Descent: Unpacking the Engine of Machine Learning</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Adarsh Nair. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/blog/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/masonry.js?v=a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/zoom.js?v=85ddb88934d28b74e78031fd54cf8308"></script> <script src="/blog/assets/js/no_defer.js?v=2781658a0a2b13ed609542042a859126"></script> <script defer src="/blog/assets/js/common.js?v=c15de51d4bb57887caa2c21988d97279"></script> <script defer src="/blog/assets/js/copy_code.js?v=c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/blog/assets/js/jupyter_new_tab.js?v=d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/blog/assets/js/mathjax-setup.js?v=a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/progress-bar.js?v=2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/blog/assets/js/vanilla-back-to-top.min.js?v=f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/blog/assets/js/search/ninja-keys.min.js?v=a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/blog/assets/js/search-setup.js?v=6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/blog/assets/js/search-data.js"></script> <script src="/blog/assets/js/shortcut-key.js?v=ccc841c459bfc0e64c1c2b5acd10df02"></script> </body> </html>