<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Whispering to Giants: My Deep Dive into the Art and Science of Prompt Engineering | Adarsh Nair </title> <meta name="author" content="Adarsh Nair"> <meta name="description" content="A deep dive into machine learning, AI, and data science. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <meta http-equiv="Content-Security-Policy" content="default-src 'self'; script-src 'self' 'unsafe-inline' https:; style-src 'self' 'unsafe-inline' https:; img-src 'self' data: https:; font-src 'self' data: https:; media-src 'self' https:; frame-src 'self' https:; connect-src 'self' https:;"> <link rel="stylesheet" href="/blog/assets/css/bootstrap.min.css?v=a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/blog/assets/css/academicons.min.css?v=f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/blog/assets/css/scholar-icons.css?v=62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-github.css?v=591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/blog/assets/css/main.css?v=d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://adarshnair.online/blog/blog/blog/2025/whispering-to-giants-my-deep-dive-into-the-art-and/"> <script src="/blog/assets/js/theme.js?v=5fea5159b787642c1bbc1f334d60f883"></script> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-native.css?v=5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="https://adarshnair.online" rel="external nofollow noopener" target="_blank"> Adarsh Nair </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/blog/"> </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/index.html">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/cv/">CV </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/repositories/">repositories </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="fa-solid fa-magnifying-glass"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-half-sun-moon" id="light-toggle-system"></i> <i class="fa-solid fa-moon" id="light-toggle-dark"></i> <i class="fa-solid fa-sun" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Whispering to Giants: My Deep Dive into the Art and Science of Prompt Engineering</h1> <p class="post-meta"> Created on October 22, 2025 by Adarsh Nair </p> <p class="post-tags"> <a href="/blog/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/blog/tag/prompt-engineering"> <i class="fa-solid fa-hashtag fa-sm"></i> Prompt Engineering</a>   <a href="/blog/blog/tag/llms"> <i class="fa-solid fa-hashtag fa-sm"></i> LLMs</a>   <a href="/blog/blog/tag/nlp"> <i class="fa-solid fa-hashtag fa-sm"></i> NLP</a>   <a href="/blog/blog/tag/ai"> <i class="fa-solid fa-hashtag fa-sm"></i> AI</a>   <a href="/blog/blog/tag/data-science"> <i class="fa-solid fa-hashtag fa-sm"></i> Data Science</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p>Hello fellow explorers of the digital frontier!</p> <p>Lately, my data science journey has taken an exciting turn into the realm of Large Language Models (LLMs). It’s like discovering a new continent, filled with powerful, albeit sometimes mysterious, intelligent beings. You see, these LLMs – models like GPT-3, LLaMA, or Bard – are astonishingly good at understanding and generating human-like text. They can write code, summarize books, answer complex questions, and even compose poetry. But here’s the kicker: their raw power is just that, raw. To truly harness it, to make these digital giants perform intricate, specific tasks, you need to know how to talk to them.</p> <p>And that, my friends, is where <strong>Prompt Engineering</strong> enters the scene.</p> <h3 id="what-is-prompt-engineering-the-art-of-precise-conversations">What is Prompt Engineering? The Art of Precise Conversations</h3> <p>Imagine you have a super-smart genie. This genie can grant almost any wish, but it’s incredibly literal. If you just say, “I want to be rich,” it might drop a single gold coin at your feet and disappear. To get what you <em>really</em> want, you need to be incredibly precise: “Genie, I wish for a sustainable, diversified investment portfolio that generates passive income of at least $10,000 per month, growing at an average of 5% annually, tax-free, for the rest of my life, without any negative impact on anyone.” Okay, maybe that’s a bit much for a genie, but you get the idea!</p> <p>Prompt engineering is precisely that: the art and science of designing, refining, and optimizing inputs (prompts) for LLMs to achieve desired outputs. It’s about bridging the gap between human intent and AI capability. It’s not just about asking a question; it’s about framing the question, providing context, setting the stage, and guiding the model towards the answer you need, not just <em>an</em> answer.</p> <p>For me, it’s been a game-changer. I used to get frustrated when an LLM would give generic responses. Now, with a bit of prompt engineering magic, I can elicit highly specific, nuanced, and incredibly useful information, making my data science workflows significantly more efficient.</p> <h3 id="deconstructing-a-prompt-the-essential-elements">Deconstructing a Prompt: The Essential Elements</h3> <p>Before we dive into techniques, let’s understand what makes a “good” prompt. Think of it as constructing a clear set of instructions for a very intelligent, but ultimately, literal, intern.</p> <ol> <li> <strong>Instruction:</strong> What do you want the model to do? This is the core command. <ul> <li> <em>Example:</em> <code class="language-plaintext highlighter-rouge">Summarize the following article.</code> </li> </ul> </li> <li> <strong>Context:</strong> What background information does the model need to understand the task or the input? <ul> <li> <em>Example:</em> <code class="language-plaintext highlighter-rouge">The article is about renewable energy trends in Europe.</code> </li> </ul> </li> <li> <strong>Input Data:</strong> The specific text, code, or data the model should process. <ul> <li> <em>Example:</em> <code class="language-plaintext highlighter-rouge">[Paste entire article here]</code> </li> </ul> </li> <li> <strong>Output Format:</strong> How do you want the answer structured? This is crucial for consistent and machine-readable outputs. <ul> <li> <em>Example:</em> <code class="language-plaintext highlighter-rouge">Provide the summary in three bullet points, each no longer than 20 words.</code> </li> </ul> </li> </ol> <p>Let’s look at a simple example:</p> <p><strong>Bad Prompt:</strong> <code class="language-plaintext highlighter-rouge">Write about climate change.</code> <em>Result: A generic essay about climate change, probably not what you needed.</em></p> <p><strong>Good Prompt:</strong> <code class="language-plaintext highlighter-rouge">You are an environmental policy analyst writing a concise brief for a government official. Your task is to summarize the economic impacts of rising sea levels on coastal cities in the next 30 years. Focus specifically on infrastructure damage and population displacement. The summary should be no more than 150 words and presented as a bulleted list.</code> <em>Result: A focused, actionable summary tailored to a specific audience and format.</em></p> <p>Notice how the “Good Prompt” assigns a <strong>persona</strong> (environmental policy analyst), specifies the <strong>task</strong> (summarize economic impacts), adds <strong>context</strong> (rising sea levels, coastal cities, next 30 years), highlights <strong>key areas</strong> (infrastructure damage, population displacement), and dictates the <strong>output format and length</strong>. This level of detail empowers the LLM to deliver exactly what you’re looking for.</p> <h3 id="my-toolkit-core-prompting-techniques-i-rely-on">My Toolkit: Core Prompting Techniques I Rely On</h3> <p>Now, let’s explore some of the most powerful prompt engineering techniques that have become staples in my daily work.</p> <h4 id="1-zero-shot-prompting-just-ask">1. Zero-shot Prompting: Just Ask!</h4> <p>This is the simplest form. You just give the instruction, and the model attempts to complete it without any prior examples. It relies purely on the knowledge it gained during its training.</p> <ul> <li> <strong>When to use:</strong> For straightforward tasks where the model’s general knowledge is sufficient.</li> <li> <strong>Example:</strong> <code class="language-plaintext highlighter-rouge">Translate the following English sentence to French: "The quick brown fox jumps over the lazy dog."</code> </li> </ul> <p>While easy, zero-shot can be unreliable for more complex or nuanced tasks, often leading to generic or even incorrect responses.</p> <h4 id="2-few-shot-prompting-show-dont-just-tell">2. Few-shot Prompting: Show, Don’t Just Tell</h4> <p>This technique is a game-changer for consistency. You provide the model with a few examples of input-output pairs that demonstrate the desired behavior <em>before</em> giving it the actual task.</p> <ul> <li> <strong>Why it’s powerful:</strong> It helps the model “learn” the pattern, style, or specific constraints you want it to follow, even if those weren’t explicitly detailed in the instruction. It’s like showing a child how to tie their shoelaces a few times before asking them to do it themselves.</li> <li> <p><strong>Example (Sentiment Analysis):</strong></p> <div class="language-plaintext highlighter-rouge"> <div class="highlight"><pre class="highlight"><code>Review: "This movie was absolutely fantastic, a real masterpiece!"
Sentiment: Positive

Review: "I regret spending my money on this, it was utterly boring."
Sentiment: Negative

Review: "The plot was okay, but the acting felt a bit wooden."
Sentiment: Neutral

Review: "What an incredible performance by the lead actor, truly captivating!"
Sentiment:
</code></pre></div> </div> <p>The model will likely infer “Positive” for the last review, having understood the pattern from the examples.</p> </li> </ul> <table> <tbody> <tr> <td>Mathematically, you can think of it as the model learning a distribution $P(\text{output}</td> <td>\text{input}, \text{example}_1, \text{example}_2, …, \text{example}_n)$, where the examples condition its understanding for the current input. The quality and diversity of your examples significantly impact the performance.</td> </tr> </tbody> </table> <h4 id="3-chain-of-thought-cot-prompting-show-your-work">3. Chain-of-Thought (CoT) Prompting: “Show Your Work”</h4> <p>This is perhaps one of the most exciting breakthroughs in prompting for complex reasoning tasks. Instead of just asking for a direct answer, you prompt the model to <em>think step-by-step</em> or provide its reasoning process.</p> <ul> <li> <strong>Why it’s powerful:</strong> It forces the model to break down complex problems into smaller, manageable steps, dramatically improving its ability to solve multi-step reasoning, arithmetic, and symbolic tasks. It’s akin to how we’re taught in school to “show all your steps” when solving a math problem.</li> <li> <strong>Example (without CoT):</strong> <code class="language-plaintext highlighter-rouge">If John has 5 apples, gives 2 to Sarah, and then buys 3 more, how many apples does John have now?</code> <ul> <li> <em>Result:</em> Often, LLMs might struggle with the sequence or make small arithmetic errors.</li> </ul> </li> <li> <p><strong>Example (with CoT):</strong></p> <div class="language-plaintext highlighter-rouge"> <div class="highlight"><pre class="highlight"><code>Question: If John has 5 apples, gives 2 to Sarah, and then buys 3 more, how many apples does John have now?

Let's think step by step:
1. John starts with 5 apples.
2. He gives 2 apples to Sarah. So, 5 - 2 = 3 apples.
3. He then buys 3 more apples. So, 3 + 3 = 6 apples.

Final Answer: John has 6 apples.
</code></pre></div> </div> <table> <tbody> <tr> <td>By providing the “Let’s think step by step” phrase, or even a few examples where the reasoning process is shown, the model learns to generate its own reasoning, leading to far more accurate results. This nudges the model to calculate $P(\text{step}_1, \text{step}_2, …, \text{step}_n, \text{final_answer}</td> <td>\text{prompt})$ rather than just $P(\text{final_answer}</td> <td>\text{prompt})$.</td> </tr> </tbody> </table> </li> </ul> <h4 id="4-role-prompting-assuming-a-persona">4. Role Prompting: Assuming a Persona</h4> <p>Assigning a specific role or persona to the LLM can significantly influence its tone, style, and the kind of information it emphasizes.</p> <ul> <li> <strong>When to use:</strong> When you need output from a particular perspective or expertise.</li> <li> <strong>Example:</strong> <code class="language-plaintext highlighter-rouge">Act as a senior data scientist explaining the concept of 'bias-variance tradeoff' to a high school student. Use clear analogies and avoid overly technical jargon.</code> </li> </ul> <p>This makes the LLM adopt the persona, making the output more relevant and easier to understand for the target audience.</p> <h3 id="the-hyperparameters-tweaking-the-ais-personality">The Hyperparameters: Tweaking the AI’s Personality</h3> <p>Beyond crafting the text of the prompt, we also have control over certain “hyperparameters” that influence the model’s output. Think of these as dials that control the AI’s creativity and focus.</p> <ul> <li> <strong>Temperature:</strong> This controls the randomness of the output. <ul> <li>A <code class="language-plaintext highlighter-rouge">temperature</code> of 0 makes the model highly deterministic, often choosing the most probable next word. Great for factual recall, coding, or summaries where consistency is key.</li> <li>A <code class="language-plaintext highlighter-rouge">temperature</code> closer to 1 makes the model more “creative” or “exploratory,” leading to more diverse and sometimes surprising outputs. Useful for brainstorming, creative writing, or generating variations.</li> </ul> </li> <li> <strong>Top-p (Nucleus Sampling):</strong> This is another way to control randomness, often used in conjunction with (or instead of) temperature. <ul> <li> <code class="language-plaintext highlighter-rouge">Top-p</code> sets a threshold for probability mass. The model only considers tokens (words/parts of words) whose cumulative probability sums up to <code class="language-plaintext highlighter-rouge">top-p</code>.</li> <li>If <code class="language-plaintext highlighter-rouge">top-p = 0.9</code>, the model considers the smallest set of most likely tokens whose combined probability is 90%. This can prevent truly bizarre outputs while still allowing for some creativity.</li> </ul> </li> </ul> <p>Understanding and adjusting these parameters is crucial for fine-tuning the model’s behavior to your specific task.</p> <h3 id="why-prompt-engineering-is-a-data-scientists-superpower">Why Prompt Engineering is a Data Scientist’s Superpower</h3> <p>In my opinion, prompt engineering is becoming an indispensable skill for any data scientist or machine learning engineer today. Here’s why:</p> <ol> <li> <strong>Rapid Prototyping:</strong> Instead of spending days or weeks training a custom model for a new NLP task, I can often achieve surprisingly good results with clever prompting, allowing for quick validation of ideas.</li> <li> <strong>Unlocking Insights:</strong> LLMs can process vast amounts of unstructured text. With good prompts, I can quickly extract specific entities, summarize research papers, categorize customer feedback, or identify trends that would otherwise require complex parsing scripts.</li> <li> <strong>Enhanced Productivity:</strong> Automating repetitive text-based tasks, generating boilerplate code, or even debugging existing code snippets becomes incredibly efficient when you know how to instruct an LLM properly.</li> <li> <strong>Reducing Fine-tuning Needs:</strong> For many domain-specific tasks, a well-engineered prompt can sometimes negate the need for expensive and data-intensive fine-tuning of an LLM, saving significant computational resources and time.</li> <li> <strong>Becoming a Better Communicator:</strong> The discipline of prompt engineering forces you to articulate your needs clearly and precisely, a skill that translates beautifully to all aspects of data science and beyond.</li> </ol> <h3 id="challenges-and-ethical-considerations">Challenges and Ethical Considerations</h3> <p>Of course, it’s not all sunshine and rainbows. Prompt engineering also comes with its own set of challenges:</p> <ul> <li> <strong>Bias Amplification:</strong> LLMs are trained on vast datasets that often reflect societal biases. If not carefully prompted, they can perpetuate or even amplify these biases in their outputs.</li> <li> <strong>Hallucinations:</strong> LLMs can confidently generate information that sounds plausible but is entirely false. Prompt engineering techniques like CoT or Retrieval Augmented Generation (RAG – where the model retrieves information from a trusted knowledge base <em>before</em> generating an answer) help mitigate this.</li> <li> <strong>Prompt Injection Attacks:</strong> Malicious users can craft prompts that hijack the LLM’s intended behavior, potentially making it reveal sensitive information, generate harmful content, or ignore safety guidelines. This is a significant security concern for applications built on LLMs.</li> <li> <strong>Evolving Field:</strong> Prompt engineering is constantly evolving. What works today might be suboptimal tomorrow as models improve and new techniques emerge.</li> </ul> <h3 id="my-call-to-action-start-experimenting">My Call to Action: Start Experimenting!</h3> <p>If you’re fascinated by AI and keen to add a powerful skill to your data science toolkit, I urge you to start experimenting with prompt engineering. Grab access to an LLM API (like OpenAI’s GPT models or Google’s PaLM/Gemini) or even use readily available open-source models. Play with different instructions, try few-shot examples, and always ask the model to “think step by step.”</p> <p>It’s an incredibly empowering feeling to guide these intelligent systems towards truly useful outcomes. The future of human-AI collaboration hinges on our ability to communicate effectively with these digital minds, and prompt engineering is our Rosetta Stone.</p> <p>Happy prompting!</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/cracking-the-ai-black-box-why-explainable-ai-xai-i/">Cracking the AI Black Box: Why Explainable AI (XAI) is Our Superpower</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/the-secret-life-of-states-how-markov-chains-predic/">The Secret Life of States: How Markov Chains Predict Our Next Move (Without Remembering the Past!)</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/gradient-descent-unpacking-the-engine-of-machine-l/">Gradient Descent: Unpacking the Engine of Machine Learning</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Adarsh Nair. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/blog/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/masonry.js?v=a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/zoom.js?v=85ddb88934d28b74e78031fd54cf8308"></script> <script src="/blog/assets/js/no_defer.js?v=2781658a0a2b13ed609542042a859126"></script> <script defer src="/blog/assets/js/common.js?v=c15de51d4bb57887caa2c21988d97279"></script> <script defer src="/blog/assets/js/copy_code.js?v=c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/blog/assets/js/jupyter_new_tab.js?v=d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/blog/assets/js/mathjax-setup.js?v=a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/progress-bar.js?v=2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/blog/assets/js/vanilla-back-to-top.min.js?v=f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/blog/assets/js/search/ninja-keys.min.js?v=a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/blog/assets/js/search-setup.js?v=6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/blog/assets/js/search-data.js"></script> <script src="/blog/assets/js/shortcut-key.js?v=ccc841c459bfc0e64c1c2b5acd10df02"></script> </body> </html>