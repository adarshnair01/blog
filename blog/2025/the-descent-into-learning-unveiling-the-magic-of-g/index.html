<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> The Descent into Learning: Unveiling the Magic of Gradient Descent | Adarsh Nair </title> <meta name="author" content="Adarsh Nair"> <meta name="description" content="A deep dive into machine learning, AI, and data science. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <meta http-equiv="Content-Security-Policy" content="default-src 'self'; script-src 'self' 'unsafe-inline' https:; style-src 'self' 'unsafe-inline' https:; img-src 'self' data: https:; font-src 'self' data: https:; media-src 'self' https:; frame-src 'self' https:; connect-src 'self' https:;"> <link rel="stylesheet" href="/blog/assets/css/bootstrap.min.css?v=a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/blog/assets/css/academicons.min.css?v=f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/blog/assets/css/scholar-icons.css?v=62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-github.css?v=591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/blog/assets/css/main.css?v=d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://adarshnair.online/blog/blog/blog/2025/the-descent-into-learning-unveiling-the-magic-of-g/"> <script src="/blog/assets/js/theme.js?v=5fea5159b787642c1bbc1f334d60f883"></script> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-native.css?v=5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="https://adarshnair.online" rel="external nofollow noopener" target="_blank"> Adarsh Nair </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/blog/"> </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/index.html">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/cv/">CV </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/repositories/">repositories </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="fa-solid fa-magnifying-glass"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-half-sun-moon" id="light-toggle-system"></i> <i class="fa-solid fa-moon" id="light-toggle-dark"></i> <i class="fa-solid fa-sun" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">The Descent into Learning: Unveiling the Magic of Gradient Descent</h1> <p class="post-meta"> Created on January 27, 2025 by Adarsh Nair </p> <p class="post-tags"> <a href="/blog/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/blog/tag/machine-learning"> <i class="fa-solid fa-hashtag fa-sm"></i> Machine Learning</a>   <a href="/blog/blog/tag/optimization"> <i class="fa-solid fa-hashtag fa-sm"></i> Optimization</a>   <a href="/blog/blog/tag/gradient-descent"> <i class="fa-solid fa-hashtag fa-sm"></i> Gradient Descent</a>   <a href="/blog/blog/tag/deep-learning"> <i class="fa-solid fa-hashtag fa-sm"></i> Deep Learning</a>   <a href="/blog/blog/tag/algorithms"> <i class="fa-solid fa-hashtag fa-sm"></i> Algorithms</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p>My journey into data science often feels like exploring a vast, exciting wilderness. There are towering peaks of complex models and deep valleys of intricate data. And amidst it all, one fundamental concept keeps resurfacing, a guiding compass without which most of our modern machine learning wouldn’t be possible: <strong>Gradient Descent</strong>.</p> <p>I remember the first time I encountered it. The name itself sounded intimidating, conjuring images of abstract calculus and complex equations. But as I peeled back the layers, I discovered an algorithm of profound simplicity and power. It’s essentially how our models learn to “get better” at their tasks, whether it’s predicting house prices or distinguishing cats from dogs.</p> <p>So, let’s embark on this adventure together and demystify Gradient Descent, making it as clear and engaging as a good story.</p> <h3 id="the-quest-finding-the-best-fit">The Quest: Finding the “Best Fit”</h3> <p>Imagine you’re trying to draw a line that best represents a set of data points on a graph. Perhaps these points show how much people study versus their exam scores. You want a line that minimizes the total “error” between the line and each point. This “error” is what we call a <strong>loss function</strong> or <strong>cost function</strong> in machine learning.</p> <p>Our goal is simple: find the parameters (like the slope and y-intercept of our line) that make this loss function as small as possible. Think of it like this: the lower the loss, the better our model fits the data.</p> <p>Now, imagine this loss function as a landscape. For a simple model, it might look like a smooth bowl or a valley. Our job is to find the lowest point in that valley. Easy, right? If you can see the whole landscape, you just walk to the bottom.</p> <p>But here’s the catch: in high-dimensional machine learning problems, our “landscape” can have thousands, even millions, of dimensions. We can’t “see” the whole thing. It’s like being blindfolded and dropped onto a mountain range, tasked with finding the absolute lowest point. How would you do it?</p> <h3 id="the-intuition-taking-steps-downhill">The Intuition: Taking Steps Downhill</h3> <p>If you’re blindfolded on a mountain and want to reach a valley, what’s your most sensible strategy? You’d probably feel around your immediate surroundings, figure out which direction goes <em>downhill</em> the steepest, and then take a small step in that direction. You’d repeat this process: feel, step, feel, step… eventually, you’d reach a low point.</p> <p>This, my friends, is the core intuition behind Gradient Descent!</p> <ul> <li> <strong>“Feeling around your immediate surroundings”</strong> translates to calculating the <strong>gradient</strong> of our loss function. The gradient tells us the direction of the steepest <em>ascent</em> (uphill).</li> <li> <strong>“Taking a small step in that direction”</strong> means updating our model’s parameters. Since we want to go <em>downhill</em>, we move in the <em>opposite</em> direction of the gradient.</li> </ul> <p>This iterative process of calculating the gradient and taking a step in the opposite direction is what allows our models to descend the “loss landscape” towards a minimum.</p> <h3 id="the-math-unpacking-the-descent">The Math: Unpacking the “Descent”</h3> <p>Let’s formalize this intuition with a bit of math. Don’t worry, we’ll keep it as clear as possible.</p> <p>Let’s say our model has parameters, which we can represent as a vector $\theta$ (pronounced “theta”). For our simple line, $\theta$ might contain the slope and the y-intercept.</p> <p>Our goal is to minimize a loss function, $J(\theta)$, which measures how “wrong” our model is for a given set of parameters $\theta$.</p> <p>The core update rule for Gradient Descent looks like this:</p> \[\theta*{new} = \theta*{old} - \alpha \nabla J(\theta\_{old})\] <p>Let’s break down each piece:</p> <ol> <li> <strong>$\theta_{new}$</strong>: These are the updated parameters, the result of our “step.”</li> <li> <strong>$\theta_{old}$</strong>: These are our current parameters, where we are on the mountain.</li> <li> <strong>$\alpha$ (alpha)</strong>: This is super important! It’s called the <strong>learning rate</strong>. Think of it as the size of our step. A small $\alpha$ means tiny cautious steps, while a large $\alpha$ means big, bold leaps. We’ll discuss its impact soon.</li> <li> <strong>$\nabla J(\theta_{old})$</strong>: This is the <strong>gradient</strong> of the loss function $J$ with respect to our parameters $\theta$, evaluated at our current position $\theta_{old}$. The upside-down triangle symbol ($\nabla$) is called “nabla” and denotes the gradient. <ul> <li> <strong>What is a gradient?</strong> If you remember calculus, a derivative tells you the slope of a function at a point. For a function with multiple inputs (like our parameters $\theta$), the gradient is a vector containing the <strong>partial derivatives</strong> of the function with respect to each input. Each partial derivative tells us how much the loss changes if we tweak just <em>that specific parameter</em> a tiny bit. The gradient vector points in the direction of the steepest increase of the loss function.</li> </ul> </li> <li> <strong>The minus sign</strong>: Because the gradient points in the direction of steepest <em>increase</em>, we want to move in the <em>opposite</em> direction to decrease the loss. Hence, the minus sign for “descent.”</li> </ol> <p>So, in plain English, the update rule says: “To find your new position, take your current position, and move a certain distance ($\alpha$) in the direction <em>opposite</em> to the steepest slope of the error function ($\nabla J(\theta)$).”</p> <h3 id="a-concrete-simplified-example-linear-regression">A Concrete (Simplified) Example: Linear Regression</h3> <p>Let’s imagine we’re building a simple linear regression model where we want to predict an output $y$ based on an input $x$. Our hypothesis function $h_\theta(x)$ is a straight line:</p> \[h\_\theta(x) = \theta_0 + \theta_1 x\] <p>Here, $\theta_0$ is the y-intercept and $\theta_1$ is the slope. These are our parameters that we want to learn.</p> <p>A common loss function for linear regression is the Mean Squared Error (MSE), defined as:</p> \[J(\theta*0, \theta_1) = \frac{1}{2m} \sum*{i=1}^{m} (h\_\theta(x^{(i)}) - y^{(i)})^2\] <p>Where $m$ is the number of data points, $x^{(i)}$ and $y^{(i)}$ are the $i$-th input and output, and the $\frac{1}{2}$ is just for mathematical convenience (it simplifies the derivative).</p> <p>To apply Gradient Descent, we need to calculate the partial derivatives of $J$ with respect to each parameter ($\theta_0$ and $\theta_1$):</p> \[\frac{\partial J}{\partial \theta*0} = \frac{1}{m} \sum*{i=1}^{m} (h\_\theta(x^{(i)}) - y^{(i)})\] \[\frac{\partial J}{\partial \theta*1} = \frac{1}{m} \sum*{i=1}^{m} (h\_\theta(x^{(i)}) - y^{(i)}) x^{(i)}\] <p>(Don’t worry about deriving these yourself right now; the important thing is that these tell us the direction of steepest increase for each parameter).</p> <p>Now, our update rules become:</p> \[\theta*0 := \theta_0 - \alpha \frac{1}{m} \sum*{i=1}^{m} (h\_\theta(x^{(i)}) - y^{(i)})\] \[\theta*1 := \theta_1 - \alpha \frac{1}{m} \sum*{i=1}^{m} (h\_\theta(x^{(i)}) - y^{(i)}) x^{(i)}\] <p>We repeat these updates for $\theta_0$ and $\theta_1$ many, many times, iteratively moving closer and closer to the values that minimize our MSE loss. Each full pass through all data points is often called an “epoch.”</p> <h3 id="the-learning-rate-alpha-a-double-edged-sword">The Learning Rate ($\alpha$): A Double-Edged Sword</h3> <p>Choosing the right learning rate is crucial.</p> <ul> <li> <strong>If $\alpha$ is too small:</strong> We take tiny steps. Convergence will be very slow, and it might take forever to reach the minimum.</li> <li> <strong>If $\alpha$ is too large:</strong> We take huge steps. We might overshoot the minimum repeatedly, bounce around erratically, or even diverge entirely and never find the minimum. Imagine trying to find the bottom of a bowl by jumping wildly.</li> </ul> <p>Finding the optimal $\alpha$ often involves experimentation, trying different values (e.g., 0.1, 0.01, 0.001) and observing how the loss function behaves over epochs. This is a common challenge and an active area of research in machine learning.</p> <h3 id="challenges-and-variations">Challenges and Variations</h3> <p>While elegant, Gradient Descent isn’t without its quirks:</p> <ol> <li> <p><strong>Local Minima:</strong> In complex loss landscapes, there might be multiple “valleys” (local minima) that are not the absolute lowest point (global minimum). Gradient Descent might get stuck in a local minimum if the learning rate isn’t sufficient to push it out. For many modern deep learning models, the loss landscapes are so complex that finding the <em>global</em> minimum isn’t always the goal; finding a “good enough” local minimum that generalizes well is often sufficient.</p> </li> <li> <p><strong>Computational Cost:</strong> The basic form we’ve discussed, <strong>Batch Gradient Descent</strong>, calculates the gradient using <em>all</em> data points in the dataset for each update. This can be computationally expensive and slow for very large datasets.</p> </li> </ol> <p>To address these challenges, several variations have emerged:</p> <ul> <li> <strong>Stochastic Gradient Descent (SGD):</strong> Instead of using all data, SGD picks just <em>one</em> random data point at a time to calculate the gradient and update parameters. This makes each step much faster, but the path to the minimum is much noisier and less direct.</li> <li> <strong>Mini-Batch Gradient Descent:</strong> This is the practical compromise. It uses a small “batch” (e.g., 32, 64, 128 data points) to calculate the gradient. It offers a balance between the stability of Batch GD and the speed of SGD. Most deep learning frameworks use mini-batch gradient descent by default.</li> <li> <strong>Optimizers (like Adam, RMSprop, Adagrad):</strong> These are advanced variations that dynamically adjust the learning rate for each parameter during training, often leading to faster and more stable convergence. They build upon the core principles of Gradient Descent.</li> </ul> <h3 id="the-unsung-hero">The Unsung Hero</h3> <p>Gradient Descent, in its various forms, is the workhorse behind a vast array of machine learning algorithms, from linear regression and logistic regression to the incredibly complex neural networks that power modern AI applications like image recognition, natural language processing, and autonomous driving. It’s the silent engine that allows these models to learn from data, refine their understanding, and ultimately make intelligent decisions.</p> <p>From that initial intimidating name, Gradient Descent has become one of the most beautiful and fundamental concepts in my data science toolkit. It teaches us that even the most complex problems can be solved by taking small, informed steps in the right direction. And in the world of data and AI, “the right direction” is always downhill on the loss landscape!</p> <p>Keep exploring, keep learning, and don’t be afraid to take that first step down the gradient!</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/cracking-the-ai-black-box-why-explainable-ai-xai-i/">Cracking the AI Black Box: Why Explainable AI (XAI) is Our Superpower</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/the-secret-life-of-states-how-markov-chains-predic/">The Secret Life of States: How Markov Chains Predict Our Next Move (Without Remembering the Past!)</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/gradient-descent-unpacking-the-engine-of-machine-l/">Gradient Descent: Unpacking the Engine of Machine Learning</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Adarsh Nair. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/blog/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/masonry.js?v=a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/zoom.js?v=85ddb88934d28b74e78031fd54cf8308"></script> <script src="/blog/assets/js/no_defer.js?v=2781658a0a2b13ed609542042a859126"></script> <script defer src="/blog/assets/js/common.js?v=c15de51d4bb57887caa2c21988d97279"></script> <script defer src="/blog/assets/js/copy_code.js?v=c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/blog/assets/js/jupyter_new_tab.js?v=d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/blog/assets/js/mathjax-setup.js?v=a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/progress-bar.js?v=2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/blog/assets/js/vanilla-back-to-top.min.js?v=f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/blog/assets/js/search/ninja-keys.min.js?v=a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/blog/assets/js/search-setup.js?v=6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/blog/assets/js/search-data.js"></script> <script src="/blog/assets/js/shortcut-key.js?v=ccc841c459bfc0e64c1c2b5acd10df02"></script> </body> </html>