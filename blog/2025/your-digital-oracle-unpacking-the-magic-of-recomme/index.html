<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Your Digital Oracle: Unpacking the Magic of Recommender Systems | Adarsh Nair </title> <meta name="author" content="Adarsh Nair"> <meta name="description" content="A deep dive into machine learning, AI, and data science. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <meta http-equiv="Content-Security-Policy" content="default-src 'self'; script-src 'self' 'unsafe-inline' https:; style-src 'self' 'unsafe-inline' https:; img-src 'self' data: https:; font-src 'self' data: https:; media-src 'self' https:; frame-src 'self' https:; connect-src 'self' https:;"> <link rel="stylesheet" href="/blog/assets/css/bootstrap.min.css?v=a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/blog/assets/css/academicons.min.css?v=f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/blog/assets/css/scholar-icons.css?v=62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-github.css?v=591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/blog/assets/css/main.css?v=d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://adarshnair.online/blog/blog/blog/2025/your-digital-oracle-unpacking-the-magic-of-recomme/"> <script src="/blog/assets/js/theme.js?v=5fea5159b787642c1bbc1f334d60f883"></script> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-native.css?v=5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/blog/cv/"> Adarsh Nair </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/blog/"> </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/index.html">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/cv/">CV </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/repositories/">repositories </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="fa-solid fa-magnifying-glass"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-half-sun-moon" id="light-toggle-system"></i> <i class="fa-solid fa-moon" id="light-toggle-dark"></i> <i class="fa-solid fa-sun" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Your Digital Oracle: Unpacking the Magic of Recommender Systems</h1> <p class="post-meta"> Created on June 21, 2025 by Adarsh Nair </p> <p class="post-tags"> <a href="/blog/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/blog/tag/machine-learning"> <i class="fa-solid fa-hashtag fa-sm"></i> Machine Learning</a>   <a href="/blog/blog/tag/recommender-systems"> <i class="fa-solid fa-hashtag fa-sm"></i> Recommender Systems</a>   <a href="/blog/blog/tag/data-science"> <i class="fa-solid fa-hashtag fa-sm"></i> Data Science</a>   <a href="/blog/blog/tag/collaborative-filtering"> <i class="fa-solid fa-hashtag fa-sm"></i> Collaborative Filtering</a>   <a href="/blog/blog/tag/ai"> <i class="fa-solid fa-hashtag fa-sm"></i> AI</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p>Alright, let’s be honest. How many times have you finished a TV show on Netflix, only for the platform to immediately suggest another one that you <em>just know</em> you’re going to binge? Or added an item to your Amazon cart, and suddenly a list of “Customers who bought this also bought…” appears, perfectly anticipating your next purchase? It feels like magic, doesn’t it? As if these platforms have a digital oracle, whispering secrets about your desires directly into their algorithms.</p> <p>Well, as someone fascinated by how data shapes our world, I’m here to tell you it’s not magic. It’s science. Specifically, it’s the incredibly clever (and sometimes complex) world of <strong>Recommender Systems</strong>. These systems are the unsung heroes of our digital age, working tirelessly behind the scenes to personalize our online experiences, making them more engaging, more relevant, and ultimately, more valuable.</p> <p>In this post, we’re going to pull back the curtain. We’ll explore what recommender systems are, why they’re so crucial, and peek into the ingenious ways they try to predict what you’ll love next. Don’t worry, we’ll keep it accessible, but we won’t shy away from the cool technical bits either!</p> <h3 id="the-unseen-hands-that-guide-us-what-are-recommender-systems">The Unseen Hands That Guide Us: What are Recommender Systems?</h3> <p>At its core, a recommender system is an information filtering system that seeks to predict the “rating” or “preference” a user would give to an item. Think about it:</p> <ul> <li> <strong>Netflix</strong> recommends movies and TV shows.</li> <li> <strong>Spotify</strong> suggests new music artists and playlists.</li> <li> <strong>Amazon</strong> proposes products you might want to buy.</li> <li> <strong>YouTube</strong> cues up the next video you should watch.</li> <li> <strong>LinkedIn</strong> connects you with people you might know.</li> </ul> <p>The goal? To help users discover new items they might like (that they wouldn’t have found otherwise) and to keep them engaged with the platform. For businesses, this translates to increased sales, longer session times, and higher user satisfaction. It’s a win-win!</p> <p>So, how do they do it? There are several main strategies, each with its own strengths and weaknesses. Let’s dive in.</p> <h3 id="chapter-1-the-building-blocks---knowing-what-you-like-content-based-filtering">Chapter 1: The Building Blocks - Knowing What You Like (Content-Based Filtering)</h3> <p>Imagine you have a personal assistant whose sole job is to recommend movies. You tell them you loved <em>Dune</em>, <em>Interstellar</em>, and <em>Arrival</em>. This assistant notices a pattern: you really enjoy epic sci-fi films with thought-provoking plots. Next time you’re looking for a movie, they’d suggest something like <em>Blade Runner 2049</em> or <em>2001: A Space Odyssey</em>.</p> <p>This is the essence of <strong>Content-Based Filtering (CBF)</strong>.</p> <p><strong>How it Works:</strong> CBF recommends items similar to those a user has liked in the past. It’s like building a profile for <em>you</em> (based on your past interactions) and a profile for <em>each item</em> (based on its features).</p> <ol> <li> <strong>Item Representation:</strong> Each item is described by a set of attributes or “features.” For movies, this could be genre (sci-fi, action, drama), actors, director, keywords, release year. For news articles, it could be topics, authors, keywords.</li> <li> <strong>User Profile:</strong> Your profile is built from the features of items you’ve interacted with (liked, rated highly, watched, read). If you watched many sci-fi movies, your profile will have a high “sci-fi” score.</li> <li> <strong>Recommendation Generation:</strong> The system then looks for items whose features strongly match your user profile.</li> </ol> <p><strong>A Glimpse at the Math (Conceptually):</strong> We can represent both your preferences and the items as vectors. For instance, a movie could be a vector like <code class="language-plaintext highlighter-rouge">[1, 0, 1, 0, 0]</code> where 1 means it’s ‘Sci-Fi’ and ‘Action’, and 0 means not ‘Comedy’, ‘Drama’, ‘Thriller’. Your user profile is an aggregate of these vectors for items you liked. To find similar items, the system often calculates the <strong>cosine similarity</strong> between your profile vector and each item’s vector.</p> <table> <tbody> <tr> <td>$ \text{cosine_similarity}(A, B) = \frac{A \cdot B}{</td> <td> </td> <td>A</td> <td> </td> <td>\cdot</td> <td> </td> <td>B</td> <td> </td> <td>} $</td> </tr> </tbody> </table> <table> <tbody> <tr> <td>Here, $A$ could be your user profile vector and $B$ an item’s vector. $A \cdot B$ is the dot product (sum of the products of corresponding elements), and $</td> <td> </td> <td>A</td> <td> </td> <td>$ and $</td> <td> </td> <td>B</td> <td> </td> <td>$ are the magnitudes (lengths) of the vectors. A higher cosine similarity (closer to 1) means the vectors point in roughly the same direction, indicating higher similarity.</td> </tr> </tbody> </table> <p><strong>Pros:</strong></p> <ul> <li> <strong>No “cold start” for users:</strong> It doesn’t need data from other users, only your own history.</li> <li> <strong>Good for niche tastes:</strong> If you like obscure indie films, CBF can still find similar ones for you.</li> <li> <strong>Interpretability:</strong> It’s easy to explain <em>why</em> an item was recommended (“You liked this movie because it’s a sci-fi film directed by Christopher Nolan, and you’ve liked his other sci-fi films”).</li> </ul> <p><strong>Cons:</strong></p> <ul> <li> <strong>Limited novelty:</strong> It tends to recommend items very similar to what you already like, potentially leading to a “filter bubble” where you’re never exposed to new genres.</li> <li> <strong>Requires rich item features:</strong> If items don’t have good descriptive data, CBF struggles.</li> <li> <strong>Cold start for new items:</strong> If a brand-new movie has no features yet, the system can’t recommend it.</li> </ul> <h3 id="chapter-2-the-power-of-the-crowd---learning-from-others-collaborative-filtering">Chapter 2: The Power of the Crowd - Learning from Others (Collaborative Filtering)</h3> <p>What if we didn’t focus on <em>what</em> an item is, but rather <em>who</em> likes it? This is the core idea behind <strong>Collaborative Filtering (CF)</strong>, which is arguably the most popular and often most effective type of recommender system. It operates on the simple, yet powerful, premise: <strong>“Tell me what your friends like, and I’ll tell you what you might like.”</strong></p> <p>There are two main branches of Collaborative Filtering:</p> <h4 id="21-memory-based-heuristic-collaborative-filtering">2.1 Memory-Based (Heuristic) Collaborative Filtering</h4> <p>These methods directly use the user-item interaction data (like ratings) to find relationships.</p> <p><strong>2.1.1 User-User Collaborative Filtering (User-Based CF)</strong> This approach finds users who are “similar” to you and recommends items that those similar users liked but you haven’t seen yet.</p> <ul> <li> <strong>How it Works:</strong> <ol> <li> <strong>Find Similar Users:</strong> Identify users whose past ratings or interactions are highly correlated with yours. If you and I both loved <em>Inception</em>, <em>The Matrix</em>, and <em>Pulp Fiction</em>, we’re likely similar.</li> <li> <strong>Generate Recommendations:</strong> Once similar users (your “neighbors”) are found, the system looks at items they liked but you haven’t interacted with. These become your recommendations.</li> </ol> </li> <li> <strong>Similarity Metrics for Users:</strong> Just like with CBF, we need a way to quantify similarity. <ul> <li> <strong>Cosine Similarity:</strong> Can also be used here, treating user ratings as vectors.</li> <li> <strong>Pearson Correlation Coefficient:</strong> This is often preferred for ratings data, as it takes into account a user’s <em>average</em> rating. It measures the linear relationship between two users’ ratings. $ \text{Pearson}(u, v) = \frac{\sum_{i}(r_{u,i} - \bar{r}<em>u)(r</em>{v,i} - \bar{r}<em>v)}{\sqrt{\sum</em>{i}(r_{u,i} - \bar{r}<em>u)^2}\sqrt{\sum</em>{i}(r_{v,i} - \bar{r}<em>v)^2}} $ Here, $r</em>{u,i}$ is user $u$’s rating for item $i$, and $\bar{r}_u$ is user $u$’s average rating. This helps account for users who generally give high ratings versus those who are more critical.</li> </ul> </li> <li> <strong>Pros:</strong> <ul> <li> <strong>Discoverability:</strong> Can recommend items completely different from what you’ve liked before, as long as a similar user liked them.</li> <li> <strong>No item features needed:</strong> Works purely on user-item interactions.</li> </ul> </li> <li> <strong>Cons:</strong> <ul> <li> <strong>Scalability:</strong> Finding similar users among millions can be computationally expensive (needs to calculate $N^2$ similarities for $N$ users).</li> <li> <strong>Data Sparsity:</strong> If users have rated very few common items, it’s hard to find good neighbors.</li> <li> <strong>Cold Start for New Users:</strong> If you’re a new user with no ratings, the system can’t find similar users for you.</li> </ul> </li> </ul> <p><strong>2.1.2 Item-Item Collaborative Filtering (Item-Based CF)</strong> Instead of finding similar users, this approach finds items similar to those you’ve liked. The similarity here is based on <em>who</em> liked them. “Users who bought X also bought Y.”</p> <ul> <li> <strong>How it Works:</strong> <ol> <li> <strong>Find Similar Items:</strong> Identify items that tend to be rated similarly by many users. If everyone who bought <em>Lord of the Rings: Fellowship of the Ring</em> also bought <em>The Two Towers</em>, then these two movies are highly similar.</li> <li> <strong>Generate Recommendations:</strong> If you liked <em>Fellowship of the Ring</em>, the system recommends <em>The Two Towers</em> because it’s similar to an item you already enjoyed.</li> </ol> </li> <li> <strong>Pros:</strong> <ul> <li> <strong>Scalability:</strong> Item similarity is often more stable over time than user similarity. The number of items is usually much smaller and changes less frequently than the number of users, making pre-computation of item similarities more feasible.</li> <li> <strong>Handles many users well:</strong> Can effectively make recommendations even with a massive user base.</li> </ul> </li> <li> <strong>Cons:</strong> <ul> <li> <strong>Cold Start for New Items:</strong> If a new item has no ratings yet, it can’t be found as similar to anything.</li> <li> <strong>Less adaptable to changing user tastes:</strong> If your tastes change rapidly, item-item might be slower to adapt than user-user.</li> </ul> </li> </ul> <h4 id="22-model-based-collaborative-filtering-matrix-factorization">2.2 Model-Based Collaborative Filtering (Matrix Factorization)</h4> <p>Memory-based CF can be powerful, but its scalability issues with huge datasets led to the development of model-based approaches, especially <strong>Matrix Factorization</strong>. This is where things get really cool, often feeling like pure magic!</p> <ul> <li> <p><strong>The Big Idea:</strong> Imagine we have a massive table (a “matrix”) where rows are users and columns are items. Each cell contains a user’s rating for an item. Most of this matrix is empty because users only rate a tiny fraction of all available items. The goal of matrix factorization is to “fill in” those missing values!</p> </li> <li> <strong>Latent Factors:</strong> Instead of directly using observed ratings, matrix factorization assumes there are some <em>hidden</em> characteristics or “latent factors” that determine why a user likes an item. <ul> <li>Think of these factors as secret ingredients of taste: perhaps a “sci-fi factor,” a “romance factor,” an “action factor,” etc., or even more abstract ones that we can’t easily name.</li> <li>Each user can be described by how much they “care about” each of these factors.</li> <li>Each item can be described by how much it “exhibits” each of these factors.</li> </ul> </li> <li> <strong>The Math (Simplified):</strong> We take our sparse user-item rating matrix, let’s call it $R$. We want to decompose it into two smaller, dense matrices: <ul> <li>$P$: A user-factor matrix (users x latent factors)</li> <li>$Q$: An item-factor matrix (items x latent factors) The prediction for a user $u$’s rating for an item $i$, denoted $\hat{r}_{ui}$, is simply the dot product of the user’s factor vector ($p_u$) and the item’s factor vector ($q_i$):</li> </ul> <p>$ \hat{r}<em>{ui} = p_u \cdot q_i^T = \sum</em>{k=1}^K p_{uk}q_{ik} $</p> <p>Here, $K$ is the number of latent factors. Essentially, we’re trying to find $P$ and $Q$ such that when multiplied together ($P \times Q^T$), they reconstruct the original rating matrix $R$ as accurately as possible, especially for the ratings we already know. The “filled-in” values in this reconstructed matrix are our predictions!</p> </li> <li> <p><strong>Algorithms:</strong> Popular techniques to find these $P$ and $Q$ matrices include Singular Value Decomposition (SVD) and Alternating Least Squares (ALS). They iteratively adjust the values in $P$ and $Q$ to minimize the difference between the predicted ratings and the actual known ratings.</p> </li> <li> <strong>Pros:</strong> <ul> <li> <strong>High Accuracy:</strong> Often produces more accurate recommendations than memory-based methods.</li> <li> <strong>Handles Sparsity:</strong> Can infer preferences even with very sparse data.</li> <li> <strong>Scalability:</strong> Once the model is trained, predictions are fast. The training process can be distributed.</li> </ul> </li> <li> <strong>Cons:</strong> <ul> <li> <strong>Cold Start for New Users/Items:</strong> If a user or item is new, they don’t have a factor vector, making recommendations difficult without additional information.</li> <li> <strong>Interpretability:</strong> The latent factors themselves are abstract and hard to explain (“Why did the system recommend this? Because it scored high on Factor 7 and Factor 12, and you like Factor 7 and Factor 12!”).</li> </ul> </li> </ul> <h3 id="chapter-3-the-best-of-both-worlds---hybrid-approaches">Chapter 3: The Best of Both Worlds - Hybrid Approaches</h3> <p>Given the strengths and weaknesses of Content-Based and Collaborative Filtering, it makes sense to combine them! <strong>Hybrid Recommender Systems</strong> blend different techniques to overcome individual limitations.</p> <p>For example, a common hybrid strategy is to use Content-Based Filtering for new users or items (to combat the cold start problem), and then transition to Collaborative Filtering (especially model-based) once enough interaction data is collected. Other approaches combine predictions from both systems, or use one system’s output as features for another. This usually leads to more robust and accurate recommendations.</p> <h3 id="chapter-4-the-bumps-in-the-road---challenges-and-considerations">Chapter 4: The Bumps in the Road - Challenges and Considerations</h3> <p>Building a great recommender system isn’t without its hurdles:</p> <ul> <li> <strong>The Cold Start Problem:</strong> This is perhaps the biggest headache. <ul> <li> <strong>New Users:</strong> If a user just joined, they have no interaction history. How do you recommend anything? (Solution: Ask them preferences, recommend popular items, use content-based methods with demographic data).</li> <li> <strong>New Items:</strong> If a new movie is released, it has no ratings. How do you get it discovered? (Solution: Use content-based methods, initially recommend to users who liked similar genres, use editorial curation).</li> </ul> </li> <li> <strong>Data Sparsity:</strong> Most users interact with only a tiny fraction of available items. Imagine the Netflix rating matrix – it’s mostly empty! This makes it hard to find patterns. Matrix factorization helps with this.</li> <li> <strong>Scalability:</strong> A system that works for 100 users might buckle under the weight of 100 million users and billions of items. Efficiency and distributed computing are key.</li> <li> <strong>Serendipity vs. Accuracy:</strong> Do we always want to recommend items that are <em>exactly</em> what you expect? Sometimes, users appreciate unexpected but delightful recommendations (serendipity). Balancing highly accurate, predictable recommendations with novel, surprising ones is an art.</li> <li> <strong>Filter Bubbles &amp; Bias:</strong> Recommenders can inadvertently create “filter bubbles,” constantly reinforcing existing preferences and limiting exposure to diverse viewpoints. They can also reflect and amplify societal biases present in the training data. This raises important ethical considerations about fairness and promoting diversity.</li> </ul> <h3 id="chapter-5-measuring-success---how-do-we-know-its-good">Chapter 5: Measuring Success - How Do We Know It’s Good?</h3> <p>How do we evaluate if our digital oracle is truly insightful? We use various metrics:</p> <ul> <li> <strong>Offline Metrics (using historical data):</strong> <ul> <li> <strong>RMSE (Root Mean Squared Error):</strong> For explicit rating predictions. It measures the average magnitude of the errors between predicted ratings ($\hat{y}<em>i$) and actual ratings ($y_i$). A lower RMSE is better. $ \text{RMSE} = \sqrt{\frac{1}{N} \sum</em>{i=1}^N (\hat{y}_i - y_i)^2} $</li> <li> <strong>Precision@K and Recall@K:</strong> For implicit feedback or ranking tasks (e.g., “show me the top 10 recommended items”). <ul> <li> <strong>Precision@K:</strong> Out of the top K recommendations, how many were actually relevant?</li> <li> <strong>Recall@K:</strong> Out of all relevant items, how many were included in the top K recommendations? We often choose K based on what’s practical (e.g., how many items fit on the first screen).</li> </ul> </li> </ul> </li> <li> <strong>Online Metrics (in live systems):</strong> <ul> <li> <strong>A/B Testing:</strong> The gold standard. Show different versions of the recommender to different user groups and measure real-world impact (click-through rates, conversion rates, time spent, retention).</li> <li> <strong>Click-Through Rate (CTR):</strong> The percentage of users who clicked on a recommended item.</li> <li> <strong>Conversion Rate:</strong> The percentage of users who clicked and then performed a desired action (e.g., made a purchase, watched the entire movie).</li> </ul> </li> </ul> <h3 id="chapter-6-the-road-ahead---beyond-the-horizon">Chapter 6: The Road Ahead - Beyond the Horizon</h3> <p>The field of recommender systems is constantly evolving. Modern systems are increasingly leveraging powerful techniques from deep learning and reinforcement learning:</p> <ul> <li> <strong>Deep Learning:</strong> Neural networks can learn incredibly complex, non-linear patterns in user behavior and item features. They can understand sequences (e.g., “what you watched just before this movie matters”), generate rich item embeddings, and handle multimodal data (images, text, audio).</li> <li> <strong>Reinforcement Learning:</strong> Instead of just predicting what you <em>might</em> like, RL aims to optimize for long-term engagement. It learns from user feedback (did they actually watch/buy it, and for how long?) to refine its strategy, much like a game-playing AI.</li> <li> <strong>Context-Aware Recommendations:</strong> Taking into account the time of day, location, device, mood, and other contextual factors to make recommendations even more precise.</li> </ul> <h3 id="conclusion-crafting-our-digital-journey">Conclusion: Crafting Our Digital Journey</h3> <p>From the humble beginnings of simple “if-then” rules to the sophisticated dance of matrix factorization and the cutting edge of deep learning, recommender systems have truly transformed how we interact with digital content and products. They are a testament to the power of data science and machine learning to create personalized experiences that delight and engage us.</p> <p>Next time Netflix suggests that perfect documentary, or Spotify introduces you to your new favorite artist, take a moment to appreciate the intricate algorithms working behind the scenes. It’s a blend of art and science, constantly learning, adapting, and striving to be your most insightful digital oracle.</p> <p>The journey into recommender systems is a fascinating one, revealing how we can predict human preferences with incredible accuracy. It’s a field ripe with challenges and opportunities, and one that continues to shape our digital world in profound ways. Perhaps, if you’re like me, you’ll be inspired to dive deeper and maybe even build your own recommender system someday!</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/cracking-the-ai-black-box-why-explainable-ai-xai-i/">Cracking the AI Black Box: Why Explainable AI (XAI) is Our Superpower</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/the-secret-life-of-states-how-markov-chains-predic/">The Secret Life of States: How Markov Chains Predict Our Next Move (Without Remembering the Past!)</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/gradient-descent-unpacking-the-engine-of-machine-l/">Gradient Descent: Unpacking the Engine of Machine Learning</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Adarsh Nair. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/blog/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/masonry.js?v=a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/zoom.js?v=85ddb88934d28b74e78031fd54cf8308"></script> <script src="/blog/assets/js/no_defer.js?v=2781658a0a2b13ed609542042a859126"></script> <script defer src="/blog/assets/js/common.js?v=c15de51d4bb57887caa2c21988d97279"></script> <script defer src="/blog/assets/js/copy_code.js?v=c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/blog/assets/js/jupyter_new_tab.js?v=d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/blog/assets/js/mathjax-setup.js?v=a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/progress-bar.js?v=2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/blog/assets/js/vanilla-back-to-top.min.js?v=f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/blog/assets/js/search/ninja-keys.min.js?v=a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/blog/assets/js/search-setup.js?v=6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/blog/assets/js/search-data.js"></script> <script src="/blog/assets/js/shortcut-key.js?v=ccc841c459bfc0e64c1c2b5acd10df02"></script> </body> </html>