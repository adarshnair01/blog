<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> My Ascent into Optimization: A Personal Dive into Gradient Descent | Adarsh Nair </title> <meta name="author" content="Adarsh Nair"> <meta name="description" content="A deep dive into machine learning, AI, and data science. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <meta http-equiv="Content-Security-Policy" content="default-src 'self'; script-src 'self' 'unsafe-inline' https:; style-src 'self' 'unsafe-inline' https:; img-src 'self' data: https:; font-src 'self' data: https:; media-src 'self' https:; frame-src 'self' https:; connect-src 'self' https:;"> <link rel="stylesheet" href="/blog/assets/css/bootstrap.min.css?v=a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/blog/assets/css/academicons.min.css?v=f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/blog/assets/css/scholar-icons.css?v=62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-github.css?v=591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/blog/assets/css/main.css?v=d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://adarshnair.online/blog/blog/2025/my-ascent-into-optimization-a-personal-dive-into-g/"> <script src="/blog/assets/js/theme.js?v=5fea5159b787642c1bbc1f334d60f883"></script> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-native.css?v=5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/blog/cv/"> Adarsh Nair </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/blog/"> </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/cv/">CV </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/repositories/">repositories </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="fa-solid fa-magnifying-glass"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-half-sun-moon" id="light-toggle-system"></i> <i class="fa-solid fa-moon" id="light-toggle-dark"></i> <i class="fa-solid fa-sun" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">My Ascent into Optimization: A Personal Dive into Gradient Descent</h1> <p class="post-meta"> Created on May 11, 2025 by Adarsh Nair </p> <p class="post-tags"> <a href="/blog/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/blog/tag/machine-learning"> <i class="fa-solid fa-hashtag fa-sm"></i> Machine Learning</a>   <a href="/blog/blog/tag/optimization"> <i class="fa-solid fa-hashtag fa-sm"></i> Optimization</a>   <a href="/blog/blog/tag/gradient-descent"> <i class="fa-solid fa-hashtag fa-sm"></i> Gradient Descent</a>   <a href="/blog/blog/tag/deep-learning"> <i class="fa-solid fa-hashtag fa-sm"></i> Deep Learning</a>   <a href="/blog/blog/tag/algorithms"> <i class="fa-solid fa-hashtag fa-sm"></i> Algorithms</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p>Welcome, fellow explorers of the digital frontier! Today, I want to pull back the curtain on one of the most foundational and fascinating algorithms in machine learning: Gradient Descent. If you’ve ever trained a neural network, fit a regression model, or optimized <em>anything</em> in data science, you’ve likely encountered this workhorse, perhaps without even realizing the elegant simplicity at its core.</p> <p>For me, understanding Gradient Descent wasn’t just about memorizing a formula; it was like discovering the secret compass that helps me navigate the vast, often foggy, landscape of data. It’s a concept that feels incredibly intuitive once you grasp the underlying idea, and that’s what I hope to share with you today.</p> <h3 id="the-mountain-problem-finding-the-lowest-point">The Mountain Problem: Finding the Lowest Point</h3> <p>Imagine yourself high up in a mountain range, blindfolded or perhaps caught in a thick fog. Your goal: reach the lowest point in the valley. You can’t see the entire landscape, but you can feel the slope directly beneath your feet. What’s your strategy?</p> <p>Intuitively, you’d take a small step in the direction that feels steepest downwards. Then you’d feel the slope again, take another step, and repeat. Eventually, by consistently moving in the direction of steepest descent, you’d reach the bottom of the valley.</p> <p>This, my friends, is the essence of Gradient Descent. In the world of machine learning, our “mountain range” is the mathematical representation of how well our model is performing, and the “lowest point” is the optimal set of parameters that make our model perform best.</p> <h3 id="the-cost-of-being-wrong-introducing-the-cost-function">The Cost of Being Wrong: Introducing the Cost Function</h3> <p>Before we can descend, we need something to descend <em>from</em>. This brings us to the <strong>cost function</strong>, also known as a loss function.</p> <p>Think of it this way: when we build a machine learning model, say, for predicting house prices, it makes guesses. Some guesses will be closer to the actual price than others. The cost function is a mathematical way of quantifying how “wrong” our model’s predictions are. A high cost means our model is performing poorly; a low cost means it’s doing well. Our ultimate goal? To find the model parameters (like the coefficients in a linear regression or the weights in a neural network) that <em>minimize</em> this cost function.</p> <p>Let’s take a simple example: <strong>Linear Regression</strong>. Our model predicts a value $\hat{y}$ based on an input $x$ and parameters $\theta_0$ (intercept) and $\theta_1$ (slope): $ \hat{y} = \theta_0 + \theta_1 x $</p> <p>A common cost function here is the <strong>Mean Squared Error (MSE)</strong>. If we have $m$ data points $(x^{(i)}, y^{(i)})$, the MSE is: $ J(\theta_0, \theta_1) = \frac{1}{2m} \sum_{i=1}^{m} (\hat{y}^{(i)} - y^{(i)})^2 $ where $ \hat{y}^{(i)} = \theta_0 + \theta_1 x^{(i)} $.</p> <p>Notice the $ \frac{1}{2} $ factor – it’s there to simplify the derivative later on, making the math a bit cleaner. Our task is to find the values of $ \theta_0 $ and $ \theta_1 $ that make $J(\theta_0, \theta_1)$ as small as possible. This $J(\theta_0, \theta_1)$ is our multi-dimensional “mountain range.”</p> <h3 id="the-compass-gradients-to-the-rescue">The Compass: Gradients to the Rescue!</h3> <p>How do we find the direction of steepest descent? This is where the magic of calculus, specifically <strong>gradients</strong>, comes in.</p> <p>For a function of a single variable, the derivative tells us the slope of the tangent line at any point. If the slope is positive, the function is going up; if negative, it’s going down.</p> <p>For a function with multiple variables (like our cost function $ J(\theta_0, \theta_1) $), we use partial derivatives. The collection of all partial derivatives, with respect to each parameter, is called the <strong>gradient</strong>. The gradient vector points in the direction of the <em>steepest ascent</em>.</p> <p>So, if we want to go <em>down</em> the mountain, we simply move in the <em>opposite</em> direction of the gradient!</p> <p>Mathematically, the gradient of our cost function $J$ with respect to our parameters $\theta$ (which could be $ \theta_0, \theta_1, \dots, \theta_n $) is denoted by $ \nabla J(\theta) $.</p> <p>For our linear regression example with MSE, we’d need to calculate the partial derivatives: $ \frac{\partial J}{\partial \theta_0} = \frac{1}{m} \sum_{i=1}^{m} (\hat{y}^{(i)} - y^{(i)}) $ $ \frac{\partial J}{\partial \theta_1} = \frac{1}{m} \sum_{i=1}^{m} (\hat{y}^{(i)} - y^{(i)}) x^{(i)} $</p> <p>These derivatives tell us how much $J$ changes when we slightly change $ \theta_0 $ or $ \theta_1 $.</p> <h3 id="taking-a-step-the-gradient-descent-update-rule">Taking a Step: The Gradient Descent Update Rule</h3> <p>With our compass (the gradient) guiding us, we can now formulate the core update rule for Gradient Descent. We start with some initial, often random, values for our parameters $\theta$. Then, we iteratively update them using the following formula:</p> <p>$ \theta_{new} = \theta_{old} - \alpha \nabla J(\theta_{old}) $</p> <p>Let’s break this down:</p> <ul> <li>$ \theta_{new} $: The updated values for our parameters.</li> <li>$ \theta_{old} $: The current values of our parameters.</li> <li>$ \alpha $ (alpha): This is the <strong>learning rate</strong>. It’s a crucial hyperparameter that dictates the size of the step we take in the direction of steepest descent.</li> <li>$ \nabla J(\theta_{old}) $: The gradient of the cost function with respect to the parameters at their current values. This vector tells us the direction of steepest <em>ascent</em>.</li> </ul> <p>Notice the minus sign before $ \alpha \nabla J(\theta_{old}) $. This is vital! Since $ \nabla J(\theta_{old}) $ points uphill, we subtract it to move downhill.</p> <h3 id="the-pacing-problem-the-learning-rate-alpha">The Pacing Problem: The Learning Rate ($\alpha$)</h3> <p>The learning rate $ \alpha $ is like the pace you set while descending the mountain.</p> <ul> <li> <strong>If $ \alpha $ is too small:</strong> You’ll take tiny, cautious steps. You’ll eventually reach the bottom, but it will take a very long time, and your model might train incredibly slowly.</li> <li> <strong>If $ \alpha $ is too large:</strong> You’ll take huge, aggressive leaps. You might overshoot the lowest point entirely, bounce around erratically, or even diverge, climbing <em>up</em> the other side of the valley or flying off the mountain altogether! The cost function might never converge, or it might even increase.</li> </ul> <p>Finding the right $ \alpha $ is often a delicate balance and a key part of hyperparameter tuning in machine learning.</p> <h3 id="a-walk-through-the-algorithm">A Walk Through the Algorithm</h3> <p>Putting it all together, here’s the typical Gradient Descent process:</p> <ol> <li> <strong>Initialization:</strong> Start with random initial values for your model’s parameters (e.g., $ \theta_0, \theta_1 $).</li> <li> <strong>Iteration:</strong> Repeat the following steps until a stopping criterion is met (e.g., the cost function stops changing significantly, or a maximum number of iterations is reached): a. <strong>Calculate Predictions:</strong> Use the current parameters to make predictions for all data points. b. <strong>Calculate Error:</strong> Compute the difference between your predictions and the actual values. c. <strong>Calculate Gradients:</strong> Compute the partial derivatives of the cost function with respect to <em>each</em> parameter. This gives you the direction of the steepest ascent. d. <strong>Update Parameters:</strong> Adjust each parameter in the opposite direction of its gradient, scaled by the learning rate: $ \theta_j := \theta_j - \alpha \frac{\partial J}{\partial \theta_j} $ (for each parameter $ \theta_j $)</li> <li> <strong>Convergence:</strong> Once the algorithm converges, your parameters should be close to the optimal values that minimize the cost function.</li> </ol> <h3 id="different-ways-to-climb-variants-of-gradient-descent">Different Ways to Climb: Variants of Gradient Descent</h3> <p>The “standard” Gradient Descent we’ve discussed so far, where we calculate the gradient using <em>all</em> data points in each iteration, is specifically called <strong>Batch Gradient Descent</strong>. While theoretically sound, it can be computationally expensive for very large datasets because it has to process the entire dataset before making a single parameter update.</p> <p>To address this, clever researchers developed variations:</p> <ol> <li> <strong>Stochastic Gradient Descent (SGD):</strong> <ul> <li> <strong>The Idea:</strong> Instead of using all data, SGD computes the gradient and updates parameters for <em>each individual data point</em> (or ‘example’) in the dataset.</li> <li> <strong>Analogy:</strong> Imagine the mountain climber taking a step, feeling the immediate slope from <em>one specific rock</em>, adjusting, then moving to the next rock.</li> <li> <strong>Pros:</strong> Much faster for large datasets as updates are frequent. Can escape shallow local minima due to its noisy updates.</li> <li> <strong>Cons:</strong> Updates are noisy and parameters can fluctuate, leading to a less stable convergence (it “wobbles” around the minimum rather than settling precisely).</li> </ul> </li> <li> <strong>Mini-Batch Gradient Descent:</strong> <ul> <li> <strong>The Idea:</strong> A sweet spot between Batch GD and SGD. It computes the gradient and updates parameters using a <em>small batch</em> of data points (e.g., 32, 64, 128 samples) at each iteration.</li> <li> <strong>Analogy:</strong> Our climber now feels the average slope across a small patch of ground before taking a step.</li> <li> <strong>Pros:</strong> Combines the best of both worlds – more stable convergence than SGD, while being much faster than Batch GD. It leverages vectorized operations well, making it computationally efficient.</li> <li> <strong>Cons:</strong> Requires tuning the batch size.</li> </ul> </li> </ol> <p>Mini-Batch Gradient Descent is by far the most commonly used variant in practice, especially in deep learning, for its efficiency and stability.</p> <h3 id="obstacles-on-the-path-challenges-and-considerations">Obstacles on the Path: Challenges and Considerations</h3> <p>While powerful, Gradient Descent isn’t without its quirks:</p> <ul> <li> <strong>Local Minima vs. Global Minima:</strong> Our “mountain range” isn’t always a perfectly smooth, convex bowl with one true bottom. It can have multiple valleys, known as <strong>local minima</strong>. Gradient Descent, by nature, only guarantees finding a local minimum. If we start our descent in a particular region, we might end up in a local minimum that isn’t the absolute lowest point (the <strong>global minimum</strong>). <ul> <li>In many deep learning applications, the loss landscapes are high-dimensional and complex, and getting stuck in a <em>bad</em> local minimum is less of a concern than thought before. Often, “good enough” local minima are found.</li> </ul> </li> <li> <strong>Saddle Points:</strong> These are points where the slope is zero in some directions but not in others, like a saddle. Gradient Descent can get stuck or slow down significantly at these points.</li> <li> <strong>Learning Rate Scheduling:</strong> Instead of using a fixed learning rate $ \alpha $, advanced optimizers often use a <em>learning rate schedule</em>, which adjusts $ \alpha $ over time. For example, starting with a larger $ \alpha $ to quickly get close to the minimum, then gradually decreasing it to fine-tune the solution and prevent overshooting.</li> </ul> <h3 id="why-this-matters-the-engine-of-learning">Why This Matters: The Engine of Learning</h3> <p>Gradient Descent, in its various forms, is the engine that drives most of the learning processes in machine learning. From the simplest linear regression to the most complex deep neural networks with millions of parameters, it’s the algorithm responsible for finding the optimal weights and biases that allow these models to learn from data.</p> <p>Every time you hear about a machine learning model achieving impressive results in image recognition, natural language processing, or recommendation systems, remember that behind the scenes, a form of Gradient Descent was tirelessly working, adjusting parameters, and pushing the model closer to its optimal performance.</p> <h3 id="my-reflection-a-foundational-pillar">My Reflection: A Foundational Pillar</h3> <p>For me, truly grasping Gradient Descent felt like unlocking a fundamental secret of how AI “thinks.” It demystified the process of “learning” from data into an elegant, iterative optimization problem. It’s a reminder that even the most complex systems are often built upon surprisingly intuitive mathematical principles.</p> <p>If you’re building a data science or machine learning portfolio, not only understanding but also being able to articulate the mechanics of Gradient Descent is incredibly valuable. It demonstrates a deep comprehension of the underlying algorithms, distinguishing you from someone who merely knows how to call a library function.</p> <p>Keep experimenting with different learning rates, ponder the implications of local minima, and perhaps even try to implement a simple Gradient Descent from scratch. It’s a journey well worth taking!</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/cracking-the-ai-black-box-why-explainable-ai-xai-i/">Cracking the AI Black Box: Why Explainable AI (XAI) is Our Superpower</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/the-secret-life-of-states-how-markov-chains-predic/">The Secret Life of States: How Markov Chains Predict Our Next Move (Without Remembering the Past!)</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/gradient-descent-unpacking-the-engine-of-machine-l/">Gradient Descent: Unpacking the Engine of Machine Learning</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Adarsh Nair. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/blog/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/masonry.js?v=a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/zoom.js?v=85ddb88934d28b74e78031fd54cf8308"></script> <script src="/blog/assets/js/no_defer.js?v=2781658a0a2b13ed609542042a859126"></script> <script defer src="/blog/assets/js/common.js?v=c15de51d4bb57887caa2c21988d97279"></script> <script defer src="/blog/assets/js/copy_code.js?v=c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/blog/assets/js/jupyter_new_tab.js?v=d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/blog/assets/js/mathjax-setup.js?v=a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/progress-bar.js?v=2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/blog/assets/js/vanilla-back-to-top.min.js?v=f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/blog/assets/js/search/ninja-keys.min.js?v=a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/blog/assets/js/search-setup.js?v=6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/blog/assets/js/search-data.js"></script> <script src="/blog/assets/js/shortcut-key.js?v=ccc841c459bfc0e64c1c2b5acd10df02"></script> </body> </html>