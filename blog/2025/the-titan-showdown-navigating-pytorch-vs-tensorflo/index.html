<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> The Titan Showdown: Navigating PyTorch vs. TensorFlow in Your ML Journey | Adarsh Nair </title> <meta name="author" content="Adarsh Nair"> <meta name="description" content="A deep dive into machine learning, AI, and data science. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <meta http-equiv="Content-Security-Policy" content="default-src 'self'; script-src 'self' 'unsafe-inline' https:; style-src 'self' 'unsafe-inline' https:; img-src 'self' data: https:; font-src 'self' data: https:; media-src 'self' https:; frame-src 'self' https:; connect-src 'self' https:;"> <link rel="stylesheet" href="/blog/assets/css/bootstrap.min.css?v=a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/blog/assets/css/academicons.min.css?v=f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/blog/assets/css/scholar-icons.css?v=62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-github.css?v=591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/blog/assets/css/main.css?v=d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://adarshnair.online/blog/blog/blog/2025/the-titan-showdown-navigating-pytorch-vs-tensorflo/"> <script src="/blog/assets/js/theme.js?v=5fea5159b787642c1bbc1f334d60f883"></script> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-native.css?v=5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="https://adarshnair.online" rel="external nofollow noopener" target="_blank"> Adarsh Nair </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/blog/"> </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/index.html">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/cv/">CV </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/repositories/">repositories </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="fa-solid fa-magnifying-glass"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-half-sun-moon" id="light-toggle-system"></i> <i class="fa-solid fa-moon" id="light-toggle-dark"></i> <i class="fa-solid fa-sun" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">The Titan Showdown: Navigating PyTorch vs. TensorFlow in Your ML Journey</h1> <p class="post-meta"> Created on June 24, 2025 by Adarsh Nair </p> <p class="post-tags"> <a href="/blog/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/blog/tag/machine-learning"> <i class="fa-solid fa-hashtag fa-sm"></i> Machine Learning</a>   <a href="/blog/blog/tag/deep-learning"> <i class="fa-solid fa-hashtag fa-sm"></i> Deep Learning</a>   <a href="/blog/blog/tag/pytorch"> <i class="fa-solid fa-hashtag fa-sm"></i> PyTorch</a>   <a href="/blog/blog/tag/tensorflow"> <i class="fa-solid fa-hashtag fa-sm"></i> TensorFlow</a>   <a href="/blog/blog/tag/data-science"> <i class="fa-solid fa-hashtag fa-sm"></i> Data Science</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p>Welcome, fellow adventurers, to the thrilling, sometimes perplexing, world of Machine Learning! If you’ve dipped your toes into deep learning, you’ve undoubtedly encountered the names: PyTorch and TensorFlow. These aren’t just libraries; they’re the colossal titans of the deep learning universe, each with its devoted followers, unique philosophies, and an ever-evolving landscape of features.</p> <p>When I first started my journey, the “PyTorch vs. TensorFlow” debate felt like a rite of passage. It was intimidating, like choosing between two powerful spells without fully understanding their incantations. Should I go with the established, production-ready giant backed by Google, or the dynamic, research-friendly challenger from Facebook? This isn’t just a technical decision; it’s a foundational choice that shapes your workflow, your debugging experience, and even the communities you engage with.</p> <p>So, grab a warm drink, settle in, and let’s demystify these two powerhouses. We’ll explore their inner workings, their strengths, their little quirks, and ultimately, help <em>you</em> understand which might be the better companion for your next grand project.</p> <h3 id="understanding-the-core-tensors-and-computational-graphs">Understanding the Core: Tensors and Computational Graphs</h3> <p>At the heart of both PyTorch and TensorFlow lies a fundamental concept: <strong>Tensors</strong>. Think of a tensor as a multi-dimensional array, much like a NumPy array, but with a superpower: it can live on a GPU for blazing-fast computations. A scalar is a 0-D tensor, a vector is a 1-D tensor, a matrix is a 2-D tensor, and so on. In deep learning, our data (images, text, audio) and our model’s parameters (weights, biases) are all represented as tensors.</p> <p>But how do these frameworks actually <em>do</em> deep learning, like training a neural network? They use something called a <strong>computational graph</strong>. Imagine a flowchart where each node is an operation (like addition, multiplication, ReLU activation) and the edges are the tensors flowing between these operations. This graph represents your entire neural network.</p> <h4 id="the-old-guard-tensorflows-static-graphs-and-its-evolution">The Old Guard: TensorFlow’s Static Graphs (and its Evolution)</h4> <p>Historically, TensorFlow was famous for its <strong>static computational graphs</strong>. This meant you had to define the <em>entire</em> network structure first, like drawing a complete blueprint, before you could feed any data through it.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Conceptual TensorFlow 1.x (static graph)
</span><span class="kn">import</span> <span class="n">tensorflow.compat.v1</span> <span class="k">as</span> <span class="n">tf</span>
<span class="n">tf</span><span class="p">.</span><span class="nf">disable_v2_behavior</span><span class="p">()</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">None</span><span class="p">,</span> <span class="mi">784</span><span class="p">))</span>
<span class="n">W</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nc">Variable</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="nf">zeros</span><span class="p">([</span><span class="mi">784</span><span class="p">,</span> <span class="mi">10</span><span class="p">]))</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nc">Variable</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="nf">zeros</span><span class="p">([</span><span class="mi">10</span><span class="p">]))</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">matmul</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">W</span><span class="p">)</span> <span class="o">+</span> <span class="n">b</span>

<span class="c1"># You'd then run this graph in a session, feeding data for 'x'
# with tf.Session() as sess:
#     sess.run(tf.global_variables_initializer())
#     result = sess.run(y, feed_dict={x: my_data})
</span></code></pre></div></div> <p><strong>Pros of Static Graphs:</strong></p> <ul> <li> <strong>Optimization:</strong> Once defined, the framework could optimize the entire graph for performance and memory usage <em>before</em> execution.</li> <li> <strong>Deployment:</strong> Easy to serialize and deploy the fixed graph to different environments (e.g., mobile, servers) without needing the Python code.</li> <li> <strong>Distributed Training:</strong> Easier to distribute parts of the graph across multiple devices/machines.</li> </ul> <p><strong>Cons of Static Graphs:</strong></p> <ul> <li> <strong>Debugging:</strong> Tracing errors was like debugging a compiled program; it was hard to inspect intermediate values directly within Python.</li> <li> <strong>Flexibility:</strong> Building models with dynamic control flow (e.g., sequence models where the graph structure changes based on input) was cumbersome.</li> </ul> <p>Enter <strong>TensorFlow 2.x</strong>! Google recognized the shift in the deep learning community and fully embraced <strong>Eager Execution</strong>. Now, TensorFlow operations run immediately, much like standard Python. You still build computational graphs under the hood for efficiency (using <code class="language-plaintext highlighter-rouge">tf.function</code>), but the development experience is much more intuitive and “Pythonic.” This was a HUGE leap and significantly closed the gap with PyTorch.</p> <h4 id="the-challenger-pytorchs-dynamic-graphs">The Challenger: PyTorch’s Dynamic Graphs</h4> <p>PyTorch, right from its inception, championed <strong>dynamic computational graphs</strong>, also known as “define-by-run” graphs. This means the graph is built on-the-fly as operations are executed.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># PyTorch (dynamic graph)
</span><span class="kn">import</span> <span class="n">torch</span>
<span class="kn">import</span> <span class="n">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>

<span class="c1"># Define a simple linear model
</span><span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="mi">784</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

<span class="c1"># Create a dummy input tensor
</span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">784</span><span class="p">)</span>

<span class="c1"># Forward pass: the graph is built as operations execute
</span><span class="n">y</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="c1"># Print the output immediately
</span><span class="nf">print</span><span class="p">(</span><span class="n">y</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span> <span class="c1"># torch.Size([1, 10])
</span></code></pre></div></div> <p><strong>Pros of Dynamic Graphs:</strong></p> <ul> <li> <strong>Debugging:</strong> You can use standard Python debuggers to step through your code, inspect tensors at any point, and understand exactly what’s happening. This is a game-changer for complex models.</li> <li> <strong>Flexibility:</strong> Extremely natural for models that require dynamic control flow (e.g., varying sequence lengths in RNNs, reinforcement learning policies).</li> <li> <strong>Pythonic:</strong> It feels very natural to a Python developer, almost like an accelerated NumPy.</li> </ul> <p><strong>Cons of Dynamic Graphs (historically):</strong></p> <ul> <li> <strong>Deployment:</strong> Deploying dynamic graphs to production environments could be trickier than TensorFlow’s static graphs (though <code class="language-plaintext highlighter-rouge">torch.jit</code> has largely addressed this).</li> <li> <strong>Optimization:</strong> Optimizing the entire graph at once was not as straightforward (again, <code class="language-plaintext highlighter-rouge">torch.jit</code> helps here).</li> </ul> <h3 id="autograd-the-magic-behind-learning">Autograd: The Magic Behind Learning</h3> <p>Both frameworks rely on <strong>automatic differentiation</strong> (often called Autograd in PyTorch) to train neural networks. This is crucial for backpropagation, where we calculate the gradients of our loss function with respect to our model’s parameters.</p> <p>Imagine you have a simple function $f(x) = x^2$. The derivative $f’(x) = 2x$. If $x=3$, then $f’(3) = 6$. In deep learning, our function is our neural network, and $x$ represents our weights. We want to find how much to adjust each weight to reduce the error. The calculus rule that makes this all possible is the <strong>chain rule</strong>.</p> <p>If we have a loss function $L$ that depends on the output $y$ of our network, which in turn depends on our weights $w$, we want to find $\frac{\partial L}{\partial w}$. The chain rule tells us:</p> <p>$ \frac{\partial L}{\partial w} = \frac{\partial L}{\partial y} \cdot \frac{\partial y}{\partial w} $</p> <p>Both PyTorch and TensorFlow efficiently compute these gradients for every operation in the computational graph. When you perform a forward pass, the frameworks record the operations. During the backward pass, they traverse this graph in reverse, applying the chain rule to compute gradients for all parameters. This magic allows us to update our weights using optimizers like Stochastic Gradient Descent (SGD):</p> <p>$ w<em>{new} = w</em>{old} - \alpha \cdot \frac{\partial L}{\partial w_{old}} $</p> <p>where $\alpha$ is the learning rate.</p> <h3 id="developer-experience-and-usability">Developer Experience and Usability</h3> <p>This is where personal preference often strongly comes into play.</p> <h4 id="pytorch-the-pythonic-pal">PyTorch: The Pythonic Pal</h4> <ul> <li> <strong>Feel:</strong> Many users describe PyTorch as feeling more “Pythonic” and closer to raw Python code. If you’re comfortable with NumPy, PyTorch’s tensor operations will feel very familiar.</li> <li> <strong>Ease of Debugging:</strong> As discussed, the dynamic graph makes debugging with standard Python tools (like <code class="language-plaintext highlighter-rouge">pdb</code>) incredibly straightforward. You can literally print any tensor at any point during execution.</li> <li> <strong>Learning Curve:</strong> Generally considered to have a gentler learning curve for those coming from a Python background, especially for research and rapid prototyping.</li> <li> <strong>Community:</strong> Vibrant and growing, particularly strong in the research community. New state-of-the-art models are often released with PyTorch implementations first.</li> </ul> <h4 id="tensorflow-the-ecosystem-powerhouse-with-keras">TensorFlow: The Ecosystem Powerhouse (with Keras)</h4> <ul> <li> <p><strong>Keras Integration:</strong> TensorFlow 2.x has fully integrated Keras as its high-level API. Keras is incredibly user-friendly for building and training neural networks quickly. If you’re starting out, Keras simplifies much of the boilerplate code.</p> <div class="language-python highlighter-rouge"> <div class="highlight"><pre class="highlight"><code><span class="c1"># TensorFlow with Keras
</span><span class="kn">import</span> <span class="n">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>
<span class="kn">from</span> <span class="n">tensorflow</span> <span class="kn">import</span> <span class="n">keras</span>
<span class="kn">from</span> <span class="n">tensorflow.keras</span> <span class="kn">import</span> <span class="n">layers</span>

<span class="c1"># Build a simple sequential model
</span><span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="nc">Sequential</span><span class="p">([</span>
    <span class="n">layers</span><span class="p">.</span><span class="nc">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="sh">'</span><span class="s">relu</span><span class="sh">'</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">784</span><span class="p">,)),</span>
    <span class="n">layers</span><span class="p">.</span><span class="nc">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="sh">'</span><span class="s">softmax</span><span class="sh">'</span><span class="p">)</span>
<span class="p">])</span>

<span class="n">model</span><span class="p">.</span><span class="nf">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="sh">'</span><span class="s">adam</span><span class="sh">'</span><span class="p">,</span>
              <span class="n">loss</span><span class="o">=</span><span class="sh">'</span><span class="s">sparse_categorical_crossentropy</span><span class="sh">'</span><span class="p">,</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">accuracy</span><span class="sh">'</span><span class="p">])</span>

<span class="c1"># model.fit(x_train, y_train, epochs=5)
</span></code></pre></div> </div> </li> <li> <strong>Ecosystem:</strong> TensorFlow boasts a massive ecosystem. This includes: <ul> <li> <strong>TensorBoard:</strong> A fantastic visualization tool for tracking training metrics, model graphs, and debugging.</li> <li> <strong>TensorFlow Serving:</strong> For high-performance, production serving of models.</li> <li> <strong>TensorFlow Lite:</strong> For deploying models on mobile and edge devices.</li> <li> <strong>TensorFlow.js:</strong> For running models in the browser.</li> <li> <strong>TPUs:</strong> Native support for Google’s Tensor Processing Units for extreme acceleration.</li> </ul> </li> <li> <strong>Learning Curve:</strong> Historically steeper, but Keras significantly flattens this. Mastering the full TensorFlow ecosystem still requires more effort, but it offers unparalleled power for specific use cases.</li> </ul> <h3 id="performance-and-scalability">Performance and Scalability</h3> <p>In terms of raw training speed for standard models on typical hardware (GPUs), both frameworks are remarkably comparable. Any differences are often due to specific implementation details or how efficiently operations are mapped to the hardware rather than an inherent superiority of one over the other.</p> <ul> <li> <strong>PyTorch:</strong> Has made significant strides in distributed training and performance optimization. <code class="language-plaintext highlighter-rouge">torch.jit</code> (TorchScript) allows you to compile PyTorch models into a static graph representation that can be optimized and deployed to production environments without Python.</li> <li> <strong>TensorFlow:</strong> Historically strong in large-scale distributed training due to its static graph nature. Its integration with TPUs and robust deployment tools like TF Serving make it a go-to for massive production systems.</li> </ul> <h3 id="when-to-choose-which-my-personal-take">When to Choose Which? My Personal Take</h3> <p>This is the million-dollar question, and frankly, there’s no single “right” answer. The “best” framework is the one that best suits <em>your</em> needs, <em>your</em> project, and <em>your</em> team.</p> <h4 id="choose-pytorch-if">Choose PyTorch if:</h4> <ul> <li> <strong>You prioritize flexibility and rapid prototyping.</strong> You’re experimenting with novel architectures, cutting-edge research, or models with highly dynamic control flow (e.g., custom RNNs, GANs, RL agents).</li> <li> <strong>You love Python and want a “Pythonic” deep learning experience.</strong> Debugging feels like debugging any other Python code.</li> <li> <strong>You’re deeply involved in academic research.</strong> Many new papers release PyTorch implementations, making it easier to reproduce and build upon existing work.</li> <li> <strong>You’re comfortable with a slightly lower-level API.</strong> While PyTorch has high-level modules like <code class="language-plaintext highlighter-rouge">nn.Module</code>, it exposes more of the underlying tensor operations, giving you fine-grained control.</li> </ul> <h4 id="choose-tensorflow-with-keras-if">Choose TensorFlow (with Keras) if:</h4> <ul> <li> <strong>You’re building large-scale production applications.</strong> Its robust deployment ecosystem (TF Serving, TFLite, TF.js) is unparalleled for moving models from research to real-world products.</li> <li> <strong>You want simplicity and speed of development, especially for common tasks.</strong> Keras makes building and training standard models incredibly intuitive and fast.</li> <li> <strong>You need integration with Google’s cloud ecosystem or TPUs.</strong> If you’re working with Google Cloud ML, TensorFlow is the native choice.</li> <li> <strong>You value extensive tooling for visualization, monitoring, and distributed training.</strong> TensorBoard is a fantastic resource.</li> <li><strong>You’re working in an enterprise environment where stability and long-term support are critical.</strong></li> </ul> <h3 id="the-convergence-a-beautiful-future">The Convergence: A Beautiful Future</h3> <p>It’s vital to acknowledge that the “PyTorch vs. TensorFlow” debate has softened considerably with the advent of TensorFlow 2.x. TensorFlow’s embrace of eager execution and Keras by default has made it much more user-friendly and dynamic, mirroring many of PyTorch’s strengths. Similarly, PyTorch’s <code class="language-plaintext highlighter-rouge">torch.jit</code> has significantly bolstered its production deployment story.</p> <p>They are learning from each other, converging towards a similar, highly productive developer experience while retaining their distinct philosophies and strengths.</p> <h3 id="your-journey-your-choice">Your Journey, Your Choice</h3> <p>My advice to anyone starting out, whether you’re a high school student fascinated by AI or a seasoned data scientist looking to expand your toolkit, is this: <strong>try both.</strong></p> <p>Start with Keras in TensorFlow to quickly build your first models and grasp the fundamental concepts without getting bogged down in boilerplate. Then, dive into PyTorch to experience its Pythonic flexibility and powerful debugging capabilities.</p> <p>Understanding both will make you a more versatile and adaptable machine learning practitioner. The “best” framework isn’t a fixed answer; it’s a dynamic one, evolving with your project, your skills, and the exciting new frontiers of AI.</p> <p>The real strength comes not from mastering one titan, but from understanding the powers of both, and knowing when to wield each with precision. Now, go forth and build something amazing!</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/cracking-the-ai-black-box-why-explainable-ai-xai-i/">Cracking the AI Black Box: Why Explainable AI (XAI) is Our Superpower</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/the-secret-life-of-states-how-markov-chains-predic/">The Secret Life of States: How Markov Chains Predict Our Next Move (Without Remembering the Past!)</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/gradient-descent-unpacking-the-engine-of-machine-l/">Gradient Descent: Unpacking the Engine of Machine Learning</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Adarsh Nair. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/blog/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/masonry.js?v=a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/zoom.js?v=85ddb88934d28b74e78031fd54cf8308"></script> <script src="/blog/assets/js/no_defer.js?v=2781658a0a2b13ed609542042a859126"></script> <script defer src="/blog/assets/js/common.js?v=c15de51d4bb57887caa2c21988d97279"></script> <script defer src="/blog/assets/js/copy_code.js?v=c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/blog/assets/js/jupyter_new_tab.js?v=d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/blog/assets/js/mathjax-setup.js?v=a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/progress-bar.js?v=2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/blog/assets/js/vanilla-back-to-top.min.js?v=f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/blog/assets/js/search/ninja-keys.min.js?v=a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/blog/assets/js/search-setup.js?v=6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/blog/assets/js/search-data.js"></script> <script src="/blog/assets/js/shortcut-key.js?v=ccc841c459bfc0e64c1c2b5acd10df02"></script> </body> </html>