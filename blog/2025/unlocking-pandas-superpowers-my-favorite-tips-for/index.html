<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Unlocking Pandas Superpowers: My Favorite Tips for Cleaner, Faster Data Science | Adarsh Nair </title> <meta name="author" content="Adarsh Nair"> <meta name="description" content="A deep dive into machine learning, AI, and data science. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <meta http-equiv="Content-Security-Policy" content="default-src 'self'; script-src 'self' 'unsafe-inline' https:; style-src 'self' 'unsafe-inline' https:; img-src 'self' data: https:; font-src 'self' data: https:; media-src 'self' https:; frame-src 'self' https:; connect-src 'self' https:;"> <link rel="stylesheet" href="/blog/assets/css/bootstrap.min.css?v=a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/blog/assets/css/academicons.min.css?v=f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/blog/assets/css/scholar-icons.css?v=62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-github.css?v=591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/blog/assets/css/main.css?v=d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://adarshnair.online/blog/blog/2025/unlocking-pandas-superpowers-my-favorite-tips-for/"> <script src="/blog/assets/js/theme.js?v=5fea5159b787642c1bbc1f334d60f883"></script> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-native.css?v=5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/blog/cv/"> Adarsh Nair </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/blog/"> </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/cv/">CV </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/repositories/">repositories </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="fa-solid fa-magnifying-glass"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-half-sun-moon" id="light-toggle-system"></i> <i class="fa-solid fa-moon" id="light-toggle-dark"></i> <i class="fa-solid fa-sun" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Unlocking Pandas Superpowers: My Favorite Tips for Cleaner, Faster Data Science</h1> <p class="post-meta"> Created on March 01, 2025 by Adarsh Nair </p> <p class="post-tags"> <a href="/blog/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/blog/tag/pandas"> <i class="fa-solid fa-hashtag fa-sm"></i> Pandas</a>   <a href="/blog/blog/tag/data-science"> <i class="fa-solid fa-hashtag fa-sm"></i> Data Science</a>   <a href="/blog/blog/tag/python"> <i class="fa-solid fa-hashtag fa-sm"></i> Python</a>   <a href="/blog/blog/tag/data-manipulation"> <i class="fa-solid fa-hashtag fa-sm"></i> Data Manipulation</a>   <a href="/blog/blog/tag/performance"> <i class="fa-solid fa-hashtag fa-sm"></i> Performance</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p>Hey everyone!</p> <p>If you’re anything like me, your journey into data science probably started with Python, and quickly, you met Pandas. It’s the workhorse, the unsung hero, the Swiss Army knife for data manipulation. But let’s be honest, sometimes Pandas can feel like a labyrinth of methods and parameters, right?</p> <p>I remember struggling with slow operations, messy code, and trying to remember which function did what. Over time, through countless projects and a lot of head-scratching, I’ve picked up some tricks that have genuinely transformed my data workflow. These aren’t just “syntax hacks”; they’re deeper insights into how Pandas works and how to leverage its power most effectively.</p> <p>So, whether you’re just starting out in your data journey, diving deep into Machine Learning Engineering (MLE) tasks, or a seasoned pro looking for a fresh perspective, I hope these tips from my own “data journal” help you unlock some Pandas superpowers!</p> <hr> <h3 id="tip-1-vectorization-is-your-best-friend-and-when-to-use-apply">Tip 1: Vectorization is Your Best Friend (and When to Use <code class="language-plaintext highlighter-rouge">apply()</code>)</h3> <p>This is probably the most crucial performance tip in Pandas. When you start working with larger datasets, iterating row-by-row can become agonizingly slow. This is where <strong>vectorization</strong> comes in.</p> <p><strong>The Problem:</strong> You have a DataFrame and you need to perform an operation on one or more columns. Your first instinct might be to use a loop or the <code class="language-plaintext highlighter-rouge">.apply()</code> method with a custom function.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">time</span>

<span class="c1"># Create a large DataFrame
</span><span class="n">df_perf</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">({</span><span class="sh">'</span><span class="s">A</span><span class="sh">'</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">rand</span><span class="p">(</span><span class="mi">1_000_000</span><span class="p">),</span> <span class="sh">'</span><span class="s">B</span><span class="sh">'</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">rand</span><span class="p">(</span><span class="mi">1_000_000</span><span class="p">)})</span>

<span class="k">def</span> <span class="nf">custom_func</span><span class="p">(</span><span class="n">row</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">row</span><span class="p">[</span><span class="sh">'</span><span class="s">A</span><span class="sh">'</span><span class="p">]</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">+</span> <span class="n">row</span><span class="p">[</span><span class="sh">'</span><span class="s">B</span><span class="sh">'</span><span class="p">]</span> <span class="o">/</span> <span class="mi">3</span>

<span class="c1"># Method 1: Using apply() on rows (generally slow)
</span><span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span>
<span class="c1"># df_perf['C_apply_row'] = df_perf.apply(custom_func, axis=1) # Uncomment to run
</span><span class="n">end_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span>
<span class="c1"># print(f"apply(axis=1) took: {end_time - start_time:.4f} seconds")
</span>
<span class="c1"># Method 2: Using apply() on a column (better, but still not optimal for simple ops)
</span><span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span>
<span class="c1"># df_perf['C_apply_col'] = df_perf['A'].apply(lambda x: x * 2) # Uncomment to run
</span><span class="n">end_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span>
<span class="c1"># print(f"apply(lambda x) took: {end_time - start_time:.4f} seconds")
</span>
<span class="c1"># Method 3: Vectorized operation (the fastest!)
</span><span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span>
<span class="n">df_perf</span><span class="p">[</span><span class="sh">'</span><span class="s">C_vectorized</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_perf</span><span class="p">[</span><span class="sh">'</span><span class="s">A</span><span class="sh">'</span><span class="p">]</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">+</span> <span class="n">df_perf</span><span class="p">[</span><span class="sh">'</span><span class="s">B</span><span class="sh">'</span><span class="p">]</span> <span class="o">/</span> <span class="mi">3</span>
<span class="n">end_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Vectorized operation took: </span><span class="si">{</span><span class="n">end_time</span> <span class="o">-</span> <span class="n">start_time</span><span class="si">:</span><span class="p">.</span><span class="mi">4</span><span class="n">f</span><span class="si">}</span><span class="s"> seconds</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <p><em>(When I run the commented-out <code class="language-plaintext highlighter-rouge">apply</code> methods for 1,000,000 rows, <code class="language-plaintext highlighter-rouge">apply(axis=1)</code> takes ~20 seconds, <code class="language-plaintext highlighter-rouge">apply(lambda x)</code> takes ~0.2 seconds, and the vectorized operation takes ~0.02 seconds!)</em></p> <p><strong>Explanation:</strong> Pandas and NumPy operations are often implemented in highly optimized C code under the hood. When you use <code class="language-plaintext highlighter-rouge">df['A'] * 2</code>, Pandas processes the <em>entire column</em> at once using these optimized routines, which is incredibly fast. When you use <code class="language-plaintext highlighter-rouge">apply()</code>, especially with <code class="language-plaintext highlighter-rouge">axis=1</code> (row-wise), you’re essentially telling Pandas to iterate over your DataFrame in a Python loop, which is much slower because Python loops are not pre-compiled like NumPy/Pandas functions.</p> <p><strong>When to use <code class="language-plaintext highlighter-rouge">apply()</code>:</strong> Don’t get me wrong, <code class="language-plaintext highlighter-rouge">apply()</code> isn’t evil! It’s indispensable when your operation is genuinely complex and cannot be expressed using vectorized functions. This includes:</p> <ul> <li>Calling a function that operates on an entire row or groups of rows, involving conditional logic across multiple columns.</li> <li>Applying a custom function from a third-party library that doesn’t have a vectorized equivalent.</li> <li>Operations that involve complex string manipulation or regex patterns on each element.</li> </ul> <p><strong>Key takeaway:</strong> Always try to find a vectorized solution first. If you can’t, then <code class="language-plaintext highlighter-rouge">apply()</code> is your go-to.</p> <hr> <h3 id="tip-2-chaining-operations-with-pipe-for-cleaner-code">Tip 2: Chaining Operations with <code class="language-plaintext highlighter-rouge">pipe()</code> for Cleaner Code</h3> <p>As your data cleaning and feature engineering pipelines grow, you might find yourself writing lots of intermediate steps, assigning them to new variables, or nesting function calls in a hard-to-read way. This is where <code class="language-plaintext highlighter-rouge">df.pipe()</code> shines.</p> <p><strong>The Problem:</strong> You have a sequence of operations, each taking a DataFrame and returning a modified DataFrame.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">add_squared_column</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">column_name</span><span class="p">):</span>
    <span class="n">df</span><span class="p">[</span><span class="sa">f</span><span class="sh">'</span><span class="si">{</span><span class="n">column_name</span><span class="si">}</span><span class="s">_squared</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">column_name</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span>
    <span class="k">return</span> <span class="n">df</span>

<span class="k">def</span> <span class="nf">subtract_mean_from_column</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">column_name</span><span class="p">):</span>
    <span class="n">df</span><span class="p">[</span><span class="n">column_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">column_name</span><span class="p">]</span> <span class="o">-</span> <span class="n">df</span><span class="p">[</span><span class="n">column_name</span><span class="p">].</span><span class="nf">mean</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">df</span>

<span class="k">def</span> <span class="nf">filter_positive_values</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">column_name</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="n">column_name</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">]</span>

<span class="n">df_data</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">({</span><span class="sh">'</span><span class="s">A</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="sh">'</span><span class="s">B</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">40</span><span class="p">]})</span>

<span class="c1"># Without pipe - multiple assignments or messy chaining
# df_temp = add_squared_column(df_data.copy(), 'A')
# df_temp2 = subtract_mean_from_column(df_temp, 'B')
# final_df_ugly = filter_positive_values(df_temp2, 'A_squared')
</span>
<span class="c1"># With pipe - clean and readable!
</span><span class="n">final_df_clean</span> <span class="o">=</span> <span class="p">(</span><span class="n">df_data</span><span class="p">.</span><span class="nf">copy</span><span class="p">()</span>
                  <span class="p">.</span><span class="nf">pipe</span><span class="p">(</span><span class="n">add_squared_column</span><span class="p">,</span> <span class="sh">'</span><span class="s">A</span><span class="sh">'</span><span class="p">)</span>
                  <span class="p">.</span><span class="nf">pipe</span><span class="p">(</span><span class="n">subtract_mean_from_column</span><span class="p">,</span> <span class="sh">'</span><span class="s">B</span><span class="sh">'</span><span class="p">)</span>
                  <span class="p">.</span><span class="nf">pipe</span><span class="p">(</span><span class="n">filter_positive_values</span><span class="p">,</span> <span class="sh">'</span><span class="s">A_squared</span><span class="sh">'</span><span class="p">))</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Original DataFrame:</span><span class="se">\n</span><span class="sh">"</span><span class="p">,</span> <span class="n">df_data</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="se">\n</span><span class="s">Processed DataFrame with pipe():</span><span class="se">\n</span><span class="sh">"</span><span class="p">,</span> <span class="n">final_df_clean</span><span class="p">)</span>
</code></pre></div></div> <p><strong>Explanation:</strong> The <code class="language-plaintext highlighter-rouge">pipe()</code> method passes the DataFrame itself as the <em>first argument</em> to the function you provide. This allows you to chain custom functions in a very readable, sequential manner, similar to how you chain built-in Pandas methods like <code class="language-plaintext highlighter-rouge">.groupby().agg().reset_index()</code>. It makes your data transformation steps explicit and easy to follow, almost like reading a recipe.</p> <p><strong>Pro Tip:</strong> Your custom functions used with <code class="language-plaintext highlighter-rouge">pipe()</code> should always return a DataFrame!</p> <hr> <h3 id="tip-3-unpacking-list-like-entries-with-explode">Tip 3: Unpacking List-like Entries with <code class="language-plaintext highlighter-rouge">explode()</code> </h3> <p>Sometimes your data isn’t perfectly flat. You might have a column where each cell contains a list, tuple, or even a set of items. Traditionally, handling this meant complex loops or <code class="language-plaintext highlighter-rouge">apply()</code> methods, often resulting in messy code. Enter <code class="language-plaintext highlighter-rouge">df.explode()</code>.</p> <p><strong>The Problem:</strong> You have a column with list-like entries, and you want each item in the list to become a separate row, duplicating the other column values.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df_skills</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">({</span>
    <span class="sh">'</span><span class="s">Name</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span><span class="sh">'</span><span class="s">Alice</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Bob</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Charlie</span><span class="sh">'</span><span class="p">],</span>
    <span class="sh">'</span><span class="s">Skills</span><span class="sh">'</span><span class="p">:</span> <span class="p">[[</span><span class="sh">'</span><span class="s">Python</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">SQL</span><span class="sh">'</span><span class="p">],</span> <span class="p">[</span><span class="sh">'</span><span class="s">R</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Java</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Python</span><span class="sh">'</span><span class="p">],</span> <span class="p">[</span><span class="sh">'</span><span class="s">Excel</span><span class="sh">'</span><span class="p">]]</span>
<span class="p">})</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Original DataFrame:</span><span class="se">\n</span><span class="sh">"</span><span class="p">,</span> <span class="n">df_skills</span><span class="p">)</span>

<span class="c1"># Using explode()
</span><span class="n">df_exploded</span> <span class="o">=</span> <span class="n">df_skills</span><span class="p">.</span><span class="nf">explode</span><span class="p">(</span><span class="sh">'</span><span class="s">Skills</span><span class="sh">'</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="se">\n</span><span class="s">Exploded DataFrame:</span><span class="se">\n</span><span class="sh">"</span><span class="p">,</span> <span class="n">df_exploded</span><span class="p">)</span>
</code></pre></div></div> <p><strong>Explanation:</strong> <code class="language-plaintext highlighter-rouge">explode()</code> transforms each element of a list-like entry into a separate row, effectively “unstacking” the data. The index and all other column values are duplicated for each new row. This is incredibly useful for:</p> <ul> <li>Analyzing individual tags or categories when a single entry can have multiple.</li> <li>Preparing data for text analysis where each word/phrase needs to be on its own row.</li> <li>Working with datasets where one-to-many relationships are stored within a single cell.</li> </ul> <p><strong>Note:</strong> <code class="language-plaintext highlighter-rouge">explode()</code> was introduced in Pandas 0.25.0, so make sure your Pandas version is up to date!</p> <hr> <h3 id="tip-4-efficient-categorical-data-for-memory-and-speed">Tip 4: Efficient Categorical Data for Memory and Speed</h3> <p>Data scientists often deal with categorical data (e.g., ‘country’, ‘product_type’, ‘gender’). Storing these as generic Python strings (<code class="language-plaintext highlighter-rouge">object</code> dtype in Pandas) can consume a lot of memory, especially with many unique values or large datasets. Converting them to Pandas’ <code class="language-plaintext highlighter-rouge">category</code> dtype can lead to massive memory savings and performance boosts.</p> <p><strong>The Problem:</strong> Your DataFrame is large, and you have many columns with repetitive string values.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df_large</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">({</span>
    <span class="sh">'</span><span class="s">product_id</span><span class="sh">'</span><span class="p">:</span> <span class="nf">range</span><span class="p">(</span><span class="mi">1_000_000</span><span class="p">),</span>
    <span class="sh">'</span><span class="s">country</span><span class="sh">'</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">choice</span><span class="p">([</span><span class="sh">'</span><span class="s">USA</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Canada</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Mexico</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Germany</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">France</span><span class="sh">'</span><span class="p">],</span> <span class="mi">1_000_000</span><span class="p">),</span>
    <span class="sh">'</span><span class="s">product_type</span><span class="sh">'</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">choice</span><span class="p">([</span><span class="sh">'</span><span class="s">Electronics</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Books</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Clothing</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Food</span><span class="sh">'</span><span class="p">],</span> <span class="mi">1_000_000</span><span class="p">),</span>
    <span class="sh">'</span><span class="s">price</span><span class="sh">'</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">rand</span><span class="p">(</span><span class="mi">1_000_000</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span>
<span class="p">})</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Memory usage before optimization:</span><span class="sh">"</span><span class="p">)</span>
<span class="n">df_large</span><span class="p">.</span><span class="nf">info</span><span class="p">(</span><span class="n">memory_usage</span><span class="o">=</span><span class="sh">'</span><span class="s">deep</span><span class="sh">'</span><span class="p">)</span> <span class="c1"># 'deep' accounts for actual string sizes
</span>
<span class="c1"># Optimize using 'category' dtype
</span><span class="n">df_large</span><span class="p">[</span><span class="sh">'</span><span class="s">country</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_large</span><span class="p">[</span><span class="sh">'</span><span class="s">country</span><span class="sh">'</span><span class="p">].</span><span class="nf">astype</span><span class="p">(</span><span class="sh">'</span><span class="s">category</span><span class="sh">'</span><span class="p">)</span>
<span class="n">df_large</span><span class="p">[</span><span class="sh">'</span><span class="s">product_type</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_large</span><span class="p">[</span><span class="sh">'</span><span class="s">product_type</span><span class="sh">'</span><span class="p">].</span><span class="nf">astype</span><span class="p">(</span><span class="sh">'</span><span class="s">category</span><span class="sh">'</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="se">\n</span><span class="s">Memory usage after optimization:</span><span class="sh">"</span><span class="p">)</span>
<span class="n">df_large</span><span class="p">.</span><span class="nf">info</span><span class="p">(</span><span class="n">memory_usage</span><span class="o">=</span><span class="sh">'</span><span class="s">deep</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div> <p><strong>Explanation:</strong> When you convert a column to the <code class="language-plaintext highlighter-rouge">category</code> dtype, Pandas stores the unique values once (the “categories”) and then represents each entry in the column as a small integer code referencing these categories. For example, if you have 1 million rows and only 5 unique countries, Pandas only needs to store the 5 country names once, plus 1 million small integers (e.g., <code class="language-plaintext highlighter-rouge">0, 1, 2, 3, 4</code>). This is much more memory-efficient than storing 1 million potentially long string objects.</p> <p><strong>Benefits:</strong></p> <ul> <li> <strong>Memory Savings:</strong> Significant, especially for columns with low cardinality (few unique values).</li> <li> <strong>Faster Operations:</strong> Many Pandas string operations become faster because they operate on integers internally. Group-by operations, sorting, and selections can also see speedups.</li> <li> <strong>Integration with ML:</strong> Many machine learning libraries (like scikit-learn) work directly with categorical data or have efficient encoders for it.</li> </ul> <p><strong>When to use <code class="language-plaintext highlighter-rouge">factorize()</code>:</strong> If you only need the underlying integer codes for a column (e.g., for certain ML algorithms) and don’t need the full <code class="language-plaintext highlighter-rouge">category</code> dtype benefits, <code class="language-plaintext highlighter-rouge">pd.factorize()</code> is a quick way to get them: <code class="language-plaintext highlighter-rouge">codes, uniques = pd.factorize(df['country'])</code> Here, <code class="language-plaintext highlighter-rouge">codes</code> will be a NumPy array of integers, and <code class="language-plaintext highlighter-rouge">uniques</code> will be a NumPy array of the unique string values corresponding to those codes.</p> <hr> <h3 id="tip-5-binning-data-with-pdcut-and-pdqcut">Tip 5: Binning Data with <code class="language-plaintext highlighter-rouge">pd.cut()</code> and <code class="language-plaintext highlighter-rouge">pd.qcut()</code> </h3> <p>Turning continuous numerical data into discrete bins (categories) is a common preprocessing step in data science. It can help simplify analysis, handle outliers, and prepare data for certain algorithms. Pandas offers two powerful functions for this: <code class="language-plaintext highlighter-rouge">pd.cut()</code> and <code class="language-plaintext highlighter-rouge">pd.qcut()</code>.</p> <p><strong>The Problem:</strong> You have a numerical column (e.g., age, income, scores) and you want to group values into ranges or quantiles.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df_scores</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">({</span><span class="sh">'</span><span class="s">StudentID</span><span class="sh">'</span><span class="p">:</span> <span class="nf">range</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span> <span class="sh">'</span><span class="s">Score</span><span class="sh">'</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">randint</span><span class="p">(</span><span class="mi">40</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">10</span><span class="p">)})</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Original Scores:</span><span class="se">\n</span><span class="sh">"</span><span class="p">,</span> <span class="n">df_scores</span><span class="p">)</span>

<span class="c1"># Using pd.cut() for fixed-width bins (or custom bins)
# We define the boundaries explicitly
</span><span class="n">bins</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">60</span><span class="p">,</span> <span class="mi">70</span><span class="p">,</span> <span class="mi">80</span><span class="p">,</span> <span class="mi">90</span><span class="p">,</span> <span class="mi">100</span><span class="p">]</span>
<span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="sh">'</span><span class="s">Fail</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">D</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">C</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">B</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">A</span><span class="sh">'</span><span class="p">]</span>
<span class="n">df_scores</span><span class="p">[</span><span class="sh">'</span><span class="s">Grade_Cut</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">cut</span><span class="p">(</span><span class="n">df_scores</span><span class="p">[</span><span class="sh">'</span><span class="s">Score</span><span class="sh">'</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="n">bins</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span> <span class="c1"># right=False makes bins like [0, 60), [60, 70)
</span>
<span class="c1"># Using pd.qcut() for quantile-based bins
# Each bin will have roughly the same number of observations
</span><span class="n">df_scores</span><span class="p">[</span><span class="sh">'</span><span class="s">Score_Quartile</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">qcut</span><span class="p">(</span><span class="n">df_scores</span><span class="p">[</span><span class="sh">'</span><span class="s">Score</span><span class="sh">'</span><span class="p">],</span> <span class="n">q</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">Bottom 25%</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">25-50%</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">50-75%</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Top 25%</span><span class="sh">'</span><span class="p">])</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="se">\n</span><span class="s">Scores with Fixed Bins (cut):</span><span class="se">\n</span><span class="sh">"</span><span class="p">,</span> <span class="n">df_scores</span><span class="p">[[</span><span class="sh">'</span><span class="s">Score</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Grade_Cut</span><span class="sh">'</span><span class="p">]])</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="se">\n</span><span class="s">Scores with Quantile Bins (qcut):</span><span class="se">\n</span><span class="sh">"</span><span class="p">,</span> <span class="n">df_scores</span><span class="p">[[</span><span class="sh">'</span><span class="s">Score</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Score_Quartile</span><span class="sh">'</span><span class="p">]])</span>
</code></pre></div></div> <p><strong>Explanation:</strong></p> <ul> <li> <p><strong><code class="language-plaintext highlighter-rouge">pd.cut(data, bins, labels=None, right=True)</code>:</strong> This function is for when you want to define your bin edges explicitly. For instance, creating age groups like “0-18”, “19-35”, “36-60”, “60+”. You provide a list of numbers that define the boundaries. <code class="language-plaintext highlighter-rouge">right=True</code> means the bin includes the rightmost edge (e.g., <code class="language-plaintext highlighter-rouge">(10, 20]</code> means <code class="language-plaintext highlighter-rouge">&gt;10</code> and <code class="language-plaintext highlighter-rouge">&lt;=20</code>).</p> </li> <li> <p><strong><code class="language-plaintext highlighter-rouge">pd.qcut(data, q, labels=None, duplicates='raise')</code>:</strong> This function is for when you want each bin to have approximately the same number of observations (equal frequency). You specify the number of quantiles <code class="language-plaintext highlighter-rouge">q</code> (e.g., <code class="language-plaintext highlighter-rouge">q=4</code> for quartiles, <code class="language-plaintext highlighter-rouge">q=10</code> for deciles). <code class="language-plaintext highlighter-rouge">qcut</code> dynamically determines the bin edges to achieve equal frequency. This is useful for percentile-based ranking or creating balanced groups.</p> </li> </ul> <p><strong>Mathematical Note:</strong> For <code class="language-plaintext highlighter-rouge">pd.cut</code>, if you have bins $B = [b_0, b_1, \ldots, b_n]$, then a value $x$ falls into the bin $(b_i, b_{i+1}]$ (if <code class="language-plaintext highlighter-rouge">right=True</code>) or $[b_i, b_{i+1})$ (if <code class="language-plaintext highlighter-rouge">right=False</code>). For <code class="language-plaintext highlighter-rouge">pd.qcut</code>, if $q$ quantiles are desired, Pandas will find $q-1$ cut points $c_1, c_2, \ldots, c_{q-1}$ such that approximately $1/q$ of the data falls between $c_i$ and $c_{i+1}$.</p> <hr> <h3 id="tip-6-reshaping-data-with-melt-and-pivot_table">Tip 6: Reshaping Data with <code class="language-plaintext highlighter-rouge">melt()</code> and <code class="language-plaintext highlighter-rouge">pivot_table()</code> </h3> <p>Data often comes in various formats, and sometimes you need to reshape it to suit your analysis or model requirements. <code class="language-plaintext highlighter-rouge">melt()</code> and <code class="language-plaintext highlighter-rouge">pivot_table()</code> are two fundamental functions for transforming data between “wide” and “long” formats.</p> <p><strong>The Problem:</strong> Your data is either too “wide” (many columns representing similar measurements) or too “long” (multiple rows for the same entity) for your needs.</p> <h4 id="melt-from-wide-to-long"> <code class="language-plaintext highlighter-rouge">melt()</code>: From Wide to Long</h4> <p>Imagine you have sales data where each product’s sales for a month are in separate columns. For plotting or certain analyses, you might want a single ‘Product’ column and a single ‘Sales’ column.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data_wide</span> <span class="o">=</span> <span class="p">{</span>
    <span class="sh">'</span><span class="s">Region</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span><span class="sh">'</span><span class="s">East</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">West</span><span class="sh">'</span><span class="p">],</span>
    <span class="sh">'</span><span class="s">Sales_Q1</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span><span class="mi">100</span><span class="p">,</span> <span class="mi">150</span><span class="p">],</span>
    <span class="sh">'</span><span class="s">Sales_Q2</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span><span class="mi">120</span><span class="p">,</span> <span class="mi">160</span><span class="p">],</span>
    <span class="sh">'</span><span class="s">Sales_Q3</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span><span class="mi">110</span><span class="p">,</span> <span class="mi">170</span><span class="p">]</span>
<span class="p">}</span>
<span class="n">df_wide</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">data_wide</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Wide Format (Original):</span><span class="se">\n</span><span class="sh">"</span><span class="p">,</span> <span class="n">df_wide</span><span class="p">)</span>

<span class="c1"># Using melt() to go from wide to long
</span><span class="n">df_long</span> <span class="o">=</span> <span class="n">df_wide</span><span class="p">.</span><span class="nf">melt</span><span class="p">(</span>
    <span class="n">id_vars</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">Region</span><span class="sh">'</span><span class="p">],</span>         <span class="c1"># Columns to keep as identifier variables
</span>    <span class="n">var_name</span><span class="o">=</span><span class="sh">'</span><span class="s">Quarter</span><span class="sh">'</span><span class="p">,</span>         <span class="c1"># Name for the new column holding the original column headers
</span>    <span class="n">value_name</span><span class="o">=</span><span class="sh">'</span><span class="s">Sales</span><span class="sh">'</span>          <span class="c1"># Name for the new column holding the values
</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="se">\n</span><span class="s">Long Format (Melted):</span><span class="se">\n</span><span class="sh">"</span><span class="p">,</span> <span class="n">df_long</span><span class="p">)</span>
</code></pre></div></div> <p><strong>Explanation:</strong> <code class="language-plaintext highlighter-rouge">melt()</code> “unpivots” your data. It takes specified identifier columns (<code class="language-plaintext highlighter-rouge">id_vars</code>) and converts all other columns (the “value columns”) into rows. The original column names become values in a new <code class="language-plaintext highlighter-rouge">var_name</code> column, and their corresponding data become values in a new <code class="language-plaintext highlighter-rouge">value_name</code> column.</p> <h4 id="pivot_table-from-long-to-wide"> <code class="language-plaintext highlighter-rouge">pivot_table()</code>: From Long to Wide</h4> <p>Now, let’s reverse the process. If you have data in a long format (e.g., transaction data with dates, products, and quantities), you might want to see product quantities summarized by date as columns.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data_long</span> <span class="o">=</span> <span class="p">{</span>
    <span class="sh">'</span><span class="s">Date</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span><span class="sh">'</span><span class="s">2023-01-01</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">2023-01-01</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">2023-01-02</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">2023-01-02</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">2023-01-02</span><span class="sh">'</span><span class="p">],</span>
    <span class="sh">'</span><span class="s">Product</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span><span class="sh">'</span><span class="s">A</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">B</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">A</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">B</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">C</span><span class="sh">'</span><span class="p">],</span>
    <span class="sh">'</span><span class="s">Quantity</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
<span class="p">}</span>
<span class="n">df_long_pivot</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">data_long</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="se">\n</span><span class="s">Long Format (Original for Pivot):</span><span class="se">\n</span><span class="sh">"</span><span class="p">,</span> <span class="n">df_long_pivot</span><span class="p">)</span>

<span class="c1"># Using pivot_table() to go from long to wide
</span><span class="n">df_pivot</span> <span class="o">=</span> <span class="n">df_long_pivot</span><span class="p">.</span><span class="nf">pivot_table</span><span class="p">(</span>
    <span class="n">index</span><span class="o">=</span><span class="sh">'</span><span class="s">Date</span><span class="sh">'</span><span class="p">,</span>       <span class="c1"># Column(s) to make new index
</span>    <span class="n">columns</span><span class="o">=</span><span class="sh">'</span><span class="s">Product</span><span class="sh">'</span><span class="p">,</span>  <span class="c1"># Column(s) to make new columns
</span>    <span class="n">values</span><span class="o">=</span><span class="sh">'</span><span class="s">Quantity</span><span class="sh">'</span><span class="p">,</span>  <span class="c1"># Column to aggregate
</span>    <span class="n">aggfunc</span><span class="o">=</span><span class="sh">'</span><span class="s">sum</span><span class="sh">'</span><span class="p">,</span>      <span class="c1"># How to aggregate if multiple values (e.g., sum, mean, count)
</span>    <span class="n">fill_value</span><span class="o">=</span><span class="mi">0</span>        <span class="c1"># Value to fill NaNs created by pivoting
</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="se">\n</span><span class="s">Wide Format (Pivoted):</span><span class="se">\n</span><span class="sh">"</span><span class="p">,</span> <span class="n">df_pivot</span><span class="p">)</span>
</code></pre></div></div> <p><strong>Explanation:</strong> <code class="language-plaintext highlighter-rouge">pivot_table()</code> “pivots” your data. You define:</p> <ul> <li> <code class="language-plaintext highlighter-rouge">index</code>: The column(s) that will become the new DataFrame index (rows).</li> <li> <code class="language-plaintext highlighter-rouge">columns</code>: The column(s) whose unique values will become new column headers.</li> <li> <code class="language-plaintext highlighter-rouge">values</code>: The column(s) whose values will populate the new DataFrame cells.</li> <li> <code class="language-plaintext highlighter-rouge">aggfunc</code>: How to aggregate the <code class="language-plaintext highlighter-rouge">values</code> if there are multiple entries for a given <code class="language-plaintext highlighter-rouge">index</code>-<code class="language-plaintext highlighter-rouge">columns</code> combination (e.g., sum them, average them, count them).</li> </ul> <p>These two functions are incredibly powerful for feature engineering and preparing data for different types of analysis or visualization.</p> <hr> <h3 id="tip-7-optimizing-memory-usage-with-smaller-dtypes">Tip 7: Optimizing Memory Usage with Smaller Dtypes</h3> <p>Following up on the categorical data tip, it’s not just strings that can hog memory. Numerical data types can also be unnecessarily large. By default, Pandas often uses <code class="language-plaintext highlighter-rouge">int64</code> for integers and <code class="language-plaintext highlighter-rouge">float64</code> for floating-point numbers. While safe, these can be overkill if your numbers don’t require such a large range or precision.</p> <p><strong>The Problem:</strong> Your DataFrame consumes too much RAM, potentially leading to slow processing or even out-of-memory errors on large datasets.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df_heavy</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">({</span>
    <span class="sh">'</span><span class="s">small_int</span><span class="sh">'</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">1_000_000</span><span class="p">),</span> <span class="c1"># numbers from 0 to 99
</span>    <span class="sh">'</span><span class="s">medium_int</span><span class="sh">'</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">50000</span><span class="p">,</span> <span class="mi">1_000_000</span><span class="p">),</span> <span class="c1"># numbers from 0 to 49999
</span>    <span class="sh">'</span><span class="s">float_val</span><span class="sh">'</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">rand</span><span class="p">(</span><span class="mi">1_000_000</span><span class="p">)</span> <span class="o">*</span> <span class="mi">10</span> <span class="c1"># float with small range
</span><span class="p">})</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Memory usage before optimization:</span><span class="sh">"</span><span class="p">)</span>
<span class="n">df_heavy</span><span class="p">.</span><span class="nf">info</span><span class="p">(</span><span class="n">memory_usage</span><span class="o">=</span><span class="sh">'</span><span class="s">deep</span><span class="sh">'</span><span class="p">)</span>

<span class="c1"># Optimize dtypes
</span><span class="n">df_heavy</span><span class="p">[</span><span class="sh">'</span><span class="s">small_int</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_heavy</span><span class="p">[</span><span class="sh">'</span><span class="s">small_int</span><span class="sh">'</span><span class="p">].</span><span class="nf">astype</span><span class="p">(</span><span class="sh">'</span><span class="s">int8</span><span class="sh">'</span><span class="p">)</span>    <span class="c1"># range -128 to 127
</span><span class="n">df_heavy</span><span class="p">[</span><span class="sh">'</span><span class="s">medium_int</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_heavy</span><span class="p">[</span><span class="sh">'</span><span class="s">medium_int</span><span class="sh">'</span><span class="p">].</span><span class="nf">astype</span><span class="p">(</span><span class="sh">'</span><span class="s">int16</span><span class="sh">'</span><span class="p">)</span> <span class="c1"># range -32768 to 32767
</span><span class="n">df_heavy</span><span class="p">[</span><span class="sh">'</span><span class="s">float_val</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_heavy</span><span class="p">[</span><span class="sh">'</span><span class="s">float_val</span><span class="sh">'</span><span class="p">].</span><span class="nf">astype</span><span class="p">(</span><span class="sh">'</span><span class="s">float32</span><span class="sh">'</span><span class="p">)</span> <span class="c1"># uses half memory of float64
</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="se">\n</span><span class="s">Memory usage after optimization:</span><span class="sh">"</span><span class="p">)</span>
<span class="n">df_heavy</span><span class="p">.</span><span class="nf">info</span><span class="p">(</span><span class="n">memory_usage</span><span class="o">=</span><span class="sh">'</span><span class="s">deep</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div> <p><strong>Explanation:</strong></p> <ul> <li> <code class="language-plaintext highlighter-rouge">int8</code>: Stores integers from -128 to 127. (1 byte per value)</li> <li> <code class="language-plaintext highlighter-rouge">int16</code>: Stores integers from -32,768 to 32,767. (2 bytes per value)</li> <li> <code class="language-plaintext highlighter-rouge">int32</code>: Stores integers from -2,147,483,648 to 2,147,483,647. (4 bytes per value)</li> <li> <code class="language-plaintext highlighter-rouge">int64</code>: Default, stores very large integers. (8 bytes per value)</li> </ul> <p>Similarly for floats:</p> <ul> <li> <code class="language-plaintext highlighter-rouge">float32</code>: Single-precision float. (4 bytes per value)</li> <li> <code class="language-plaintext highlighter-rouge">float64</code>: Default, double-precision float. (8 bytes per value)</li> </ul> <p>By selecting the smallest possible dtype that can still accurately represent your data, you can significantly reduce memory footprint. This is crucial for working with datasets that barely fit into memory, and it can also speed up operations because less data needs to be moved around.</p> <hr> <h3 id="conclusion-your-pandas-journey-continues">Conclusion: Your Pandas Journey Continues!</h3> <p>Pandas is a rich library, and these tips are just the tip of the iceberg. What I’ve shared today are strategies I’ve found to be profoundly impactful in writing more efficient, readable, and robust data manipulation code. From understanding the power of vectorization to artfully reshaping your data and optimizing memory, each tip builds towards becoming a more confident and effective data scientist.</p> <p>The best way to master Pandas (or any library) is to experiment, try different approaches, and actively seek out new ways to solve problems. Don’t be afraid to break things and then fix them! The more you play with data, the more intuitive these “superpowers” will become.</p> <p>What are your favorite Pandas tips? I’d love to hear them! Happy data wrangling!</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/cracking-the-ai-black-box-why-explainable-ai-xai-i/">Cracking the AI Black Box: Why Explainable AI (XAI) is Our Superpower</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/the-secret-life-of-states-how-markov-chains-predic/">The Secret Life of States: How Markov Chains Predict Our Next Move (Without Remembering the Past!)</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/gradient-descent-unpacking-the-engine-of-machine-l/">Gradient Descent: Unpacking the Engine of Machine Learning</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Adarsh Nair. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/blog/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/masonry.js?v=a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/zoom.js?v=85ddb88934d28b74e78031fd54cf8308"></script> <script src="/blog/assets/js/no_defer.js?v=2781658a0a2b13ed609542042a859126"></script> <script defer src="/blog/assets/js/common.js?v=c15de51d4bb57887caa2c21988d97279"></script> <script defer src="/blog/assets/js/copy_code.js?v=c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/blog/assets/js/jupyter_new_tab.js?v=d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/blog/assets/js/mathjax-setup.js?v=a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/progress-bar.js?v=2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/blog/assets/js/vanilla-back-to-top.min.js?v=f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/blog/assets/js/search/ninja-keys.min.js?v=a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/blog/assets/js/search-setup.js?v=6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/blog/assets/js/search-data.js"></script> <script src="/blog/assets/js/shortcut-key.js?v=ccc841c459bfc0e64c1c2b5acd10df02"></script> </body> </html>