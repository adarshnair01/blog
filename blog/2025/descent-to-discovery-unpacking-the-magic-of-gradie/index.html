<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Descent to Discovery: Unpacking the Magic of Gradient Descent | Adarsh Nair </title> <meta name="author" content="Adarsh Nair"> <meta name="description" content="A deep dive into machine learning, AI, and data science. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <meta http-equiv="Content-Security-Policy" content="default-src 'self'; script-src 'self' 'unsafe-inline' https:; style-src 'self' 'unsafe-inline' https:; img-src 'self' data: https:; font-src 'self' data: https:; media-src 'self' https:; frame-src 'self' https:; connect-src 'self' https:;"> <link rel="stylesheet" href="/blog/assets/css/bootstrap.min.css?v=a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/blog/assets/css/academicons.min.css?v=f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/blog/assets/css/scholar-icons.css?v=62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-github.css?v=591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/blog/assets/css/main.css?v=d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://adarshnair.online/blog/blog/blog/2025/descent-to-discovery-unpacking-the-magic-of-gradie/"> <script src="/blog/assets/js/theme.js?v=5fea5159b787642c1bbc1f334d60f883"></script> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-native.css?v=5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="https://adarshnair.online" rel="external nofollow noopener" target="_blank"> Adarsh Nair </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/blog/"> </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/index.html">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/about/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/cv/">CV </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="https://adarshnair.online/books/" rel="external nofollow noopener" target="_blank">books </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="fa-solid fa-magnifying-glass"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-half-sun-moon" id="light-toggle-system"></i> <i class="fa-solid fa-moon" id="light-toggle-dark"></i> <i class="fa-solid fa-sun" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Descent to Discovery: Unpacking the Magic of Gradient Descent</h1> <p class="post-meta"> Created on November 25, 2025 by Adarsh Nair </p> <p class="post-tags"> <a href="/blog/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/blog/tag/machine-learning"> <i class="fa-solid fa-hashtag fa-sm"></i> Machine Learning</a>   <a href="/blog/blog/tag/optimization"> <i class="fa-solid fa-hashtag fa-sm"></i> Optimization</a>   <a href="/blog/blog/tag/gradient-descent"> <i class="fa-solid fa-hashtag fa-sm"></i> Gradient Descent</a>   <a href="/blog/blog/tag/algorithms"> <i class="fa-solid fa-hashtag fa-sm"></i> Algorithms</a>   <a href="/blog/blog/tag/deep-learning"> <i class="fa-solid fa-hashtag fa-sm"></i> Deep Learning</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p>My fellow data explorers,</p> <p>Have you ever found yourself at the top of a hill, trying to find the quickest way down to the valley floor? Perhaps you close your eyes, extend your arms, and simply try to feel the steepest slope under your feet, taking small steps in that direction. This intuitive act, in essence, captures the spirit of one of the most foundational and powerful algorithms in machine learning: <strong>Gradient Descent</strong>.</p> <p>As I’ve journeyed through the landscapes of data science and machine learning, I’ve come to appreciate Gradient Descent not just as a mathematical tool, but as the elegant engine that allows models to “learn.” It’s the silent workhorse behind everything from simple linear regression to the colossal neural networks that power modern AI. Today, I want to take you on a personal exploration of this algorithm, breaking down its essence in a way that’s both accessible and deeply insightful.</p> <h3 id="the-quest-finding-the-best-parameters">The Quest: Finding the “Best” Parameters</h3> <p>At the heart of almost every supervised machine learning task is the goal of finding the “best” set of parameters (or weights) for our model. These parameters are what the model uses to make predictions. For instance, in a simple linear regression model, we’re trying to find the optimal slope ($m$) and y-intercept ($b$) for the line that best fits our data ($y = mx + b$). In more complex models, these parameters can number in the millions!</p> <p>But what does “best” mean? It means the parameters that allow our model to make the most accurate predictions, or conversely, the ones that result in the least amount of error. This error is quantified by something we call a <strong>Cost Function</strong> (or Loss Function).</p> <h3 id="the-mountain-we-must-descend-the-cost-function">The Mountain We Must Descend: The Cost Function</h3> <p>Imagine our model’s parameters as coordinates on a landscape. The height of this landscape at any given point (set of parameters) represents the “cost” or “error” our model incurs with those specific parameters. Our ultimate goal is to find the lowest point in this landscape – the global minimum – where the cost function is at its absolute lowest.</p> <p>Let’s take a common example: <strong>Mean Squared Error (MSE)</strong>, often used in linear regression. If our model predicts $\hat{y}$ and the actual value is $y$, the error for one data point is $(\hat{y} - y)$. MSE averages the square of these errors across all our training data points.</p> <p>For a linear regression model with one feature $x$ and parameters $\theta_0$ (intercept) and $\theta_1$ (slope), our prediction is $h_\theta(x^{(i)}) = \theta_0 + \theta_1 x^{(i)}$. The cost function $J(\theta)$ would look something like this:</p> \[J(\theta_0, \theta_1) = \frac{1}{2m} \sum_{i=1}^{m} (h_\theta(x^{(i)}) - y^{(i)})^2\] <p>Here:</p> <ul> <li>$m$ is the number of training examples.</li> <li>$h_\theta(x^{(i)})$ is our model’s prediction for the $i$-th example.</li> <li>$y^{(i)}$ is the actual target value for the $i$-th example.</li> <li>The $1/2$ is a common convention that simplifies the derivative calculation later.</li> </ul> <p>This cost function $J(\theta)$ is a function of our parameters ($\theta_0, \theta_1$). Our mission, should we choose to accept it, is to find the values of $\theta_0$ and $\theta_1$ that minimize $J(\theta)$.</p> <h3 id="our-compass-the-gradient">Our Compass: The Gradient</h3> <p>Now that we know we’re trying to find the bottom of our cost function “valley,” how do we navigate? This is where the “Gradient” comes in.</p> <p>In calculus, a derivative tells us the slope of a function at a particular point. For functions with multiple variables (like our cost function $J(\theta_0, \theta_1)$), we use <strong>partial derivatives</strong>. A partial derivative tells us how the cost function changes as we tweak just one parameter, holding all others constant.</p> <p>The <strong>gradient</strong> is simply a vector containing all these partial derivatives. It points in the direction of the <em>steepest ascent</em> on our cost landscape.</p> <p>Think back to our hill-climbing analogy. If you’re standing on the side of a mountain, the gradient tells you which direction is straight <em>up</em>. But we want to go <em>down</em> to the valley floor. So, we do the opposite: we move in the direction <em>opposite</em> to the gradient.</p> <p>Mathematically, if $\theta$ represents our vector of parameters ($\theta_0, \theta_1, \dots, \theta_n$), the gradient of the cost function $J(\theta)$ is denoted as $\nabla J(\theta)$.</p> <p>For each parameter $\theta_j$, the partial derivative $\frac{\partial}{\partial \theta_j} J(\theta)$ tells us the slope of the cost function with respect to that specific parameter.</p> <h3 id="taking-steps-the-learning-rate-and-update-rule">Taking Steps: The Learning Rate and Update Rule</h3> <p>Once we know the direction of steepest descent (opposite to the gradient), we need to decide how big a step to take. This “step size” is controlled by a crucial hyperparameter called the <strong>learning rate</strong>, denoted by $\alpha$ (alpha).</p> <p>The learning rate is a small, positive number (e.g., 0.01, 0.001). If $\alpha$ is too large, we might overshoot the minimum, bouncing around or even diverging. If $\alpha$ is too small, we’ll take tiny steps, making the learning process painstakingly slow. Finding the right $\alpha$ is often a bit of an art and a key part of machine learning engineering.</p> <p>The <strong>Gradient Descent update rule</strong> combines all these elements:</p> <p>For each parameter $\theta_j$ in our model, we update it simultaneously using the following equation:</p> \[\theta_j := \theta_j - \alpha \frac{\partial}{\partial \theta_j} J(\theta)\] <p>Let’s break this down:</p> <ul> <li>$\theta_j := \theta_j$: This means we are updating the value of $\theta_j$.</li> <li>$\alpha$: Our learning rate, controlling the step size.</li> <li>$\frac{\partial}{\partial \theta_j} J(\theta)$: The partial derivative of the cost function with respect to $\theta_j$. This tells us the slope for parameter $\theta_j$.</li> <li>The minus sign: This is critical! It ensures we move <em>down</em> the slope, against the gradient.</li> </ul> <p>We repeat this update process iteratively, taking small steps down the cost function landscape, until we ideally reach a point where the cost function no longer significantly decreases – indicating we’ve found our minimum.</p> <h3 id="the-gradient-descent-algorithm-in-action">The Gradient Descent Algorithm in Action</h3> <p>Let’s put it all together. Here’s how a typical Gradient Descent algorithm unfolds:</p> <ol> <li> <p><strong>Initialize Parameters:</strong> Start with an initial guess for our model’s parameters $\theta$ (often random values, or zeros). This is like dropping ourselves at an arbitrary point on our cost mountain.</p> </li> <li> <p><strong>Choose a Learning Rate ($\alpha$):</strong> Select a suitable learning rate. This often requires some experimentation and tuning.</p> </li> <li> <p><strong>Iterate Until Convergence:</strong> Repeat the following steps for a set number of iterations, or until the change in the cost function between iterations becomes very small (indicating we’ve reached a minimum): a. <strong>Calculate the Gradient:</strong> For <em>each</em> parameter $\theta_j$, calculate its partial derivative $\frac{\partial}{\partial \theta_j} J(\theta)$ using the current parameter values and <em>all</em> training data. b. <strong>Update Parameters:</strong> Simultaneously update <em>all</em> parameters using the update rule: \(\theta_j := \theta_j - \alpha \frac{\partial}{\partial \theta_j} J(\theta)\)</p> </li> </ol> <p>As we iterate, the cost $J(\theta)$ should decrease with each step, and our parameters $\theta$ will slowly converge towards the optimal values that minimize the cost.</p> <h3 id="variations-on-a-theme-batch-stochastic-and-mini-batch">Variations on a Theme: Batch, Stochastic, and Mini-Batch</h3> <p>The Gradient Descent we’ve described so far is often called <strong>Batch Gradient Descent</strong>. Why “Batch”? Because in each step, we calculate the gradient using <em>all</em> the training examples.</p> <p>While Batch Gradient Descent guarantees a smooth convergence to the minimum (for convex functions), it can be incredibly slow if you have a massive dataset. Imagine recalculating the gradient over millions or billions of data points in every single step!</p> <p>This led to the development of other variants:</p> <ol> <li> <strong>Stochastic Gradient Descent (SGD):</strong> Instead of using all training examples, SGD picks <em>one</em> random training example at a time to calculate the gradient and update the parameters. <ul> <li> <strong>Pros:</strong> Extremely fast updates. Can sometimes escape shallow local minima due to its “noisy” updates.</li> <li> <strong>Cons:</strong> Updates are very noisy, causing the cost function to fluctuate and not always precisely converge to the global minimum, but rather “hover” around it.</li> </ul> </li> <li> <strong>Mini-Batch Gradient Descent:</strong> This is the most popular variant in practice. It’s a compromise between Batch GD and SGD. Instead of using all examples or just one, Mini-Batch GD uses a small, randomly selected subset of the training data (a “mini-batch”) to compute the gradient. <ul> <li> <strong>Pros:</strong> Much faster than Batch GD. Smoother convergence than SGD. Leverages highly optimized matrix operations in modern hardware.</li> <li> <strong>Cons:</strong> Still requires careful tuning of the learning rate and mini-batch size.</li> </ul> </li> </ol> <p>When you hear people talk about “Gradient Descent” in the context of deep learning, they are almost always referring to Mini-Batch Gradient Descent (or one of its more advanced variants like Adam, RMSprop, etc., which build upon these principles).</p> <h3 id="navigating-the-terrain-challenges-and-considerations">Navigating the Terrain: Challenges and Considerations</h3> <p>While Gradient Descent is elegant, it’s not without its challenges:</p> <ul> <li> <strong>Local Minima:</strong> For complex, non-convex cost functions (common in neural networks), the landscape can have multiple “valleys” (local minima). Gradient Descent might get stuck in a local minimum instead of finding the absolute best (global) minimum. SGD and its variants can sometimes help jump out of these.</li> <li> <strong>Learning Rate Selection:</strong> As discussed, choosing the right $\alpha$ is critical. Too small, and training takes forever. Too large, and you might diverge or oscillate around the minimum.</li> <li> <strong>Feature Scaling:</strong> If your features have very different scales (e.g., one feature ranges from 0-1 and another from 0-1,000,000), the cost function can become stretched and elongated. Gradient Descent will then take a zigzag path, slowing down convergence. Scaling your features (e.g., normalization or standardization) can make the cost function more spherical, allowing GD to converge much faster.</li> </ul> <h3 id="my-takeaway-the-elegance-of-iteration">My Takeaway: The Elegance of Iteration</h3> <p>My journey with Gradient Descent has always reinforced the power of iterative refinement. It’s a testament to how simple, repeated steps, guided by a clear objective (minimizing error), can lead to incredibly sophisticated results.</p> <p>Gradient Descent isn’t just an algorithm; it’s a paradigm for learning. It shows us that by understanding the “slope” of our errors, we can systematically adjust our approach, moving closer and closer to an optimal solution. From fitting a line to recognizing faces, this fundamental concept underpins much of the AI revolution.</p> <p>So, the next time you marvel at a machine learning model’s predictive power, remember the silent, persistent mountain climber within: Gradient Descent, diligently making its way down the cost function landscape, one calculated step at a time. It’s truly a journey of descent to discovery.</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/cracking-the-ai-black-box-why-explainable-ai-xai-i/">Cracking the AI Black Box: Why Explainable AI (XAI) is Our Superpower</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/the-secret-life-of-states-how-markov-chains-predic/">The Secret Life of States: How Markov Chains Predict Our Next Move (Without Remembering the Past!)</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/gradient-descent-unpacking-the-engine-of-machine-l/">Gradient Descent: Unpacking the Engine of Machine Learning</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Adarsh Nair. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/blog/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/masonry.js?v=a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/zoom.js?v=85ddb88934d28b74e78031fd54cf8308"></script> <script src="/blog/assets/js/no_defer.js?v=2781658a0a2b13ed609542042a859126"></script> <script defer src="/blog/assets/js/common.js?v=c15de51d4bb57887caa2c21988d97279"></script> <script defer src="/blog/assets/js/copy_code.js?v=c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/blog/assets/js/jupyter_new_tab.js?v=d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/blog/assets/js/mathjax-setup.js?v=a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/progress-bar.js?v=2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/blog/assets/js/vanilla-back-to-top.min.js?v=f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/blog/assets/js/search/ninja-keys.min.js?v=a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/blog/assets/js/search-setup.js?v=6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/blog/assets/js/search-data.js"></script> <script src="/blog/assets/js/shortcut-key.js?v=ccc841c459bfc0e64c1c2b5acd10df02"></script> </body> </html>