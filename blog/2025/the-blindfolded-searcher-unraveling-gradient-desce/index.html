<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> The Blindfolded Searcher: Unraveling Gradient Descent, the Core of Machine Learning's Learning | Adarsh Nair </title> <meta name="author" content="Adarsh Nair"> <meta name="description" content="A deep dive into machine learning, AI, and data science. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <meta http-equiv="Content-Security-Policy" content="default-src 'self'; script-src 'self' 'unsafe-inline' https:; style-src 'self' 'unsafe-inline' https:; img-src 'self' data: https:; font-src 'self' data: https:; media-src 'self' https:; frame-src 'self' https:; connect-src 'self' https:;"> <link rel="stylesheet" href="/blog/assets/css/bootstrap.min.css?v=a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/blog/assets/css/academicons.min.css?v=f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/blog/assets/css/scholar-icons.css?v=62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-github.css?v=591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/blog/assets/css/main.css?v=d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://adarshnair.online/blog/blog/blog/2025/the-blindfolded-searcher-unraveling-gradient-desce/"> <script src="/blog/assets/js/theme.js?v=5fea5159b787642c1bbc1f334d60f883"></script> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-native.css?v=5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="https://adarshnair.online" rel="external nofollow noopener" target="_blank"> Adarsh Nair </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/blog/"> </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/index.html">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/about/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/cv/">CV </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="https://adarshnair.online/books/" rel="external nofollow noopener" target="_blank">books </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="fa-solid fa-magnifying-glass"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-half-sun-moon" id="light-toggle-system"></i> <i class="fa-solid fa-moon" id="light-toggle-dark"></i> <i class="fa-solid fa-sun" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">The Blindfolded Searcher: Unraveling Gradient Descent, the Core of Machine Learning's Learning</h1> <p class="post-meta"> Created on September 04, 2025 by Adarsh Nair </p> <p class="post-tags"> <a href="/blog/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/blog/tag/machine-learning"> <i class="fa-solid fa-hashtag fa-sm"></i> Machine Learning</a>   <a href="/blog/blog/tag/gradient-descent"> <i class="fa-solid fa-hashtag fa-sm"></i> Gradient Descent</a>   <a href="/blog/blog/tag/optimization"> <i class="fa-solid fa-hashtag fa-sm"></i> Optimization</a>   <a href="/blog/blog/tag/deep-learning"> <i class="fa-solid fa-hashtag fa-sm"></i> Deep Learning</a>   <a href="/blog/blog/tag/algorithms"> <i class="fa-solid fa-hashtag fa-sm"></i> Algorithms</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p>Ah, Gradient Descent. The name itself might sound intimidating, conjuring images of complex calculus and abstract algebra. But trust me, once you grasp its core idea, you’ll see it for what it truly is: an elegant, intuitive, and incredibly powerful engine driving most of what we call “learning” in machine learning.</p> <p>I still remember the “aha!” moment when Gradient Descent clicked for me. It wasn’t in a lecture hall staring at equations, but when a brilliant mentor described it as a blindfolded person trying to find the bottom of a valley. Today, I want to share that intuition with you, and then, yes, we’ll dive into the beautiful math that makes it all work.</p> <h2 id="the-quest-for-the-lowest-point-an-intuition">The Quest for the Lowest Point: An Intuition</h2> <p>Imagine you’re standing blindfolded on a vast, uneven landscape. Your goal? To find the absolute lowest point in this valley. You can’t see anything, but you can feel the slope directly beneath your feet.</p> <p>What would you do? Naturally, you’d take a small step downhill. If the ground sloped steeply to your left, you’d step left. If it sloped gently forward, you’d step gently forward. You’d keep doing this, iteratively taking small steps in the steepest downhill direction, until you couldn’t feel any more slope – meaning you’ve reached a flat bottom.</p> <p>Congratulations, you’ve just performed Gradient Descent!</p> <p>In the world of machine learning, our “landscape” is defined by a <strong>cost function</strong> (also known as a loss function or objective function). This function measures how “wrong” our model’s predictions are compared to the actual values. Our goal is to find the set of model parameters (like the weights and biases in a neural network, or the slope and intercept in linear regression) that <strong>minimize</strong> this cost function. A lower cost means a better, more accurate model.</p> <p>The “slope beneath your feet” is precisely what the <strong>gradient</strong> tells us. The gradient is a vector that points in the direction of the <em>steepest ascent</em>. Since we want to go <em>downhill</em> to minimize the cost, we move in the <em>opposite</em> direction of the gradient.</p> <h2 id="peeking-under-the-hood-the-math-behind-the-magic">Peeking Under the Hood: The Math Behind the Magic</h2> <p>Let’s formalize this intuition. Suppose we have a cost function $J(\theta_0, \theta_1, …, \theta_n)$ that depends on our model’s parameters $\theta_0, \theta_1, …, \theta_n$. Our goal is to find the values of these $\theta$s that minimize $J$.</p> <p>The core update rule for Gradient Descent is deceptively simple:</p> <p>$\theta_j := \theta_j - \alpha \frac{\partial}{\partial \theta_j} J(\theta_0, \theta_1, …, \theta_n)$</p> <p>Let’s break down each component:</p> <ul> <li> <strong>$\theta_j$</strong>: This represents a single parameter of our model. For instance, in simple linear regression $h_\theta(x) = \theta_0 + \theta_1 x$, we have two parameters: $\theta_0$ (the intercept) and $\theta_1$ (the slope). We update <em>each</em> parameter simultaneously.</li> <li> <strong>$:=$</strong>: This isn’t an equals sign! It means “update $\theta_j$ to be the value on the right-hand side.”</li> <li> <strong>$\alpha$ (alpha)</strong>: This is perhaps the most crucial hyperparameter: the <strong>learning rate</strong>. Think of it as the size of your steps in the valley. <ul> <li>If $\alpha$ is too small, you’ll take tiny baby steps. You might eventually reach the bottom, but it will take an incredibly long time.</li> <li>If $\alpha$ is too large, you might overshoot the bottom, bounce around erratically, or even diverge completely and climb out of the valley! Finding the right $\alpha$ is often an art and a science.</li> </ul> </li> <li> <strong>$\frac{\partial}{\partial \theta_j} J(\theta)$</strong>: This is the <strong>partial derivative</strong> of the cost function $J$ with respect to the parameter $\theta_j$. In simple terms, it tells us how much the cost function changes if we slightly change $\theta_j$. This is our “slope beneath your feet” for that particular parameter dimension. The collection of all such partial derivatives forms the <strong>gradient vector</strong>.</li> <li> <strong>The Minus Sign</strong>: Remember we want to go <em>downhill</em>. The derivative tells us the direction of <em>steepest ascent</em>. So, to go downhill, we subtract it.</li> </ul> <h3 id="a-concrete-example-linear-regression">A Concrete Example: Linear Regression</h3> <p>Let’s ground this with a familiar example: <strong>Linear Regression</strong>. Our hypothesis function is $h_\theta(x) = \theta_0 + \theta_1 x$. A common cost function for linear regression is the Mean Squared Error (MSE), often written as:</p> <p>$J(\theta_0, \theta_1) = \frac{1}{2m} \sum_{i=1}^m (h_\theta(x^{(i)}) - y^{(i)})^2$</p> <p>Here:</p> <ul> <li>$m$ is the number of training examples.</li> <li>$(x^{(i)}, y^{(i)})$ is the $i$-th training example.</li> <li>The $\frac{1}{2}$ is just for mathematical convenience (it makes the derivative cleaner, canceling out a 2).</li> </ul> <p>Now, let’s calculate the partial derivatives for our two parameters:</p> <p>For $\theta_0$: $\frac{\partial}{\partial \theta_0} J(\theta_0, \theta_1) = \frac{1}{m} \sum_{i=1}^m (h_\theta(x^{(i)}) - y^{(i)})$</p> <p>For $\theta_1$: $\frac{\partial}{\partial \theta_1} J(\theta_0, \theta_1) = \frac{1}{m} \sum_{i=1}^m (h_\theta(x^{(i)}) - y^{(i)}) x^{(i)}$</p> <p>With these derivatives, our update rules become:</p> <p>$\theta_0 := \theta_0 - \alpha \frac{1}{m} \sum_{i=1}^m (h_\theta(x^{(i)}) - y^{(i)})$</p> <p>$\theta_1 := \theta_1 - \alpha \frac{1}{m} \sum_{i=1}^m (h_\theta(x^{(i)}) - y^{(i)}) x^{(i)}$</p> <p>We iterate these updates simultaneously for all parameters until convergence (when the cost function stops decreasing significantly). This iterative process is what allows our model to “learn” the best $\theta$ values to fit the data.</p> <h2 id="varieties-of-the-descent-batch-stochastic-and-mini-batch">Varieties of the Descent: Batch, Stochastic, and Mini-Batch</h2> <p>The basic Gradient Descent algorithm we’ve discussed so far computes the gradient using <em>all</em> the training examples in each iteration. This is specifically called <strong>Batch Gradient Descent (BGD)</strong>. While reliable, it has its limitations, especially with vast datasets. This led to the development of its siblings:</p> <h3 id="1-batch-gradient-descent-bgd">1. Batch Gradient Descent (BGD)</h3> <ul> <li> <strong>How it works</strong>: Computes the gradient of the cost function with respect to the parameters for <em>the entire training dataset</em> in each step.</li> <li> <strong>Pros</strong>: <ul> <li>Guaranteed to converge to the global minimum for convex cost functions (like linear regression’s MSE).</li> <li>Smoother descent paths.</li> </ul> </li> <li> <strong>Cons</strong>: <ul> <li>Very slow for large datasets because it processes all data points before making a single parameter update.</li> <li>Requires a lot of memory to load the entire dataset.</li> <li>Can get stuck in local minima for non-convex functions.</li> </ul> </li> </ul> <h3 id="2-stochastic-gradient-descent-sgd">2. Stochastic Gradient Descent (SGD)</h3> <ul> <li> <strong>How it works</strong>: Instead of using all training examples, SGD picks <em>one</em> random training example at a time to calculate the gradient and update the parameters.</li> <li> <strong>Pros</strong>: <ul> <li>Much faster for large datasets because it makes frequent updates.</li> <li>The “noise” introduced by processing one example at a time can help it escape shallow local minima in complex, non-convex landscapes (common in deep learning).</li> </ul> </li> <li> <strong>Cons</strong>: <ul> <li>The cost function fluctuates much more because the updates are based on individual, noisy examples. It won’t necessarily converge smoothly to the exact minimum but will oscillate around it.</li> <li>Might require a decaying learning rate to settle down.</li> </ul> </li> </ul> <h3 id="3-mini-batch-gradient-descent-mbgd">3. Mini-Batch Gradient Descent (MBGD)</h3> <ul> <li> <strong>How it works</strong>: This is the most common and practical variant today. It’s a compromise between BGD and SGD. Instead of using all examples or just one, it uses a small, randomly selected subset (a “mini-batch”) of the training data to compute the gradient and update parameters. Typical mini-batch sizes range from 32 to 256.</li> <li> <strong>Pros</strong>: <ul> <li>Faster than BGD and more stable than SGD.</li> <li>Leverages highly optimized matrix operations, often leading to better computational efficiency than pure SGD.</li> <li>Benefits from the noise of SGD (potentially escaping local minima) while having more stable updates.</li> </ul> </li> <li> <strong>Cons</strong>: <ul> <li>Requires tuning an additional hyperparameter: the mini-batch size.</li> </ul> </li> </ul> <h2 id="challenges-and-considerations">Challenges and Considerations</h2> <p>While Gradient Descent is powerful, it’s not without its quirks:</p> <ul> <li> <strong>Local Minima</strong>: For complex, non-convex cost functions (like those in deep neural networks), the landscape can have many “dips” or local minima. Gradient Descent might get stuck in one of these instead of reaching the true global minimum. SGD and Mini-Batch GD’s inherent noise can sometimes help “kick” the optimizer out of shallow local minima.</li> <li> <strong>Saddle Points</strong>: These are points where the slope is zero in some directions but not a minimum (like a saddle on a horse). GD can get stuck here too.</li> <li> <strong>Learning Rate Selection</strong>: As discussed, $\alpha$ is critical. Modern optimizers (like Adam, RMSprop, Adagrad) adapt the learning rate during training, making the process much more robust and efficient.</li> <li> <strong>Feature Scaling</strong>: If your input features have very different scales (e.g., one feature ranges from 0-1 and another from 0-10,000), the cost function can look like a long, narrow ellipse. Gradient Descent will “zig-zag” inefficiently towards the minimum. Scaling features (e.g., normalization) transforms this into a more circular contour, allowing GD to converge much faster.</li> </ul> <h2 id="the-enduring-elegance">The Enduring Elegance</h2> <p>Gradient Descent, in its various forms, is the bedrock upon which so much of modern machine learning is built. From simple linear models to the most sophisticated deep neural networks, the principle remains the same: iteratively adjust parameters in the direction that reduces error.</p> <p>It’s an algorithm that perfectly encapsulates the “learning” process in machines — feeling its way through a complex problem, making small adjustments, and slowly but surely improving its performance. For me, understanding Gradient Descent wasn’t just about memorizing an equation; it was about truly appreciating how machines can <em>optimize</em> and <em>learn</em> from data, one careful step at a time. It’s a foundational concept that will serve you well, no matter how deep you dive into the world of AI.</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/cracking-the-ai-black-box-why-explainable-ai-xai-i/">Cracking the AI Black Box: Why Explainable AI (XAI) is Our Superpower</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/the-secret-life-of-states-how-markov-chains-predic/">The Secret Life of States: How Markov Chains Predict Our Next Move (Without Remembering the Past!)</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/gradient-descent-unpacking-the-engine-of-machine-l/">Gradient Descent: Unpacking the Engine of Machine Learning</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Adarsh Nair. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/blog/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/masonry.js?v=a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/zoom.js?v=85ddb88934d28b74e78031fd54cf8308"></script> <script src="/blog/assets/js/no_defer.js?v=2781658a0a2b13ed609542042a859126"></script> <script defer src="/blog/assets/js/common.js?v=c15de51d4bb57887caa2c21988d97279"></script> <script defer src="/blog/assets/js/copy_code.js?v=c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/blog/assets/js/jupyter_new_tab.js?v=d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/blog/assets/js/mathjax-setup.js?v=a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/progress-bar.js?v=2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/blog/assets/js/vanilla-back-to-top.min.js?v=f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/blog/assets/js/search/ninja-keys.min.js?v=a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/blog/assets/js/search-setup.js?v=6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/blog/assets/js/search-data.js"></script> <script src="/blog/assets/js/shortcut-key.js?v=ccc841c459bfc0e64c1c2b5acd10df02"></script> </body> </html>