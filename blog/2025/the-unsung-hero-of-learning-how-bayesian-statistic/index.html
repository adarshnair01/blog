<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> The Unsung Hero of Learning: How Bayesian Statistics Updates Our Worldview with Every New Piece of Data | Adarsh Nair </title> <meta name="author" content="Adarsh Nair"> <meta name="description" content="A deep dive into machine learning, AI, and data science. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <meta http-equiv="Content-Security-Policy" content="default-src 'self'; script-src 'self' 'unsafe-inline' https:; style-src 'self' 'unsafe-inline' https:; img-src 'self' data: https:; font-src 'self' data: https:; media-src 'self' https:; frame-src 'self' https:; connect-src 'self' https:;"> <link rel="stylesheet" href="/blog/assets/css/bootstrap.min.css?v=a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/blog/assets/css/academicons.min.css?v=f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/blog/assets/css/scholar-icons.css?v=62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-github.css?v=591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/blog/assets/css/main.css?v=d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://adarshnair.online/blog/blog/2025/the-unsung-hero-of-learning-how-bayesian-statistic/"> <script src="/blog/assets/js/theme.js?v=5fea5159b787642c1bbc1f334d60f883"></script> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-native.css?v=5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/blog/cv/"> Adarsh Nair </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/blog/"> </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/cv/">CV </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/repositories/">repositories </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="fa-solid fa-magnifying-glass"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-half-sun-moon" id="light-toggle-system"></i> <i class="fa-solid fa-moon" id="light-toggle-dark"></i> <i class="fa-solid fa-sun" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">The Unsung Hero of Learning: How Bayesian Statistics Updates Our Worldview with Every New Piece of Data</h1> <p class="post-meta"> Created on March 24, 2025 by Adarsh Nair </p> <p class="post-tags"> <a href="/blog/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/blog/tag/bayesian-statistics"> <i class="fa-solid fa-hashtag fa-sm"></i> Bayesian Statistics</a>   <a href="/blog/blog/tag/probability"> <i class="fa-solid fa-hashtag fa-sm"></i> Probability</a>   <a href="/blog/blog/tag/data-science"> <i class="fa-solid fa-hashtag fa-sm"></i> Data Science</a>   <a href="/blog/blog/tag/machine-learning"> <i class="fa-solid fa-hashtag fa-sm"></i> Machine Learning</a>   <a href="/blog/blog/tag/statistical-inference"> <i class="fa-solid fa-hashtag fa-sm"></i> Statistical Inference</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p>Hey there, fellow curious minds!</p> <p>Have you ever found yourself in a situation where you had a strong hunch about something, then you got some new information, and suddenly, your hunch either got way stronger or completely flipped? That feeling, that iterative process of updating your beliefs based on evidence, is not just a quirk of human psychology – it’s the very essence of Bayesian Statistics.</p> <p>For the longest time, when I first dipped my toes into the vast ocean of data science, statistics felt like a rigid rulebook. You collect data, you run a test, you get a p-value, and boom – a definitive answer. But something always felt a little off. What about what I <em>already</em> knew? What about my gut feeling, my prior experience? Did all that just get ignored?</p> <p>That’s where Bayesian Statistics stepped in and quite frankly, blew my mind. It introduced a framework that didn’t just acknowledge prior knowledge; it <em>demanded</em> it. It gave me a way to quantify uncertainty, to learn sequentially, and to truly build models that evolve with every new piece of data, much like how our own brains learn. It’s not just a statistical method; it’s a philosophy for understanding the world.</p> <h3 id="the-problem-with-fixed-probabilities">The Problem with “Fixed” Probabilities</h3> <p>Let’s start with a simple thought experiment. Imagine you’ve just moved to a new town. On your first morning, you see 10 cars pass by, and 8 of them are blue. What’s your immediate thought? “Wow, this town really loves blue cars!”</p> <p>Now, in traditional “frequentist” statistics (which most of us encounter first), if you wanted to know the true proportion of blue cars, you’d just keep counting. As you see more cars – hundreds, thousands – your estimate of the proportion of blue cars would converge on the “true” proportion. It’s like flipping a coin a million times to determine if it’s fair. The probability of getting heads is a fixed, inherent property of the coin, and we just need enough data to estimate it.</p> <p>But what if you only saw those 10 cars? Or what if you had a prior belief that, generally, blue cars aren’t <em>that</em> common? Frequentist methods often struggle with small datasets and don’t easily incorporate existing knowledge or beliefs <em>before</em> you’ve seen any data. It’s like starting every experiment from a blank slate, ignoring centuries of accumulated human wisdom.</p> <h3 id="enter-bayes-a-journey-of-belief-updates">Enter Bayes: A Journey of Belief Updates</h3> <p>Bayesian statistics offers a refreshingly intuitive alternative. Instead of assuming probabilities are fixed, objective properties waiting to be discovered, Bayesians treat probability as a <em>degree of belief</em>. And crucially, these beliefs are not static. They are constantly updated as new evidence comes to light.</p> <p>Think back to our blue car town.</p> <ol> <li> <strong>Your Initial Belief (Prior):</strong> Before seeing any cars, you might have a general idea about car colors. Maybe you believe only about 15% of cars are blue (based on your previous experience). This is your <strong>Prior Probability</strong>. It’s your initial best guess, your starting point.</li> <li> <strong>The Evidence (Likelihood):</strong> You observe 10 cars, and 8 are blue. This is your data, your evidence.</li> <li> <strong>Your Updated Belief (Posterior):</strong> How does seeing 8 out of 10 blue cars change your initial belief of 15%? It probably makes you think, “Okay, maybe 15% was too low for <em>this</em> town!” You’d adjust your belief upwards. This new, updated belief is your <strong>Posterior Probability</strong>.</li> </ol> <p>This continuous loop of <em>prior $\rightarrow$ evidence $\rightarrow$ posterior</em> is the heart of Bayesian inference. And the mathematical formula that orchestrates this elegant dance? <strong>Bayes’ Theorem</strong>.</p> <h3 id="unpacking-bayes-theorem-the-formula-that-changes-everything">Unpacking Bayes’ Theorem: The Formula That Changes Everything</h3> <p>At its core, Bayes’ Theorem looks like this:</p> \[P(H|E) = \frac{P(E|H) \cdot P(H)}{P(E)}\] <p>Don’t let the symbols intimidate you! Let’s break it down, term by term:</p> <ul> <li> <table> <tbody> <tr> <td>**$P(H</td> <td>E)$ (Posterior Probability):** This is what we <em>want</em> to know. It’s the probability of our <strong>Hypothesis (H)</strong> being true, <em>given the Evidence (E)</em> we’ve just observed. In our blue car example, it would be the probability that the proportion of blue cars in this town is high, <em>after</em> seeing 8 blue cars out of 10. This is your updated belief!</td> </tr> </tbody> </table> </li> <li> <table> <tbody> <tr> <td>**$P(E</td> <td>H)$ (Likelihood):** This is the probability of observing the <strong>Evidence (E)</strong>, <em>if our Hypothesis (H)</em> were true. If you hypothesized that the town truly has a very high proportion of blue cars (say, 80%), how likely would it be to see 8 blue cars out of 10? If you hypothesized a low proportion (say, 15%), how likely would it be to see 8 out of 10 blue cars? The likelihood tells you how well your hypothesis explains the data.</td> </tr> </tbody> </table> </li> <li> <p><strong>$P(H)$ (Prior Probability):</strong> This is our initial <strong>Prior Probability</strong> of the <strong>Hypothesis (H)</strong> being true, <em>before</em> we’ve seen any new evidence. This is where your gut feeling, your existing knowledge, or even previous experiments come into play. In our blue car scenario, this was your initial belief that about 15% of cars are blue.</p> </li> <li> <table> <tbody> <tr> <td> <strong>$P(E)$ (Marginal Likelihood or Evidence):</strong> This is the total probability of observing the <strong>Evidence (E)</strong>, regardless of whether our hypothesis is true or not. It’s essentially a normalizing constant that ensures our posterior probabilities sum up to 1. For practical purposes, especially when comparing different hypotheses, you can often think of it as the sum of $P(E</td> <td>H) \cdot P(H)$ over all possible hypotheses. It’s like asking: “Overall, how surprising is this evidence?”</td> </tr> </tbody> </table> </li> </ul> <p>So, in plain English, Bayes’ Theorem states: <strong>Your Updated Belief</strong> is proportional to <strong>(How well your hypothesis explains the data) * (Your initial belief in the hypothesis)</strong>. The $P(E)$ just scales it correctly.</p> <h3 id="a-concrete-example-the-not-so-fair-coin">A Concrete Example: The Not-So-Fair Coin</h3> <p>Let’s make this even more tangible with a classic example: coin flipping. Imagine a friend hands you a coin. You suspect it might be biased towards heads.</p> <p><strong>Hypotheses (H):</strong></p> <ul> <li>$H_1$: The coin is fair ($P(\text{Heads}) = 0.5$).</li> <li>$H_2$: The coin is biased ($P(\text{Heads}) = 0.8$).</li> </ul> <p><strong>1. Your Prior Beliefs ($P(H)$):</strong> Before any flips, you’re generally skeptical of biased coins. You might believe:</p> <ul> <li>$P(H_1)$ (Coin is fair) = 0.9 (90% chance it’s fair).</li> <li>$P(H_2)$ (Coin is biased) = 0.1 (10% chance it’s biased).</li> </ul> <p><strong>2. The Evidence (E):</strong> You flip the coin three times and get three Heads (HHH).</p> <p><strong>3. The Likelihood ($P(E|H)$):</strong> How likely is this evidence under each hypothesis?</p> <ul> <li> <table> <tbody> <tr> <td>If $H_1$ (fair) is true: $P(\text{HHH}</td> <td>H_1) = (0.5)^3 = 0.125$.</td> </tr> </tbody> </table> </li> <li> <table> <tbody> <tr> <td>If $H_2$ (biased) is true: $P(\text{HHH}</td> <td>H_2) = (0.8)^3 = 0.512$.</td> </tr> </tbody> </table> </li> </ul> <p>Notice how the evidence (HHH) is much more likely if the coin is biased.</p> <table> <tbody> <tr> <td>**4. Calculating the Posterior ($P(H</td> <td>E)$):**</td> </tr> </tbody> </table> <p>Now, let’s use Bayes’ Theorem to update our beliefs. We need $P(E)$ first. $P(E) = P(E|H_1)P(H_1) + P(E|H_2)P(H_2)$ (This is the “marginal likelihood” over our two hypotheses) $P(E) = (0.125)(0.9) + (0.512)(0.1)$ $P(E) = 0.1125 + 0.0512 = 0.1637$</p> <p>Now for our updated beliefs:</p> <ul> <li> <p><strong>Posterior for $H_1$ (fair):</strong> $P(H_1|\text{HHH}) = \frac{P(\text{HHH}|H_1) \cdot P(H_1)}{P(E)}$ $P(H_1|\text{HHH}) = \frac{0.125 \cdot 0.9}{0.1637} = \frac{0.1125}{0.1637} \approx 0.687$</p> </li> <li> <p><strong>Posterior for $H_2$ (biased):</strong> $P(H_2|\text{HHH}) = \frac{P(\text{HHH}|H_2) \cdot P(H_2)}{P(E)}$ $P(H_2|\text{HHH}) = \frac{0.512 \cdot 0.1}{0.1637} = \frac{0.0512}{0.1637} \approx 0.313$</p> </li> </ul> <p>What happened?</p> <ul> <li>Your belief that the coin is fair ($H_1$) dropped from 90% to about 68.7%.</li> <li>Your belief that the coin is biased ($H_2$) jumped from 10% to about 31.3%!</li> </ul> <p>Three heads in a row didn’t make you instantly declare the coin biased, because your prior belief in fairness was strong. But it significantly shifted your confidence. If you got more heads, the belief in bias would continue to grow, eventually overwhelming your initial skepticism. This is learning in action!</p> <h3 id="why-is-this-so-powerful-for-data-science-and-machine-learning">Why is This So Powerful for Data Science and Machine Learning?</h3> <p>Bayesian statistics isn’t just a neat party trick with coins; it’s a foundational paradigm for intelligent systems.</p> <ol> <li> <strong>Incorporating Prior Knowledge:</strong> In real-world problems, we often have existing knowledge. Bayesian methods allow us to bake this knowledge directly into our models. This is crucial when data is sparse or expensive to acquire. <ul> <li> <em>Example:</em> If you’re building a spam filter, you know, a priori, that most emails are <em>not</em> spam. This prior belief helps prevent misclassifying legitimate emails as spam, even if they contain a few “spammy” words.</li> </ul> </li> <li> <strong>Quantifying Uncertainty (Not Just Point Estimates):</strong> Unlike frequentist methods that often give you a single “best estimate,” Bayesian methods provide an entire <em>distribution</em> for your parameters. This means you don’t just get an answer; you get a probability distribution of <em>all possible answers</em>, showing how confident you are in each. <ul> <li> <em>Example:</em> Instead of saying “the average customer conversion rate is 5.2%”, a Bayesian approach might say “the conversion rate is most likely 5.2%, but there’s a 95% chance it’s between 4.8% and 5.6%.” This offers a much richer understanding for decision-makers.</li> </ul> </li> <li> <strong>Sequential Learning:</strong> Bayesian models are inherently designed to learn iteratively. As new data streams in, you don’t have to retrain your entire model from scratch. Your current posterior becomes the prior for the next batch of data. <ul> <li> <em>Example:</em> A recommendation system can continuously update its understanding of your preferences with every movie you watch or product you buy, refining its recommendations over time.</li> </ul> </li> <li> <p><strong>Robustness with Small Data:</strong> When you have very little data, frequentist methods can be unreliable. Bayesian methods, by leveraging priors, can often yield more stable and sensible results even with limited observations.</p> </li> <li> <strong>Direct Answers to “What We Want to Know”:</strong> Frequentist methods often give you the probability of seeing data <em>given</em> a null hypothesis (the p-value). Bayes gives you the probability of a hypothesis being true <em>given</em> the data, which is usually what people actually want to know. “What’s the probability this drug works?” vs. “What’s the probability of observing this patient outcome if the drug <em>didn’t</em> work?”</li> </ol> <h3 id="bayesian-applications-in-the-wild">Bayesian Applications in the Wild</h3> <ul> <li> <strong>Spam Filtering (Naive Bayes):</strong> One of the earliest and most widespread applications. The probability that an email is spam, given certain words in it, is calculated using Bayes’ theorem.</li> <li> <strong>Medical Diagnostics:</strong> What’s the probability a patient has a rare disease, given a positive test result? Bayes’ theorem is critical for interpreting such results accurately, especially when false positives are possible.</li> <li> <strong>A/B Testing:</strong> Bayesian A/B tests can often provide faster and more intuitive results than traditional frequentist methods, telling you directly the probability that version B is better than version A.</li> <li> <strong>Personalized Recommendations:</strong> Systems like Netflix or Amazon use Bayesian principles to update their understanding of your preferences and recommend content.</li> <li> <strong>Robotics and Autonomous Systems:</strong> Robots constantly update their understanding of their environment based on sensor data, using Bayesian filters (like Kalman filters) to estimate their position and surroundings.</li> <li> <strong>Parameter Estimation:</strong> In complex machine learning models, Bayesian methods can be used to estimate the parameters of the model (e.g., in a neural network), providing uncertainty estimates for those parameters.</li> </ul> <h3 id="a-note-on-priors-the-subjectivity-debate">A Note on Priors: The “Subjectivity” Debate</h3> <table> <tbody> <tr> <td>One common critique of Bayesian statistics is the role of the “prior.” If your prior is just your personal belief, isn’t that subjective? Yes, it can be! But “subjective” doesn’t mean “bad” or “arbitrary.” A well-chosen prior reflects genuine expert knowledge or established scientific consensus. And often, as you collect more and more data, the evidence ($P(E</td> <td>H)$) will swamp even a strong prior, making the posterior converge regardless of your starting point. For situations where you truly have no strong prior knowledge, we can use “uninformative priors” that try to be as neutral as possible.</td> </tr> </tbody> </table> <h3 id="your-journey-begins">Your Journey Begins</h3> <p>Bayesian statistics isn’t just a branch of math; it’s a way of thinking that mirrors how we, as humans, learn and adapt. It’s about starting with a best guess, observing the world, and then intelligently updating that guess. This iterative, adaptive nature makes it incredibly powerful for building intelligent systems that can navigate the messy, uncertain real world.</p> <p>So, the next time you update your opinion based on new information, give a nod to Reverend Bayes. You’re thinking like a Bayesian, and that’s a powerful way to understand and interact with our data-rich universe. Dive deeper, explore some online tutorials, or try to implement Bayes’ theorem for a simple problem. Your worldview might just get a little more sophisticated with every new piece of data you encounter!</p> <p>Keep learning, keep questioning, and embrace the uncertainty!</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/cracking-the-ai-black-box-why-explainable-ai-xai-i/">Cracking the AI Black Box: Why Explainable AI (XAI) is Our Superpower</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/the-secret-life-of-states-how-markov-chains-predic/">The Secret Life of States: How Markov Chains Predict Our Next Move (Without Remembering the Past!)</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/gradient-descent-unpacking-the-engine-of-machine-l/">Gradient Descent: Unpacking the Engine of Machine Learning</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Adarsh Nair. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/blog/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/masonry.js?v=a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/zoom.js?v=85ddb88934d28b74e78031fd54cf8308"></script> <script src="/blog/assets/js/no_defer.js?v=2781658a0a2b13ed609542042a859126"></script> <script defer src="/blog/assets/js/common.js?v=c15de51d4bb57887caa2c21988d97279"></script> <script defer src="/blog/assets/js/copy_code.js?v=c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/blog/assets/js/jupyter_new_tab.js?v=d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/blog/assets/js/mathjax-setup.js?v=a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/progress-bar.js?v=2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/blog/assets/js/vanilla-back-to-top.min.js?v=f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/blog/assets/js/search/ninja-keys.min.js?v=a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/blog/assets/js/search-setup.js?v=6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/blog/assets/js/search-data.js"></script> <script src="/blog/assets/js/shortcut-key.js?v=ccc841c459bfc0e64c1c2b5acd10df02"></script> </body> </html>