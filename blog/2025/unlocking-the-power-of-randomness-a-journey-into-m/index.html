<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Unlocking the Power of Randomness: A Journey into Monte Carlo Simulations | Adarsh Nair </title> <meta name="author" content="Adarsh Nair"> <meta name="description" content="A deep dive into machine learning, AI, and data science. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <meta http-equiv="Content-Security-Policy" content="default-src 'self'; script-src 'self' 'unsafe-inline' https:; style-src 'self' 'unsafe-inline' https:; img-src 'self' data: https:; font-src 'self' data: https:; media-src 'self' https:; frame-src 'self' https:; connect-src 'self' https:;"> <link rel="stylesheet" href="/blog/assets/css/bootstrap.min.css?v=a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/blog/assets/css/academicons.min.css?v=f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/blog/assets/css/scholar-icons.css?v=62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-github.css?v=591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/blog/assets/css/main.css?v=d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://adarshnair.online/blog/blog/2025/unlocking-the-power-of-randomness-a-journey-into-m/"> <script src="/blog/assets/js/theme.js?v=5fea5159b787642c1bbc1f334d60f883"></script> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-native.css?v=5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/blog/cv/"> Adarsh Nair </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/blog/"> </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/cv/">CV </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/repositories/">repositories </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="fa-solid fa-magnifying-glass"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-half-sun-moon" id="light-toggle-system"></i> <i class="fa-solid fa-moon" id="light-toggle-dark"></i> <i class="fa-solid fa-sun" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Unlocking the Power of Randomness: A Journey into Monte Carlo Simulations</h1> <p class="post-meta"> Created on September 15, 2025 by Adarsh Nair </p> <p class="post-tags"> <a href="/blog/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/blog/tag/monte-carlo"> <i class="fa-solid fa-hashtag fa-sm"></i> Monte Carlo</a>   <a href="/blog/blog/tag/simulations"> <i class="fa-solid fa-hashtag fa-sm"></i> Simulations</a>   <a href="/blog/blog/tag/data-science"> <i class="fa-solid fa-hashtag fa-sm"></i> Data Science</a>   <a href="/blog/blog/tag/probability"> <i class="fa-solid fa-hashtag fa-sm"></i> Probability</a>   <a href="/blog/blog/tag/python"> <i class="fa-solid fa-hashtag fa-sm"></i> Python</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p>Have you ever found yourself staring down a problem that feels… well, <em>impossible</em> to solve directly? Perhaps you need to calculate the area of an irregularly shaped pond, estimate the probability of profit for a new business venture with tons of variables, or even understand the complex behavior of particles in a physical system. Traditional mathematical methods might lead you down a rabbit hole of intractable equations.</p> <p>What if I told you there’s a powerful, elegant, and surprisingly intuitive technique that can tackle these kinds of challenges by simply embracing randomness? Welcome to the fascinating world of <strong>Monte Carlo simulations</strong>.</p> <p>Today, I want to take you on a journey to explore this incredible tool. We’ll demystify its core concepts, walk through some classic examples, and discover why it’s become an indispensable part of the data scientist’s and machine learning engineer’s toolkit.</p> <h3 id="the-genesis-of-randomness-a-little-history-lesson">The Genesis of Randomness: A Little History Lesson</h3> <p>Our story begins not in a classroom, but amidst the top-secret scientific endeavors of World War II. During the Manhattan Project, scientists like Stanislaw Ulam and John von Neumann were grappling with complex neutron diffusion problems that were impossible to solve analytically. Ulam, recovering from an illness, pondered how to estimate the probability of success in a game of solitaire, which led him to think about using random sampling for similar physics problems.</p> <p>Because much of this work involved randomness and was highly classified, von Neumann, inspired by Ulam’s uncle’s gambling habits in the casinos of Monaco, code-named the method “Monte Carlo.” It was a fitting name for a technique that uses random sampling to estimate deterministic quantities. Pretty cool, right?</p> <h3 id="the-core-idea-when-chaos-leads-to-clarity">The Core Idea: When Chaos Leads to Clarity</h3> <p>At its heart, Monte Carlo simulation is about using repeated random sampling to obtain numerical results. It’s a method that works on the principle that if you randomly sample a process enough times, the results from your simulations will converge towards the true underlying probability or value. This is thanks to a fundamental concept in statistics called the <strong>Law of Large Numbers</strong>.</p> <p>Think of it this way: if you flip a fair coin a few times, you might get 70% heads. But if you flip it a thousand times, you’ll likely get something much closer to 50% heads. Flip it a million times, and you’ll be incredibly close. Monte Carlo applies this same logic to far more complex scenarios.</p> <p>The general steps for a Monte Carlo simulation are often quite simple:</p> <ol> <li> <strong>Define the system or problem:</strong> Clearly outline what you’re trying to measure or estimate.</li> <li> <strong>Generate random inputs:</strong> Create a large number of random samples for the variables in your system. These samples should reflect the actual probability distributions of those variables.</li> <li> <strong>Perform a deterministic computation:</strong> For each set of random inputs, run your model or calculation. This yields a single outcome for that particular simulation.</li> <li> <strong>Aggregate the results:</strong> Collect all the outcomes from your many simulations and analyze them to estimate the desired quantity (e.g., mean, probability, variance).</li> </ol> <p>Let’s dive into some practical examples to make this concrete.</p> <h3 id="hands-on-example-1-estimating-pi-pi-with-virtual-darts">Hands-On Example 1: Estimating Pi ($\pi$) with Virtual Darts</h3> <p>This is a classic and wonderfully intuitive example. Imagine you have a perfect square with a circle inscribed inside it. The circle touches the midpoints of all four sides of the square.</p> <p>Now, imagine you’re throwing darts completely randomly at this square. Some darts will land inside the circle, and some will land outside but still within the square.</p> <p>The key insight here is the <strong>ratio of areas</strong>:</p> <p>The area of the square is $A_{square} = (2r)^2 = 4r^2$, where $r$ is the radius of the circle (and half the side length of the square). The area of the inscribed circle is $A_{circle} = \pi r^2$.</p> <p>Therefore, the ratio of the circle’s area to the square’s area is: \(\frac{A_{circle}}{A_{square}} = \frac{\pi r^2}{4r^2} = \frac{\pi}{4}\)</p> <p>If we throw darts randomly, the ratio of darts that land <em>inside</em> the circle to the total number of darts thrown <em>into the square</em> should approximate this area ratio.</p> <p>So, if $N_{circle}$ is the count of darts inside the circle and $N_{total}$ is the total count of darts: \(\frac{N_{circle}}{N_{total}} \approx \frac{\pi}{4}\)</p> <p>This means we can estimate $\pi$ using: \(\pi \approx 4 \times \frac{N_{circle}}{N_{total}}\)</p> <p><strong>How do we simulate this?</strong></p> <ol> <li> <strong>Imagine our square</strong> ranging from $(-1, -1)$ to $(1, 1)$ on a coordinate plane. Its side length is 2, and its area is 4.</li> <li> <strong>Our inscribed circle</strong> has a radius of 1, centered at $(0, 0)$.</li> <li> <strong>To “throw a dart,”</strong> we generate two random numbers, $x$ and $y$, each uniformly distributed between -1 and 1. This represents a random point within our square.</li> <li> <strong>To check if the dart landed in the circle,</strong> we calculate its distance from the origin $(0,0)$. If $x^2 + y^2 &lt; 1^2$ (i.e., less than the squared radius), the point is inside the circle.</li> </ol> <p>Let’s look at a conceptual Python snippet:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">random</span>
<span class="kn">import</span> <span class="n">math</span>

<span class="n">num_simulations</span> <span class="o">=</span> <span class="mi">1000000</span>  <span class="c1"># A large number of darts
</span><span class="n">points_inside_circle</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">total_points</span> <span class="o">=</span> <span class="mi">0</span>

<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">num_simulations</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">random</span><span class="p">.</span><span class="nf">uniform</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># Random x-coordinate
</span>    <span class="n">y</span> <span class="o">=</span> <span class="n">random</span><span class="p">.</span><span class="nf">uniform</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># Random y-coordinate
</span>
    <span class="n">distance_from_origin</span> <span class="o">=</span> <span class="n">math</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">x</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">y</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">distance_from_origin</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span> <span class="c1"># Check if point is inside the unit circle
</span>        <span class="n">points_inside_circle</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="n">total_points</span> <span class="o">+=</span> <span class="mi">1</span>

<span class="n">pi_estimate</span> <span class="o">=</span> <span class="mi">4</span> <span class="o">*</span> <span class="p">(</span><span class="n">points_inside_circle</span> <span class="o">/</span> <span class="n">total_points</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Estimated Pi: </span><span class="si">{</span><span class="n">pi_estimate</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
<span class="c1"># print(f"Actual Pi: {math.pi}")
</span></code></pre></div></div> <p>As <code class="language-plaintext highlighter-rouge">num_simulations</code> increases, our <code class="language-plaintext highlighter-rouge">pi_estimate</code> will get closer and closer to the true value of $\pi$. This simple yet powerful example perfectly illustrates the core mechanism of Monte Carlo.</p> <h3 id="hands-on-example-2-simulating-business-profitability-and-risk">Hands-On Example 2: Simulating Business Profitability and Risk</h3> <p>Let’s move to a scenario that’s perhaps more directly relevant to data science and business analytics: estimating the probability of making a profit on a new venture.</p> <p>Imagine you’re evaluating a small startup. You have an initial investment cost, but the revenue and operational costs are uncertain and can vary significantly. Traditional methods might give you a single “best-case” or “worst-case” scenario, but Monte Carlo can give you a <em>distribution</em> of possible outcomes and a more robust probability of profit.</p> <p>Let’s define our variables with some assumed distributions:</p> <ul> <li> <strong>Initial Investment:</strong> $50,000 (let’s assume this is fixed for simplicity, though it could also be a distribution).</li> <li> <strong>Monthly Revenue:</strong> We estimate it follows a Normal distribution with a mean of $30,000 and a standard deviation of $8,000. It could be higher or lower.</li> <li> <strong>Monthly Operating Costs:</strong> We estimate this follows a Uniform distribution between $10,000 and $25,000. It’s less predictable but within a range.</li> <li> <strong>Project Duration:</strong> 12 months.</li> </ul> <p>Our goal is to estimate the probability that the total profit over 12 months will be positive.</p> <p><strong>Profit</strong> = (Total Revenue - Total Operating Costs) - Initial Investment</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="n">num_simulations</span> <span class="o">=</span> <span class="mi">100000</span> <span class="c1"># Number of times we simulate the business
</span>
<span class="n">initial_investment</span> <span class="o">=</span> <span class="mi">50000</span>
<span class="n">project_duration_months</span> <span class="o">=</span> <span class="mi">12</span>

<span class="n">profitable_ventures</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">all_profits</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">num_simulations</span><span class="p">):</span>
    <span class="c1"># Simulate monthly revenues for the project duration
</span>    <span class="c1"># Using numpy's normal distribution for revenue
</span>    <span class="n">monthly_revenues</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">30000</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">8000</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">project_duration_months</span><span class="p">)</span>
    <span class="n">total_revenue</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">monthly_revenues</span><span class="p">)</span>

    <span class="c1"># Simulate monthly operating costs for the project duration
</span>    <span class="c1"># Using numpy's uniform distribution for costs
</span>    <span class="n">monthly_costs</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">uniform</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mi">25000</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">project_duration_months</span><span class="p">)</span>
    <span class="n">total_operating_costs</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">monthly_costs</span><span class="p">)</span>

    <span class="c1"># Calculate net profit for this single simulation
</span>    <span class="n">net_profit</span> <span class="o">=</span> <span class="p">(</span><span class="n">total_revenue</span> <span class="o">-</span> <span class="n">total_operating_costs</span><span class="p">)</span> <span class="o">-</span> <span class="n">initial_investment</span>
    <span class="n">all_profits</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">net_profit</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">net_profit</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">profitable_ventures</span> <span class="o">+=</span> <span class="mi">1</span>

<span class="n">probability_of_profit</span> <span class="o">=</span> <span class="n">profitable_ventures</span> <span class="o">/</span> <span class="n">num_simulations</span>
<span class="n">average_profit</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">all_profits</span><span class="p">)</span>
<span class="n">std_dev_profit</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">std</span><span class="p">(</span><span class="n">all_profits</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Probability of making a profit: </span><span class="si">{</span><span class="n">probability_of_profit</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="o">%</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Average profit across simulations: $</span><span class="si">{</span><span class="n">average_profit</span><span class="si">:</span><span class="p">,.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Standard deviation of profit: $</span><span class="si">{</span><span class="n">std_dev_profit</span><span class="si">:</span><span class="p">,.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># We could also visualize the distribution of all_profits using a histogram
# import matplotlib.pyplot as plt
# plt.hist(all_profits, bins=50)
# plt.axvline(0, color='r', linestyle='dashed', linewidth=1, label='Break-even')
# plt.title('Distribution of Simulated Profits')
# plt.xlabel('Profit ($)')
# plt.ylabel('Frequency')
# plt.show()
</span></code></pre></div></div> <p>With this simulation, we’re not just getting a single profit number; we’re getting a statistical understanding of the venture’s potential. We can see the <em>likelihood</em> of various outcomes. This is incredibly valuable for decision-making!</p> <h3 id="why-monte-carlo-is-a-data-scientists-best-friend">Why Monte Carlo is a Data Scientist’s Best Friend</h3> <p>Monte Carlo simulations are far more than just estimating $\pi$ or business profits. They are a workhorse in various data science and machine learning domains:</p> <ol> <li> <strong>High-Dimensional Integrals:</strong> Many problems in statistics, physics, and engineering require calculating complex integrals (e.g., expected values of functions of random variables) that are analytically intractable, especially in high dimensions. Monte Carlo integration offers an efficient way to estimate these.</li> <li> <strong>Uncertainty Quantification:</strong> When building predictive models, we often want to know not just “what will happen,” but “how likely is it to happen,” or “what’s the range of possible outcomes?” Monte Carlo allows us to propagate uncertainties through complex models and understand the distribution of results.</li> <li> <strong>Sensitivity Analysis:</strong> By varying input parameters according to their distributions, Monte Carlo can help identify which inputs have the most significant impact on the output, aiding in model refinement or strategic planning.</li> <li> <strong>Reinforcement Learning (RL):</strong> In RL, Monte Carlo methods are used to estimate the value of states or state-action pairs by averaging returns observed from many random episodes. For example, Monte Carlo Tree Search (MCTS) uses simulations to explore possible moves in games like Go.</li> <li> <strong>Bayesian Inference (MCMC):</strong> A more advanced cousin, Markov Chain Monte Carlo (MCMC), is crucial for sampling from complex probability distributions (especially posterior distributions in Bayesian statistics) that are impossible to sample directly. This allows us to make inferences even with highly complex models.</li> </ol> <h3 id="limitations-and-considerations">Limitations and Considerations</h3> <p>While powerful, Monte Carlo isn’t a silver bullet. It’s important to be aware of its limitations:</p> <ul> <li> <strong>Computational Cost:</strong> To achieve high accuracy, you often need a very large number of simulations. The convergence rate is typically $O(1/\sqrt{N})$, meaning to halve your error, you need to quadruple the number of samples ($N$). This can be computationally expensive for complex models.</li> <li> <strong>Quality of Random Numbers:</strong> Monte Carlo relies on “pseudo-random” number generators (PRNGs), which are deterministic algorithms designed to produce sequences that <em>appear</em> random. The quality of these generators can significantly impact the accuracy of your simulation. For most data science tasks, built-in library functions (like <code class="language-plaintext highlighter-rouge">numpy.random</code>) are sufficient.</li> <li> <strong>“Curse of Dimensionality” (Mitigated but Present):</strong> While Monte Carlo is less affected by high dimensionality than deterministic numerical integration methods, covering a vast high-dimensional space still requires a large number of samples to adequately explore the problem space.</li> </ul> <h3 id="wrapping-up-our-journey">Wrapping Up Our Journey</h3> <p>Monte Carlo simulations are a testament to the idea that sometimes, the most complex problems can be tamed by surprisingly simple, iterative approaches. By harnessing the power of randomness and relying on the Law of Large Numbers, we can gain deep insights into systems that would otherwise remain opaque.</p> <p>From estimating fundamental mathematical constants like $\pi$ to evaluating intricate business risks and powering advanced AI algorithms, Monte Carlo is a versatile and indispensable tool for anyone working with data and uncertainty.</p> <p>So, the next time you face a problem that seems too complex for a direct mathematical solution, remember the elegant simplicity of Monte Carlo. Embrace the chaos, simulate, and let the random numbers guide you to clarity. Go forth and experiment!</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/cracking-the-ai-black-box-why-explainable-ai-xai-i/">Cracking the AI Black Box: Why Explainable AI (XAI) is Our Superpower</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/the-secret-life-of-states-how-markov-chains-predic/">The Secret Life of States: How Markov Chains Predict Our Next Move (Without Remembering the Past!)</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/gradient-descent-unpacking-the-engine-of-machine-l/">Gradient Descent: Unpacking the Engine of Machine Learning</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Adarsh Nair. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/blog/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/masonry.js?v=a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/zoom.js?v=85ddb88934d28b74e78031fd54cf8308"></script> <script src="/blog/assets/js/no_defer.js?v=2781658a0a2b13ed609542042a859126"></script> <script defer src="/blog/assets/js/common.js?v=c15de51d4bb57887caa2c21988d97279"></script> <script defer src="/blog/assets/js/copy_code.js?v=c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/blog/assets/js/jupyter_new_tab.js?v=d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/blog/assets/js/mathjax-setup.js?v=a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/progress-bar.js?v=2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/blog/assets/js/vanilla-back-to-top.min.js?v=f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/blog/assets/js/search/ninja-keys.min.js?v=a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/blog/assets/js/search-setup.js?v=6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/blog/assets/js/search-data.js"></script> <script src="/blog/assets/js/shortcut-key.js?v=ccc841c459bfc0e64c1c2b5acd10df02"></script> </body> </html>