<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Ascending from Ignorance: A Personal Journey into Gradient Descent | Adarsh Nair </title> <meta name="author" content="Adarsh Nair"> <meta name="description" content="A deep dive into machine learning, AI, and data science. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <meta http-equiv="Content-Security-Policy" content="default-src 'self'; script-src 'self' 'unsafe-inline' https:; style-src 'self' 'unsafe-inline' https:; img-src 'self' data: https:; font-src 'self' data: https:; media-src 'self' https:; frame-src 'self' https:; connect-src 'self' https:;"> <link rel="stylesheet" href="/blog/assets/css/bootstrap.min.css?v=a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/blog/assets/css/academicons.min.css?v=f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/blog/assets/css/scholar-icons.css?v=62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-github.css?v=591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/blog/assets/css/main.css?v=d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://adarshnair.online/blog/blog/blog/2025/ascending-from-ignorance-a-personal-journey-into-g/"> <script src="/blog/assets/js/theme.js?v=5fea5159b787642c1bbc1f334d60f883"></script> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-native.css?v=5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="https://adarshnair.online" rel="external nofollow noopener" target="_blank"> Adarsh Nair </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/blog/"> </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/index.html">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/about/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/cv/">CV </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="https://adarshnair.online/books/" rel="external nofollow noopener" target="_blank">books </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="fa-solid fa-magnifying-glass"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-half-sun-moon" id="light-toggle-system"></i> <i class="fa-solid fa-moon" id="light-toggle-dark"></i> <i class="fa-solid fa-sun" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Ascending from Ignorance: A Personal Journey into Gradient Descent</h1> <p class="post-meta"> Created on January 02, 2025 by Adarsh Nair </p> <p class="post-tags"> <a href="/blog/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/blog/tag/machine-learning"> <i class="fa-solid fa-hashtag fa-sm"></i> Machine Learning</a>   <a href="/blog/blog/tag/optimization"> <i class="fa-solid fa-hashtag fa-sm"></i> Optimization</a>   <a href="/blog/blog/tag/algorithms"> <i class="fa-solid fa-hashtag fa-sm"></i> Algorithms</a>   <a href="/blog/blog/tag/deep-learning"> <i class="fa-solid fa-hashtag fa-sm"></i> Deep Learning</a>   <a href="/blog/blog/tag/calculus"> <i class="fa-solid fa-hashtag fa-sm"></i> Calculus</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p>Hello, fellow data explorers!</p> <p>Today, I want to take you on a journey, a descent, if you will, into one of the most fundamental algorithms in machine learning: <strong>Gradient Descent</strong>. When I first encountered this concept, it felt like unlocking a secret chamber in the vast castle of AI. It’s the engine behind countless machine learning models, from simple linear regression to the most complex deep neural networks. Understanding it isn’t just about memorizing a formula; it’s about grasping the core idea of how machines optimize and learn.</p> <p>So, grab your virtual hiking boots – we’re going to climb down a metaphorical mountain to find the lowest point.</p> <h3 id="the-mountain-were-trying-to-conquer-our-cost-function">The Mountain We’re Trying to Conquer: Our Cost Function</h3> <p>Imagine you’re trying to build a machine learning model that predicts house prices. You have historical data: house sizes, number of bedrooms, location, and their corresponding prices. Your model will try to find a relationship between these features and the price.</p> <p>At its heart, any machine learning model is trying to make predictions as accurately as possible. When it makes a mistake, we want to know <em>how big</em> that mistake is. This “mistake” or “error” is precisely what we quantify with something called a <strong>Cost Function</strong> (or Loss Function).</p> <p>Let’s take a super simple example: <strong>Linear Regression</strong>. We want to find a straight line $h_\theta(x) = \theta_0 + \theta_1 x$ that best fits our data. Here, $x$ could be the house size, and $h_\theta(x)$ is our predicted price. The $\theta_0$ and $\theta_1$ are our model’s parameters (the intercept and slope of the line). These are the values we need to “learn.”</p> <p>How do we define “best fit”? We want the predicted prices to be as close as possible to the actual prices. A common cost function for this is the <strong>Mean Squared Error (MSE)</strong>, often divided by 2 for mathematical convenience later:</p> \[J(\theta*0, \theta_1) = \frac{1}{2m} \sum*{i=1}^{m} (h\_\theta(x^{(i)}) - y^{(i)})^2\] <p>Let’s break this down:</p> <ul> <li>$m$: The number of training examples (houses).</li> <li>$x^{(i)}$: The input feature (e.g., size) of the $i$-th house.</li> <li>$y^{(i)}$: The actual price of the $i$-th house.</li> <li>$h_\theta(x^{(i)})$: Our model’s predicted price for the $i$-th house, using our current $\theta_0$ and $\theta_1$ values.</li> <li>The $(h_\theta(x^{(i)}) - y^{(i)})^2$: This is the squared difference between our prediction and the actual value. We square it to ensure positive errors (whether we overpredict or underpredict, it’s still an error) and to penalize larger errors more heavily.</li> <li>The $\frac{1}{2m} \sum_{i=1}^{m}$: We sum up all these squared errors and average them (the $1/m$ part). The $1/2$ is just a constant to make the derivative calculation cleaner.</li> </ul> <p>So, our goal is clear: find the values of $\theta_0$ and $\theta_1$ that <strong>minimize</strong> $J(\theta_0, \theta_1)$. If we find those $\theta$ values, our model will be making the smallest possible average squared error, meaning it’s the “best fit” line.</p> <h3 id="the-descent-how-do-we-find-the-lowest-point">The Descent: How Do We Find the Lowest Point?</h3> <p>Imagine our cost function $J(\theta_0, \theta_1)$ as a landscape. Since it depends on two parameters ($\theta_0$ and $\theta_1$), we can visualize it as a 3D bowl or a valley. The “height” at any point in this landscape represents the error (the value of $J$). Our task is to find the very bottom of that bowl.</p> <p>How would you do it if you were blindfolded and dropped onto this landscape?</p> <p>You’d probably feel around. Which way is downhill? Once you find the steepest downhill direction, you’d take a small step in that direction. Then you’d repeat: feel around, find the steepest downhill, take another step. You’d keep doing this until you couldn’t find any direction that goes further down – you’d be at the bottom!</p> <p>This intuitive process is precisely what Gradient Descent does.</p> <h3 id="the-math-behind-the-steepest-downhill">The Math Behind the “Steepest Downhill”</h3> <p>This “steepest downhill” direction is given to us by something called the <strong>gradient</strong>. For a function with multiple variables (like our $J(\theta_0, \theta_1)$), the gradient is a vector that points in the direction of the <em>greatest increase</em> of the function.</p> <p>Since we want to go <em>downhill</em> (minimize the function), we’ll move in the <em>opposite</em> direction of the gradient.</p> <p>Mathematically, the components of the gradient vector are the <strong>partial derivatives</strong> of the function with respect to each variable.</p> <p>For our cost function $J(\theta_0, \theta_1)$, the partial derivatives are:</p> \[\frac{\partial}{\partial \theta_j} J(\theta_0, \theta_1)\] <p>Let’s quickly recall what a derivative tells us: it’s the slope of a function at a particular point. A positive slope means the function is increasing; a negative slope means it’s decreasing. The magnitude of the slope tells us how steep it is.</p> <p>So, if we take the partial derivative of $J$ with respect to $\theta_0$, it tells us how much $J$ changes when we slightly change $\theta_0$, holding $\theta_1$ constant. The same applies to $\theta_1$.</p> <p>Calculating these for our Linear Regression cost function:</p> <p>For $\theta_0$: \(\frac{\partial}{\partial \theta*0} J(\theta_0, \theta_1) = \frac{1}{m} \sum*{i=1}^{m} (h\_\theta(x^{(i)}) - y^{(i)})\)</p> <p>For $\theta_1$: \(\frac{\partial}{\partial \theta*1} J(\theta_0, \theta_1) = \frac{1}{m} \sum*{i=1}^{m} (h\_\theta(x^{(i)}) - y^{(i)}) \cdot x^{(i)}\)</p> <p>(Note: The $1/2$ in the cost function conveniently cancels out when taking the derivative of the squared term using the chain rule: $\frac{d}{dx} \frac{1}{2}(f(x))^2 = \frac{1}{2} \cdot 2 f(x) \cdot f’(x) = f(x) f’(x)$).</p> <h3 id="the-gradient-descent-algorithm-putting-it-all-together">The Gradient Descent Algorithm: Putting It All Together</h3> <p>Now that we have the steepest descent direction, we can formulate the update rule. We start with some initial, random guesses for our parameters ($\theta_0, \theta_1$). Then, we repeatedly update them until we reach the bottom of the cost function.</p> <p>The update rule for each parameter $\theta_j$ is:</p> \[\theta_j := \theta_j - \alpha \frac{\partial}{\partial \theta_j} J(\theta_0, \theta_1)\] <p>Let’s break down this crucial equation:</p> <ul> <li>$\theta_j$: This represents one of our parameters (e.g., $\theta_0$ or $\theta_1$).</li> <li> <code class="language-plaintext highlighter-rouge">:=</code>: This means “assign the new value to.”</li> <li>$\alpha$ (alpha): This is the <strong>learning rate</strong>. It’s a small positive number (e.g., 0.01, 0.001) that controls the size of the step we take in each iteration. <ul> <li>If $\alpha$ is too small, we’ll take tiny steps, and it will take a very long time to reach the minimum.</li> <li>If $\alpha$ is too large, we might overshoot the minimum, bounce around, or even diverge and never find the minimum! It’s a critical hyperparameter to tune.</li> </ul> </li> <li>$\frac{\partial}{\partial \theta_j} J(\theta_0, \theta_1)$: This is the partial derivative we just discussed – the slope of the cost function with respect to $\theta_j$.</li> <li>The minus sign: Remember, the derivative points in the direction of <em>increase</em>. We want to go <em>downhill</em>, so we subtract the gradient.</li> </ul> <p><strong>The Algorithm in a Nutshell:</strong></p> <ol> <li> <strong>Initialize Parameters</strong>: Start with random values for $\theta_0, \theta_1$ (and any other $\theta$s if you have more features).</li> <li> <strong>Choose a Learning Rate ($\alpha$)</strong>: Pick a small, positive value.</li> <li> <strong>Iterate (Repeat until convergence):</strong> <ul> <li>Calculate the partial derivatives of the cost function with respect to <em>each</em> parameter using <em>all</em> your training data.</li> <li>Simultaneously update each parameter using the formula: $\theta_0 := \theta_0 - \alpha \frac{1}{m} \sum_{i=1}^{m} (h_\theta(x^{(i)}) - y^{(i)})$ $\theta_1 := \theta_1 - \alpha \frac{1}{m} \sum_{i=1}^{m} (h_\theta(x^{(i)}) - y^{(i)}) \cdot x^{(i)}$</li> <li>Crucially, you must update $\theta_0$ and $\theta_1$ (and any other parameters) <strong>simultaneously</strong>. This means you calculate all the new $\theta$ values based on the <em>old</em> $\theta$ values from the previous iteration, then update them all at once. If you update sequentially, you’d be using an already updated $\theta_0$ to calculate the update for $\theta_1$, which changes the path of descent.</li> </ul> </li> </ol> <p>How do we know when to stop? We can stop when the cost function’s value stops decreasing significantly, or when the changes in our $\theta$ values become very, very small (i.e., we’ve reached a flat bottom). Or, more practically, we can just run it for a fixed number of iterations.</p> <h3 id="visualizing-the-descent">Visualizing the Descent</h3> <p>Imagine our cost function is a simple parabola $J(\theta) = \theta^2$. The derivative is $\frac{d}{d\theta} J(\theta) = 2\theta$. Our update rule would be: $\theta := \theta - \alpha (2\theta)$.</p> <p>Let $\alpha = 0.1$. If we start at $\theta = 4$:</p> <ol> <li>$\theta := 4 - 0.1(2 \cdot 4) = 4 - 0.8 = 3.2$</li> <li>$\theta := 3.2 - 0.1(2 \cdot 3.2) = 3.2 - 0.64 = 2.56$</li> <li>$\theta := 2.56 - 0.1(2 \cdot 2.56) = 2.56 - 0.512 = 2.048$</li> </ol> <p>Notice how $\theta$ is steadily approaching 0 (which is the minimum of $\theta^2$). The steps get smaller as $\theta$ gets closer to 0, because the derivative ($2\theta$) also gets smaller. This is precisely what we want!</p> <h3 id="challenges-and-variants">Challenges and Variants</h3> <p>While elegant, Gradient Descent isn’t without its considerations:</p> <ol> <li> <p><strong>Local Minima</strong>: Our analogy of a simple bowl assumes our cost function is <strong>convex</strong>, meaning it has only one global minimum. Many complex models (especially deep neural networks) have non-convex cost functions with many “dips” or <strong>local minima</strong>. Gradient Descent might get stuck in a local minimum instead of reaching the absolute lowest point (global minimum). Fortunately, in high-dimensional spaces, local minima are often “good enough” or saddle points are more common.</p> </li> <li> <p><strong>Computational Cost of Batch Gradient Descent</strong>: The version we’ve discussed is technically <strong>Batch Gradient Descent</strong>. Why “batch”? Because to calculate each partial derivative, we sum over <em>all</em> $m$ training examples. If you have millions or billions of data points, each step of Gradient Descent can be very slow.</p> </li> </ol> <p>This leads us to more practical variants:</p> <ul> <li> <p><strong>Stochastic Gradient Descent (SGD)</strong>: Instead of summing over all $m$ examples, SGD calculates the gradient and updates parameters using <em>just one randomly chosen training example</em> at each step. \(\theta*j := \theta_j - \alpha (h*\theta(x^{(i)}) - y^{(i)}) \cdot x^{(i)}\_j\) (Here, $x^{(i)}_j$ refers to the $j$-th feature of the $i$-th training example. For $\theta_0$, $x^{(i)}_0 = 1$). SGD is much faster per update, but the path to the minimum is much noisier and zig-zags due to the variance of individual data points. It might never perfectly converge but will generally oscillate around the minimum.</p> </li> <li> <p><strong>Mini-batch Gradient Descent</strong>: This is the most popular variant in practice. It’s a compromise between Batch GD and SGD. Instead of using all data or just one data point, it uses a small “mini-batch” of $k$ training examples (e.g., 32, 64, 128) to compute the gradient. \(\theta*j := \theta_j - \alpha \frac{1}{k} \sum*{i=batch}^{} (h\_\theta(x^{(i)}) - y^{(i)}) \cdot x^{(i)}\_j\) Mini-batch GD is computationally efficient like SGD (due to vectorized operations on batches) and smoother than SGD, making it a powerful and widely used optimization algorithm for large datasets and complex models.</p> </li> </ul> <h3 id="conclusion-the-unsung-hero">Conclusion: The Unsung Hero</h3> <p>Gradient Descent, in its various forms, is the silent workhorse of modern machine learning. It’s the mechanism through which models learn, adapt, and refine their understanding of data. From identifying objects in images to understanding human language, this humble algorithm, born from the simple idea of “going downhill,” empowers machines to navigate complex data landscapes and find optimal solutions.</p> <p>The next time you see a machine learning model performing its task, remember the elegant dance of Gradient Descent happening beneath the surface, iteratively guiding the model parameters towards a state of minimal error. It’s a beautiful testament to how foundational mathematical concepts underpin the most advanced technologies of our time.</p> <p>Keep exploring, keep learning, and keep descending!</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/cracking-the-ai-black-box-why-explainable-ai-xai-i/">Cracking the AI Black Box: Why Explainable AI (XAI) is Our Superpower</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/the-secret-life-of-states-how-markov-chains-predic/">The Secret Life of States: How Markov Chains Predict Our Next Move (Without Remembering the Past!)</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/gradient-descent-unpacking-the-engine-of-machine-l/">Gradient Descent: Unpacking the Engine of Machine Learning</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Adarsh Nair. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/blog/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/masonry.js?v=a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/zoom.js?v=85ddb88934d28b74e78031fd54cf8308"></script> <script src="/blog/assets/js/no_defer.js?v=2781658a0a2b13ed609542042a859126"></script> <script defer src="/blog/assets/js/common.js?v=c15de51d4bb57887caa2c21988d97279"></script> <script defer src="/blog/assets/js/copy_code.js?v=c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/blog/assets/js/jupyter_new_tab.js?v=d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/blog/assets/js/mathjax-setup.js?v=a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/progress-bar.js?v=2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/blog/assets/js/vanilla-back-to-top.min.js?v=f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/blog/assets/js/search/ninja-keys.min.js?v=a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/blog/assets/js/search-setup.js?v=6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/blog/assets/js/search-data.js"></script> <script src="/blog/assets/js/shortcut-key.js?v=ccc841c459bfc0e64c1c2b5acd10df02"></script> </body> </html>