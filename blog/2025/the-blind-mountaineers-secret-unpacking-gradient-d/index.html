<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> The Blind Mountaineer's Secret: Unpacking Gradient Descent | Adarsh Nair </title> <meta name="author" content="Adarsh Nair"> <meta name="description" content="A deep dive into machine learning, AI, and data science. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <meta http-equiv="Content-Security-Policy" content="default-src 'self'; script-src 'self' 'unsafe-inline' https:; style-src 'self' 'unsafe-inline' https:; img-src 'self' data: https:; font-src 'self' data: https:; media-src 'self' https:; frame-src 'self' https:; connect-src 'self' https:;"> <link rel="stylesheet" href="/blog/assets/css/bootstrap.min.css?v=a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/blog/assets/css/academicons.min.css?v=f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/blog/assets/css/scholar-icons.css?v=62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-github.css?v=591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/blog/assets/css/main.css?v=d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://adarshnair.online/blog/blog/blog/2025/the-blind-mountaineers-secret-unpacking-gradient-d/"> <script src="/blog/assets/js/theme.js?v=5fea5159b787642c1bbc1f334d60f883"></script> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-native.css?v=5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="https://adarshnair.online" rel="external nofollow noopener" target="_blank"> Adarsh Nair </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/blog/"> </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/index.html">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/cv/">CV </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/repositories/">repositories </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="fa-solid fa-magnifying-glass"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-half-sun-moon" id="light-toggle-system"></i> <i class="fa-solid fa-moon" id="light-toggle-dark"></i> <i class="fa-solid fa-sun" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">The Blind Mountaineer's Secret: Unpacking Gradient Descent</h1> <p class="post-meta"> Created on August 27, 2025 by Adarsh Nair </p> <p class="post-tags"> <a href="/blog/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/blog/tag/machine-learning"> <i class="fa-solid fa-hashtag fa-sm"></i> Machine Learning</a>   <a href="/blog/blog/tag/optimization"> <i class="fa-solid fa-hashtag fa-sm"></i> Optimization</a>   <a href="/blog/blog/tag/gradient-descent"> <i class="fa-solid fa-hashtag fa-sm"></i> Gradient Descent</a>   <a href="/blog/blog/tag/deep-learning"> <i class="fa-solid fa-hashtag fa-sm"></i> Deep Learning</a>   <a href="/blog/blog/tag/algorithms"> <i class="fa-solid fa-hashtag fa-sm"></i> Algorithms</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p>From fitting a simple line to data points to training the complex neural networks that power AI, there’s an unsung hero working tirelessly behind the scenes: <strong>Gradient Descent</strong>. When I first dove into the world of machine learning, I was mesmerized by how models could “learn.” But the <em>how</em> was a mystery that fascinated me. It felt like magic, until I realized the magic was just really elegant math and a brilliant optimization strategy.</p> <p>Let’s embark on a journey to demystify this fundamental algorithm, imagining ourselves as blindfolded mountaineers trying to find the lowest point in a vast, undulating landscape.</p> <h3 id="the-problem-finding-the-best-fit">The Problem: Finding the “Best” Fit</h3> <p>Imagine you have a scatter plot of data points, and you want to draw a straight line that best represents the trend. How do you define “best”? In machine learning, “best” usually means minimizing a <strong>cost function</strong> (or loss function).</p> <p>For our simple line-fitting example (linear regression), a common cost function is the Mean Squared Error (MSE). It measures the average of the squared differences between our predicted line and the actual data points. Our line is defined by its parameters: slope ($m$) and y-intercept ($c$). So, our cost function $J(m, c)$ tells us how “bad” our current line is.</p> <p>Our ultimate goal? To find the values of $m$ and $c$ that make $J(m, c)$ as small as possible. This is where Gradient Descent steps in.</p> <h3 id="the-mountain-analogy-walking-blindfolded">The Mountain Analogy: Walking Blindfolded</h3> <p>Picture yourself standing on a mountain. Your goal is to reach the lowest point in the valley, but you’re blindfolded. You can’t see the whole landscape. What’s your strategy?</p> <p>You’d probably feel the ground beneath your feet. Which direction is downhill? You’d take a small step in that direction, then re-evaluate. Repeat, repeat, repeat, until you feel like you can’t go any further down.</p> <p>This, my friends, is the essence of Gradient Descent.</p> <ul> <li> <strong>The Mountain Landscape:</strong> This is our cost function, $J(\theta)$, where $\theta$ represents our model’s parameters (like $m$ and $c$ for our line). The height of the mountain at any point is the value of the cost function for a given set of parameters.</li> <li> <strong>Our Current Position:</strong> This is our current set of parameters, $\theta_{current}$.</li> <li> <strong>Feeling the Ground:</strong> How do we know which way is downhill? This is where calculus comes in – specifically, <strong>derivatives</strong>. A derivative tells us the slope or rate of change of a function at a particular point. For a multi-dimensional function (like our cost function with multiple parameters), we use <strong>partial derivatives</strong> and combine them into a <strong>gradient</strong>.</li> <li> <strong>Taking a Step:</strong> We move our parameters in the direction opposite to the gradient (because the gradient points uphill, and we want to go downhill). The size of our step is controlled by something called the <strong>learning rate</strong>.</li> </ul> <h3 id="the-math-behind-the-walk">The Math Behind the Walk</h3> <p>Let’s formalize our blind mountaineer’s strategy.</p> <p><strong>1. The Cost Function:</strong> We start with a cost function, $J(\theta)$, which we want to minimize. For simplicity, let’s imagine we only have one parameter, $\theta$.</p> <p><strong>2. The Direction of Steepest Ascent (The Derivative):</strong> The derivative of $J(\theta)$ with respect to $\theta$, denoted as $\frac{dJ(\theta)}{d\theta}$, tells us the slope of the cost function curve at our current $\theta$.</p> <ul> <li>If $\frac{dJ(\theta)}{d\theta}$ is positive, increasing $\theta$ will increase $J(\theta)$. To go downhill, we need to <em>decrease</em> $\theta$.</li> <li>If $\frac{dJ(\theta)}{d\theta}$ is negative, increasing $\theta$ will decrease $J(\theta)$. To go downhill, we need to <em>increase</em> $\theta$.</li> </ul> <p>Notice a pattern? We always want to move in the direction <em>opposite</em> to the sign of the derivative.</p> <p><strong>3. The Gradient (For Multiple Parameters):</strong> Most real-world models have many parameters ($\theta_1, \theta_2, …, \theta_n$). In such cases, we use the <strong>gradient</strong>, denoted by $\nabla J(\theta)$. The gradient is a vector of all the partial derivatives of the cost function with respect to each parameter:</p> <p>$\nabla J(\theta) = \begin{pmatrix} \frac{\partial J(\theta)}{\partial \theta_1} \ \frac{\partial J(\theta)}{\partial \theta_2} \ \vdots \ \frac{\partial J(\theta)}{\partial \theta_n} \end{pmatrix}$</p> <p>Each element in this vector tells us how much the cost changes if we slightly vary that particular parameter, while holding others constant. The gradient vector points in the direction of the steepest <em>increase</em> in the cost function. Since we want to minimize the cost, we move in the opposite direction.</p> <p><strong>4. The Update Rule:</strong> This is the core of Gradient Descent. We update our parameters iteratively using this rule:</p> <p>$\theta_{new} = \theta_{old} - \alpha \nabla J(\theta_{old})$</p> <p>Let’s break it down:</p> <ul> <li>$\theta_{new}$: Our updated parameters after taking a step.</li> <li>$\theta_{old}$: Our current parameters.</li> <li>$\alpha$ (alpha): This is the <strong>learning rate</strong>. It’s a hyperparameter that determines the size of the step we take in the direction of the minimum. <ul> <li>If $\alpha$ is too small, convergence will be very slow. We’ll crawl down the mountain.</li> <li>If $\alpha$ is too large, we might overshoot the minimum, bounce around erratically, or even diverge entirely (jump off the mountain!).</li> </ul> </li> <li>$\nabla J(\theta_{old})$: The gradient of the cost function at our current parameters. This tells us the direction of steepest ascent. By subtracting it, we move in the direction of steepest descent.</li> </ul> <h3 id="a-step-by-step-journey">A Step-by-Step Journey</h3> <p>The Gradient Descent algorithm proceeds as follows:</p> <ol> <li> <strong>Initialize Parameters:</strong> Start with an initial guess for our model’s parameters ($\theta$), often randomly chosen.</li> <li> <strong>Choose a Learning Rate ($\alpha$):</strong> Select a suitable value for $\alpha$. This requires some experimentation.</li> <li> <strong>Iterate (Take Steps):</strong> <ul> <li> <strong>Calculate the Gradient:</strong> Compute $\nabla J(\theta)$ using the current parameters.</li> <li> <strong>Update Parameters:</strong> Apply the update rule: $\theta := \theta - \alpha \nabla J(\theta)$.</li> </ul> </li> <li> <strong>Repeat:</strong> Continue steps 3a and 3b until a stopping criterion is met. This could be: <ul> <li>The change in $\theta$ becomes very small (we’ve reached a flat bottom).</li> <li>The change in $J(\theta)$ becomes very small (the cost isn’t decreasing significantly).</li> <li>A maximum number of iterations is reached.</li> </ul> </li> </ol> <h3 id="navigating-the-landscape-challenges-and-considerations">Navigating the Landscape: Challenges and Considerations</h3> <p>Our blind mountaineer’s journey isn’t always straightforward.</p> <ul> <li> <strong>Local vs. Global Minima:</strong> Our mountain landscape might have multiple “valleys” or dips. Gradient Descent is guaranteed to find <em>a</em> minimum, but it might get stuck in a <strong>local minimum</strong> rather than the absolute lowest point (<strong>global minimum</strong>). The starting point of our parameters can influence which minimum we find.</li> <li> <strong>The Learning Rate Dilemma:</strong> As discussed, choosing the right $\alpha$ is crucial. It’s often tuned through experimentation or using adaptive learning rate algorithms (like Adam, RMSprop) that adjust $\alpha$ during training.</li> <li> <strong>Vanishing and Exploding Gradients:</strong> In deep neural networks, gradients can become extremely small (vanishing) or extremely large (exploding) during backpropagation, making training difficult. This is a more advanced topic but highlights that Gradient Descent, while powerful, isn’t without its challenges.</li> </ul> <h3 id="variations-on-the-theme-efficiency-and-robustness">Variations on the Theme: Efficiency and Robustness</h3> <p>The “classic” Gradient Descent we’ve discussed is often called <strong>Batch Gradient Descent</strong>. Why “Batch”? Because for each step, we calculate the gradient using <em>all</em> the training examples in our dataset. This can be computationally very expensive if you have millions or billions of data points.</p> <p>To address this, more efficient variants have emerged:</p> <ol> <li> <strong>Stochastic Gradient Descent (SGD):</strong> Instead of using the entire dataset, SGD calculates the gradient and updates parameters using just <strong>one single random training example</strong> at each step. <ul> <li> <strong>Pros:</strong> Extremely fast updates, especially for large datasets. Its “noisy” updates can help escape shallow local minima.</li> <li> <strong>Cons:</strong> The path to the minimum is much more erratic and noisy. It might never truly “settle” at the exact minimum but rather oscillate around it.</li> </ul> </li> <li> <strong>Mini-Batch Gradient Descent:</strong> This is often the sweet spot and the most commonly used variant. It calculates the gradient and updates parameters using a small “batch” of training examples (e.g., 32, 64, 128 examples) instead of just one or all of them. <ul> <li> <strong>Pros:</strong> Smoother convergence than SGD, but faster updates than Batch GD. It balances the computational efficiency of SGD with the stability of Batch GD. It benefits from vectorized operations on GPUs.</li> <li> <strong>Cons:</strong> Requires choosing a mini-batch size.</li> </ul> </li> </ol> <h3 id="why-it-matters-the-engine-of-learning">Why It Matters: The Engine of Learning</h3> <p>Gradient Descent, in its various forms, is the engine that drives most of modern machine learning and deep learning. It’s how:</p> <ul> <li>Linear and Logistic Regression models find their optimal coefficients.</li> <li>Neural networks adjust their vast numbers of weights and biases to learn complex patterns from data.</li> <li>Models “converge” to a state where they perform best on unseen data.</li> </ul> <p>Understanding Gradient Descent isn’t just about memorizing an equation; it’s about grasping the core idea of iterative improvement, of feeling your way towards a solution when the full picture is hidden. It’s a beautiful testament to how simple, repeatable steps can lead to profound intelligence.</p> <p>My journey of understanding this core algorithm transformed my perception of machine learning from mystical art to an elegant science. The next time you see an AI perform something amazing, remember the blind mountaineer, taking careful steps down the slope, guided by the gradient, towards an optimal solution. It’s not magic; it’s just very good math!</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/cracking-the-ai-black-box-why-explainable-ai-xai-i/">Cracking the AI Black Box: Why Explainable AI (XAI) is Our Superpower</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/the-secret-life-of-states-how-markov-chains-predic/">The Secret Life of States: How Markov Chains Predict Our Next Move (Without Remembering the Past!)</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/gradient-descent-unpacking-the-engine-of-machine-l/">Gradient Descent: Unpacking the Engine of Machine Learning</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Adarsh Nair. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/blog/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/masonry.js?v=a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/zoom.js?v=85ddb88934d28b74e78031fd54cf8308"></script> <script src="/blog/assets/js/no_defer.js?v=2781658a0a2b13ed609542042a859126"></script> <script defer src="/blog/assets/js/common.js?v=c15de51d4bb57887caa2c21988d97279"></script> <script defer src="/blog/assets/js/copy_code.js?v=c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/blog/assets/js/jupyter_new_tab.js?v=d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/blog/assets/js/mathjax-setup.js?v=a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/progress-bar.js?v=2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/blog/assets/js/vanilla-back-to-top.min.js?v=f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/blog/assets/js/search/ninja-keys.min.js?v=a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/blog/assets/js/search-setup.js?v=6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/blog/assets/js/search-data.js"></script> <script src="/blog/assets/js/shortcut-key.js?v=ccc841c459bfc0e64c1c2b5acd10df02"></script> </body> </html>