<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> My Climb Down the Loss Mountain: A Journey into Gradient Descent | Adarsh Nair </title> <meta name="author" content="Adarsh Nair"> <meta name="description" content="A deep dive into machine learning, AI, and data science. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <meta http-equiv="Content-Security-Policy" content="default-src 'self'; script-src 'self' 'unsafe-inline' https:; style-src 'self' 'unsafe-inline' https:; img-src 'self' data: https:; font-src 'self' data: https:; media-src 'self' https:; frame-src 'self' https:; connect-src 'self' https:;"> <link rel="stylesheet" href="/blog/assets/css/bootstrap.min.css?v=a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/blog/assets/css/academicons.min.css?v=f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/blog/assets/css/scholar-icons.css?v=62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-github.css?v=591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/blog/assets/css/main.css?v=d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://adarshnair.online/blog/blog/blog/2025/my-climb-down-the-loss-mountain-a-journey-into-gra/"> <script src="/blog/assets/js/theme.js?v=5fea5159b787642c1bbc1f334d60f883"></script> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-native.css?v=5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/blog/cv/"> Adarsh Nair </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/blog/"> </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/index.html">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/cv/">CV </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/repositories/">repositories </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="fa-solid fa-magnifying-glass"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-half-sun-moon" id="light-toggle-system"></i> <i class="fa-solid fa-moon" id="light-toggle-dark"></i> <i class="fa-solid fa-sun" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">My Climb Down the Loss Mountain: A Journey into Gradient Descent</h1> <p class="post-meta"> Created on February 03, 2025 by Adarsh Nair </p> <p class="post-tags"> <a href="/blog/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/blog/tag/machine-learning"> <i class="fa-solid fa-hashtag fa-sm"></i> Machine Learning</a>   <a href="/blog/blog/tag/gradient-descent"> <i class="fa-solid fa-hashtag fa-sm"></i> Gradient Descent</a>   <a href="/blog/blog/tag/optimization"> <i class="fa-solid fa-hashtag fa-sm"></i> Optimization</a>   <a href="/blog/blog/tag/deep-learning"> <i class="fa-solid fa-hashtag fa-sm"></i> Deep Learning</a>   <a href="/blog/blog/tag/algorithms"> <i class="fa-solid fa-hashtag fa-sm"></i> Algorithms</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p>Welcome, fellow explorers of the digital frontier!</p> <p>Today, I want to share a story, a journey really, that’s fundamental to understanding how intelligent systems come to be. It’s a tale of finding the lowest point in a complex landscape, a quest for optimal answers – and it’s called <strong>Gradient Descent</strong>.</p> <p>Think of it this way: Imagine you’re blindfolded, standing on a vast, undulating terrain somewhere in the mountains. Your goal? To reach the lowest point in the valley. You can’t see the path ahead, but you <em>can</em> feel the slope directly beneath your feet. What do you do? Naturally, you’d take a step in the direction that feels steepest downwards. You’d repeat this process, taking small steps, always feeling for the steepest descent, until you eventually find yourself at the bottom.</p> <p>This, in a nutshell, is the intuitive magic behind Gradient Descent.</p> <h2 id="the-quest-for-best-understanding-the-loss-function">The Quest for “Best”: Understanding the Loss Function</h2> <p>Before we dive deeper into our descent, we need to understand <em>what</em> we’re trying to minimize. In machine learning, this “mountain” we’re trying to climb down is called the <strong>Loss Function</strong> (or Cost Function, or Objective Function).</p> <p>Let’s say we’re building a model to predict house prices. We feed it features like square footage, number of bedrooms, and location. Our model then spits out a predicted price. We also know the <em>actual</em> price of that house. The difference between our model’s prediction and the actual price is an “error.” The loss function quantifies this error across many houses.</p> <p>A common loss function for regression tasks is the <strong>Mean Squared Error (MSE)</strong>. If we have a simple linear model $h_\theta(x) = \theta_0 + \theta_1 x$ (where $\theta_0$ and $\theta_1$ are our model’s parameters, essentially the ‘slope’ and ‘y-intercept’ of our line), the MSE loss function, often denoted as $J(\theta)$, would look something like this:</p> \[J(\theta) = \frac{1}{2m} \sum_{i=1}^{m} (h_\theta(x^{(i)}) - y^{(i)})^2\] <p>Here:</p> <ul> <li>$m$ is the number of training examples.</li> <li>$x^{(i)}$ are the input features for the $i$-th example.</li> <li>$y^{(i)}$ is the actual target value for the $i$-th example.</li> <li>$h_\theta(x^{(i)})$ is our model’s prediction for the $i$-th example.</li> <li>$\theta$ represents all our model’s parameters (in our simple example, $\theta_0$ and $\theta_1$).</li> </ul> <p>Our goal is to find the values of $\theta$ (our parameters) that make $J(\theta)$ as small as possible. This minimum point represents the “best fit” line (or hyperplane in higher dimensions) for our data, minimizing the overall prediction error.</p> <h2 id="the-compass-what-is-a-gradient">The Compass: What is a Gradient?</h2> <p>Remember our blindfolded mountain climber? How did they know which way was “down”? By feeling the slope. In mathematics, the “slope” in multiple dimensions is given by the <strong>gradient</strong>.</p> <p>The gradient of a function tells us the direction of the <em>steepest ascent</em>. If we want to go <em>downhill</em>, we simply move in the <em>opposite</em> direction of the gradient.</p> <p>Mathematically, the gradient of our loss function $J(\theta)$ with respect to its parameters $\theta$ is a vector of its partial derivatives:</p> \[\nabla J(\theta) = \begin{pmatrix} \frac{\partial J(\theta)}{\partial \theta_0} \\ \frac{\partial J(\theta)}{\partial \theta_1} \\ \vdots \\ \frac{\partial J(\theta)}{\partial \theta_n} \end{pmatrix}\] <p>Each $\frac{\partial J(\theta)}{\partial \theta_j}$ tells us how much the loss function $J(\theta)$ changes if we slightly tweak just one of our parameters, $\theta_j$, while keeping all other parameters constant. It’s essentially the sensitivity of our error to each individual parameter.</p> <h2 id="taking-a-step-the-gradient-descent-update-rule">Taking a Step: The Gradient Descent Update Rule</h2> <p>With our loss function defined and our compass (the gradient) in hand, we can now formulate the core update rule for Gradient Descent. At each step, we update our parameters $\theta_j$ by moving them in the direction <em>opposite</em> to the gradient, scaled by a small factor.</p> <p>For each parameter $\theta_j$ in our model, we apply this update simultaneously:</p> \[\theta_j := \theta_j - \alpha \frac{\partial J(\theta)}{\partial \theta_j}\] <p>Let’s break this crucial equation down:</p> <ol> <li> <strong>$\theta_j := \theta_j$</strong>: This means “update $\theta_j$ to a new value.”</li> <li> <strong>$-$</strong>: This negative sign is vital! It signifies that we’re moving in the direction <em>opposite</em> to the gradient (downhill), not uphill.</li> <li> <strong>$\alpha$ (alpha)</strong>: This is perhaps the most critical hyperparameter: the <strong>learning rate</strong>. It controls the size of the step we take down the mountain.</li> <li> <strong>$\frac{\partial J(\theta)}{\partial \theta_j}$</strong>: This is the partial derivative of the loss function with respect to parameter $\theta_j$. It tells us the slope of the loss function at our current position along the $\theta_j$ dimension.</li> </ol> <p>So, in essence, for each parameter, we calculate how much it contributes to the overall error (via the partial derivative), and then we adjust that parameter a little bit in the direction that would reduce the error, with the size of that adjustment determined by the learning rate. We repeat this process many times (called “epochs”) until our parameters converge to a stable state, ideally at the bottom of the loss function.</p> <h3 id="the-power-of-alpha-the-learning-rate">The Power of $\alpha$: The Learning Rate</h3> <p>The learning rate, $\alpha$, is our step size. Choosing the right $\alpha$ is incredibly important:</p> <ul> <li> <strong>If $\alpha$ is too small:</strong> We’ll take tiny, hesitant steps. It will take a very long time to reach the bottom, and our model might train excessively slowly.</li> <li> <strong>If $\alpha$ is too large:</strong> We might overshoot the minimum, bouncing back and forth wildly, or even diverge completely and climb <em>up</em> the mountain to infinity! Our model will fail to converge.</li> </ul> <p>Finding the optimal learning rate often involves a bit of experimentation and techniques like learning rate schedules, but it’s a critical knob to tune for effective model training.</p> <h2 id="types-of-descent-batch-stochastic-and-mini-batch">Types of Descent: Batch, Stochastic, and Mini-Batch</h2> <p>Our general Gradient Descent algorithm works, but there are different ways to calculate that gradient, each with its own trade-offs:</p> <ol> <li> <strong>Batch Gradient Descent (BGD):</strong> <ul> <li> <strong>How it works:</strong> It calculates the gradient of the loss function using <em>all</em> the training examples in each iteration.</li> <li> <strong>Pros:</strong> Guaranteed to converge to the global minimum for convex loss functions (like MSE for linear regression). Very stable updates.</li> <li> <strong>Cons:</strong> Can be very slow and computationally expensive if you have a massive dataset, as it has to process all data for every single parameter update. It’s like feeling the slope of the <em>entire mountain</em> before taking one step.</li> </ul> </li> <li> <strong>Stochastic Gradient Descent (SGD):</strong> <ul> <li> <strong>How it works:</strong> Instead of using all data, it calculates the gradient and updates parameters using only <em>one</em> randomly chosen training example at a time.</li> <li> <strong>Pros:</strong> Much faster per iteration, especially for large datasets. It’s like taking a step after feeling the slope under <em>one foot</em>. This “noise” can also help escape shallow local minima in complex loss landscapes.</li> <li> <strong>Cons:</strong> The updates are very noisy, causing the loss function to fluctuate wildly. It might never truly “settle” at the exact minimum but rather oscillate around it.</li> </ul> </li> <li> <strong>Mini-Batch Gradient Descent:</strong> <ul> <li> <strong>How it works:</strong> This is the most common and practical approach. It’s a compromise between BGD and SGD. It calculates the gradient and updates parameters using a small “batch” of training examples (typically 32, 64, 128, etc.).</li> <li> <strong>Pros:</strong> Balances the speed of SGD with the stability of BGD. It benefits from vectorized operations (processing multiple examples at once is efficient on modern hardware). It’s the best of both worlds, offering relatively stable convergence while being computationally efficient.</li> </ul> </li> </ol> <h2 id="navigating-the-terrain-challenges-and-considerations">Navigating the Terrain: Challenges and Considerations</h2> <p>While Gradient Descent is incredibly powerful, the “loss mountain” isn’t always a smooth, convex bowl leading to a single, obvious minimum.</p> <ul> <li> <strong>Local Minima:</strong> In complex models (like deep neural networks), the loss function can have many “dips” or “valleys” that are local minima, but not the absolute lowest point (global minimum). Gradient Descent might get stuck in one of these. SGD’s inherent “noise” can sometimes help jump out of shallow local minima.</li> <li> <strong>Saddle Points:</strong> These are points where the slope is zero, but it’s neither a minimum nor a maximum – it’s a maximum in one direction and a minimum in another. Gradient Descent can slow down significantly or get stuck here.</li> <li> <strong>Feature Scaling:</strong> If your input features have vastly different scales (e.g., house size in square feet vs. number of bedrooms), the loss function can become very elongated and distorted. This makes Gradient Descent zigzag inefficiently. Scaling your features (e.g., normalization) helps make the loss landscape more spherical, allowing GD to converge faster.</li> </ul> <h2 id="the-heartbeat-of-learning">The Heartbeat of Learning</h2> <p>Gradient Descent, in its various forms, is the workhorse behind a vast array of machine learning and deep learning algorithms. From training simple linear regression models to optimizing the billions of parameters in state-of-the-art neural networks for image recognition, natural language processing, and more – it’s the fundamental mechanism that allows these models to learn from data.</p> <p>Every time a machine “improves” its performance, or learns a new pattern, chances are Gradient Descent (or one of its more advanced variants like Adam, RMSprop, Adagrad, which are essentially smarter ways of adapting the learning rate or momentum) is silently guiding its parameters down the loss mountain.</p> <h2 id="my-journey-continues">My Journey Continues…</h2> <p>Learning about Gradient Descent was a pivotal moment in my own data science journey. It transformed my understanding of abstract mathematical concepts into practical, tangible mechanisms that power AI. It’s a beautiful demonstration of how simple, iterative steps, guided by a clear objective, can lead to powerful and intelligent outcomes.</p> <p>As you continue your own exploration of machine learning, remember the blindfolded climber. Understand the terrain (the loss function), trust your compass (the gradient), and choose your steps wisely (the learning rate). With these principles, you’re well-equipped to guide your models to their own “best” answers. Keep learning, keep experimenting, and keep descending!</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/cracking-the-ai-black-box-why-explainable-ai-xai-i/">Cracking the AI Black Box: Why Explainable AI (XAI) is Our Superpower</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/the-secret-life-of-states-how-markov-chains-predic/">The Secret Life of States: How Markov Chains Predict Our Next Move (Without Remembering the Past!)</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/gradient-descent-unpacking-the-engine-of-machine-l/">Gradient Descent: Unpacking the Engine of Machine Learning</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Adarsh Nair. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/blog/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/masonry.js?v=a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/zoom.js?v=85ddb88934d28b74e78031fd54cf8308"></script> <script src="/blog/assets/js/no_defer.js?v=2781658a0a2b13ed609542042a859126"></script> <script defer src="/blog/assets/js/common.js?v=c15de51d4bb57887caa2c21988d97279"></script> <script defer src="/blog/assets/js/copy_code.js?v=c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/blog/assets/js/jupyter_new_tab.js?v=d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/blog/assets/js/mathjax-setup.js?v=a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/progress-bar.js?v=2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/blog/assets/js/vanilla-back-to-top.min.js?v=f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/blog/assets/js/search/ninja-keys.min.js?v=a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/blog/assets/js/search-setup.js?v=6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/blog/assets/js/search-data.js"></script> <script src="/blog/assets/js/shortcut-key.js?v=ccc841c459bfc0e64c1c2b5acd10df02"></script> </body> </html>