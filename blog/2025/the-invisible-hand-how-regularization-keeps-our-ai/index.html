<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> The Invisible Hand: How Regularization Keeps Our AI Honest and Humble | Adarsh Nair </title> <meta name="author" content="Adarsh Nair"> <meta name="description" content="A deep dive into machine learning, AI, and data science. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <meta http-equiv="Content-Security-Policy" content="default-src 'self'; script-src 'self' 'unsafe-inline' https:; style-src 'self' 'unsafe-inline' https:; img-src 'self' data: https:; font-src 'self' data: https:; media-src 'self' https:; frame-src 'self' https:; connect-src 'self' https:;"> <link rel="stylesheet" href="/blog/assets/css/bootstrap.min.css?v=a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/blog/assets/css/academicons.min.css?v=f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/blog/assets/css/scholar-icons.css?v=62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-github.css?v=591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/blog/assets/css/main.css?v=d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://adarshnair.online/blog/blog/blog/2025/the-invisible-hand-how-regularization-keeps-our-ai/"> <script src="/blog/assets/js/theme.js?v=5fea5159b787642c1bbc1f334d60f883"></script> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-native.css?v=5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/blog/cv/"> Adarsh Nair </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/blog/"> </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/index.html">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/cv/">CV </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/repositories/">repositories </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="fa-solid fa-magnifying-glass"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-half-sun-moon" id="light-toggle-system"></i> <i class="fa-solid fa-moon" id="light-toggle-dark"></i> <i class="fa-solid fa-sun" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">The Invisible Hand: How Regularization Keeps Our AI Honest and Humble</h1> <p class="post-meta"> Created on April 07, 2025 by Adarsh Nair </p> <p class="post-tags"> <a href="/blog/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/blog/tag/machine-learning"> <i class="fa-solid fa-hashtag fa-sm"></i> Machine Learning</a>   <a href="/blog/blog/tag/regularization"> <i class="fa-solid fa-hashtag fa-sm"></i> Regularization</a>   <a href="/blog/blog/tag/overfitting"> <i class="fa-solid fa-hashtag fa-sm"></i> Overfitting</a>   <a href="/blog/blog/tag/data-science"> <i class="fa-solid fa-hashtag fa-sm"></i> Data Science</a>   <a href="/blog/blog/tag/model-training"> <i class="fa-solid fa-hashtag fa-sm"></i> Model Training</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p>As a young data science enthusiast, I remember staring at complex equations, feeling a mix of awe and dread. One concept, in particular, kept popping up: <strong>Regularization</strong>. It sounded fancy, intimidating even. But as I delved deeper, I realized it wasn’t just another mathematical trick; it was the <em>invisible hand</em> guiding my models towards true understanding, away from mere memorization.</p> <p>Imagine a student preparing for an exam. This student could spend hours cramming every single fact, every minute detail from the textbook. When the exam comes, if the questions are <em>exactly</em> what they crammed, they’ll ace it. But what if the questions are phrased differently, or require applying those facts to a new scenario? Our cramming student might struggle because they memorized, but didn’t truly <em>understand</em>.</p> <p>In the world of Machine Learning, this “cramming student” is what we call an <strong>overfit model</strong>. And just like in school, overfitting is a problem we desperately need to solve.</p> <hr> <h3 id="the-peril-of-perfect-memory-understanding-overfitting">The Peril of Perfect Memory: Understanding Overfitting</h3> <p>Let’s say we’re building a model to predict house prices based on features like size, number of bedrooms, and location. We collect a bunch of data (our “training data”) and train our model.</p> <p>An overfit model is like that cramming student. It learns the training data <em>too well</em>. It doesn’t just learn the underlying patterns; it also learns the noise, the quirks, the random fluctuations present in that specific dataset. It builds an incredibly complex relationship that fits every single training point almost perfectly.</p> <p>Take a look at this conceptual illustration:</p> <p><img src="https://i.imgur.com/gO1Xz2h.png" alt="Conceptual graph showing overfitting vs. good fit"> <em>(Imagine the blue dots are our training data points. The green line is a good model, capturing the general trend. The red line is an overfit model, twisting and turning to hit every single blue dot, including the noisy ones.)</em></p> <p>While an overfit model might achieve incredibly low error rates on the data it <em>trained on</em>, it utterly fails when presented with new, unseen data (our “test data”). Why? Because it hasn’t learned the general rules; it’s memorized specific examples. It’s like our student failing a new kind of question because they only memorized answers to old ones. This inability to perform well on new data is called <strong>poor generalization</strong>.</p> <p>This is where Regularization steps in.</p> <hr> <h3 id="enter-regularization-the-humble-whisperer">Enter Regularization: The Humble Whisperer</h3> <p>Regularization is a technique designed to prevent overfitting by discouraging overly complex models. Think of it as a mentor whispering to our model, “Hey, don’t get too confident. Don’t try to explain <em>every single wobble</em> in the data. Focus on the main story.”</p> <p>How does it do this? By adding a <strong>penalty</strong> to our model’s complexity to the loss function it’s trying to minimize.</p> <p>Let’s recall the heart of most machine learning models: the <strong>loss function</strong>. During training, our model tries to find the set of parameters (often represented as $\theta$ or $w$) that minimizes this loss function. A common loss function for regression tasks is the Mean Squared Error (MSE):</p> <p>$J(\theta) = \frac{1}{2m} \sum_{i=1}^m (h_\theta(x^{(i)}) - y^{(i)})^2$</p> <p>Here, $h_\theta(x^{(i)})$ is our model’s prediction for the $i$-th data point, $y^{(i)}$ is the actual value, and $m$ is the number of data points. The goal is to make $h_\theta(x^{(i)})$ as close to $y^{(i)}$ as possible.</p> <p>Regularization modifies this objective. Instead of just minimizing the error, we minimize the error <em>plus</em> a penalty term related to the size of our model’s parameters:</p> <p>$J_{regularized}(\theta) = \text{Loss}(\theta) + \text{Regularization Term}$</p> <p>This “Regularization Term” is where the magic happens. It nudges the model to prefer simpler explanations by making it “costly” for parameters to take on very large values. If a parameter’s value becomes excessively large, it implies that the model is putting too much emphasis on a specific feature, potentially over-fitting to noise associated with that feature.</p> <p>The strength of this penalty is controlled by a hyperparameter, usually denoted as $\lambda$ (lambda).</p> <ul> <li> <strong>Small $\lambda$</strong>: Little penalty, model can still be complex, risk of overfitting.</li> <li> <strong>Large $\lambda$</strong>: Strong penalty, forces parameters towards zero, risk of underfitting (model is too simple and misses important patterns).</li> </ul> <p>Finding the right $\lambda$ is crucial and often involves techniques like cross-validation.</p> <hr> <h3 id="the-two-main-flavors-l1-lasso-and-l2-ridge">The Two Main Flavors: L1 (Lasso) and L2 (Ridge)</h3> <p>There are two primary types of regularization you’ll encounter, each with its own unique “personality”:</p> <h4 id="1-l2-regularization-ridge-regression">1. L2 Regularization (Ridge Regression)</h4> <p><strong>The Gentle Nudge</strong></p> <p>L2 regularization adds a penalty proportional to the <em>square</em> of the magnitude of the coefficients.</p> <p>The regularized loss function becomes:</p> <p>$J_{\text{Ridge}}(\theta) = \frac{1}{2m} \sum_{i=1}^m (h_\theta(x^{(i)}) - y^{(i)})^2 + \lambda \sum_{j=1}^n \theta_j^2$</p> <p>Here, $\sum_{j=1}^n \theta_j^2$ is the sum of the squares of all the model’s parameters (excluding the intercept term, which usually isn’t regularized).</p> <p><strong>Intuition:</strong> L2 regularization acts like a gentle push. It discourages large parameter values but rarely forces them to be <em>exactly</em> zero. It encourages all features to contribute a little, shrinking their coefficients towards zero but keeping them in the model. Think of it as making sure no single student gets <em>too</em> loud or dominates the discussion; everyone contributes in a balanced way.</p> <p><strong>Analogy:</strong> Imagine a group project where everyone has a role. L2 regularization ensures that everyone participates, but no one tries to take over completely. All the features stay in the model, just with smaller, more controlled influence.</p> <h4 id="2-l1-regularization-lasso-regression">2. L1 Regularization (Lasso Regression)</h4> <p><strong>The Feature Selector</strong></p> <p>L1 regularization adds a penalty proportional to the <em>absolute value</em> of the magnitude of the coefficients.</p> <p>The regularized loss function becomes:</p> <table> <tbody> <tr> <td>$J_{\text{Lasso}}(\theta) = \frac{1}{2m} \sum_{i=1}^m (h_\theta(x^{(i)}) - y^{(i)})^2 + \lambda \sum_{j=1}^n</td> <td>\theta_j</td> <td>$</td> </tr> </tbody> </table> <table> <tbody> <tr> <td>Here, $\sum_{j=1}^n</td> <td>\theta_j</td> <td>$ is the sum of the absolute values of all the model’s parameters.</td> </tr> </tbody> </table> <p><strong>Intuition:</strong> L1 regularization is a bit more aggressive. Besides shrinking coefficients, it has a unique property: it can drive some coefficients <em>exactly to zero</em>. This means that L1 regularization can effectively perform <strong>feature selection</strong> by completely eliminating the influence of less important features from the model.</p> <p><strong>Analogy:</strong> Back to our group project, L1 regularization is like identifying which team members are truly contributing and which ones are just along for the ride. It might decide that some features are simply not important enough and remove them from the model entirely, simplifying the overall explanation.</p> <hr> <h3 id="why-the-difference-a-quick-peek-at-the-maths-geometry">Why the Difference? A Quick Peek at the Math’s Geometry</h3> <p>Without diving too deep into the complex geometry, we can visualize why L1 and L2 behave differently.</p> <p>Imagine the contours of our original loss function (like concentric ellipses representing regions of equal error). Our goal is to find the center of the smallest ellipse that touches the “constraint region” imposed by regularization.</p> <ul> <li> <strong>L2’s constraint region</strong> is a <strong>circle</strong> (or sphere in higher dimensions): $\sum \theta_j^2 \le T$. When the elliptical loss contours touch this circular constraint, it typically happens at a point where all coefficients are non-zero.</li> <li> <table> <tbody> <tr> <td> <strong>L1’s constraint region</strong> is a <strong>diamond</strong> (or octahedron in higher dimensions): $\sum</td> <td>\theta_j</td> <td>\le T$. The corners of this diamond lie on the axes. When the elliptical loss contours touch this diamond-shaped constraint, it’s very common for them to touch at one of these corners, where one or more coefficients are exactly zero.</td> </tr> </tbody> </table> </li> </ul> <p>This geometric difference is why L1 is capable of sparsity (driving coefficients to zero) and L2 is not.</p> <hr> <h3 id="beyond-l1l2-other-regularization-strategies">Beyond L1/L2: Other Regularization Strategies</h3> <p>While L1 and L2 are fundamental, regularization isn’t just about tweaking loss functions. Other powerful techniques exist:</p> <ul> <li> <strong>Dropout (for Neural Networks):</strong> Imagine during training, randomly “switching off” a percentage of neurons in a neural network. This prevents any single neuron from becoming too reliant on others, forcing the network to learn more robust features. It’s like training several slightly different models simultaneously and averaging their opinions.</li> <li> <strong>Early Stopping:</strong> This is a simple yet effective technique. Instead of training your model until the training loss is at its absolute minimum, you monitor its performance on a separate <em>validation set</em>. When the validation error starts to <em>increase</em> (meaning the model is starting to overfit to the training data), you stop training. It’s like telling our student, “You’ve learned enough for the exam; further cramming will just confuse you.”</li> <li> <strong>Data Augmentation:</strong> For tasks involving images, text, or audio, we can artificially expand our training dataset by creating slightly modified versions of existing data (e.g., rotating images, translating text, adding noise to audio). This exposes the model to more variations, making it less likely to overfit to specific examples.</li> <li> <strong>Batch Normalization:</strong> A technique used in deep learning to normalize the inputs to layers, which stabilizes the learning process and can act as a form of regularization.</li> </ul> <hr> <h3 id="the-art-of-balancing-the-hyperparameter-lambda">The Art of Balancing: The Hyperparameter $\lambda$</h3> <p>Remember $\lambda$? It’s the dial that controls the strength of our regularization.</p> <ul> <li>If $\lambda$ is too small, the penalty is weak, and our model might still overfit.</li> <li>If $\lambda$ is too large, the penalty is too strong, and our model might become too simplistic, leading to <strong>underfitting</strong> (where it doesn’t even capture the main patterns).</li> </ul> <p>Finding the optimal $\lambda$ is crucial. This is typically done using techniques like <strong>cross-validation</strong>, where we split our data into multiple folds, train the model on some folds, and validate $\lambda$’s performance on the remaining fold, repeating the process.</p> <hr> <h3 id="my-takeaway-the-humble-model-is-the-best-model">My Takeaway: The Humble Model is the Best Model</h3> <p>Through my own projects and learning experiences, regularization has become one of my go-to tools. It taught me that sometimes, a model that looks “perfect” on your training data is actually a liar. The true measure of a model’s worth is its ability to generalize, to adapt to the unknown.</p> <p>Regularization isn’t about getting the absolute lowest training error. It’s about building robust, reliable models that truly <em>understand</em> the underlying relationships in the data, rather than just memorizing them. It’s about fostering humility in our algorithms, ensuring they remain practical, honest, and truly useful in the real world.</p> <p>So, the next time you’re training a model and grappling with overfitting, remember the invisible hand of regularization. It’s there to guide your model, just like a good mentor, helping it learn not just <em>what</em> to think, but <em>how</em> to think. And that, I believe, is the essence of true intelligence, both artificial and human.</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/cracking-the-ai-black-box-why-explainable-ai-xai-i/">Cracking the AI Black Box: Why Explainable AI (XAI) is Our Superpower</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/the-secret-life-of-states-how-markov-chains-predic/">The Secret Life of States: How Markov Chains Predict Our Next Move (Without Remembering the Past!)</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/gradient-descent-unpacking-the-engine-of-machine-l/">Gradient Descent: Unpacking the Engine of Machine Learning</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Adarsh Nair. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/blog/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/masonry.js?v=a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/zoom.js?v=85ddb88934d28b74e78031fd54cf8308"></script> <script src="/blog/assets/js/no_defer.js?v=2781658a0a2b13ed609542042a859126"></script> <script defer src="/blog/assets/js/common.js?v=c15de51d4bb57887caa2c21988d97279"></script> <script defer src="/blog/assets/js/copy_code.js?v=c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/blog/assets/js/jupyter_new_tab.js?v=d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/blog/assets/js/mathjax-setup.js?v=a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/progress-bar.js?v=2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/blog/assets/js/vanilla-back-to-top.min.js?v=f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/blog/assets/js/search/ninja-keys.min.js?v=a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/blog/assets/js/search-setup.js?v=6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/blog/assets/js/search-data.js"></script> <script src="/blog/assets/js/shortcut-key.js?v=ccc841c459bfc0e64c1c2b5acd10df02"></script> </body> </html>