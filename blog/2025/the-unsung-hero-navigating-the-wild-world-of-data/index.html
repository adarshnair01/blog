<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> The Unsung Hero: Navigating the Wild World of Data Cleaning Strategies | Adarsh Nair </title> <meta name="author" content="Adarsh Nair"> <meta name="description" content="A deep dive into machine learning, AI, and data science. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <meta http-equiv="Content-Security-Policy" content="default-src 'self'; script-src 'self' 'unsafe-inline' https:; style-src 'self' 'unsafe-inline' https:; img-src 'self' data: https:; font-src 'self' data: https:; media-src 'self' https:; frame-src 'self' https:; connect-src 'self' https:;"> <link rel="stylesheet" href="/blog/assets/css/bootstrap.min.css?v=a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/blog/assets/css/academicons.min.css?v=f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/blog/assets/css/scholar-icons.css?v=62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-github.css?v=591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/blog/assets/css/main.css?v=d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://adarshnair.online/blog/blog/blog/2025/the-unsung-hero-navigating-the-wild-world-of-data/"> <script src="/blog/assets/js/theme.js?v=5fea5159b787642c1bbc1f334d60f883"></script> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-native.css?v=5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="https://adarshnair.online" rel="external nofollow noopener" target="_blank"> Adarsh Nair </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/blog/"> </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/index.html">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/cv/">CV </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="https://adarshnair.online/books/" rel="external nofollow noopener" target="_blank">books </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="fa-solid fa-magnifying-glass"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-half-sun-moon" id="light-toggle-system"></i> <i class="fa-solid fa-moon" id="light-toggle-dark"></i> <i class="fa-solid fa-sun" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">The Unsung Hero: Navigating the Wild World of Data Cleaning Strategies</h1> <p class="post-meta"> Created on July 26, 2025 by Adarsh Nair </p> <p class="post-tags"> <a href="/blog/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/blog/tag/data-cleaning"> <i class="fa-solid fa-hashtag fa-sm"></i> Data Cleaning</a>   <a href="/blog/blog/tag/data-preprocessing"> <i class="fa-solid fa-hashtag fa-sm"></i> Data Preprocessing</a>   <a href="/blog/blog/tag/machine-learning"> <i class="fa-solid fa-hashtag fa-sm"></i> Machine Learning</a>   <a href="/blog/blog/tag/data-science"> <i class="fa-solid fa-hashtag fa-sm"></i> Data Science</a>   <a href="/blog/blog/tag/python"> <i class="fa-solid fa-hashtag fa-sm"></i> Python</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <h2 id="the-unsung-hero-navigating-the-wild-world-of-data-cleaning-strategies">The Unsung Hero: Navigating the Wild World of Data Cleaning Strategies</h2> <p>Hey everyone! Ever dream of building the next groundbreaking AI model or uncovering a hidden truth in a sea of numbers? That’s the exciting part of data science, right? But before you can train your fancy neural networks or impress with elegant visualizations, there’s a crucial, often overlooked, and sometimes messy step: <strong>Data Cleaning</strong>.</p> <p>Imagine trying to bake a gourmet cake with rotten eggs, stale flour, and moldy fruit. No matter how skilled a baker you are, the result will be… well, inedible. The same principle applies to data science: <strong>“Garbage In, Garbage Out” (GIGO)</strong>. If your input data is flawed, incomplete, or inconsistent, even the most sophisticated algorithms will produce unreliable and misleading results.</p> <p>Think of me as your guide on an adventure into the data cleaning wilderness. It’s less glamorous than model building, but it’s where the real magic (and sometimes frustration!) begins. I’ve spent countless hours sifting through messy datasets, and trust me, mastering data cleaning is one of the most valuable superpowers you can develop. It’s estimated that data professionals spend 60-80% of their time on data cleaning and preparation – a significant chunk!</p> <h3 id="why-bother-the-gigo-principle-in-action">Why Bother? The GIGO Principle in Action</h3> <p>Why dedicate so much effort to cleaning? Because dirty data can lead to:</p> <ol> <li> <strong>Inaccurate Models</strong>: A model trained on biased or incorrect data will make poor predictions. If your sales data has errors, your forecast will be off, leading to bad business decisions.</li> <li> <strong>Misleading Insights</strong>: Visualizations and statistical analyses performed on unclean data can tell a completely false story, causing you to draw incorrect conclusions.</li> <li> <strong>Wasted Time &amp; Resources</strong>: Debugging a model when the real issue is messy data is a frustrating and time-consuming process. It’s far more efficient to get the data right from the start.</li> <li> <strong>Algorithm Failures</strong>: Some algorithms are very sensitive to missing values or outliers and might simply crash or produce nonsense without proper data preparation.</li> </ol> <h3 id="the-data-cleaning-detective-kit-common-culprits">The Data Cleaning Detective Kit: Common Culprits</h3> <p>Before we jump into solutions, let’s identify the common types of ‘dirt’ we might encounter. Think of yourself as a detective, inspecting your data for clues!</p> <ol> <li> <strong>Missing Values (NaNs)</strong>: These are literally gaps in your data. Maybe a sensor failed, a user skipped a field, or data was lost during transfer. Represented as <code class="language-plaintext highlighter-rouge">NaN</code> (Not a Number), <code class="language-plaintext highlighter-rouge">None</code>, or even empty strings.</li> <li> <strong>Outliers</strong>: Data points that significantly deviate from other observations. They could be legitimate extreme values, or they could be errors in data entry or measurement.</li> <li> <strong>Duplicate Records</strong>: Identical (or nearly identical) rows of data that appear multiple times. These can inflate counts and skew analyses.</li> <li> <strong>Inconsistent Data Types &amp; Formats</strong>: <ul> <li> <strong>Different units</strong>: ‘cm’ vs. ‘meters’ for height.</li> <li> <strong>Varied spellings</strong>: ‘New York’, ‘NY’, ‘NYC’ for the same city.</li> <li> <strong>Case sensitivity</strong>: ‘Apple’ vs. ‘apple’.</li> <li> <strong>Incorrect data types</strong>: Numbers stored as strings, dates as generic objects.</li> </ul> </li> <li> <strong>Structural Errors</strong>: Typos, incorrect labeling, or inconsistent naming conventions (e.g., <code class="language-plaintext highlighter-rouge">cust_id</code> vs. <code class="language-plaintext highlighter-rouge">customer_id</code>).</li> <li> <strong>Invalid Data</strong>: Values that are outside a valid range (e.g., age = 200, temperature = -500°C) or don’t conform to business rules.</li> </ol> <h3 id="strategies-in-action-your-cleaning-arsenal">Strategies in Action: Your Cleaning Arsenal</h3> <p>Now, let’s roll up our sleeves and tackle these issues with some practical strategies.</p> <h4 id="1-handling-missing-values">1. Handling Missing Values</h4> <p>Missing values are perhaps the most common problem. Your approach depends heavily on the nature and quantity of the missing data.</p> <p><strong>Identification</strong>: In Python, using <code class="language-plaintext highlighter-rouge">pandas</code>, you can quickly see missing counts:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="sh">'</span><span class="s">your_data.csv</span><span class="sh">'</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="nf">isnull</span><span class="p">().</span><span class="nf">sum</span><span class="p">())</span>
</code></pre></div></div> <p><strong>Treatment Options</strong>:</p> <ul> <li> <strong>Deletion</strong>: <ul> <li> <strong>Row Deletion</strong>: If a row has too many missing values, or if the dataset is large enough that removing a few rows won’t significantly impact the analysis, you can simply drop them. This is often the simplest approach, but beware of losing valuable information.</li> <li> <strong>Column Deletion</strong>: If an entire column has a very high percentage of missing values (e.g., &gt;70-80%), it might be better to drop the whole column, as it provides little useful information.</li> <li> <em>When to use</em>: Small amount of missing data relative to the dataset size; non-critical features.</li> </ul> </li> <li> <strong>Imputation</strong>: Replacing missing values with estimated ones. This is often preferred over deletion to preserve data. <ul> <li> <strong>Mean/Median/Mode Imputation</strong>: <ul> <li> <strong>Mean</strong>: Replace with the average value of the column. Best for numerical data without extreme outliers, assuming a normal distribution.</li> <li> <strong>Median</strong>: Replace with the middle value. More robust to outliers than the mean. Best for numerical data, especially skewed distributions.</li> <li> <strong>Mode</strong>: Replace with the most frequent value. Best for categorical or discrete numerical data.</li> </ul> <p>Let $X$ be a feature with $N$ observed values $x_1, x_2, \ldots, x_N$. The <strong>mean</strong> imputation for a missing value $x_{missing}$ would be: $x_{missing} = \bar{X} = \frac{1}{N} \sum_{i=1}^{N} x_i$</p> <p><em>When to use</em>: Simple, quick, but can reduce variance and distort relationships if not used carefully.</p> </li> <li> <strong>Advanced Imputation</strong>: <ul> <li> <strong>Forward Fill (ffill) / Backward Fill (bfill)</strong>: Propagating the next or previous valid observation forward or backward. Useful for time series data.</li> <li> <strong>Regression Imputation</strong>: Predict the missing value using other features in the dataset, treating the missing feature as a target variable in a regression model.</li> <li> <strong>K-Nearest Neighbors (KNN) Imputation</strong>: Find the $K$ closest data points to the one with the missing value and impute based on their values. More sophisticated but computationally intensive.</li> </ul> </li> </ul> </li> </ul> <h4 id="2-detecting-and-treating-outliers">2. Detecting and Treating Outliers</h4> <p>Outliers can heavily skew statistics and model training. Deciding whether to keep, transform, or remove an outlier requires careful consideration and domain knowledge.</p> <p><strong>Identification</strong>:</p> <ul> <li> <strong>Visualization</strong>: Box plots, scatter plots, and histograms are excellent for spotting outliers visually.</li> <li> <strong>Statistical Methods</strong>: <ul> <li> <strong>Z-score</strong>: Measures how many standard deviations a data point is from the mean. $Z = \frac{x - \mu}{\sigma}$ Where $x$ is the data point, $\mu$ is the mean, and $\sigma$ is the standard deviation. A common threshold for an outlier is typically $|Z| &gt; 3$. This method assumes your data is normally distributed.</li> <li> <strong>Interquartile Range (IQR)</strong>: More robust to skewed distributions. First, calculate $Q1$ (25th percentile) and $Q3$ (75th percentile). Then, $IQR = Q3 - Q1$. Outliers are typically defined as values falling below $Q1 - 1.5 \times IQR$ or above $Q3 + 1.5 \times IQR$.</li> </ul> </li> </ul> <p><strong>Treatment Options</strong>:</p> <ul> <li> <strong>Removal</strong>: If an outlier is clearly an error and doesn’t represent true variability (e.g., a person’s age listed as 200), it’s best to remove it.</li> <li> <strong>Capping (Winsorization)</strong>: Replace outliers with a maximum or minimum reasonable value. For example, replace all values above $Q3 + 1.5 \times IQR$ with $Q3 + 1.5 \times IQR$.</li> <li> <strong>Transformation</strong>: Applying a mathematical transformation like a logarithm or square root can compress the range of the data, reducing the impact of extreme values. E.g., $log(x)$.</li> <li> <strong>Keep Them</strong>: Sometimes, outliers are crucial data points (e.g., identifying fraud or rare disease cases). Understanding their context is key.</li> </ul> <h4 id="3-eliminating-duplicate-records">3. Eliminating Duplicate Records</h4> <p>Duplicate records can inflate your dataset, leading to biased statistics and model training.</p> <p><strong>Identification</strong>: Pandas makes this straightforward:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">print</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="nf">duplicated</span><span class="p">().</span><span class="nf">sum</span><span class="p">())</span> <span class="c1"># Count duplicates
</span><span class="n">duplicate_rows</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">.</span><span class="nf">duplicated</span><span class="p">(</span><span class="n">keep</span><span class="o">=</span><span class="bp">False</span><span class="p">)]</span> <span class="c1"># View all duplicate occurrences
</span></code></pre></div></div> <p>The <code class="language-plaintext highlighter-rouge">keep</code> parameter can be ‘first’, ‘last’, or <code class="language-plaintext highlighter-rouge">False</code> to mark all duplicates.</p> <p><strong>Treatment Options</strong>:</p> <ul> <li> <strong>Removal</strong>: The most common approach. <div class="language-python highlighter-rouge"> <div class="highlight"><pre class="highlight"><code><span class="n">df_cleaned</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">drop_duplicates</span><span class="p">(</span><span class="n">keep</span><span class="o">=</span><span class="sh">'</span><span class="s">first</span><span class="sh">'</span><span class="p">)</span> <span class="c1"># Keep the first occurrence
</span></code></pre></div> </div> <p><em>When to use</em>: Always, unless duplicates have specific meaning (e.g., multiple purchases by the same customer, which are distinct transactions). Be careful with subsets of columns to define a unique record. For instance, two people might have the same name, but different IDs.</p> </li> </ul> <h4 id="4-standardizing-inconsistent-data">4. Standardizing Inconsistent Data</h4> <p>This is where the ‘detective’ work truly shines, often requiring domain knowledge.</p> <p><strong>Common Issues &amp; Solutions</strong>:</p> <ul> <li> <strong>Case Sensitivity</strong>: ‘apple’, ‘Apple’, ‘APPLE’ should all be the same. <div class="language-python highlighter-rouge"> <div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">column_name</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">column_name</span><span class="sh">'</span><span class="p">].</span><span class="nb">str</span><span class="p">.</span><span class="nf">lower</span><span class="p">()</span> <span class="c1"># Convert to lowercase
</span></code></pre></div> </div> </li> <li> <strong>Whitespace</strong>: Extra spaces can make ‘ New York’ different from ‘New York’. <div class="language-python highlighter-rouge"> <div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">column_name</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">column_name</span><span class="sh">'</span><span class="p">].</span><span class="nb">str</span><span class="p">.</span><span class="nf">strip</span><span class="p">()</span> <span class="c1"># Remove leading/trailing spaces
</span></code></pre></div> </div> </li> <li> <strong>Units</strong>: Ensure all numerical values for a feature are in the same unit (e.g., convert all weights to kilograms).</li> <li> <strong>Categorical Inconsistencies</strong>: ‘NY’, ‘New York’, ‘NYC’ referring to the same entity. <ul> <li> <strong>Mapping</strong>: Create a dictionary to map inconsistent values to a standard one.</li> <li> <strong>Fuzzy Matching</strong>: For larger datasets or more complex variations, libraries like <code class="language-plaintext highlighter-rouge">fuzzywuzzy</code> can help identify similar strings.</li> <li> <strong>Regular Expressions (Regex)</strong>: Powerful for finding and replacing patterns (e.g., extracting numbers from mixed text).</li> </ul> </li> <li> <strong>Incorrect Data Types</strong>: Ensure numeric columns are <code class="language-plaintext highlighter-rouge">int</code> or <code class="language-plaintext highlighter-rouge">float</code>, and dates are <code class="language-plaintext highlighter-rouge">datetime</code> objects. <div class="language-python highlighter-rouge"> <div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">numeric_column</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">to_numeric</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">numeric_column</span><span class="sh">'</span><span class="p">],</span> <span class="n">errors</span><span class="o">=</span><span class="sh">'</span><span class="s">coerce</span><span class="sh">'</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">date_column</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">to_datetime</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">date_column</span><span class="sh">'</span><span class="p">],</span> <span class="n">errors</span><span class="o">=</span><span class="sh">'</span><span class="s">coerce</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div> </div> <p><code class="language-plaintext highlighter-rouge">errors='coerce'</code> will turn unparseable values into <code class="language-plaintext highlighter-rouge">NaN</code>, which you can then handle.</p> </li> </ul> <h4 id="5-rectifying-structural-errors">5. Rectifying Structural Errors</h4> <p>These errors often relate to how the data is organized or collected.</p> <ul> <li> <strong>Column Renaming</strong>: Make column names consistent and descriptive (e.g., <code class="language-plaintext highlighter-rouge">cust_id</code> to <code class="language-plaintext highlighter-rouge">customer_id</code>).</li> <li> <strong>Merging/Reshaping</strong>: Sometimes data needs to be merged from multiple sources or reshaped (e.g., from wide to long format) to be usable.</li> <li> <strong>Typos</strong>: Manual correction or using libraries like <code class="language-plaintext highlighter-rouge">pyspellchecker</code> for textual data.</li> </ul> <h4 id="6-validating-data">6. Validating Data</h4> <p>After applying cleaning steps, it’s crucial to validate your changes and ensure new issues haven’t been introduced.</p> <ul> <li> <strong>Rule-based Validation</strong>: Define specific rules your data must adhere to (e.g., age must be &gt; 0 and &lt; 120; product IDs must follow a <code class="language-plaintext highlighter-rouge">XX-YYYY-ZZ</code> pattern).</li> <li> <strong>Cross-referencing</strong>: Compare cleaned data against external, trusted sources if available.</li> <li> <strong>Summary Statistics &amp; Visualizations</strong>: Re-run <code class="language-plaintext highlighter-rouge">df.describe()</code>, <code class="language-plaintext highlighter-rouge">df.isnull().sum()</code>, and re-plot distributions to see the impact of your cleaning.</li> </ul> <h3 id="the-art-of-cleaning-pro-tips--mindset">The Art of Cleaning: Pro Tips &amp; Mindset</h3> <p>Data cleaning is rarely a linear process. It’s iterative, exploratory, and requires a good dose of critical thinking.</p> <ol> <li> <strong>Always Explore First</strong>: Before you touch anything, perform thorough Exploratory Data Analysis (EDA). Visualizations are your best friend here. Get a feel for the data’s distribution, relationships, and inherent patterns.</li> <li> <strong>Document Everything</strong>: This is paramount for reproducibility and collaboration. Keep a log of every cleaning step, every decision made, and why you made it. Version control your cleaning scripts!</li> <li> <strong>Domain Knowledge is Gold</strong>: Collaborate with subject matter experts. They can provide context for outliers, clarify valid ranges, and help interpret ambiguous data. What looks like an error to you might be a critical piece of information to them.</li> <li> <strong>Don’t Over-Clean</strong>: Removing too much data or imputing aggressively can lead to loss of valuable information or introduce bias. Sometimes, less is more. The goal is to make the data usable, not perfect.</li> <li> <strong>Automate Where Possible</strong>: Once you’ve established a cleaning routine for a specific dataset or type of data, write functions or scripts to automate it. This saves time and ensures consistency for future datasets.</li> <li> <strong>It’s an Iterative Process</strong>: You might clean for missing values, only to find new outliers emerge, which then reveals more inconsistencies. Be prepared to go back and forth.</li> </ol> <h3 id="conclusion-your-data-cleaning-superpower">Conclusion: Your Data Cleaning Superpower</h3> <p>While data cleaning might not get the same headlines as the latest AI breakthrough, it is undeniably the bedrock of all successful data science projects. It’s where you truly get to understand your data, its quirks, and its potential.</p> <p>By mastering these strategies, you’re not just fixing errors; you’re transforming raw, noisy information into a valuable, reliable asset. You’re giving your models the best possible chance to learn and your insights the strongest foundation to stand on.</p> <p>So, next time you dive into a new dataset, embrace your inner data detective. Armed with these strategies, you’re ready to tackle the mess, uncover the truth, and pave the way for powerful, accurate, and impactful data-driven solutions. Happy cleaning!</p> <hr> <p><em>This blog post is part of my portfolio showcasing practical data science skills. Connect with me for more insights and projects!</em></p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/cracking-the-ai-black-box-why-explainable-ai-xai-i/">Cracking the AI Black Box: Why Explainable AI (XAI) is Our Superpower</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/the-secret-life-of-states-how-markov-chains-predic/">The Secret Life of States: How Markov Chains Predict Our Next Move (Without Remembering the Past!)</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/gradient-descent-unpacking-the-engine-of-machine-l/">Gradient Descent: Unpacking the Engine of Machine Learning</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Adarsh Nair. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/blog/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/masonry.js?v=a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/zoom.js?v=85ddb88934d28b74e78031fd54cf8308"></script> <script src="/blog/assets/js/no_defer.js?v=2781658a0a2b13ed609542042a859126"></script> <script defer src="/blog/assets/js/common.js?v=c15de51d4bb57887caa2c21988d97279"></script> <script defer src="/blog/assets/js/copy_code.js?v=c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/blog/assets/js/jupyter_new_tab.js?v=d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/blog/assets/js/mathjax-setup.js?v=a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/progress-bar.js?v=2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/blog/assets/js/vanilla-back-to-top.min.js?v=f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/blog/assets/js/search/ninja-keys.min.js?v=a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/blog/assets/js/search-setup.js?v=6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/blog/assets/js/search-data.js"></script> <script src="/blog/assets/js/shortcut-key.js?v=ccc841c459bfc0e64c1c2b5acd10df02"></script> </body> </html>