<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> The Data Detective's Toolkit: Unmasking Truths with Hypothesis Testing | Adarsh Nair </title> <meta name="author" content="Adarsh Nair"> <meta name="description" content="A deep dive into machine learning, AI, and data science. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <meta http-equiv="Content-Security-Policy" content="default-src 'self'; script-src 'self' 'unsafe-inline' https:; style-src 'self' 'unsafe-inline' https:; img-src 'self' data: https:; font-src 'self' data: https:; media-src 'self' https:; frame-src 'self' https:; connect-src 'self' https:;"> <link rel="stylesheet" href="/blog/assets/css/bootstrap.min.css?v=a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/blog/assets/css/academicons.min.css?v=f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/blog/assets/css/scholar-icons.css?v=62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-github.css?v=591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/blog/assets/css/main.css?v=d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://adarshnair.online/blog/blog/blog/2025/the-data-detectives-toolkit-unmasking-truths-with/"> <script src="/blog/assets/js/theme.js?v=5fea5159b787642c1bbc1f334d60f883"></script> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-native.css?v=5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="https://adarshnair.online" rel="external nofollow noopener" target="_blank"> Adarsh Nair </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/blog/"> </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/index.html">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/cv/">CV </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="https://adarshnair.online/books/" rel="external nofollow noopener" target="_blank">books </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="fa-solid fa-magnifying-glass"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-half-sun-moon" id="light-toggle-system"></i> <i class="fa-solid fa-moon" id="light-toggle-dark"></i> <i class="fa-solid fa-sun" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">The Data Detective's Toolkit: Unmasking Truths with Hypothesis Testing</h1> <p class="post-meta"> Created on August 28, 2025 by Adarsh Nair </p> <p class="post-tags"> <a href="/blog/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/blog/tag/hypothesis-testing"> <i class="fa-solid fa-hashtag fa-sm"></i> Hypothesis Testing</a>   <a href="/blog/blog/tag/statistics"> <i class="fa-solid fa-hashtag fa-sm"></i> Statistics</a>   <a href="/blog/blog/tag/data-science"> <i class="fa-solid fa-hashtag fa-sm"></i> Data Science</a>   <a href="/blog/blog/tag/machine-learning"> <i class="fa-solid fa-hashtag fa-sm"></i> Machine Learning</a>   <a href="/blog/blog/tag/a-b-testing"> <i class="fa-solid fa-hashtag fa-sm"></i> A/B Testing</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p>Hey there, fellow data adventurer!</p> <p>Have you ever encountered a claim that made you pause? “Our new fertilizer increases crop yield by 20%!” or “This new website layout will double our conversion rates!” As curious minds and future data scientists, our intuition might chime in, but how do we <em>prove</em> or <em>disprove</em> such statements with solid evidence? We can’t just take someone’s word for it, right?</p> <p>That’s where <strong>Hypothesis Testing</strong> swoops in, cape flowing, ready to bring rigor and statistical muscle to our decision-making. I remember feeling completely lost when I first encountered terms like ‘p-values’ and ‘null hypotheses’ – it felt like a secret language. But trust me, once you grasp the core idea, it’s incredibly empowering. It’s not just for statisticians in ivory towers; it’s a fundamental tool in the arsenal of every data professional, from A/B testing user interfaces to evaluating the impact of new machine learning models.</p> <p>So, grab your imaginary magnifying glass; we’re about to become data detectives!</p> <h2 id="whats-the-big-idea-behind-hypothesis-testing">What’s the Big Idea Behind Hypothesis Testing?</h2> <p>At its heart, hypothesis testing is a formal procedure for investigating our ideas (hypotheses) about the world using data. Think of it like a courtroom drama:</p> <ul> <li> <strong>The Claim:</strong> Someone makes a statement (e.g., “The defendant is innocent,” or “This new drug has no effect”).</li> <li> <strong>The Evidence:</strong> We gather data (witness testimonies, lab results, or, in our case, numerical observations).</li> <li> <strong>The Verdict:</strong> Based on the evidence, we decide whether there’s enough proof to reject the initial claim, or if we must stick with it.</li> </ul> <p>The beauty of this process is that it provides a structured, quantitative way to answer questions, moving us beyond mere gut feelings into the realm of evidence-based conclusions.</p> <h2 id="the-two-pillars-null-and-alternative-hypotheses">The Two Pillars: Null and Alternative Hypotheses</h2> <p>Every hypothesis test starts with two opposing statements:</p> <h3 id="1-the-null-hypothesis-h_0---the-status-quo">1. The Null Hypothesis ($H_0$) - The Status Quo</h3> <p>This is our “default assumption,” the statement of no effect, no difference, or no relationship. It’s what we assume to be true unless our data screams otherwise. Think of it as the “innocent until proven guilty” in our courtroom analogy. We try to <em>disprove</em> the null hypothesis.</p> <ul> <li> <strong>Examples:</strong> <ul> <li>“The new fertilizer has <em>no effect</em> on crop yield.” ($\mu_{new} = \mu_{old}$)</li> <li>“The average weight of chocolate bars is <em>exactly</em> 100 grams.” ($\mu = 100$)</li> <li>“There is <em>no difference</em> in conversion rates between website Version A and Version B.” ($p_A = p_B$)</li> </ul> </li> </ul> <p>We often formulate $H_0$ to include an “equals” sign.</p> <h3 id="2-the-alternative-hypothesis-h_1-or-h_a---the-challenger">2. The Alternative Hypothesis ($H_1$ or $H_A$) - The Challenger</h3> <p>This is the claim we’re trying to find evidence <em>for</em>. It’s typically the opposite of the null hypothesis. It represents the new effect, the difference, or the relationship we suspect exists.</p> <ul> <li> <strong>Examples:</strong> <ul> <li>“The new fertilizer <em>increases</em> crop yield.” ($\mu_{new} &gt; \mu_{old}$) - This is a <strong>one-tailed test</strong>.</li> <li>“The average weight of chocolate bars is <em>not</em> 100 grams.” ($\mu \ne 100$) - This is a <strong>two-tailed test</strong>.</li> <li>“The conversion rate of website Version A is <em>different from</em> Version B.” ($p_A \ne p_B$) - Also a <strong>two-tailed test</strong>.</li> </ul> </li> </ul> <p>Our goal is to gather enough evidence to <em>reject</em> $H_0$ in favor of $H_1$. If we can’t reject $H_0$, it doesn’t mean $H_0$ is true; it just means we didn’t find enough evidence to dispute it with the data we have.</p> <h2 id="the-journey-steps-of-a-hypothesis-test">The Journey: Steps of a Hypothesis Test</h2> <p>Let’s walk through the standardized procedure:</p> <h3 id="step-1-formulate-your-hypotheses-h_0-and-h_1">Step 1: Formulate Your Hypotheses ($H_0$ and $H_1$)</h3> <p>As discussed above, clearly state what you’re testing. This is the foundation!</p> <h3 id="step-2-choose-a-significance-level-alpha">Step 2: Choose a Significance Level ($\alpha$)</h3> <p>This is a critical choice. The <strong>significance level</strong>, denoted by $\alpha$ (alpha), is the probability of making a <strong>Type I error</strong> (more on this in a moment). It’s our threshold for how much risk we’re willing to take in rejecting a true null hypothesis.</p> <p>Common values for $\alpha$ are 0.05 (5%), 0.01 (1%), or 0.10 (10%). If $\alpha = 0.05$, we’re saying: “I’m willing to accept a 5% chance of incorrectly rejecting $H_0$ when it’s actually true.” The choice of $\alpha$ depends on the consequences of making a Type I error – for drug trials, you might choose a very small $\alpha$ like 0.01 or even 0.001.</p> <h3 id="step-3-collect-data-and-choose-an-appropriate-test">Step 3: Collect Data and Choose an Appropriate Test</h3> <p>This involves good experimental design and random sampling. Once you have your data, you’ll select a statistical test (e.g., t-test, z-test, chi-squared test, ANOVA) based on your data type, sample size, and the nature of your hypothesis.</p> <h3 id="step-4-calculate-the-test-statistic">Step 4: Calculate the Test Statistic</h3> <p>Based on your collected data and the chosen test, you’ll compute a <strong>test statistic</strong>. This single number quantifies how much your sample data deviates from what the null hypothesis predicts.</p> <p>For example, if testing a mean: $Z = \frac{\bar{x} - \mu_0}{\sigma / \sqrt{n}}$</p> <p>Where:</p> <ul> <li>$\bar{x}$ is the sample mean</li> <li>$\mu_0$ is the hypothesized population mean (from $H_0$)</li> <li>$\sigma$ is the population standard deviation</li> <li>$n$ is the sample size</li> </ul> <p>A larger absolute value of the test statistic means your sample mean is further away from the null hypothesis’s mean, making $H_0$ less likely.</p> <h3 id="step-5-determine-the-p-value">Step 5: Determine the P-value</h3> <p>Here’s the star of the show: the <strong>p-value</strong>. This is <em>the probability of observing a test statistic as extreme as, or more extreme than, the one calculated from your sample data, assuming that the null hypothesis ($H_0$) is true.</em></p> <p>Let that sink in for a moment. A small p-value means that if $H_0$ were true, getting our observed data (or even more extreme data) would be very, very unlikely. It’s like rolling a dice 100 times and getting ‘6’ every time. If the dice is fair ($H_0$: it’s fair), that’s an incredibly unlikely event (small p-value), so we’d reject the idea that the dice is fair.</p> <h3 id="step-6-make-a-decision">Step 6: Make a Decision</h3> <p>Finally, we compare our p-value to our chosen significance level ($\alpha$):</p> <ul> <li> <strong>If p-value &lt; $\alpha$:</strong> We <strong>reject the null hypothesis ($H_0$)</strong>. This means there is statistically significant evidence to support the alternative hypothesis ($H_1$).</li> <li> <strong>If p-value $\ge \alpha$:</strong> We <strong>fail to reject the null hypothesis ($H_0$)</strong>. This means there is <em>not enough statistically significant evidence</em> to support the alternative hypothesis. Crucially, “failing to reject” is <em>not</em> the same as “accepting” $H_0$. It just means the data doesn’t provide strong enough reasons to discard $H_0$.</li> </ul> <h2 id="the-ghastly-ghosts-type-i-and-type-ii-errors">The Ghastly Ghosts: Type I and Type II Errors</h2> <p>No decision-making process is perfect, and hypothesis testing comes with its own set of potential pitfalls:</p> <ol> <li> <strong>Type I Error (False Positive):</strong> This occurs when we <strong>reject a true null hypothesis</strong>. <ul> <li> <strong>Probability:</strong> $\alpha$ (our significance level).</li> <li> <strong>Analogy:</strong> Convicting an innocent person.</li> <li> <strong>In Data Science:</strong> Declaring a new feature improves conversion when it actually doesn’t.</li> </ul> </li> <li> <strong>Type II Error (False Negative):</strong> This occurs when we <strong>fail to reject a false null hypothesis</strong>. <ul> <li> <strong>Probability:</strong> $\beta$ (beta).</li> <li> <strong>Analogy:</strong> Letting a guilty person go free.</li> <li> <strong>In Data Science:</strong> Failing to detect a real improvement in a new algorithm.</li> </ul> </li> </ol> <p>There’s an inherent trade-off: decreasing the chance of a Type I error (e.g., by lowering $\alpha$) generally increases the chance of a Type II error, and vice-versa. The specific context of your problem helps you decide which type of error is more costly and, thus, which one you’d prioritize minimizing.</p> <h2 id="a-simple-example-the-chocolate-bar-mystery">A Simple Example: The Chocolate Bar Mystery</h2> <p>Let’s say a chocolate factory claims their new “SuperSweet” bar weighs, on average, exactly 100 grams. A consumer group suspects it weighs less.</p> <ol> <li> <strong>Hypotheses:</strong> <ul> <li>$H_0: \mu = 100$ (The average weight is 100g)</li> <li>$H_1: \mu &lt; 100$ (The average weight is less than 100g) - This is a one-tailed test.</li> </ul> </li> <li> <p><strong>Significance Level:</strong> Let’s choose $\alpha = 0.05$. We’re willing to take a 5% chance of falsely accusing the factory.</p> </li> <li> <p><strong>Data Collection:</strong> The consumer group randomly samples 30 SuperSweet bars and finds their average weight ($\bar{x}$) is 98 grams, with a sample standard deviation ($s$) of 5 grams.</p> </li> <li> <p><strong>Test Statistic:</strong> Since we have sample standard deviation and a sample size &gt; 30, we can use a t-test (or z-test as $n$ is large enough for CLT implications). Let’s conceptually use a t-score: $t = \frac{\bar{x} - \mu_0}{s / \sqrt{n}} = \frac{98 - 100}{5 / \sqrt{30}} = \frac{-2}{5 / 5.477} \approx \frac{-2}{0.913} \approx -2.19$</p> </li> <li> <p><strong>P-value:</strong> We look up the probability of getting a t-score of -2.19 or less with 29 degrees of freedom (n-1). Using a t-distribution table or software, this p-value would be approximately 0.018.</p> </li> <li> <strong>Decision:</strong> <ul> <li>p-value (0.018) &lt; $\alpha$ (0.05).</li> <li>Therefore, we <strong>reject the null hypothesis</strong>.</li> </ul> </li> </ol> <p><strong>Conclusion:</strong> Based on our sample, there is statistically significant evidence (at the 0.05 level) to suggest that the average weight of SuperSweet chocolate bars is less than 100 grams. The consumer group has a strong case!</p> <h2 id="hypothesis-testing-in-the-wild-data-science--machine-learning">Hypothesis Testing in the Wild: Data Science &amp; Machine Learning</h2> <p>Hypothesis testing isn’t just for academic research; it’s fundamental to data science and machine learning:</p> <ul> <li> <strong>A/B Testing:</strong> This is perhaps the most common application. When you launch a new website feature, ad copy, or product recommendation algorithm, you run an A/B test. <ul> <li>$H_0$: Version A (current) and Version B (new) have no difference in performance (e.g., click-through rate, conversion rate).</li> <li>$H_1$: Version A and Version B have a statistically significant difference.</li> <li>You use hypothesis tests to determine if the observed difference is real or just due to random chance.</li> </ul> </li> <li> <p><strong>Model Performance Comparison:</strong> Did your new, complex deep learning model really outperform the simpler baseline model, or was the apparent improvement just a fluke on your test set? Hypothesis tests can compare metrics like accuracy, F1-score, or RMSE between models.</p> </li> <li> <p><strong>Feature Selection:</strong> When building a predictive model, you might use hypothesis tests to determine if a particular feature has a statistically significant relationship with your target variable, helping you decide whether to include it in your model.</p> </li> <li> <strong>Causal Inference:</strong> While correlation doesn’t imply causation, carefully designed experiments combined with hypothesis testing are crucial for inferring causality – like whether a new marketing campaign truly led to increased sales.</li> </ul> <h2 id="important-caveats-and-nuances">Important Caveats and Nuances</h2> <ul> <li> <p><strong>“Fail to Reject” is Not “Accept”:</strong> This is a common misunderstanding. Failing to reject $H_0$ simply means you didn’t find <em>enough evidence</em> to contradict it. It doesn’t mean $H_0$ is proven true. The absence of evidence is not the evidence of absence.</p> </li> <li> <p><strong>Statistical Significance $\ne$ Practical Significance:</strong> A very large sample size might show a tiny, practically irrelevant difference to be statistically significant. For example, a new drug might lower blood pressure by a statistically significant 0.1 mmHg – but is that practically useful? Always consider the real-world impact alongside the p-value.</p> </li> <li> <p><strong>Assumptions Matter:</strong> Most statistical tests come with assumptions (e.g., data normality, independence of observations). Violating these can invalidate your results. Always check your assumptions!</p> </li> <li> <p><strong>P-hacking:</strong> Be wary of running many tests or manipulating data until you get a desired p-value. This practice, known as p-hacking, undermines the integrity of your findings. Always state your hypotheses and analysis plan <em>before</em> collecting or analyzing data.</p> </li> </ul> <h2 id="your-journey-as-a-data-detective">Your Journey as a Data Detective</h2> <p>Hypothesis testing is a powerful, rigorous framework for making informed decisions from data. It equips you with the statistical grammar to challenge claims, validate observations, and build trust in your data-driven insights. It’s not just a set of formulas; it’s a way of thinking critically about evidence and uncertainty.</p> <p>As you delve deeper into data science and machine learning, you’ll find that the principles of hypothesis testing underpin many advanced techniques and best practices. So, keep asking questions, keep formulating hypotheses, and keep testing them with the sharp tools of statistics. The truth is out there, and now you have a powerful way to unmask it!</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/cracking-the-ai-black-box-why-explainable-ai-xai-i/">Cracking the AI Black Box: Why Explainable AI (XAI) is Our Superpower</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/the-secret-life-of-states-how-markov-chains-predic/">The Secret Life of States: How Markov Chains Predict Our Next Move (Without Remembering the Past!)</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/gradient-descent-unpacking-the-engine-of-machine-l/">Gradient Descent: Unpacking the Engine of Machine Learning</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Adarsh Nair. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/blog/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/masonry.js?v=a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/zoom.js?v=85ddb88934d28b74e78031fd54cf8308"></script> <script src="/blog/assets/js/no_defer.js?v=2781658a0a2b13ed609542042a859126"></script> <script defer src="/blog/assets/js/common.js?v=c15de51d4bb57887caa2c21988d97279"></script> <script defer src="/blog/assets/js/copy_code.js?v=c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/blog/assets/js/jupyter_new_tab.js?v=d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/blog/assets/js/mathjax-setup.js?v=a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/progress-bar.js?v=2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/blog/assets/js/vanilla-back-to-top.min.js?v=f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/blog/assets/js/search/ninja-keys.min.js?v=a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/blog/assets/js/search-setup.js?v=6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/blog/assets/js/search-data.js"></script> <script src="/blog/assets/js/shortcut-key.js?v=ccc841c459bfc0e64c1c2b5acd10df02"></script> </body> </html>