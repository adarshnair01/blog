<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> The Unseen Predictor: Unraveling the Magic of Markov Chains | Adarsh Nair </title> <meta name="author" content="Adarsh Nair"> <meta name="description" content="A deep dive into machine learning, AI, and data science. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <meta http-equiv="Content-Security-Policy" content="default-src 'self'; script-src 'self' 'unsafe-inline' https:; style-src 'self' 'unsafe-inline' https:; img-src 'self' data: https:; font-src 'self' data: https:; media-src 'self' https:; frame-src 'self' https:; connect-src 'self' https:;"> <link rel="stylesheet" href="/blog/assets/css/bootstrap.min.css?v=a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/blog/assets/css/academicons.min.css?v=f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/blog/assets/css/scholar-icons.css?v=62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-github.css?v=591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/blog/assets/css/main.css?v=d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://adarshnair.online/blog/blog/blog/2025/the-unseen-predictor-unraveling-the-magic-of-marko/"> <script src="/blog/assets/js/theme.js?v=5fea5159b787642c1bbc1f334d60f883"></script> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-native.css?v=5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="https://adarshnair.online" rel="external nofollow noopener" target="_blank"> Adarsh Nair </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/blog/"> </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/index.html">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/cv/">CV </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="https://adarshnair.online/books/" rel="external nofollow noopener" target="_blank">books </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="fa-solid fa-magnifying-glass"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-half-sun-moon" id="light-toggle-system"></i> <i class="fa-solid fa-moon" id="light-toggle-dark"></i> <i class="fa-solid fa-sun" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">The Unseen Predictor: Unraveling the Magic of Markov Chains</h1> <p class="post-meta"> Created on September 07, 2025 by Adarsh Nair </p> <p class="post-tags"> <a href="/blog/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/blog/tag/markov-chains"> <i class="fa-solid fa-hashtag fa-sm"></i> Markov Chains</a>   <a href="/blog/blog/tag/data-science"> <i class="fa-solid fa-hashtag fa-sm"></i> Data Science</a>   <a href="/blog/blog/tag/machine-learning"> <i class="fa-solid fa-hashtag fa-sm"></i> Machine Learning</a>   <a href="/blog/blog/tag/probability"> <i class="fa-solid fa-hashtag fa-sm"></i> Probability</a>   <a href="/blog/blog/tag/nlp"> <i class="fa-solid fa-hashtag fa-sm"></i> NLP</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p>Hello fellow explorers of data and algorithms!</p> <p>Today, I want to share a concept that, for me, truly opened up a new way of thinking about prediction and randomness: <strong>Markov Chains</strong>. It’s one of those elegant ideas in mathematics and computer science that, once understood, seems to pop up everywhere. If you’ve ever predicted tomorrow’s weather based on today’s, or watched a chess game unfold, you’ve implicitly touched upon the very essence of what a Markov Chain models.</p> <p>When I first encountered them, the name sounded intimidating. “Markov Chain” – it conjured images of complex formulas and abstract theories. But as I delved deeper, I realized its core idea is beautifully simple, yet incredibly powerful. It’s about modeling sequences where the future depends <em>only</em> on the present, not on the entire history that led to the present. Intrigued? Let’s unpack this!</p> <h3 id="the-magic-of-memorylessness-the-markov-property">The Magic of “Memorylessness”: The Markov Property</h3> <p>Imagine you’re playing a board game. Your next possible moves depend solely on where your piece is <em>right now</em>, not on all the squares you’ve visited before. That, in a nutshell, is the <strong>Markov Property</strong>.</p> <p>Formally, a Markov Chain is a stochastic (random) process that satisfies the Markov Property: the probability of transitioning to any particular state depends only on the current state, and not on the sequence of states that preceded it.</p> <p>Think about it:</p> <ul> <li> <strong>Weather:</strong> If it’s sunny today, what are the chances it’s sunny, cloudy, or rainy tomorrow? Does knowing it was rainy <em>two</em> days ago really change those probabilities much, given we know today is sunny? Often, for simple models, the answer is “no.” Today’s weather is enough.</li> <li> <strong>Text Generation:</strong> If I’m generating a sentence, and my current word is “the,” what’s the most likely next word? “Cat,” “dog,” “quick”? Does knowing the <em>previous</em> word was “jumped” significantly alter the probability of what comes after “the,” compared to if the previous word was “saw”? In a simple Markov Chain, only “the” matters.</li> </ul> <p>This “memorylessness” is what makes Markov Chains so elegant and computationally efficient. We don’t need to store or process an entire history, just the current moment.</p> <h3 id="building-blocks-of-a-markov-chain">Building Blocks of a Markov Chain</h3> <p>To truly understand a Markov Chain, we need to define its core components:</p> <ol> <li> <p><strong>States:</strong> These are all the possible “conditions” or “locations” our system can be in. In our weather example, the states could be {Sunny, Cloudy, Rainy}. If we’re modeling word sequences, each unique word in our vocabulary could be a state.</p> </li> <li> <p><strong>Transitions:</strong> These are the movements from one state to another. If it’s Sunny today, it might transition to Cloudy tomorrow.</p> </li> <li> <p><strong>Transition Probabilities:</strong> This is the heart of the chain. For every possible pair of states, there’s a probability of moving from the first state to the second. These probabilities are usually constant over time (though time-inhomogeneous Markov chains exist, we’ll stick to the simpler, common kind for now).</p> </li> </ol> <p>Let’s use our simple weather example. Suppose we observe the weather for many days and collect the following probabilities:</p> <ul> <li>If it’s <strong>Sunny</strong> today: <ul> <li>Probability of being Sunny tomorrow: 0.8</li> <li>Probability of being Cloudy tomorrow: 0.15</li> <li>Probability of being Rainy tomorrow: 0.05</li> </ul> </li> <li>If it’s <strong>Cloudy</strong> today: <ul> <li>Probability of being Sunny tomorrow: 0.2</li> <li>Probability of being Cloudy tomorrow: 0.6</li> <li>Probability of being Rainy tomorrow: 0.2</li> </ul> </li> <li>If it’s <strong>Rainy</strong> today: <ul> <li>Probability of being Sunny tomorrow: 0.1</li> <li>Probability of being Cloudy tomorrow: 0.3</li> <li>Probability of being Rainy tomorrow: 0.6</li> </ul> </li> </ul> <p>We can represent these transition probabilities in a <strong>Transition Matrix</strong>, $P$:</p> \[P = \begin{pmatrix} 0.8 &amp; 0.15 &amp; 0.05 \\ 0.2 &amp; 0.6 &amp; 0.2 \\ 0.1 &amp; 0.3 &amp; 0.6 \end{pmatrix}\] <p>Here, the rows represent the <em>current state</em>, and the columns represent the <em>next state</em>. So, $P_{ij}$ is the probability of moving from state $i$ to state $j$. Notice that the sum of probabilities in each row <em>must</em> equal 1, because from any given state, you <em>must</em> transition to <em>some</em> state (including staying in the same state).</p> <h3 id="visualizing-the-dance-state-diagrams">Visualizing the Dance: State Diagrams</h3> <p>Matrices are great for calculations, but sometimes a visual helps. We can represent our Markov Chain as a <strong>state diagram</strong>:</p> <ul> <li>Each state is a node (a circle).</li> <li>Each possible transition is an arrow (a directed edge) from one node to another.</li> <li>The probability of that transition is written on the arrow.</li> </ul> <p>Imagine arrows connecting “Sunny,” “Cloudy,” and “Rainy” circles, each with its associated probability. This gives us an intuitive map of how the system evolves.</p> <h3 id="the-grand-ballet-long-term-behavior-and-steady-state">The Grand Ballet: Long-Term Behavior and Steady-State</h3> <p>One of the most fascinating aspects of Markov Chains is their <strong>long-term behavior</strong>. If we let our system run for many, many steps (e.g., predict the weather far into the future), does the influence of our <em>initial</em> starting state eventually fade away? Does the system settle into a predictable distribution of states?</p> <p>For many Markov Chains (specifically, irreducible and aperiodic ones), the answer is a resounding <strong>yes</strong>! The system will eventually reach a <strong>stationary distribution</strong>, also known as the <strong>steady-state distribution</strong>, denoted by $\pi$. This distribution tells us the long-run probability of being in each state, regardless of where the system started.</p> <p>Mathematically, if $\pi$ is the stationary distribution vector (where $\pi_i$ is the long-run probability of being in state $i$), then it satisfies the equation:</p> \[\pi P = \pi\] <p>This equation simply means that if the system is already in its stationary distribution $\pi$, applying one more transition (multiplying by $P$) will result in the same distribution $\pi$. It’s a stable equilibrium!</p> <p>For our weather example, calculating the steady-state would tell us, over many years, what percentage of days are, on average, Sunny, Cloudy, or Rainy in that particular location, regardless of whether we start our prediction on a sunny day or a rainy day. This is incredibly powerful for understanding the inherent characteristics of a system.</p> <h3 id="where-the-magic-happens-real-world-applications">Where the Magic Happens: Real-World Applications</h3> <p>Markov Chains, despite their apparent simplicity, are the backbone of many sophisticated algorithms and models in data science and machine learning:</p> <ol> <li> <strong>Natural Language Processing (NLP): Text Generation &amp; Prediction</strong> <ul> <li>The most common “hello world” for Markov Chains in NLP is predicting the next word in a sequence. By building a transition matrix where states are words and probabilities are how often one word follows another, you can generate surprisingly coherent (though often repetitive) text.</li> <li>More advanced forms, like <strong>Hidden Markov Models (HMMs)</strong>, are used for speech recognition, part-of-speech tagging, and bioinformatics (e.g., analyzing DNA sequences). Here, the underlying states are “hidden” (e.g., a phoneme), and we only observe their emissions (e.g., sounds or letters).</li> </ul> </li> <li> <strong>Google PageRank Algorithm</strong> <ul> <li>Yes, the very algorithm that helped Google dominate search engines has its roots in Markov Chains! Imagine a “random surfer” clicking links on web pages. Each web page is a state, and the links are transitions. The transition probability from page A to page B is determined by the number of outbound links on page A. The stationary distribution of this Markov Chain gives us the PageRank: pages that are visited more often in the long run (have a higher probability in the steady-state) are considered more important.</li> </ul> </li> <li> <strong>Reinforcement Learning (RL)</strong> <ul> <li>Markov Chains are fundamental to understanding <strong>Markov Decision Processes (MDPs)</strong>, which are the formal framework for reinforcement learning. In RL, an agent interacts with an environment, moving through states, taking actions, and receiving rewards. The environment’s dynamics are often modeled as a Markov Chain, where the agent’s actions influence the transition probabilities.</li> </ul> </li> <li> <strong>Modeling Physical and Biological Systems</strong> <ul> <li>From the movement of molecules to the spread of diseases, Markov Chains can model various natural phenomena where the “next step” depends only on the “current step.”</li> </ul> </li> <li> <strong>Finance</strong> <ul> <li>While stock prices are far from perfectly memoryless, simplified models sometimes use Markov Chains to predict market states (e.g., bull market, bear market, stagnant market) or model credit risk.</li> </ul> </li> </ol> <h3 id="the-fine-print-limitations">The Fine Print: Limitations</h3> <p>While powerful, it’s important to acknowledge the limitations of Markov Chains:</p> <ul> <li> <strong>The Memoryless Assumption:</strong> This is the big one. Is the future <em>truly</em> independent of the past, given the present? Often, in real-world complex systems, history <em>does</em> matter (e.g., long-term economic trends, human behavior). More sophisticated models might use higher-order Markov Chains (where the last N states matter) or other non-Markovian approaches.</li> <li> <strong>State Space Size:</strong> If you have too many possible states, the transition matrix can become enormous and computationally unwieldy to build and process.</li> <li> <strong>Stationary Probabilities:</strong> While many chains converge to a steady state, not all do. This depends on properties like irreducibility (can you get from any state to any other state?) and aperiodicity (does the system cycle predictably?).</li> </ul> <h3 id="concluding-thoughts">Concluding Thoughts</h3> <p>My journey into understanding Markov Chains was a journey from apprehension to appreciation. They represent a beautiful blend of simplicity and utility, offering a powerful lens through which to view and predict sequential events in an uncertain world.</p> <p>From forecasting tomorrow’s rain to understanding how Google ranks web pages, the principles of states, transitions, and the elegant Markov Property are at play. As data scientists and machine learning engineers, grasping these foundational concepts not only strengthens our analytical toolkit but also deepens our appreciation for the probabilistic dance that underpins so much of the world around us.</p> <p>So, the next time you see a weather forecast or type a sentence into a predictive text field, remember the humble yet mighty Markov Chain – the unseen predictor, quietly shaping our understanding of the future.</p> <p>Keep exploring, keep learning!</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/cracking-the-ai-black-box-why-explainable-ai-xai-i/">Cracking the AI Black Box: Why Explainable AI (XAI) is Our Superpower</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/the-secret-life-of-states-how-markov-chains-predic/">The Secret Life of States: How Markov Chains Predict Our Next Move (Without Remembering the Past!)</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/gradient-descent-unpacking-the-engine-of-machine-l/">Gradient Descent: Unpacking the Engine of Machine Learning</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Adarsh Nair. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/blog/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/masonry.js?v=a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/zoom.js?v=85ddb88934d28b74e78031fd54cf8308"></script> <script src="/blog/assets/js/no_defer.js?v=2781658a0a2b13ed609542042a859126"></script> <script defer src="/blog/assets/js/common.js?v=c15de51d4bb57887caa2c21988d97279"></script> <script defer src="/blog/assets/js/copy_code.js?v=c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/blog/assets/js/jupyter_new_tab.js?v=d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/blog/assets/js/mathjax-setup.js?v=a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/progress-bar.js?v=2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/blog/assets/js/vanilla-back-to-top.min.js?v=f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/blog/assets/js/search/ninja-keys.min.js?v=a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/blog/assets/js/search-setup.js?v=6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/blog/assets/js/search-data.js"></script> <script src="/blog/assets/js/shortcut-key.js?v=ccc841c459bfc0e64c1c2b5acd10df02"></script> </body> </html>