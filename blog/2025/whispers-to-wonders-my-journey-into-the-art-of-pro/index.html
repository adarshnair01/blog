<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Whispers to Wonders: My Journey into the Art of Prompt Engineering | Adarsh Nair </title> <meta name="author" content="Adarsh Nair"> <meta name="description" content="A deep dive into machine learning, AI, and data science. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <meta http-equiv="Content-Security-Policy" content="default-src 'self'; script-src 'self' 'unsafe-inline' https:; style-src 'self' 'unsafe-inline' https:; img-src 'self' data: https:; font-src 'self' data: https:; media-src 'self' https:; frame-src 'self' https:; connect-src 'self' https:;"> <link rel="stylesheet" href="/blog/assets/css/bootstrap.min.css?v=a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/blog/assets/css/academicons.min.css?v=f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/blog/assets/css/scholar-icons.css?v=62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-github.css?v=591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/blog/assets/css/main.css?v=d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://adarshnair.online/blog/blog/2025/whispers-to-wonders-my-journey-into-the-art-of-pro/"> <script src="/blog/assets/js/theme.js?v=5fea5159b787642c1bbc1f334d60f883"></script> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-native.css?v=5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/blog/cv/"> Adarsh Nair </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/blog/"> </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/cv/">CV </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/repositories/">repositories </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="fa-solid fa-magnifying-glass"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-half-sun-moon" id="light-toggle-system"></i> <i class="fa-solid fa-moon" id="light-toggle-dark"></i> <i class="fa-solid fa-sun" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Whispers to Wonders: My Journey into the Art of Prompt Engineering</h1> <p class="post-meta"> Created on September 21, 2025 by Adarsh Nair </p> <p class="post-tags"> <a href="/blog/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/blog/tag/prompt-engineering"> <i class="fa-solid fa-hashtag fa-sm"></i> Prompt Engineering</a>   <a href="/blog/blog/tag/llm"> <i class="fa-solid fa-hashtag fa-sm"></i> LLM</a>   <a href="/blog/blog/tag/nlp"> <i class="fa-solid fa-hashtag fa-sm"></i> NLP</a>   <a href="/blog/blog/tag/ai"> <i class="fa-solid fa-hashtag fa-sm"></i> AI</a>   <a href="/blog/blog/tag/machine-learning"> <i class="fa-solid fa-hashtag fa-sm"></i> Machine Learning</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p>As a budding data scientist, my initial forays into the world of Large Language Models (LLMs) felt like magic. I’d type a question, hit enter, and <em>poof</em> – a coherent, often insightful, answer would appear. It was like having an infinitely patient, incredibly knowledgeable friend at my fingertips. But, as with any magic, there’s often a hidden spellbook, and for LLMs, that spellbook is called <strong>Prompt Engineering</strong>.</p> <h3 id="my-early-encounters-the-frustration-of-generic-answers">My Early Encounters: The Frustration of Generic Answers</h3> <p>My journey started innocently enough. I’d ask an LLM to “summarize this article” or “explain gradient descent.” The results were… fine. They were usually correct, but rarely <em>exactly</em> what I wanted. Sometimes the summary missed crucial details, or the explanation of gradient descent felt too academic when I needed it simplified for a high school student. It was like ordering a custom cake and getting a perfectly decent vanilla one. Good, but not <em>my</em> good.</p> <p>I quickly realized that just “talking” to the AI wasn’t enough. It needed to be guided, coaxed, almost <em>programmed</em> with natural language. This realization was my “aha!” moment, pushing me headfirst into the fascinating domain of Prompt Engineering.</p> <h3 id="so-what-exactly-is-prompt-engineering">So, What Exactly IS Prompt Engineering?</h3> <p>At its core, <strong>Prompt Engineering is the discipline of designing and refining inputs (prompts) for large language models to elicit desired outputs.</strong> Think of it less like simply asking a question and more like being a director for a highly talented, but sometimes unfocused, actor. You’re giving instructions, setting the scene, defining the character, and outlining the plot to get the best performance.</p> <p>It’s a blend of art and science. The art comes from understanding language, context, and human intention. The science lies in applying structured techniques, testing hypotheses, and iteratively refining your approach based on the model’s responses.</p> <h3 id="why-does-prompt-engineering-matter-so-much">Why Does Prompt Engineering Matter So Much?</h3> <p>You might wonder, if LLMs are so smart, why do we need to be so careful with our words? Here’s why:</p> <ol> <li> <strong>Unlocking Precision and Creativity:</strong> A well-engineered prompt can transform a generic response into a highly specific, accurate, or even creatively brilliant one. It allows us to tap into the full potential of these models.</li> <li> <strong>Mitigating AI Limitations:</strong> LLMs, despite their brilliance, can “hallucinate” (make up facts), be biased, or misunderstand subtle nuances. Thoughtful prompting can guide them away from these pitfalls.</li> <li> <strong>Efficiency and Cost-Saving:</strong> In production environments, fewer iterations mean faster results and lower API costs. Good prompts reduce the back-and-forth, getting you to the optimal output quicker.</li> <li> <strong>Accessibility for Non-Coders:</strong> Prompt engineering democratizes AI interaction. You don’t need to write complex code; you just need to learn how to “speak” to the AI effectively.</li> </ol> <h3 id="my-toolkit-essential-prompt-engineering-techniques">My Toolkit: Essential Prompt Engineering Techniques</h3> <p>Through countless hours of experimentation, reading papers, and engaging with the community, I’ve built a personal toolkit of effective prompt engineering strategies. Let’s dive into some of the most impactful ones:</p> <h4 id="1-clarity-and-specificity-the-golden-rule">1. Clarity and Specificity: The Golden Rule</h4> <p>This might sound obvious, but it’s often overlooked. Vague prompts lead to vague answers. Always strive for crystal-clear instructions.</p> <ul> <li> <strong>Bad Prompt:</strong> “Tell me about data science.”</li> <li> <strong>Good Prompt:</strong> “Explain the core concepts of data science for someone with a high school level understanding, focusing on the steps involved in a typical data science project. Use analogies to make it easy to grasp.”</li> </ul> <p>Notice how the good prompt specifies the <em>audience</em>, <em>focus</em>, and <em>desired style</em>.</p> <p><strong>Tip:</strong> Use <strong>delimiters</strong> (like triple backticks <code class="language-plaintext highlighter-rouge">```</code>, quotes <code class="language-plaintext highlighter-rouge">""</code>, or XML tags <code class="language-plaintext highlighter-rouge">&lt;tag&gt;</code>) to clearly separate different parts of your prompt, especially when providing text or specific instructions.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>You are an expert technical writer. Summarize the following text, focusing on the main findings and implications for future research.

Text to summarize: ```[Insert long article text here]```
</code></pre></div></div> <h4 id="2-role-playing-giving-the-ai-a-persona">2. Role-Playing: Giving the AI a Persona</h4> <p>One of the most powerful techniques is to instruct the LLM to adopt a specific persona. This subtly shifts its response style, tone, and focus, making it more aligned with your needs.</p> <ul> <li> <strong>Prompt:</strong> “Act as a senior data scientist explaining the difference between supervised and unsupervised learning to a client. Keep it concise and use business-relevant examples.”</li> </ul> <p>By assigning the role “senior data scientist,” the model will draw upon a different knowledge base and communication style than if it were, say, a high school teacher.</p> <h4 id="3-few-shot-learning-in-context-learning-leading-by-example">3. Few-Shot Learning (In-Context Learning): Leading by Example</h4> <p>Sometimes, it’s easier to show than to tell. Few-shot learning involves providing the model with a few examples of desired input-output pairs. This guides the model without needing to fine-tune it on a large dataset.</p> <p>Imagine you want to classify customer reviews as positive, negative, or neutral.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Review: "The product arrived broken."
Sentiment: Negative

Review: "I love this new feature!"
Sentiment: Positive

Review: "It's okay, nothing special."
Sentiment: Neutral

Review: "Setup was a nightmare, but it works now."
Sentiment:
</code></pre></div></div> <table> <tbody> <tr> <td>Here, the model learns the <em>pattern</em> from the examples. Mathematically, we are influencing the conditional probability of the output given the input by conditioning it on the provided examples: $P(\text{Output}</td> <td>\text{Input}, \text{Examples})$. The examples essentially shift the model’s “understanding” of the task for the current inference.</td> </tr> </tbody> </table> <h4 id="4-chain-of-thought-cot-prompting-thinking-step-by-step">4. Chain-of-Thought (CoT) Prompting: Thinking Step-by-Step</h4> <p>This technique encourages the LLM to break down a complex problem into intermediate steps before arriving at a final answer. It mimics human reasoning and significantly improves performance on complex reasoning tasks (like math problems or logical puzzles).</p> <ul> <li> <strong>Bad Prompt:</strong> “What is $123 \times 45 + 678$?” (Often leads to direct, sometimes incorrect, answers).</li> <li> <strong>Good Prompt (CoT):</strong> “Calculate $123 \times 45 + 678$. Think step by step and show your work.”</li> </ul> <p>The model would then output something like:</p> <ol> <li>First, calculate $123 \times 45$. $123 \times 40 = 4920$ $123 \times 5 = 615$ $4920 + 615 = 5535$</li> <li>Next, add $678$ to the result. $5535 + 678 = 6213$</li> <li>Final Answer: $6213$</li> </ol> <table> <tbody> <tr> <td>By forcing the model to generate these intermediate steps ($S_1, S_2, …, S_n$), we guide its internal reasoning process. This essentially changes the probability distribution it’s sampling from: instead of directly predicting $P(\text{Answer}</td> <td>\text{Input})$, it predicts $P(\text{Answer}</td> <td>\text{Input}, S_1, …, S_n)$, which is often more accurate for complex tasks. This is incredibly powerful for complex problem-solving!</td> </tr> </tbody> </table> <h4 id="5-output-formatting-structuring-for-success">5. Output Formatting: Structuring for Success</h4> <p>Sometimes, the content is perfect, but the format makes it hard to use. Prompt engineering allows you to dictate the output structure.</p> <ul> <li> <strong>Prompt:</strong> “Summarize the key findings from the attached research paper on climate change. Present the summary as a JSON object with two keys: <code class="language-plaintext highlighter-rouge">title</code> and <code class="language-plaintext highlighter-rouge">summary_points</code> (an array of bullet points).”</li> </ul> <p>This is crucial for integrating LLM outputs into automated workflows or applications, allowing downstream systems to easily parse the information.</p> <h3 id="the-iterative-nature-of-prompt-engineering-my-personal-loop">The Iterative Nature of Prompt Engineering: My Personal Loop</h3> <p>My journey with prompt engineering has reinforced a core principle of data science: it’s rarely a one-shot deal. It’s an iterative process:</p> <ol> <li> <strong>Formulate:</strong> Craft your initial prompt based on your understanding and desired outcome.</li> <li> <strong>Test:</strong> Submit the prompt to the LLM.</li> <li> <strong>Analyze:</strong> Evaluate the output. Was it good? Was it close? Where did it fall short?</li> <li> <strong>Refine:</strong> Adjust the prompt based on your analysis. Maybe add more specificity, change the persona, include an example, or try CoT.</li> <li><strong>Repeat!</strong></li> </ol> <p>This loop is where the “art” truly shines. It’s about developing an intuition for how the model interprets your words and then strategically adjusting your language to guide it.</p> <h3 id="challenges-and-the-ethical-compass">Challenges and the Ethical Compass</h3> <p>While prompt engineering is incredibly powerful, it’s not without its challenges.</p> <ul> <li> <strong>Bias Amplification:</strong> If the training data contains biases, poorly crafted prompts can inadvertently amplify them.</li> <li> <strong>Misinformation:</strong> Even with the best prompts, LLMs can sometimes generate convincing but incorrect information.</li> <li> <strong>Prompt Injection:</strong> A more advanced concern where malicious users try to “hijack” the model’s instructions through clever prompts.</li> </ul> <p>As prompt engineers, we carry a responsibility to be mindful of these issues and strive to create prompts that are fair, accurate, and safe.</p> <h3 id="my-aha-moments-and-whats-next">My Aha! Moments and What’s Next</h3> <p>One of my biggest “aha!” moments came when I used Chain-of-Thought prompting to solve a complex coding problem. Instead of asking for the final code directly, I first asked the AI to outline the logic, then break it down into functions, and <em>then</em> write the code. The resulting code was not only correct but also well-structured and easy to understand – far superior to my initial attempts. It taught me the power of guiding the AI’s internal thought process.</p> <p>Prompt engineering is a rapidly evolving field, almost a new language layer on top of natural language. It’s a skill that’s becoming as essential for data scientists and developers interacting with LLMs as SQL is for database interaction or Python for scripting.</p> <h3 id="ready-to-craft-your-own-spells">Ready to Craft Your Own Spells?</h3> <p>If you’re eager to unlock the true potential of AI, I urge you to dive into prompt engineering. Start simple, experiment widely, and don’t be afraid to iterate. The future of human-AI collaboration hinges on our ability to communicate effectively, and mastering the art of the prompt is your ticket to being a part of that future.</p> <p>So, go forth and engineer some amazing prompts! Your journey to transforming whispers into wonders begins now.</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/cracking-the-ai-black-box-why-explainable-ai-xai-i/">Cracking the AI Black Box: Why Explainable AI (XAI) is Our Superpower</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/the-secret-life-of-states-how-markov-chains-predic/">The Secret Life of States: How Markov Chains Predict Our Next Move (Without Remembering the Past!)</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/gradient-descent-unpacking-the-engine-of-machine-l/">Gradient Descent: Unpacking the Engine of Machine Learning</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Adarsh Nair. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/blog/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/masonry.js?v=a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/zoom.js?v=85ddb88934d28b74e78031fd54cf8308"></script> <script src="/blog/assets/js/no_defer.js?v=2781658a0a2b13ed609542042a859126"></script> <script defer src="/blog/assets/js/common.js?v=c15de51d4bb57887caa2c21988d97279"></script> <script defer src="/blog/assets/js/copy_code.js?v=c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/blog/assets/js/jupyter_new_tab.js?v=d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/blog/assets/js/mathjax-setup.js?v=a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/progress-bar.js?v=2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/blog/assets/js/vanilla-back-to-top.min.js?v=f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/blog/assets/js/search/ninja-keys.min.js?v=a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/blog/assets/js/search-setup.js?v=6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/blog/assets/js/search-data.js"></script> <script src="/blog/assets/js/shortcut-key.js?v=ccc841c459bfc0e64c1c2b5acd10df02"></script> </body> </html>