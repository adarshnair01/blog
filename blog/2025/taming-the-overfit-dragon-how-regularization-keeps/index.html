<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Taming the Overfit Dragon: How Regularization Keeps Our Models Honest | Adarsh Nair </title> <meta name="author" content="Adarsh Nair"> <meta name="description" content="A deep dive into machine learning, AI, and data science. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <meta http-equiv="Content-Security-Policy" content="default-src 'self'; script-src 'self' 'unsafe-inline' https:; style-src 'self' 'unsafe-inline' https:; img-src 'self' data: https:; font-src 'self' data: https:; media-src 'self' https:; frame-src 'self' https:; connect-src 'self' https:;"> <link rel="stylesheet" href="/blog/assets/css/bootstrap.min.css?v=a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/blog/assets/css/academicons.min.css?v=f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/blog/assets/css/scholar-icons.css?v=62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-github.css?v=591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/blog/assets/css/main.css?v=d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://adarshnair.online/blog/blog/blog/2025/taming-the-overfit-dragon-how-regularization-keeps/"> <script src="/blog/assets/js/theme.js?v=5fea5159b787642c1bbc1f334d60f883"></script> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-native.css?v=5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="https://adarshnair.online" rel="external nofollow noopener" target="_blank"> Adarsh Nair </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/blog/"> </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/index.html">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/cv/">CV </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/repositories/">repositories </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="fa-solid fa-magnifying-glass"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-half-sun-moon" id="light-toggle-system"></i> <i class="fa-solid fa-moon" id="light-toggle-dark"></i> <i class="fa-solid fa-sun" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Taming the Overfit Dragon: How Regularization Keeps Our Models Honest</h1> <p class="post-meta"> Created on February 28, 2025 by Adarsh Nair </p> <p class="post-tags"> <a href="/blog/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/blog/tag/machine-learning"> <i class="fa-solid fa-hashtag fa-sm"></i> Machine Learning</a>   <a href="/blog/blog/tag/regularization"> <i class="fa-solid fa-hashtag fa-sm"></i> Regularization</a>   <a href="/blog/blog/tag/overfitting"> <i class="fa-solid fa-hashtag fa-sm"></i> Overfitting</a>   <a href="/blog/blog/tag/data-science"> <i class="fa-solid fa-hashtag fa-sm"></i> Data Science</a>   <a href="/blog/blog/tag/model-training"> <i class="fa-solid fa-hashtag fa-sm"></i> Model Training</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p>As a budding data scientist or someone just diving into the fascinating world of Machine Learning, you’re constantly seeking ways to build smarter, more reliable models. You want your algorithms to be insightful, not just parrots repeating what they’ve heard. But there’s a sneaky challenge lurking in the shadows of every dataset: <strong>overfitting</strong>.</p> <p>Imagine you’re studying for a big test. One strategy is to <em>memorize</em> every single word in the textbook – every example, every footnote. You might ace questions that are <em>exactly</em> like the ones in the book. But what happens when the test asks a question phrased differently or presents a new scenario? Your memorized answers might fall flat.</p> <p>Another strategy is to <em>understand</em> the core concepts, the underlying principles, and how they apply in various situations. You might not get every minor detail right, but you’ll be much better equipped to tackle novel problems.</p> <p>This analogy perfectly captures the essence of overfitting in machine learning, and why we need a powerful technique called <strong>Regularization</strong>.</p> <h3 id="the-peril-of-overfitting-when-models-learn-too-much">The Peril of Overfitting: When Models Learn Too Much</h3> <p>In machine learning, our goal is to build a model that can make accurate predictions on <em>new, unseen data</em>. We train our models on a specific dataset (the “training data”), and then we expect them to perform well in the real world.</p> <p><strong>Overfitting occurs when a model learns the training data <em>too well</em> – so well that it starts to memorize the noise and specific quirks of that particular dataset, rather than learning the underlying patterns.</strong></p> <p>Think back to our student:</p> <ul> <li> <strong>Overfit model:</strong> The student who memorized the textbook. Great performance on training data (questions identical to the textbook), but poor performance on test data (newly phrased questions).</li> <li> <strong>Good model:</strong> The student who understood the concepts. Decent performance on training data (they’re still learning!), and good performance on test data.</li> </ul> <p>An overfit model will have very low error on the training set but significantly higher error on a validation or test set. It’s like a highly complex function that wiggles and twists to hit every single training data point, even the noisy outliers. While it looks perfect on paper (training data), it’s terrible at generalizing.</p> <p>This problem is closely tied to the <strong>Bias-Variance Trade-off</strong>:</p> <ul> <li> <strong>High Bias (Underfitting):</strong> The model is too simple and can’t capture the underlying patterns in the data. It’s like trying to fit a straight line to a curved relationship. Both training and test error are high.</li> <li> <strong>High Variance (Overfitting):</strong> The model is too complex and overly sensitive to the training data. It captures noise as if it were a real pattern. Low training error, but high test error.</li> </ul> <p>Our sweet spot is a model with a good balance, where it captures the true signal without being swayed by the noise.</p> <h3 id="enter-regularization-the-models-disciplinarian">Enter Regularization: The Model’s Disciplinarian</h3> <p>So, how do we prevent our models from becoming overly confident memorizers? We introduce <strong>regularization</strong>.</p> <p>Regularization is a technique that essentially <strong>adds a penalty to the model’s complexity</strong> during training. It discourages the model from assigning extremely large weights (coefficients) to individual features. Why is this important? Because large weights often indicate that the model is heavily relying on specific features, making it overly sensitive to minor fluctuations in the input data – a hallmark of overfitting.</p> <p>Imagine you’re an architect designing a building. You want it to be beautiful and functional, but also stable and robust. Regularization is like adding structural constraints: “Don’t make any single beam ridiculously thick unless it’s absolutely necessary, and ensure the overall structure is balanced.”</p> <h3 id="the-core-idea-penalizing-complexity">The Core Idea: Penalizing Complexity</h3> <p>Let’s look at the heart of most machine learning models: the <strong>cost function (or loss function)</strong>. This function measures how well our model is performing. Our goal during training is to minimize this cost. For a typical linear regression model, the cost function might look like the Mean Squared Error (MSE):</p> <p>$ J(\theta) = \frac{1}{2m} \sum<em>{i=1}^m (h</em>\theta(x^{(i)}) - y^{(i)})^2 $</p> <p>Here:</p> <ul> <li>$J(\theta)$ is the cost, which we want to minimize.</li> <li>$m$ is the number of training examples.</li> <li>$h_\theta(x^{(i)})$ is our model’s prediction for the $i$-th example.</li> <li>$y^{(i)}$ is the actual value for the $i$-th example.</li> <li>$\theta$ represents the model’s parameters (the weights or coefficients we are trying to learn).</li> </ul> <p>Without regularization, the model can make $J(\theta)$ very small by letting some $\theta_j$ (individual weights) grow arbitrarily large to perfectly fit every training point.</p> <p>Regularization modifies this cost function by adding a <strong>penalty term</strong>:</p> <p>$ J_{regularized}(\theta) = J(\theta) + \text{Penalty Term} $</p> <p>Now, when our optimization algorithm tries to minimize $J_{regularized}(\theta)$, it has to do two things simultaneously:</p> <ol> <li>Minimize the original error ($J(\theta)$).</li> <li>Keep the model’s complexity (usually represented by the magnitude of its weights, $\theta_j$) in check by minimizing the penalty term.</li> </ol> <p>This forces the model to find a balance – fitting the data reasonably well <em>without</em> becoming excessively complex or relying too heavily on any single feature.</p> <h3 id="the-two-heavy-hitters-l1-lasso-and-l2-ridge">The Two Heavy Hitters: L1 (Lasso) and L2 (Ridge)</h3> <p>There are several types of regularization, but two stand out for their widespread use and effectiveness: L1 and L2 regularization.</p> <h4 id="1-l2-regularization-ridge-regression">1. L2 Regularization: Ridge Regression</h4> <p>L2 regularization adds a penalty proportional to the <strong>sum of the squared magnitudes</strong> of the coefficients ($\theta_j$). It’s also known as <strong>Ridge Regression</strong> for linear models.</p> <p>The penalty term looks like this: $ \text{Penalty Term}<em>{L2} = \lambda \sum</em>{j=1}^p \theta_j^2 $</p> <p>So, the full L2 regularized cost function becomes: $ J<em>{L2}(\theta) = \frac{1}{2m} \sum</em>{i=1}^m (h<em>\theta(x^{(i)}) - y^{(i)})^2 + \lambda \sum</em>{j=1}^p \theta_j^2 $</p> <p><strong>Intuition:</strong></p> <ul> <li> <strong>Shrinking, Not Zeroing:</strong> L2 regularization tends to shrink all the coefficients towards zero, but it rarely makes them <em>exactly</em> zero. It encourages a more even distribution of weight across all features.</li> <li> <strong>Preventing Extremes:</strong> If a feature’s coefficient tries to become very large, its square will become <em>even larger</em>, incurring a significant penalty. This prevents any single feature from dominating the model.</li> <li> <strong>Analogy:</strong> Imagine a soccer team where everyone passes the ball. No one player is allowed to hog the ball and take all the shots, even if they’re good. Everyone contributes, leading to a more robust team effort.</li> <li> <strong>Geometric View:</strong> If you imagine the optimization problem graphically, L2 regularization constrains the coefficients to lie within a circle (or sphere in higher dimensions).</li> </ul> <p><strong>When to use L2:</strong> It’s particularly useful when you have many features that are all somewhat relevant, or when you have multicollinearity (features that are highly correlated with each other).</p> <h4 id="2-l1-regularization-lasso-regression">2. L1 Regularization: Lasso Regression</h4> <p>L1 regularization adds a penalty proportional to the <strong>sum of the absolute magnitudes</strong> of the coefficients ($\theta_j$). It’s commonly known as <strong>Lasso Regression</strong> (Least Absolute Shrinkage and Selection Operator).</p> <p>The penalty term looks like this: $ \text{Penalty Term}<em>{L1} = \lambda \sum</em>{j=1}^p |\theta_j| $</p> <p>And the full L1 regularized cost function: $ J<em>{L1}(\theta) = \frac{1}{2m} \sum</em>{i=1}^m (h<em>\theta(x^{(i)}) - y^{(^{(i)})})^2 + \lambda \sum</em>{j=1}^p |\theta_j| $</p> <p><strong>Intuition:</strong></p> <ul> <li> <strong>Feature Selection:</strong> Unlike L2, L1 regularization has a unique property: it can shrink some coefficients <em>all the way to zero</em>. This effectively performs <strong>feature selection</strong>, meaning it completely removes less important features from the model.</li> <li> <strong>Sparsity:</strong> L1 regularization encourages sparse models, where only a subset of features have non-zero coefficients. This can make the model simpler and more interpretable.</li> <li> <strong>Analogy:</strong> Back to our soccer team: L1 regularization is like the coach deciding, “Okay, these three players are absolutely crucial, these two are useful in specific situations, and the rest aren’t making enough impact, so we’re benching them (setting their contribution to zero).”</li> <li> <strong>Geometric View:</strong> L1 regularization constrains the coefficients to lie within a diamond shape (or octahedron in higher dimensions). The “corners” of this diamond often coincide with axes, causing coefficients to hit zero.</li> </ul> <p><strong>When to use L1:</strong> It’s excellent when you suspect many of your features are irrelevant, or when you want a simpler, more interpretable model by automatically selecting the most important features.</p> <h4 id="3-elastic-net-regularization">3. Elastic Net Regularization</h4> <p>What if you want the best of both worlds? <strong>Elastic Net Regularization</strong> combines both L1 and L2 penalties. It has two hyperparameters, one for the L1 ratio and one for the L2 ratio. This allows it to perform both feature selection and coefficient shrinkage, often performing very well in situations with highly correlated features.</p> <h3 id="the-balancing-act-the-lambda-lambda-hyperparameter">The Balancing Act: The $\lambda$ (Lambda) Hyperparameter</h3> <p>You might have noticed the $\lambda$ (lambda) symbol in both L1 and L2 penalty terms. This is a crucial <strong>hyperparameter</strong> that controls the <strong>strength of the regularization</strong>.</p> <ul> <li> <strong>If $\lambda$ is 0:</strong> There’s no penalty term, and we’re back to our original, unregularized model, prone to overfitting.</li> <li> <strong>As $\lambda$ increases:</strong> The penalty for large coefficients becomes stronger. The model is forced to be simpler, and coefficients are shrunk more aggressively. This can potentially lead to underfitting if $\lambda$ is too large (too much bias).</li> <li> <strong>Finding the Sweet Spot:</strong> The goal is to find an optimal $\lambda$ value that balances the trade-off between bias and variance, leading to the best generalization performance on unseen data. We typically find this optimal $\lambda$ using techniques like <strong>cross-validation</strong>.</li> </ul> <h3 id="why-regularization-is-your-best-friend">Why Regularization is Your Best Friend</h3> <p>Regularization is a fundamental concept in machine learning that helps us build models that:</p> <ol> <li> <strong>Generalize Better:</strong> They perform well not just on the data they’ve seen, but on new, unseen data.</li> <li> <strong>Are More Robust:</strong> Less sensitive to noise and outliers in the training data.</li> <li> <strong>Are Simpler (especially L1):</strong> Can lead to more interpretable models by identifying truly important features.</li> <li> <strong>Mitigate Overfitting:</strong> It’s one of the primary tools in a data scientist’s arsenal against this common problem.</li> </ol> <p>Beyond L1 and L2, regularization principles extend to other areas like <strong>Dropout</strong> in neural networks (randomly “dropping out” neurons during training to prevent co-adaptation) or <strong>Early Stopping</strong> (stopping training before the model fully converges on the training data, based on validation set performance).</p> <h3 id="conclusion-embracing-controlled-complexity">Conclusion: Embracing Controlled Complexity</h3> <p>In the pursuit of highly accurate models, it’s tempting to let our algorithms become as complex as possible to minimize training error. However, as we’ve seen, this often leads to models that are brittle and perform poorly in the real world.</p> <p>Regularization provides an elegant solution: it’s a mechanism for controlled complexity. By gently nudging our model’s parameters towards smaller values or even zero, we encourage it to focus on the truly significant patterns in the data, rather than getting bogged down by noise.</p> <p>So, the next time you’re building a machine learning model, remember the power of regularization. It’s not just a mathematical trick; it’s a guiding principle that helps our models understand, not just memorize, making them truly intelligent and reliable. It’s how we tame the overfit dragon and ensure our models are honest predictors of the future.</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/cracking-the-ai-black-box-why-explainable-ai-xai-i/">Cracking the AI Black Box: Why Explainable AI (XAI) is Our Superpower</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/the-secret-life-of-states-how-markov-chains-predic/">The Secret Life of States: How Markov Chains Predict Our Next Move (Without Remembering the Past!)</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/gradient-descent-unpacking-the-engine-of-machine-l/">Gradient Descent: Unpacking the Engine of Machine Learning</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Adarsh Nair. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/blog/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/masonry.js?v=a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/zoom.js?v=85ddb88934d28b74e78031fd54cf8308"></script> <script src="/blog/assets/js/no_defer.js?v=2781658a0a2b13ed609542042a859126"></script> <script defer src="/blog/assets/js/common.js?v=c15de51d4bb57887caa2c21988d97279"></script> <script defer src="/blog/assets/js/copy_code.js?v=c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/blog/assets/js/jupyter_new_tab.js?v=d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/blog/assets/js/mathjax-setup.js?v=a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/progress-bar.js?v=2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/blog/assets/js/vanilla-back-to-top.min.js?v=f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/blog/assets/js/search/ninja-keys.min.js?v=a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/blog/assets/js/search-setup.js?v=6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/blog/assets/js/search-data.js"></script> <script src="/blog/assets/js/shortcut-key.js?v=ccc841c459bfc0e64c1c2b5acd10df02"></script> </body> </html>