<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Whispering to Giants: The Art and Science of Prompt Engineering | Adarsh Nair </title> <meta name="author" content="Adarsh Nair"> <meta name="description" content="A deep dive into machine learning, AI, and data science. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <meta http-equiv="Content-Security-Policy" content="default-src 'self'; script-src 'self' 'unsafe-inline' https:; style-src 'self' 'unsafe-inline' https:; img-src 'self' data: https:; font-src 'self' data: https:; media-src 'self' https:; frame-src 'self' https:; connect-src 'self' https:;"> <link rel="stylesheet" href="/blog/assets/css/bootstrap.min.css?v=a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/blog/assets/css/academicons.min.css?v=f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/blog/assets/css/scholar-icons.css?v=62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-github.css?v=591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/blog/assets/css/main.css?v=d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://adarshnair.online/blog/blog/2026/whispering-to-giants-the-art-and-science-of-prompt/"> <script src="/blog/assets/js/theme.js?v=5fea5159b787642c1bbc1f334d60f883"></script> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-native.css?v=5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/blog/cv/"> Adarsh Nair </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/blog/"> </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/cv/">CV </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/repositories/">repositories </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="fa-solid fa-magnifying-glass"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-half-sun-moon" id="light-toggle-system"></i> <i class="fa-solid fa-moon" id="light-toggle-dark"></i> <i class="fa-solid fa-sun" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Whispering to Giants: The Art and Science of Prompt Engineering</h1> <p class="post-meta"> Created on January 31, 2026 by Adarsh Nair </p> <p class="post-tags"> <a href="/blog/blog/2026"> <i class="fa-solid fa-calendar fa-sm"></i> 2026 </a>   ·   <a href="/blog/blog/tag/prompt-engineering"> <i class="fa-solid fa-hashtag fa-sm"></i> Prompt Engineering</a>   <a href="/blog/blog/tag/large-language-models"> <i class="fa-solid fa-hashtag fa-sm"></i> Large Language Models</a>   <a href="/blog/blog/tag/nlp"> <i class="fa-solid fa-hashtag fa-sm"></i> NLP</a>   <a href="/blog/blog/tag/ai"> <i class="fa-solid fa-hashtag fa-sm"></i> AI</a>   <a href="/blog/blog/tag/data-science"> <i class="fa-solid fa-hashtag fa-sm"></i> Data Science</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <h2 id="whispering-to-giants-the-art-and-science-of-prompt-engineering">Whispering to Giants: The Art and Science of Prompt Engineering</h2> <p>Hey everyone!</p> <p>Remember the first time you typed something into ChatGPT or another AI chatbot? Maybe it was a simple question, a request for a story, or even a line of code. For many of us, it felt a bit like magic, watching those words appear almost instantly, coherent and often surprisingly insightful. It was a glimpse into a new world of interaction.</p> <p>But then, perhaps you tried something more complex. You asked for a summary of a dense article, a comparison of two intricate concepts, or even a step-by-step guide to a tricky problem. Sometimes the AI nailed it, other times it gave you something… close, but not quite right. Or worse, it confidently delivered something entirely fabricated!</p> <p>This moment – the gap between what you asked for and what you got – is precisely where <strong>Prompt Engineering</strong> steps in.</p> <h3 id="what-is-prompt-engineering-more-than-just-asking">What is Prompt Engineering? More Than Just Asking</h3> <p>At its heart, Prompt Engineering is the discipline of designing and refining inputs (prompts) for Large Language Models (LLMs) to achieve desired outputs. Think of it like this: LLMs are incredibly vast libraries of knowledge and reasoning patterns. They don’t <em>understand</em> in the human sense, but they are masters at predicting the next most probable word based on the patterns they’ve learned from trillions of words of text.</p> <p>A prompt is the initial set of conditions, the guiding star, that sets the LLM on a specific trajectory through its immense probabilistic landscape. When you type a prompt, you’re essentially setting up a conditional probability:</p> \[P(\text{output} | \text{prompt})\] <p>This simply means, “What’s the probability of generating a particular sequence of words (output), given the input sequence of words (prompt)?” Your job as a prompt engineer is to craft that <code class="language-plaintext highlighter-rouge">prompt</code> in such a way that it maximizes the probability of getting the <code class="language-plaintext highlighter-rouge">output</code> you want, and minimizes the probability of getting garbage.</p> <p>It’s like talking to a super-intelligent, incredibly knowledgeable, but sometimes overly literal alien. You have to be precise, clear, and sometimes even teach it how to think <em>your</em> way for that specific task. It’s becoming an indispensable skill for anyone working with AI, from developers building applications to researchers exploring new frontiers, and especially for Data Scientists and Machine Learning Engineers looking to leverage these powerful tools efficiently.</p> <h3 id="why-does-it-matter-so-much">Why Does it Matter So Much?</h3> <p>In an era where LLMs are becoming foundational models for countless applications, mastering prompt engineering allows us to:</p> <ol> <li> <strong>Unlock Full Potential:</strong> Extract specific, high-quality, and nuanced information from models that might otherwise give generic responses.</li> <li> <strong>Increase Efficiency:</strong> Get the desired output faster, reducing the need for extensive post-processing or iterative corrections.</li> <li> <strong>Reduce Costs:</strong> More effective prompts mean fewer API calls, which can translate to significant savings in larger applications.</li> <li> <strong>Improve Reliability:</strong> Guide models to perform complex reasoning steps, reducing hallucinations and improving factual consistency.</li> <li> <strong>Rapid Prototyping:</strong> Quickly test ideas and build functional AI features without needing to fine-tune a model with massive datasets.</li> </ol> <p>For a Data Scientist or MLE, this means you can build powerful proof-of-concepts, augment data, generate synthetic datasets, develop intelligent agents, or even assist in code generation and debugging – all with just well-crafted text.</p> <h3 id="the-toolkit-key-principles-and-techniques">The Toolkit: Key Principles and Techniques</h3> <p>Let’s dive into some practical techniques that form the bedrock of effective prompt engineering.</p> <h4 id="1-clarity-and-specificity-the-golden-rule">1. Clarity and Specificity: The Golden Rule</h4> <p>This might sound obvious, but it’s astonishing how much difference a few clear words can make. LLMs don’t read between the lines; they follow instructions.</p> <p><strong>Bad Prompt:</strong> “Tell me about climate change.” <em>Output: A general overview, potentially very long and unspecific.</em></p> <p><strong>Good Prompt:</strong> “Explain the primary causes of anthropogenic climate change to a high school student in no more than 200 words. Focus on greenhouse gases and their sources. Use simple language.” <em>Output: Concise, targeted, and audience-appropriate.</em></p> <p><strong>Key Takeaways:</strong></p> <ul> <li> <strong>Be Direct:</strong> State your request clearly.</li> <li> <strong>Define Audience/Persona:</strong> “Explain to a child,” “write as a marketing expert.”</li> <li> <strong>Specify Format:</strong> “In bullet points,” “as a JSON object,” “in Markdown.”</li> <li> <strong>Set Constraints:</strong> “No more than 5 sentences,” “only use facts from X source.”</li> <li> <p><strong>Use Delimiters:</strong> For separating instructions from content (e.g., triple backticks <code class="language-plaintext highlighter-rouge">```</code>, angle brackets <code class="language-plaintext highlighter-rouge">&lt;&gt;</code>, XML tags <code class="language-plaintext highlighter-rouge">&lt;tag&gt;</code>). This helps the model distinguish instructions from the text it needs to process.</p> <div class="language-markdown highlighter-rouge"> <div class="highlight"><pre class="highlight"><code>Your task is to summarize the following text, enclosed in triple backticks, for a 5th grader.

</code></pre></div> </div> <p>The recent intergovernmental panel on climate change report highlighted the accelerating rate of global temperature increase, attributing it primarily to human activities, notably the burning of fossil fuels and deforestation. These actions lead to an enhanced greenhouse effect, trapping more heat in the Earth’s atmosphere.</p> <div class="language-plaintext highlighter-rouge"> <div class="highlight"><pre class="highlight"><code></code></pre></div> </div> </li> </ul> <h4 id="2-role-playing-giving-the-ai-a-persona">2. Role-Playing: Giving the AI a Persona</h4> <p>Assigning a role to the LLM can dramatically alter the tone, style, and even the “knowledge base” it draws from. It helps the model align its output with a specific expertise or perspective.</p> <p><strong>Example:</strong></p> <ul> <li> <p><strong>Prompt 1 (No Role):</strong> “Explain quantum physics.” <em>Output: A dense, possibly overwhelming explanation.</em></p> </li> <li> <p><strong>Prompt 2 (With Role):</strong> “You are a friendly high school physics teacher explaining quantum physics to your class. Break down complex ideas into simple analogies. Start with the idea of particles behaving like waves.” <em>Output: More accessible, engaging, and structured for a specific learning goal.</em></p> </li> </ul> <table> <tbody> <tr> <td>This technique is powerful because it conditions the model’s entire response generation process. The $P(\text{output}</td> <td>\text{prompt})$ now includes a strong conditioning on the ‘role’ token(s) and their associated learned patterns.</td> </tr> </tbody> </table> <h4 id="3-few-shot-learning-in-context-learning-learning-from-examples">3. Few-Shot Learning (In-Context Learning): Learning from Examples</h4> <p>LLMs are excellent at pattern recognition. By providing a few examples of desired input/output pairs, you can “teach” the model a new task or specific format without any actual fine-tuning (weight updates). This is called “in-context learning.”</p> <p><strong>Example (Sentiment Classification):</strong></p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Classify the sentiment of the following reviews as 'positive', 'negative', or 'neutral'.

Review: "The movie was absolutely fantastic, great acting!"
Sentiment: positive

Review: "The service was slow and the food was cold."
Sentiment: negative

Review: "The weather was okay, nothing special."
Sentiment: neutral

Review: "I loved every minute of the concert, truly memorable."
Sentiment:
</code></pre></div></div> <table> <tbody> <tr> <td>Here, the model isn’t <em>learning</em> in the traditional sense of updating its weights. Instead, the examples adjust the conditional probability distribution $P(\text{output}</td> <td>\text{input}, \text{examples})$ such that the model is heavily biased to continue the established pattern. It’s essentially completing a sequence based on the preceding pattern, but that pattern happens to encode the desired task.</td> </tr> </tbody> </table> <h4 id="4-chain-of-thought-cot-prompting-thinking-step-by-step">4. Chain-of-Thought (CoT) Prompting: Thinking Step-by-Step</h4> <p>This is arguably one of the most significant breakthroughs in prompt engineering for complex reasoning tasks. Instead of just asking for a final answer, you instruct the model to “think step by step” or show its reasoning process.</p> <p><strong>Why it works:</strong></p> <p>LLMs often struggle with multi-step reasoning. If you just ask for the final answer, they might jump to conclusions, make errors, or hallucinate. By forcing them to articulate their thought process, you:</p> <ul> <li> <strong>Decompose the Problem:</strong> Break a large problem into smaller, manageable steps.</li> <li> <strong>Expose Intermediate Reasoning:</strong> Allow the model to show its work, making errors easier to spot.</li> <li> <strong>Improve Accuracy:</strong> The act of generating intermediate steps often leads to a more accurate final answer.</li> </ul> <p><strong>Example:</strong></p> <p><strong>Bad Prompt:</strong> “If a train leaves station A at 9:00 AM traveling at 60 mph, and another train leaves station B at 10:00 AM traveling at 75 mph, heading towards station A (which is 300 miles away from B), when do they meet?”</p> <p><em>Output: Might give an incorrect time or a simplified explanation.</em></p> <p><strong>Good Prompt (CoT):</strong> “Let’s solve this step by step.</p> <ol> <li>First, calculate how far the first train travels before the second train starts.</li> <li>Then, determine the remaining distance between the trains.</li> <li>Calculate their combined speed (relative speed).</li> <li>Finally, divide the remaining distance by their combined speed to find the time until they meet. Now, using these steps, please solve the following problem: If a train leaves station A at 9:00 AM traveling at 60 mph, and another train leaves station B at 10:00 AM traveling at 75 mph, heading towards station A (which is 300 miles away from B), when do they meet?”</li> </ol> <p><em>Output: The model will typically break down the problem, showing calculations for each step, leading to a much higher chance of a correct answer.</em></p> <p>The <code class="language-plaintext highlighter-rouge">Let's solve this step by step.</code> phrase is often enough, but explicitly outlining the steps like above can be even more effective for particularly tricky problems.</p> <h4 id="5-self-refinement-and-iteration-the-ai-critic">5. Self-Refinement and Iteration: The AI Critic</h4> <p>A more advanced form of CoT involves asking the model to critique its own output and then improve upon it. This simulates an iterative refinement process.</p> <p><strong>Example:</strong></p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Generate a short marketing slogan for a new eco-friendly smart water bottle that tracks hydration.

[Model generates slogan 1]

Critique the above slogan. Is it catchy? Does it clearly convey the product's benefits? Suggest improvements.

[Model critiques slogan 1 and suggests improvements]

Now, generate a revised slogan based on your critique.

[Model generates improved slogan 2]
</code></pre></div></div> <p>This technique helps overcome initial limitations and push the model towards higher quality, more nuanced outputs.</p> <h4 id="6-controlling-output-format-structure-is-key">6. Controlling Output Format: Structure is Key</h4> <p>For integrating LLM outputs into applications or further processing, predictable output formats are crucial.</p> <p><strong>Example:</strong></p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Extract the following information from the text below as a JSON object:
<span class="p">-</span> Product Name
<span class="p">-</span> Price
<span class="p">-</span> Customer Rating (on a scale of 1-5)
<span class="p">-</span> Key Features (as a list)

Text: "The new 'AquaFlow Pro' smart water bottle is a game-changer! Priced at $49.99, it boasts an impressive 4.7-star rating. Its key features include real-time hydration tracking, a durable bamboo casing, and Bluetooth connectivity."

<span class="p">```</span><span class="nl">json
</span><span class="p">{</span><span class="w">
  </span><span class="nl">"Product Name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"AquaFlow Pro"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"Price"</span><span class="p">:</span><span class="w"> </span><span class="s2">"$49.99"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"Customer Rating"</span><span class="p">:</span><span class="w"> </span><span class="mf">4.7</span><span class="p">,</span><span class="w">
  </span><span class="nl">"Key Features"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
    </span><span class="s2">"real-time hydration tracking"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"durable bamboo casing"</span><span class="p">,</span><span class="w">
    </span><span class="s2">"Bluetooth connectivity"</span><span class="w">
  </span><span class="p">]</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div> <p>This ensures the output is machine-readable and ready for downstream tasks in your data pipeline or application.</p> <h3 id="the-iterative-process-experiment-evaluate-refine">The Iterative Process: Experiment, Evaluate, Refine</h3> <p>Prompt Engineering is rarely a one-shot process. It’s an iterative loop:</p> <ol> <li> <strong>Formulate:</strong> Write an initial prompt.</li> <li> <strong>Test:</strong> Run the prompt through the LLM.</li> <li> <strong>Evaluate:</strong> Does the output meet your criteria? Is it accurate, relevant, complete, and in the right format?</li> <li> <strong>Refine:</strong> Based on the evaluation, adjust the prompt. Add more specificity, change the role, provide examples, or introduce CoT.</li> <li> <strong>Repeat:</strong> Keep iterating until you achieve the desired quality.</li> </ol> <p>This scientific method approach is fundamental. It requires patience, critical thinking, and a willingness to experiment.</p> <h3 id="challenges-and-limitations">Challenges and Limitations</h3> <p>While powerful, prompt engineering isn’t a magic bullet:</p> <ul> <li> <strong>Hallucinations:</strong> LLMs can still generate plausible-sounding but factually incorrect information. Careful prompting can mitigate this but not eliminate it entirely.</li> <li> <strong>Bias:</strong> Models reflect biases present in their training data. Prompts need to be designed to minimize reinforcing or generating harmful biases.</li> <li> <strong>Context Window Limits:</strong> Models have a finite amount of text they can process at once. Very long examples or complex instructions can exceed this limit.</li> <li> <strong>Prompt Sensitivity:</strong> Minor changes in wording can sometimes lead to drastically different outputs, making robust prompt design challenging.</li> <li> <strong>Art vs. Science:</strong> There’s still a significant “art” to crafting truly effective prompts, relying on intuition and experience alongside scientific principles.</li> </ul> <h3 id="prompt-engineering-for-your-data-science--mle-portfolio">Prompt Engineering for Your Data Science &amp; MLE Portfolio</h3> <p>So, why is this skill so crucial for aspiring (and current) Data Scientists and Machine Learning Engineers?</p> <ol> <li> <strong>Rapid Prototyping:</strong> Imagine quickly testing a hypothesis for a text classification task or generating synthetic data to bootstrap a model – prompt engineering lets you do this in minutes, not days.</li> <li> <strong>Feature Engineering:</strong> LLMs can help generate new features from raw text data (e.g., extracting entities, sentiments, topics) that you can then feed into traditional ML models.</li> <li> <strong>Data Augmentation:</strong> Create variations of existing data or generate entirely new data points for training, especially useful for scarce data.</li> <li> <strong>Building Intelligent Agents:</strong> Develop sophisticated conversational agents, code assistants, or research tools by orchestrating multiple prompts and chaining LLM calls.</li> <li> <strong>Understanding Model Capabilities:</strong> By systematically testing different prompts, you gain a deeper understanding of what these powerful models are capable of and where their limitations lie.</li> <li> <strong>Bridge to Product:</strong> For MLEs, prompt engineering is often the direct interface between the user’s intent and the AI’s execution. A well-engineered prompt is a key component of a good user experience in AI products.</li> </ol> <p>Including projects in your portfolio that showcase your prompt engineering skills – perhaps a system that extracts financial data, a content generation tool, or a chatbot that gives empathetic advice – will demonstrate a highly sought-after, cutting-edge capability.</p> <h3 id="conclusion-your-new-superpower">Conclusion: Your New Superpower</h3> <p>Prompt Engineering is more than just a trick; it’s a fundamental shift in how we interact with and “program” the next generation of intelligent systems. It empowers us to wield the immense capabilities of LLMs with precision and purpose.</p> <p>It’s a field that’s evolving at lightning speed, with new techniques and best practices emerging constantly. The best way to learn is by doing: get your hands dirty, experiment, and embrace the iterative process. Start building, start whispering your precise instructions to these digital giants, and watch them deliver incredible results.</p> <p>This skill isn’t just a niche; it’s becoming a universal language for navigating the AI-driven future. Go forth and prompt!</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/cracking-the-ai-black-box-why-explainable-ai-xai-i/">Cracking the AI Black Box: Why Explainable AI (XAI) is Our Superpower</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/the-secret-life-of-states-how-markov-chains-predic/">The Secret Life of States: How Markov Chains Predict Our Next Move (Without Remembering the Past!)</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/gradient-descent-unpacking-the-engine-of-machine-l/">Gradient Descent: Unpacking the Engine of Machine Learning</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Adarsh Nair. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/blog/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/masonry.js?v=a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/zoom.js?v=85ddb88934d28b74e78031fd54cf8308"></script> <script src="/blog/assets/js/no_defer.js?v=2781658a0a2b13ed609542042a859126"></script> <script defer src="/blog/assets/js/common.js?v=c15de51d4bb57887caa2c21988d97279"></script> <script defer src="/blog/assets/js/copy_code.js?v=c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/blog/assets/js/jupyter_new_tab.js?v=d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/blog/assets/js/mathjax-setup.js?v=a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/progress-bar.js?v=2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/blog/assets/js/vanilla-back-to-top.min.js?v=f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/blog/assets/js/search/ninja-keys.min.js?v=a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/blog/assets/js/search-setup.js?v=6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/blog/assets/js/search-data.js"></script> <script src="/blog/assets/js/shortcut-key.js?v=ccc841c459bfc0e64c1c2b5acd10df02"></script> </body> </html>