<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> The Data Scientist's Compass: Navigating Uncertainty with Hypothesis Testing | Adarsh Nair </title> <meta name="author" content="Adarsh Nair"> <meta name="description" content="A deep dive into machine learning, AI, and data science. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <meta http-equiv="Content-Security-Policy" content="default-src 'self'; script-src 'self' 'unsafe-inline' https:; style-src 'self' 'unsafe-inline' https:; img-src 'self' data: https:; font-src 'self' data: https:; media-src 'self' https:; frame-src 'self' https:; connect-src 'self' https:;"> <link rel="stylesheet" href="/blog/assets/css/bootstrap.min.css?v=a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/blog/assets/css/academicons.min.css?v=f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/blog/assets/css/scholar-icons.css?v=62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-github.css?v=591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/blog/assets/css/main.css?v=d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://adarshnair.online/blog/blog/blog/2026/the-data-scientists-compass-navigating-uncertainty/"> <script src="/blog/assets/js/theme.js?v=5fea5159b787642c1bbc1f334d60f883"></script> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-native.css?v=5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="https://adarshnair.online" rel="external nofollow noopener" target="_blank"> Adarsh Nair </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/blog/"> </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/index.html">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/cv/">CV </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/repositories/">repositories </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="fa-solid fa-magnifying-glass"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-half-sun-moon" id="light-toggle-system"></i> <i class="fa-solid fa-moon" id="light-toggle-dark"></i> <i class="fa-solid fa-sun" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">The Data Scientist's Compass: Navigating Uncertainty with Hypothesis Testing</h1> <p class="post-meta"> Created on January 18, 2026 by Adarsh Nair </p> <p class="post-tags"> <a href="/blog/blog/2026"> <i class="fa-solid fa-calendar fa-sm"></i> 2026 </a>   ·   <a href="/blog/blog/tag/hypothesis-testing"> <i class="fa-solid fa-hashtag fa-sm"></i> Hypothesis Testing</a>   <a href="/blog/blog/tag/statistics"> <i class="fa-solid fa-hashtag fa-sm"></i> Statistics</a>   <a href="/blog/blog/tag/data-science"> <i class="fa-solid fa-hashtag fa-sm"></i> Data Science</a>   <a href="/blog/blog/tag/a-b-testing"> <i class="fa-solid fa-hashtag fa-sm"></i> A/B Testing</a>   <a href="/blog/blog/tag/inferential-statistics"> <i class="fa-solid fa-hashtag fa-sm"></i> Inferential Statistics</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p>Hey everyone!</p> <p>Welcome back to my journal, where I demystify the concepts that power our data-driven world. Today, we’re diving into a topic that’s absolutely fundamental for anyone aspiring to build intelligent systems or make sense of complex datasets: <strong>Hypothesis Testing</strong>.</p> <p>Remember that time you wondered if a new ad campaign <em>really</em> boosted sales, or if a particular ingredient <em>actually</em> made a difference in your favorite recipe? As data scientists and machine learning engineers, we’re constantly bombarded with claims and data. Our gut feelings can be helpful, but when it comes to making critical decisions that impact products, users, or even lives, we need something more robust. We need a way to move beyond intuition and let the data speak for itself, with a structured, scientific approach. That’s where the magic of Hypothesis Testing comes in.</p> <h3 id="whats-the-big-idea-the-core-of-statistical-proof">What’s the Big Idea? The Core of Statistical Proof</h3> <p>At its heart, Hypothesis Testing is like setting up a scientific debate with your data. You propose two opposing statements about a population parameter (like a mean, proportion, or variance), and then use your sample data to see which statement the evidence supports. Think of it like a courtroom drama, an analogy I find incredibly useful.</p> <p><strong>The Null Hypothesis ($H_0$): The Status Quo, The Innocent Until Proven Guilty</strong> This is our default assumption, the “nothing new is happening” statement. It often represents the status quo, no effect, or no difference. It’s what we assume to be true unless we find strong evidence against it.</p> <p><em>Example:</em></p> <ul> <li>“The new fertilizer has no effect on plant growth.”</li> <li>“The website’s conversion rate is still 5%.”</li> <li>“There is no difference in average test scores between two teaching methods.”</li> </ul> <p>We always phrase $H_0$ to contain an equality (e.g., $=$, $\le$, $\ge$).</p> <p><strong>The Alternative Hypothesis ($H_1$ or $H_A$): What We’re Trying to Prove, The “Guilty” Plea</strong> This is the claim we’re trying to find evidence <em>for</em>. It’s the statement that contradicts the null hypothesis, suggesting there <em>is</em> an effect, a difference, or a change. This is often the research hypothesis we’re interested in.</p> <p><em>Example:</em></p> <ul> <li>“The new fertilizer <em>does</em> increase plant growth.”</li> <li>“The website’s conversion rate is <em>greater than</em> 5%.”</li> <li>“There <em>is</em> a difference in average test scores between two teaching methods.”</li> </ul> <p>The alternative hypothesis usually contains an inequality (e.g., $\ne$, $&lt;$, $&gt;$).</p> <p><strong>The Courtroom Analogy Revisited:</strong></p> <ul> <li> <strong>$H_0$:</strong> The defendant is innocent. (This is our default assumption).</li> <li> <strong>$H_1$:</strong> The defendant is guilty. (This is what the prosecution tries to prove).</li> </ul> <p>In a courtroom, you don’t <em>prove</em> innocence; you only fail to prove guilt. Similarly, in hypothesis testing, we either <strong>reject the null hypothesis</strong> (meaning we found enough evidence to support the alternative) or <strong>fail to reject the null hypothesis</strong> (meaning we didn’t find enough evidence against the null, so we stick with the status quo). We <em>never</em> “accept” the null hypothesis, because we’re just saying the data isn’t strong enough to overturn it.</p> <h3 id="the-peril-of-errors-type-i-and-type-ii">The Peril of Errors: Type I and Type II</h3> <p>Now, in any courtroom, mistakes can happen. A truly innocent person might be found guilty, or a truly guilty person might walk free. In statistics, we call these:</p> <ol> <li> <strong>Type I Error ($\alpha$ - Alpha): False Positive</strong> <ul> <li>This occurs when we <strong>reject the null hypothesis when it is actually true</strong>.</li> <li> <em>Courtroom:</em> Convicting an innocent person.</li> <li> <em>Example:</em> Concluding the new ad campaign increased sales when, in reality, it didn’t.</li> <li>We set a <em>significance level</em> (denoted by $\alpha$) for this error, typically 0.05 or 0.01. This means we’re willing to accept a 5% or 1% chance of making a Type I error. A smaller $\alpha$ makes it harder to reject $H_0$.</li> </ul> </li> <li> <strong>Type II Error ($\beta$ - Beta): False Negative</strong> <ul> <li>This occurs when we <strong>fail to reject the null hypothesis when it is actually false</strong>.</li> <li> <em>Courtroom:</em> Letting a guilty person walk free.</li> <li> <em>Example:</em> Concluding the new ad campaign <em>didn’t</em> increase sales when, in reality, it actually did.</li> <li>The probability of avoiding a Type II error (1 - $\beta$) is called the <strong>power of the test</strong>. A higher power is desirable, meaning the test is good at detecting an effect when one truly exists.</li> </ul> </li> </ol> <p>There’s an inherent trade-off between Type I and Type II errors. Reducing one often increases the other. The choice of $\alpha$ depends on the consequences of each error in your specific domain. For instance, in drug trials, a Type I error (declaring a drug effective when it isn’t) might be more serious than a Type II error (missing an effective drug), so a very low $\alpha$ is chosen.</p> <h3 id="the-journey-steps-of-hypothesis-testing">The Journey: Steps of Hypothesis Testing</h3> <p>So, how do we actually <em>do</em> this? It’s a structured journey, and like any good adventure, there are clear steps to follow:</p> <ol> <li> <p><strong>Formulate Your Hypotheses ($H_0$ and $H_1$):</strong> Clearly state the null and alternative hypotheses based on your research question.</p> <p><em>Example:</em> I want to know if my new ML model has a higher accuracy than the old one (which was 85%).</p> <ul> <li>$H_0: \mu_{new_model} \le 0.85$ (The new model’s accuracy is 85% or less)</li> <li>$H_1: \mu_{new_model} &gt; 0.85$ (The new model’s accuracy is greater than 85%)</li> </ul> </li> <li> <p><strong>Choose a Significance Level ($\alpha$):</strong> Decide how much risk of a Type I error you’re willing to take. Common choices are 0.05 (5%) or 0.01 (1%). This threshold will be crucial in our decision-making.</p> </li> <li> <p><strong>Collect Data and Choose the Right Test Statistic:</strong> Gather your sample data. Based on your data type, sample size, and what you’re trying to compare, you’ll select an appropriate statistical test (e.g., Z-test, T-test, Chi-squared test, ANOVA). Each test calculates a <strong>test statistic</strong>, which is a standardized value that quantifies how much your sample data deviates from what would be expected under the null hypothesis.</p> </li> <li> <p><strong>Calculate the P-value:</strong> This brings us to the famous (or infamous, depending on who you ask) <strong>p-value</strong>. The p-value is perhaps the most misunderstood concept in all of statistics, but it’s incredibly powerful when interpreted correctly.</p> <p><em>Imagine you’re rolling a fair die (six sides, equal probability for each number). If you roll a 6 ten times in a row, you’d start to question if the die is truly fair, wouldn’t you?</em></p> <p>The p-value is essentially: \(P(\text{observing data as extreme as, or more extreme than, what you got } | H_0 \text{ is true})\) In simpler terms, it’s the probability of seeing your observed results (or something even more extreme) <em>if the null hypothesis were actually true</em>. A small p-value means your observed data would be very unlikely if $H_0$ were true, suggesting $H_0$ might be false.</p> </li> <li> <p><strong>Make a Decision:</strong> Compare your calculated p-value to your chosen significance level ($\alpha$).</p> <ul> <li> <strong>If $p &lt; \alpha$:</strong> Reject the null hypothesis ($H_0$). There is statistically significant evidence to support the alternative hypothesis ($H_1$).</li> <li> <strong>If $p \ge \alpha$:</strong> Fail to reject the null hypothesis ($H_0$). There is not enough statistically significant evidence to support the alternative hypothesis ($H_1$).</li> </ul> <p>Crucially, “failing to reject $H_0$” does <em>not</em> mean $H_0$ is true. It simply means our data isn’t strong enough to say it’s false.</p> </li> </ol> <h3 id="lets-walk-through-an-example-the-case-of-the-new-website-feature">Let’s Walk Through an Example: The Case of the New Website Feature</h3> <p>Let’s put on our data detective hats and walk through a scenario. Imagine I’ve just launched a new feature on my portfolio website – say, an interactive chart showing project progress. My old bounce rate (percentage of visitors who leave after viewing only one page) was consistently around 60%. I’m hoping this new feature <em>reduces</em> the bounce rate. This is where hypothesis testing steps in.</p> <p><strong>Step 1: Formulate Hypotheses</strong></p> <ul> <li>My current bounce rate is $P_0 = 0.60$. I want to see if the new feature reduces it.</li> <li>$H_0: P \ge 0.60$ (The new feature has no effect, or even increases, the bounce rate)</li> <li>$H_1: P &lt; 0.60$ (The new feature reduces the bounce rate) <ul> <li> <em>Note:</em> This is a <strong>one-tailed test</strong> because I’m specifically interested in a <em>reduction</em>. If I just wanted to see if it <em>changed</em> (either up or down), it would be a two-tailed test.</li> </ul> </li> </ul> <p><strong>Step 2: Choose Significance Level ($\alpha$)</strong> I’ll choose a common $\alpha = 0.05$. This means I’m willing to accept a 5% chance of falsely concluding the new feature reduced the bounce rate when it didn’t (Type I error).</p> <p><strong>Step 3: Collect Data and Choose Test Statistic</strong> I let the new feature run for a month and collect data. Out of 1000 visitors, 570 bounced. So, my sample bounce rate is $\hat{p} = 570/1000 = 0.57$. Since I’m dealing with proportions and a relatively large sample size, a Z-test for proportions is appropriate. The test statistic for proportions is calculated as: \(Z = \frac{\hat{p} - P_0}{\sqrt{\frac{P_0(1-P_0)}{n}}}\) Where:</p> <ul> <li>$\hat{p}$ = sample proportion (0.57)</li> <li>$P_0$ = hypothesized population proportion under $H_0$ (0.60)</li> <li>$n$ = sample size (1000)</li> </ul> <p>Let’s plug in the numbers: \(Z = \frac{0.57 - 0.60}{\sqrt{\frac{0.60(1-0.60)}{1000}}} = \frac{-0.03}{\sqrt{\frac{0.60 \times 0.40}{1000}}} = \frac{-0.03}{\sqrt{\frac{0.24}{1000}}} = \frac{-0.03}{\sqrt{0.00024}} \approx \frac{-0.03}{0.01549} \approx -1.936\)</p> <p><strong>Step 4: Calculate the P-value</strong> For a Z-score of -1.936 in a one-tailed test (looking for values less than 0.60), we consult a Z-table or use statistical software. The p-value associated with $Z \approx -1.936$ for a left-tailed test is approximately 0.0264.</p> <p><strong>Step 5: Make a Decision</strong></p> <ul> <li>My p-value is 0.0264.</li> <li>My significance level ($\alpha$) is 0.05.</li> <li>Since $0.0264 &lt; 0.05$, my p-value is less than $\alpha$.</li> </ul> <p><strong>Conclusion:</strong> I reject the null hypothesis ($H_0$). There is statistically significant evidence (at the 0.05 level) to suggest that the new feature <em>has</em> reduced the website’s bounce rate. Success!</p> <h3 id="why-this-matters-for-data-scientists-and-mles">Why This Matters for Data Scientists and MLEs</h3> <p>Hypothesis testing isn’t just an academic exercise; it’s a cornerstone of data-driven decision-making in the real world:</p> <ul> <li> <strong>A/B Testing:</strong> This is the bread and butter of product development. Is Feature A better than Feature B? Is the new website design leading to more clicks? Hypothesis testing provides the statistical rigor to answer these questions reliably.</li> <li> <strong>Model Comparison:</strong> Is your fancy new deep learning model <em>truly</em> performing better than the simpler baseline model, or is the observed difference just due to random chance in your validation set? Hypothesis testing helps you make that call.</li> <li> <strong>Feature Selection:</strong> Does a particular feature <em>really</em> have a predictive impact, or can you remove it without significant loss of model performance?</li> <li> <strong>Understanding Uncertainty:</strong> It helps us quantify and communicate the uncertainty in our conclusions, fostering a more responsible and realistic approach to data insights.</li> <li> <strong>Bias Detection:</strong> Are there statistically significant differences in model performance across different demographic groups, hinting at potential bias?</li> </ul> <h3 id="beyond-the-p-value-practical-vs-statistical-significance">Beyond the P-Value: Practical vs. Statistical Significance</h3> <p>Before we wrap up, a crucial distinction: <strong>statistical significance</strong> versus <strong>practical significance</strong>.</p> <p>A p-value might tell you that a difference is unlikely to be due to chance (statistically significant), but that difference might be tiny and inconsequential in the real world. For instance, if your new ad campaign increased sales by 0.001% with a p-value of 0.001, it’s statistically significant, but is it practically significant enough to justify the cost of the campaign? Probably not.</p> <p>Always consider the <em>magnitude</em> of the effect alongside its statistical significance. A true data scientist or ML engineer doesn’t just chase low p-values; they aim for impactful, meaningful changes.</p> <h3 id="final-thoughts-your-datas-inner-voice">Final Thoughts: Your Data’s Inner Voice</h3> <p>Hypothesis testing is your compass in the vast ocean of data. It empowers you to move beyond guesswork, challenging assumptions and making informed decisions with statistical backing. It teaches you to be skeptical, to demand evidence, and to understand the limitations of your conclusions.</p> <p>As you continue your journey in data science and machine learning, mastering hypothesis testing will be invaluable. It transforms you from someone who just <em>looks</em> at data into someone who can <em>interrogate</em> it, extract its secrets, and build a stronger, more reliable foundation for your models and insights.</p> <p>So, go forth and test those hypotheses! Let your data lead the way.</p> <p>Happy analyzing! [Your Name/Alias]</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/cracking-the-ai-black-box-why-explainable-ai-xai-i/">Cracking the AI Black Box: Why Explainable AI (XAI) is Our Superpower</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/the-secret-life-of-states-how-markov-chains-predic/">The Secret Life of States: How Markov Chains Predict Our Next Move (Without Remembering the Past!)</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/gradient-descent-unpacking-the-engine-of-machine-l/">Gradient Descent: Unpacking the Engine of Machine Learning</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Adarsh Nair. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/blog/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/masonry.js?v=a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/zoom.js?v=85ddb88934d28b74e78031fd54cf8308"></script> <script src="/blog/assets/js/no_defer.js?v=2781658a0a2b13ed609542042a859126"></script> <script defer src="/blog/assets/js/common.js?v=c15de51d4bb57887caa2c21988d97279"></script> <script defer src="/blog/assets/js/copy_code.js?v=c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/blog/assets/js/jupyter_new_tab.js?v=d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/blog/assets/js/mathjax-setup.js?v=a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/progress-bar.js?v=2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/blog/assets/js/vanilla-back-to-top.min.js?v=f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/blog/assets/js/search/ninja-keys.min.js?v=a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/blog/assets/js/search-setup.js?v=6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/blog/assets/js/search-data.js"></script> <script src="/blog/assets/js/shortcut-key.js?v=ccc841c459bfc0e64c1c2b5acd10df02"></script> </body> </html>