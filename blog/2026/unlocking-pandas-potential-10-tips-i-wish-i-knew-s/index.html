<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Unlocking Pandas Potential: 10 Tips I Wish I Knew Sooner | Adarsh Nair </title> <meta name="author" content="Adarsh Nair"> <meta name="description" content="A deep dive into machine learning, AI, and data science. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <meta http-equiv="Content-Security-Policy" content="default-src 'self'; script-src 'self' 'unsafe-inline' https:; style-src 'self' 'unsafe-inline' https:; img-src 'self' data: https:; font-src 'self' data: https:; media-src 'self' https:; frame-src 'self' https:; connect-src 'self' https:;"> <link rel="stylesheet" href="/blog/assets/css/bootstrap.min.css?v=a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/blog/assets/css/academicons.min.css?v=f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/blog/assets/css/scholar-icons.css?v=62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-github.css?v=591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/blog/assets/css/main.css?v=d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://adarshnair.online/blog/blog/blog/2026/unlocking-pandas-potential-10-tips-i-wish-i-knew-s/"> <script src="/blog/assets/js/theme.js?v=5fea5159b787642c1bbc1f334d60f883"></script> <link defer rel="stylesheet" href="/blog/assets/css/jekyll-pygments-themes-native.css?v=5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/blog/cv/"> Adarsh Nair </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/blog/"> </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/index.html">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/cv/">CV </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/repositories/">repositories </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="fa-solid fa-magnifying-glass"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-half-sun-moon" id="light-toggle-system"></i> <i class="fa-solid fa-moon" id="light-toggle-dark"></i> <i class="fa-solid fa-sun" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Unlocking Pandas Potential: 10 Tips I Wish I Knew Sooner</h1> <p class="post-meta"> Created on January 07, 2026 by Adarsh Nair </p> <p class="post-tags"> <a href="/blog/blog/2026"> <i class="fa-solid fa-calendar fa-sm"></i> 2026 </a>   ·   <a href="/blog/blog/tag/pandas"> <i class="fa-solid fa-hashtag fa-sm"></i> Pandas</a>   <a href="/blog/blog/tag/data-science"> <i class="fa-solid fa-hashtag fa-sm"></i> Data Science</a>   <a href="/blog/blog/tag/python"> <i class="fa-solid fa-hashtag fa-sm"></i> Python</a>   <a href="/blog/blog/tag/data-analysis"> <i class="fa-solid fa-hashtag fa-sm"></i> Data Analysis</a>   <a href="/blog/blog/tag/optimization"> <i class="fa-solid fa-hashtag fa-sm"></i> Optimization</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p>Ah, Pandas. If you’ve spent any time in the Data Science realm, you know this library is like a trusty Swiss Army knife for data manipulation in Python. It’s often one of the first tools you learn, and for good reason – it’s incredibly versatile and powerful. But like any powerful tool, there are nuances and hidden gems that, once discovered, can dramatically change how you interact with your data.</p> <p>I remember my early days, staring at slow <code class="language-plaintext highlighter-rouge">for</code> loops, wrestling with indexing errors, and watching my laptop fan spin up like a jet engine when dealing with “large” datasets (which back then meant anything over 100,000 rows!). Over time, through countless projects, frustrating bugs, and a lot of Stack Overflow digging, I started accumulating a personal toolkit of Pandas best practices.</p> <p>This isn’t just a list of features; it’s a collection of practical insights that have genuinely reshaped my workflow. My goal is to share these “aha!” moments with you, whether you’re just starting out or looking to refine your Pandas game. Let’s dive in and unlock some serious Pandas potential!</p> <hr> <h3 id="1-embrace-vectorization-ditch-the-loops">1. Embrace Vectorization: Ditch the Loops!</h3> <p>This is probably the most fundamental and impactful tip. When you first learn Python, <code class="language-plaintext highlighter-rouge">for</code> loops are your best friend. But in Pandas, they can be your biggest bottleneck. Pandas operations are designed to be “vectorized,” meaning they operate on entire arrays (or Series/DataFrames) at once, often leveraging highly optimized C code under the hood.</p> <p><strong>The Problem:</strong> Using <code class="language-plaintext highlighter-rouge">for</code> loops or <code class="language-plaintext highlighter-rouge">df.apply()</code> with row-wise operations can be incredibly slow, especially on large datasets.</p> <p><strong>The Solution:</strong> Whenever possible, use built-in Pandas methods or NumPy functions.</p> <p>Let’s say you want to square a column of numbers:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="c1"># Create a sample DataFrame
</span><span class="n">data</span> <span class="o">=</span> <span class="p">{</span><span class="sh">'</span><span class="s">value</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">]}</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="c1"># The SLOW way (using .apply() with a lambda, or a loop)
# df['squared_slow'] = df['value'].apply(lambda x: x**2)
</span>
<span class="c1"># The FAST way (vectorized operation)
</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">squared_fast</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">value</span><span class="sh">'</span><span class="p">]</span> <span class="o">**</span> <span class="mi">2</span>
<span class="nf">print</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</code></pre></div></div> <p>The difference in performance can be staggering. For simple arithmetic, comparison, or string operations, always default to the vectorized approach. The underlying C implementation can perform operations much faster, often in $O(1)$ time for each operation across the entire column, compared to $O(N)$ for a Python loop where $N$ is the number of rows.</p> <p><strong>When <code class="language-plaintext highlighter-rouge">apply()</code> is Okay:</strong> Sometimes you have complex custom logic that can’t be easily vectorized. In such cases, <code class="language-plaintext highlighter-rouge">df.apply()</code> can be useful, especially when applied column-wise (<code class="language-plaintext highlighter-rouge">axis=0</code>) or row-wise (<code class="language-plaintext highlighter-rouge">axis=1</code>) where it might be slightly better than a pure Python loop. But always ask yourself: “Can I do this with a vectorized operation?”</p> <h3 id="2-master-loc-and-iloc-your-indexing-superpowers">2. Master <code class="language-plaintext highlighter-rouge">loc</code> and <code class="language-plaintext highlighter-rouge">iloc</code>: Your Indexing Superpowers</h3> <p>Selecting data correctly and efficiently is crucial. Pandas offers <code class="language-plaintext highlighter-rouge">loc</code> and <code class="language-plaintext highlighter-rouge">iloc</code> for powerful, explicit indexing. Trying to use <code class="language-plaintext highlighter-rouge">df[]</code> for complex selections can lead to confusing errors or, worse, silent bugs.</p> <ul> <li> <strong><code class="language-plaintext highlighter-rouge">.loc</code> (Location-based indexing):</strong> Used for label-based indexing. You pass row and column <em>labels</em>.</li> <li> <strong><code class="language-plaintext highlighter-rouge">.iloc</code> (Integer-location based indexing):</strong> Used for integer-position based indexing. You pass row and column <em>integers</em>.</li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data</span> <span class="o">=</span> <span class="p">{</span><span class="sh">'</span><span class="s">Name</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span><span class="sh">'</span><span class="s">Alice</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Bob</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Charlie</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">David</span><span class="sh">'</span><span class="p">],</span>
        <span class="sh">'</span><span class="s">Age</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span><span class="mi">25</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">35</span><span class="p">,</span> <span class="mi">40</span><span class="p">],</span>
        <span class="sh">'</span><span class="s">City</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span><span class="sh">'</span><span class="s">NY</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">LA</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">CHI</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">SF</span><span class="sh">'</span><span class="p">]}</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">a</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">b</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">c</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">d</span><span class="sh">'</span><span class="p">])</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Original DataFrame:</span><span class="se">\n</span><span class="sh">"</span><span class="p">,</span> <span class="n">df</span><span class="p">)</span>

<span class="c1"># Using .loc (label-based)
</span><span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="se">\n</span><span class="s">Select row </span><span class="sh">'</span><span class="s">b</span><span class="sh">'</span><span class="s"> and column </span><span class="sh">'</span><span class="s">Age</span><span class="sh">'</span><span class="s"> using .loc:</span><span class="sh">"</span><span class="p">,</span> <span class="n">df</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="sh">'</span><span class="s">b</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Age</span><span class="sh">'</span><span class="p">])</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="se">\n</span><span class="s">Select rows </span><span class="sh">'</span><span class="s">a</span><span class="sh">'</span><span class="s"> to </span><span class="sh">'</span><span class="s">c</span><span class="sh">'</span><span class="s"> and columns </span><span class="sh">'</span><span class="s">Name</span><span class="sh">'</span><span class="s"> and </span><span class="sh">'</span><span class="s">City</span><span class="sh">'</span><span class="s"> using .loc:</span><span class="se">\n</span><span class="sh">"</span><span class="p">,</span> <span class="n">df</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="sh">'</span><span class="s">a</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">c</span><span class="sh">'</span><span class="p">,</span> <span class="p">[</span><span class="sh">'</span><span class="s">Name</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">City</span><span class="sh">'</span><span class="p">]])</span>

<span class="c1"># Using .iloc (integer-position based)
</span><span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="se">\n</span><span class="s">Select the element at row index 1, column index 0 using .iloc:</span><span class="sh">"</span><span class="p">,</span> <span class="n">df</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="se">\n</span><span class="s">Select the first three rows and the first two columns using .iloc:</span><span class="se">\n</span><span class="sh">"</span><span class="p">,</span> <span class="n">df</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">:</span><span class="mi">2</span><span class="p">])</span>
</code></pre></div></div> <p>The key is clarity and preventing <code class="language-plaintext highlighter-rouge">SettingWithCopyWarning</code>. When you use <code class="language-plaintext highlighter-rouge">df[...] = value</code>, Pandas might create a copy of a slice, and your assignment might not modify the original DataFrame. Using <code class="language-plaintext highlighter-rouge">df.loc[row_selector, col_selector] = value</code> explicitly tells Pandas your intent and ensures you modify the original data.</p> <h3 id="3-taming-memory-with-categorical-data-types">3. Taming Memory with Categorical Data Types</h3> <p>When you’re dealing with columns that have a limited number of unique string values (like ‘Gender’, ‘Country’, ‘Product_Type’), Pandas often stores them as <code class="language-plaintext highlighter-rouge">object</code> dtype (Python strings). This can be a huge memory hog for large datasets.</p> <p><strong>The Solution:</strong> Convert these columns to the <code class="language-plaintext highlighter-rouge">category</code> dtype. Categorical data types store the unique values once and then represent each entry as an integer pointer to that unique value. This is incredibly memory-efficient and can speed up certain operations like <code class="language-plaintext highlighter-rouge">groupby()</code>.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data</span> <span class="o">=</span> <span class="p">{</span><span class="sh">'</span><span class="s">product</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span><span class="sh">'</span><span class="s">A</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">B</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">A</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">C</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">B</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">A</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">C</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">B</span><span class="sh">'</span><span class="p">],</span>
        <span class="sh">'</span><span class="s">region</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span><span class="sh">'</span><span class="s">East</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">West</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">East</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">North</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">South</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">West</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">East</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">North</span><span class="sh">'</span><span class="p">],</span>
        <span class="sh">'</span><span class="s">sales</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span><span class="mi">100</span><span class="p">,</span> <span class="mi">150</span><span class="p">,</span> <span class="mi">120</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">180</span><span class="p">,</span> <span class="mi">130</span><span class="p">,</span> <span class="mi">210</span><span class="p">,</span> <span class="mi">160</span><span class="p">]}</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Original DataFrame info:</span><span class="sh">"</span><span class="p">)</span>
<span class="n">df</span><span class="p">.</span><span class="nf">info</span><span class="p">(</span><span class="n">memory_usage</span><span class="o">=</span><span class="sh">'</span><span class="s">deep</span><span class="sh">'</span><span class="p">)</span>

<span class="c1"># Convert 'product' and 'region' to 'category' dtype
</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">product</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">product</span><span class="sh">'</span><span class="p">].</span><span class="nf">astype</span><span class="p">(</span><span class="sh">'</span><span class="s">category</span><span class="sh">'</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">region</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">region</span><span class="sh">'</span><span class="p">].</span><span class="nf">astype</span><span class="p">(</span><span class="sh">'</span><span class="s">category</span><span class="sh">'</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="se">\n</span><span class="s">DataFrame info after converting to category dtype:</span><span class="sh">"</span><span class="p">)</span>
<span class="n">df</span><span class="p">.</span><span class="nf">info</span><span class="p">(</span><span class="n">memory_usage</span><span class="o">=</span><span class="sh">'</span><span class="s">deep</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div> <p>Notice the significant drop in memory usage, especially if your strings are long and repetitive! This is a low-hanging fruit for optimizing large datasets.</p> <h3 id="4-groupby-power-ups-agg-transform-and-beyond">4. Groupby() Power-Ups: <code class="language-plaintext highlighter-rouge">agg()</code>, <code class="language-plaintext highlighter-rouge">transform()</code>, and Beyond</h3> <p><code class="language-plaintext highlighter-rouge">groupby()</code> is a cornerstone of data analysis. While <code class="language-plaintext highlighter-rouge">df.groupby('col').mean()</code> is great, <code class="language-plaintext highlighter-rouge">agg()</code> and <code class="language-plaintext highlighter-rouge">transform()</code> unlock even more power.</p> <ul> <li> <strong><code class="language-plaintext highlighter-rouge">.agg()</code>:</strong> Apply multiple aggregation functions to one or more columns.</li> <li> <strong><code class="language-plaintext highlighter-rouge">.transform()</code>:</strong> Perform a group-wise calculation and return a Series with the same index as the original DataFrame. This is perfect for imputing missing values with group means, or normalizing data within groups.</li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data</span> <span class="o">=</span> <span class="p">{</span><span class="sh">'</span><span class="s">group</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span><span class="sh">'</span><span class="s">A</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">A</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">B</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">B</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">A</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">B</span><span class="sh">'</span><span class="p">],</span>
        <span class="sh">'</span><span class="s">value</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">22</span><span class="p">]}</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Original DataFrame:</span><span class="se">\n</span><span class="sh">"</span><span class="p">,</span> <span class="n">df</span><span class="p">)</span>

<span class="c1"># Using .agg() for multiple aggregations
</span><span class="n">aggregated_df</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">groupby</span><span class="p">(</span><span class="sh">'</span><span class="s">group</span><span class="sh">'</span><span class="p">)[</span><span class="sh">'</span><span class="s">value</span><span class="sh">'</span><span class="p">].</span><span class="nf">agg</span><span class="p">([</span><span class="sh">'</span><span class="s">mean</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">sum</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">count</span><span class="sh">'</span><span class="p">])</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="se">\n</span><span class="s">Aggregated DataFrame using .agg():</span><span class="se">\n</span><span class="sh">"</span><span class="p">,</span> <span class="n">aggregated_df</span><span class="p">)</span>

<span class="c1"># Using .transform() to add group-wise mean back to original DataFrame
</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">group_mean</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">groupby</span><span class="p">(</span><span class="sh">'</span><span class="s">group</span><span class="sh">'</span><span class="p">)[</span><span class="sh">'</span><span class="s">value</span><span class="sh">'</span><span class="p">].</span><span class="nf">transform</span><span class="p">(</span><span class="sh">'</span><span class="s">mean</span><span class="sh">'</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="se">\n</span><span class="s">DataFrame with group_mean using .transform():</span><span class="se">\n</span><span class="sh">"</span><span class="p">,</span> <span class="n">df</span><span class="p">)</span>
</code></pre></div></div> <p><code class="language-plaintext highlighter-rouge">transform()</code> is incredibly useful because it ensures the output shape matches the input, allowing you to seamlessly integrate group-wise statistics back into your original data.</p> <h3 id="5-reading-large-csvs-smartly-with-read_csv">5. Reading Large CSVs Smartly with <code class="language-plaintext highlighter-rouge">read_csv()</code> </h3> <p>Loading data is often the first step. For massive CSV files, <code class="language-plaintext highlighter-rouge">pd.read_csv()</code> has powerful parameters that can save you memory and time.</p> <ul> <li> <strong><code class="language-plaintext highlighter-rouge">dtype</code>:</strong> Specify column data types upfront to prevent Pandas from inferring them (which can be slow and memory-intensive) and to ensure correct types (e.g., <code class="language-plaintext highlighter-rouge">category</code>).</li> <li> <strong><code class="language-plaintext highlighter-rouge">usecols</code>:</strong> Load only the columns you actually need.</li> <li> <strong><code class="language-plaintext highlighter-rouge">nrows</code>:</strong> Load only a subset of rows (e.g., for quick exploration or debugging).</li> <li> <strong><code class="language-plaintext highlighter-rouge">chunksize</code>:</strong> If your file is too large to fit into memory, read it in chunks and process each chunk.</li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Imagine 'large_data.csv' has millions of rows and many columns
# For demonstration, let's create a dummy CSV
</span><span class="n">dummy_data</span> <span class="o">=</span> <span class="p">{</span><span class="sh">'</span><span class="s">id</span><span class="sh">'</span><span class="p">:</span> <span class="nf">range</span><span class="p">(</span><span class="mi">100000</span><span class="p">),</span> <span class="sh">'</span><span class="s">feature1</span><span class="sh">'</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">rand</span><span class="p">(</span><span class="mi">100000</span><span class="p">),</span>
              <span class="sh">'</span><span class="s">category_col</span><span class="sh">'</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">choice</span><span class="p">([</span><span class="sh">'</span><span class="s">A</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">B</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">C</span><span class="sh">'</span><span class="p">],</span> <span class="mi">100000</span><span class="p">),</span>
              <span class="sh">'</span><span class="s">text_col</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span><span class="sh">'</span><span class="s">some_long_string</span><span class="sh">'</span><span class="p">]</span> <span class="o">*</span> <span class="mi">100000</span><span class="p">}</span>
<span class="n">dummy_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">dummy_data</span><span class="p">)</span>
<span class="n">dummy_df</span><span class="p">.</span><span class="nf">to_csv</span><span class="p">(</span><span class="sh">'</span><span class="s">large_data.csv</span><span class="sh">'</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="c1"># Smart reading of 'large_data.csv'
# Only load 'id', 'feature1', 'category_col'
# Specify dtypes to optimize memory
</span><span class="n">df_optimized</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="sh">'</span><span class="s">large_data.csv</span><span class="sh">'</span><span class="p">,</span>
                           <span class="n">usecols</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">id</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">feature1</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">category_col</span><span class="sh">'</span><span class="p">],</span>
                           <span class="n">dtype</span><span class="o">=</span><span class="p">{</span><span class="sh">'</span><span class="s">id</span><span class="sh">'</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">int32</span><span class="p">,</span>
                                  <span class="sh">'</span><span class="s">feature1</span><span class="sh">'</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">,</span>
                                  <span class="sh">'</span><span class="s">category_col</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">category</span><span class="sh">'</span><span class="p">})</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Optimized DataFrame info from large_data.csv:</span><span class="sh">"</span><span class="p">)</span>
<span class="n">df_optimized</span><span class="p">.</span><span class="nf">info</span><span class="p">(</span><span class="n">memory_usage</span><span class="o">=</span><span class="sh">'</span><span class="s">deep</span><span class="sh">'</span><span class="p">)</span>

<span class="c1"># To clean up the dummy file
</span><span class="kn">import</span> <span class="n">os</span>
<span class="n">os</span><span class="p">.</span><span class="nf">remove</span><span class="p">(</span><span class="sh">'</span><span class="s">large_data.csv</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div> <p>These parameters are your best friends when dealing with datasets that push the boundaries of your system’s memory.</p> <h3 id="6-chain-your-methods-for-cleaner-code">6. Chain Your Methods for Cleaner Code</h3> <p>Chaining operations means calling multiple Pandas methods sequentially, one after another, on the same DataFrame or Series, without creating intermediate variables. This makes your code more readable and often more efficient, as Pandas can sometimes optimize the operations internally.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data</span> <span class="o">=</span> <span class="p">{</span><span class="sh">'</span><span class="s">city</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span><span class="sh">'</span><span class="s">NY</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">LA</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">NY</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">SF</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">LA</span><span class="sh">'</span><span class="p">],</span>
        <span class="sh">'</span><span class="s">temp_f</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span><span class="mi">70</span><span class="p">,</span> <span class="mi">85</span><span class="p">,</span> <span class="mi">72</span><span class="p">,</span> <span class="mi">60</span><span class="p">,</span> <span class="mi">88</span><span class="p">],</span>
        <span class="sh">'</span><span class="s">humidity</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span><span class="mi">60</span><span class="p">,</span> <span class="mi">75</span><span class="p">,</span> <span class="mi">62</span><span class="p">,</span> <span class="mi">55</span><span class="p">,</span> <span class="mi">70</span><span class="p">]}</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="c1"># Traditional, non-chained approach
# df_filtered = df[df['temp_f'] &gt; 70]
# df_converted = df_filtered.assign(temp_c=(df_filtered['temp_f'] - 32) * 5/9)
# final_df = df_converted.sort_values('temp_c', ascending=False)
</span>
<span class="c1"># Chained approach
</span><span class="n">final_df_chained</span> <span class="o">=</span> <span class="p">(</span><span class="n">df</span>
                    <span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">temp_f</span><span class="sh">'</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">70</span><span class="p">]</span> <span class="c1"># Filter rows
</span>                    <span class="p">.</span><span class="nf">assign</span><span class="p">(</span><span class="n">temp_c</span><span class="o">=</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">temp_f</span><span class="sh">'</span><span class="p">]</span> <span class="o">-</span> <span class="mi">32</span><span class="p">)</span> <span class="o">*</span> <span class="mi">5</span><span class="o">/</span><span class="mi">9</span><span class="p">)</span> <span class="c1"># Create new column
</span>                    <span class="p">.</span><span class="nf">sort_values</span><span class="p">(</span><span class="sh">'</span><span class="s">temp_c</span><span class="sh">'</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span> <span class="c1"># Sort
</span>                    <span class="p">.</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span> <span class="c1"># Reset index for clean output
</span>                   <span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Chained DataFrame:</span><span class="se">\n</span><span class="sh">"</span><span class="p">,</span> <span class="n">final_df_chained</span><span class="p">)</span>
</code></pre></div></div> <p>The parentheses around the chain (<code class="language-plaintext highlighter-rouge">(df...)</code>) are a good practice. They allow you to break the chain into multiple lines, enhancing readability without needing line continuation characters (<code class="language-plaintext highlighter-rouge">\</code>). This makes your data transformation steps feel like a clear, flowing pipeline.</p> <h3 id="7-understanding-inplacetrue-use-with-caution">7. Understanding <code class="language-plaintext highlighter-rouge">inplace=True</code>: Use with Caution</h3> <p>You’ve probably seen <code class="language-plaintext highlighter-rouge">df.drop('col', inplace=True)</code> or <code class="language-plaintext highlighter-rouge">df.fillna(0, inplace=True)</code>. The <code class="language-plaintext highlighter-rouge">inplace=True</code> argument modifies the DataFrame directly, rather than returning a new DataFrame.</p> <p><strong>The perceived benefit:</strong> Saves memory by not creating a copy.</p> <p><strong>The actual downsides (and why you should mostly avoid it):</strong></p> <ul> <li> <strong>Breaks method chaining:</strong> If a method returns <code class="language-plaintext highlighter-rouge">None</code> (as many <code class="language-plaintext highlighter-rouge">inplace=True</code> methods do), you can’t chain further operations.</li> <li> <strong>Less readable code:</strong> It’s harder to see the flow of transformations.</li> <li> <strong>Debugging:</strong> It makes debugging harder because intermediate states aren’t preserved.</li> <li> <strong><code class="language-plaintext highlighter-rouge">SettingWithCopyWarning</code>:</strong> Can sometimes contribute to this confusing warning when modifying slices.</li> </ul> <p><strong>The Solution:</strong> Re-assign the result of the operation. It’s clearer, enables chaining, and Pandas is often smart enough to optimize memory even when re-assigning.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">({</span><span class="sh">'</span><span class="s">A</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">nan</span><span class="p">,</span> <span class="mi">4</span><span class="p">]})</span>

<span class="c1"># The 'inplace=True' way (avoids chaining)
# df.fillna(0, inplace=True)
# df.drop(columns=['A'], inplace=True) # This would error if chained after fillna
</span>
<span class="c1"># The re-assignment way (enables chaining and clarity)
</span><span class="n">df_clean</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">).</span><span class="nf">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">A_old</span><span class="sh">'</span><span class="p">],</span> <span class="n">errors</span><span class="o">=</span><span class="sh">'</span><span class="s">ignore</span><span class="sh">'</span><span class="p">)</span> <span class="c1"># .drop() on a non-existent column would error otherwise
</span><span class="n">df_clean</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">).</span><span class="nf">assign</span><span class="p">(</span><span class="n">B</span><span class="o">=</span><span class="p">[</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">7</span><span class="p">,</span><span class="mi">8</span><span class="p">])</span> <span class="c1"># Create another column, for example
</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">DataFrame after re-assignment:</span><span class="se">\n</span><span class="sh">"</span><span class="p">,</span> <span class="n">df</span><span class="p">)</span> <span class="c1"># df is still original
</span><span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="se">\n</span><span class="s">Cleaned DataFrame after re-assignment:</span><span class="se">\n</span><span class="sh">"</span><span class="p">,</span> <span class="n">df_clean</span><span class="p">)</span>
</code></pre></div></div> <p>I’ve learned to almost completely avoid <code class="language-plaintext highlighter-rouge">inplace=True</code>. The minor memory saving is rarely worth the loss in readability and flexibility.</p> <h3 id="8-datetime-dynamo-working-with-time-series-data">8. Datetime Dynamo: Working with Time Series Data</h3> <p>Pandas excels at handling time-series data. If your dataset has dates or timestamps, converting them to Pandas <code class="language-plaintext highlighter-rouge">datetime</code> objects is crucial for powerful operations.</p> <ul> <li> <strong><code class="language-plaintext highlighter-rouge">pd.to_datetime()</code>:</strong> Convert strings or numbers to datetime objects.</li> <li> <strong><code class="language-plaintext highlighter-rouge">.dt</code> accessor:</strong> Access date/time components (year, month, day, hour, etc.).</li> <li> <strong><code class="language-plaintext highlighter-rouge">resample()</code>:</strong> Change the frequency of your time series data (e.g., from daily to monthly).</li> <li> <strong><code class="language-plaintext highlighter-rouge">shift()</code>:</strong> Move data points forward or backward in time, useful for calculating differences or lagged values.</li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data</span> <span class="o">=</span> <span class="p">{</span><span class="sh">'</span><span class="s">date</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span><span class="sh">'</span><span class="s">2023-01-01</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">2023-01-02</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">2023-01-03</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">2023-01-04</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">2023-02-01</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">2023-02-02</span><span class="sh">'</span><span class="p">],</span>
        <span class="sh">'</span><span class="s">value</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">13</span><span class="p">,</span> <span class="mi">16</span><span class="p">]}</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="c1"># Convert 'date' column to datetime objects
</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">date</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">to_datetime</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">date</span><span class="sh">'</span><span class="p">])</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">set_index</span><span class="p">(</span><span class="sh">'</span><span class="s">date</span><span class="sh">'</span><span class="p">)</span> <span class="c1"># Set 'date' as the index for time series operations
</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">DataFrame with datetime index:</span><span class="se">\n</span><span class="sh">"</span><span class="p">,</span> <span class="n">df</span><span class="p">)</span>

<span class="c1"># Access year and month
</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">year</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">index</span><span class="p">.</span><span class="n">year</span>
<span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">month</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">index</span><span class="p">.</span><span class="n">month</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="se">\n</span><span class="s">DataFrame with year and month columns:</span><span class="se">\n</span><span class="sh">"</span><span class="p">,</span> <span class="n">df</span><span class="p">)</span>

<span class="c1"># Resample to monthly mean
</span><span class="n">monthly_mean</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">value</span><span class="sh">'</span><span class="p">].</span><span class="nf">resample</span><span class="p">(</span><span class="sh">'</span><span class="s">M</span><span class="sh">'</span><span class="p">).</span><span class="nf">mean</span><span class="p">()</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="se">\n</span><span class="s">Monthly mean values:</span><span class="se">\n</span><span class="sh">"</span><span class="p">,</span> <span class="n">monthly_mean</span><span class="p">)</span>

<span class="c1"># Calculate daily change
</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">value_lagged</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">value</span><span class="sh">'</span><span class="p">].</span><span class="nf">shift</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">daily_change</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">value</span><span class="sh">'</span><span class="p">]</span> <span class="o">-</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">value_lagged</span><span class="sh">'</span><span class="p">]</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="se">\n</span><span class="s">DataFrame with lagged value and daily change:</span><span class="se">\n</span><span class="sh">"</span><span class="p">,</span> <span class="n">df</span><span class="p">)</span>
</code></pre></div></div> <p>Handling time correctly is essential for almost any dataset with a temporal component. The <code class="language-plaintext highlighter-rouge">.dt</code> accessor opens up a world of possibilities for feature engineering from timestamps.</p> <h3 id="9-monitor-and-optimize-memory-usage">9. Monitor and Optimize Memory Usage</h3> <p>Ever had your Python kernel crash with a memory error? It happens! Keeping an eye on memory usage, especially with large datasets, is a good habit.</p> <ul> <li> <strong><code class="language-plaintext highlighter-rouge">df.info(memory_usage='deep')</code>:</strong> Get a detailed breakdown of memory used by each column. <code class="language-plaintext highlighter-rouge">deep=True</code> ensures strings are accurately counted, not just their pointers.</li> <li> <strong>Downcasting:</strong> After loading data, if you know a column (e.g., <code class="language-plaintext highlighter-rouge">int64</code>) only contains small numbers, you can downcast it to a smaller integer type (<code class="language-plaintext highlighter-rouge">int32</code>, <code class="language-plaintext highlighter-rouge">int16</code>, <code class="language-plaintext highlighter-rouge">int8</code>). Similar for floats (<code class="language-plaintext highlighter-rouge">float32</code>).</li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Create a DataFrame with large integer and float types
</span><span class="n">large_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">({</span>
    <span class="sh">'</span><span class="s">big_int</span><span class="sh">'</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">100000</span><span class="p">,</span> <span class="mi">100000</span><span class="p">).</span><span class="nf">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">int64</span><span class="p">),</span>
    <span class="sh">'</span><span class="s">big_float</span><span class="sh">'</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">rand</span><span class="p">(</span><span class="mi">100000</span><span class="p">).</span><span class="nf">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">float64</span><span class="p">)</span>
<span class="p">})</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Original DataFrame memory usage:</span><span class="sh">"</span><span class="p">)</span>
<span class="n">large_df</span><span class="p">.</span><span class="nf">info</span><span class="p">(</span><span class="n">memory_usage</span><span class="o">=</span><span class="sh">'</span><span class="s">deep</span><span class="sh">'</span><span class="p">)</span>

<span class="c1"># Downcast to smaller dtypes
</span><span class="n">large_df</span><span class="p">[</span><span class="sh">'</span><span class="s">big_int</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">to_numeric</span><span class="p">(</span><span class="n">large_df</span><span class="p">[</span><span class="sh">'</span><span class="s">big_int</span><span class="sh">'</span><span class="p">],</span> <span class="n">downcast</span><span class="o">=</span><span class="sh">'</span><span class="s">integer</span><span class="sh">'</span><span class="p">)</span>
<span class="n">large_df</span><span class="p">[</span><span class="sh">'</span><span class="s">big_float</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">to_numeric</span><span class="p">(</span><span class="n">large_df</span><span class="p">[</span><span class="sh">'</span><span class="s">big_float</span><span class="sh">'</span><span class="p">],</span> <span class="n">downcast</span><span class="o">=</span><span class="sh">'</span><span class="s">float</span><span class="sh">'</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="se">\n</span><span class="s">DataFrame memory usage after downcasting:</span><span class="sh">"</span><span class="p">)</span>
<span class="n">large_df</span><span class="p">.</span><span class="nf">info</span><span class="p">(</span><span class="n">memory_usage</span><span class="o">=</span><span class="sh">'</span><span class="s">deep</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div> <p>Combine this with <code class="language-plaintext highlighter-rouge">category</code> conversion (Tip 3) and smart <code class="language-plaintext highlighter-rouge">read_csv()</code> (Tip 5) for a powerful memory optimization trifecta!</p> <h3 id="10-the-pipe-method-for-custom-function-chaining">10. The <code class="language-plaintext highlighter-rouge">.pipe()</code> Method for Custom Function Chaining</h3> <p>Sometimes your transformation logic is complex and involves custom functions that don’t neatly fit into a chained method call. That’s where <code class="language-plaintext highlighter-rouge">.pipe()</code> comes in handy. It allows you to insert custom functions into your method chain, treating them as if they were a Pandas method.</p> <p>Your custom function should take a DataFrame or Series as its first argument and return a DataFrame or Series.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">standardize_column</span><span class="p">(</span><span class="n">df_series</span><span class="p">,</span> <span class="n">col_name</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">Standardizes a specified column in a DataFrame.</span><span class="sh">"""</span>
    <span class="n">mean_val</span> <span class="o">=</span> <span class="n">df_series</span><span class="p">[</span><span class="n">col_name</span><span class="p">].</span><span class="nf">mean</span><span class="p">()</span>
    <span class="n">std_val</span> <span class="o">=</span> <span class="n">df_series</span><span class="p">[</span><span class="n">col_name</span><span class="p">].</span><span class="nf">std</span><span class="p">()</span>
    <span class="c1"># Handle division by zero for constant columns
</span>    <span class="k">if</span> <span class="n">std_val</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">df_series</span><span class="p">[</span><span class="sa">f</span><span class="sh">'</span><span class="si">{</span><span class="n">col_name</span><span class="si">}</span><span class="s">_standardized</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">df_series</span><span class="p">[</span><span class="sa">f</span><span class="sh">'</span><span class="si">{</span><span class="n">col_name</span><span class="si">}</span><span class="s">_standardized</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">df_series</span><span class="p">[</span><span class="n">col_name</span><span class="p">]</span> <span class="o">-</span> <span class="n">mean_val</span><span class="p">)</span> <span class="o">/</span> <span class="n">std_val</span>
    <span class="k">return</span> <span class="n">df_series</span>

<span class="n">data</span> <span class="o">=</span> <span class="p">{</span><span class="sh">'</span><span class="s">feature1</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">40</span><span class="p">,</span> <span class="mi">50</span><span class="p">],</span>
        <span class="sh">'</span><span class="s">feature2</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span><span class="mi">100</span><span class="p">,</span> <span class="mi">120</span><span class="p">,</span> <span class="mi">110</span><span class="p">,</span> <span class="mi">130</span><span class="p">,</span> <span class="mi">105</span><span class="p">]}</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Original DataFrame:</span><span class="se">\n</span><span class="sh">"</span><span class="p">,</span> <span class="n">df</span><span class="p">)</span>

<span class="c1"># Use .pipe() to chain a custom function
</span><span class="n">transformed_df</span> <span class="o">=</span> <span class="p">(</span><span class="n">df</span>
                  <span class="p">.</span><span class="nf">assign</span><span class="p">(</span><span class="n">feature1_plus_10</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="sh">'</span><span class="s">feature1</span><span class="sh">'</span><span class="p">]</span> <span class="o">+</span> <span class="mi">10</span><span class="p">)</span>
                  <span class="p">.</span><span class="nf">pipe</span><span class="p">(</span><span class="n">standardize_column</span><span class="p">,</span> <span class="n">col_name</span><span class="o">=</span><span class="sh">'</span><span class="s">feature1</span><span class="sh">'</span><span class="p">)</span> <span class="c1"># Pass df as first arg, col_name as second
</span>                  <span class="p">.</span><span class="nf">pipe</span><span class="p">(</span><span class="n">standardize_column</span><span class="p">,</span> <span class="n">col_name</span><span class="o">=</span><span class="sh">'</span><span class="s">feature2</span><span class="sh">'</span><span class="p">)</span>
                 <span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="se">\n</span><span class="s">Transformed DataFrame using .pipe():</span><span class="se">\n</span><span class="sh">"</span><span class="p">,</span> <span class="n">transformed_df</span><span class="p">)</span>
</code></pre></div></div> <p><code class="language-plaintext highlighter-rouge">.pipe()</code> promotes cleaner, more modular code when your transformations involve custom logic, keeping the benefits of chaining. It’s a slightly more advanced trick, but incredibly useful once you get the hang of it.</p> <hr> <h3 id="wrapping-up">Wrapping Up</h3> <p>These 10 tips represent a significant leap in how I approach data manipulation with Pandas. From understanding the core philosophy of vectorization to optimizing memory and structuring code for readability, each one has played a part in making my data science journey smoother and more efficient.</p> <p>Remember, practice is key. Try applying these tips to your own datasets, experiment with different scenarios, and don’t be afraid to break things! The best way to learn is by doing. As you continue your journey in data science, these Pandas techniques will become second nature, empowering you to tackle even the most challenging datasets with confidence and flair. Happy “Pandas-ing”!</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/cracking-the-ai-black-box-why-explainable-ai-xai-i/">Cracking the AI Black Box: Why Explainable AI (XAI) is Our Superpower</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/the-secret-life-of-states-how-markov-chains-predic/">The Secret Life of States: How Markov Chains Predict Our Next Move (Without Remembering the Past!)</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/blog/2026/gradient-descent-unpacking-the-engine-of-machine-l/">Gradient Descent: Unpacking the Engine of Machine Learning</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Adarsh Nair. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/blog/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/masonry.js?v=a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/zoom.js?v=85ddb88934d28b74e78031fd54cf8308"></script> <script src="/blog/assets/js/no_defer.js?v=2781658a0a2b13ed609542042a859126"></script> <script defer src="/blog/assets/js/common.js?v=c15de51d4bb57887caa2c21988d97279"></script> <script defer src="/blog/assets/js/copy_code.js?v=c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/blog/assets/js/jupyter_new_tab.js?v=d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/blog/assets/js/mathjax-setup.js?v=a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/blog/assets/js/progress-bar.js?v=2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/blog/assets/js/vanilla-back-to-top.min.js?v=f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/blog/assets/js/search/ninja-keys.min.js?v=a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/blog/assets/js/search-setup.js?v=6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/blog/assets/js/search-data.js"></script> <script src="/blog/assets/js/shortcut-key.js?v=ccc841c459bfc0e64c1c2b5acd10df02"></script> </body> </html>